"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[6453],{11470:(e,n,t)=>{t.d(n,{A:()=>j});var a=t(96540),r=t(18215),i=t(23104),o=t(56347),s=t(205),l=t(57485),c=t(31682),d=t(70679);function u(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p(e){const{values:n,children:t}=e;return(0,a.useMemo)(()=>{const e=n??function(e){return u(e).map(({props:{value:e,label:n,attributes:t,default:a}})=>({value:e,label:n,attributes:t,default:a}))}(t);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function h({value:e,tabValues:n}){return n.some(n=>n.value===e)}function m({queryString:e=!1,groupId:n}){const t=(0,o.W6)(),r=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,l.aZ)(r),(0,a.useCallback)(e=>{if(!r)return;const n=new URLSearchParams(t.location.search);n.set(r,e),t.replace({...t.location,search:n.toString()})},[r,t])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:r}=e,i=p(e),[o,l]=(0,a.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!h({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:i})),[c,u]=m({queryString:t,groupId:r}),[f,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,r]=(0,d.Dv)(n);return[t,(0,a.useCallback)(e=>{n&&r.set(e)},[n,r])]}({groupId:r}),b=(()=>{const e=c??f;return h({value:e,tabValues:i})?e:null})();(0,s.A)(()=>{b&&l(b)},[b]);return{selectedValue:o,selectValue:(0,a.useCallback)(e=>{if(!h({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),g(e)},[u,g,i]),tabValues:i}}var g=t(92303);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var w=t(74848);function y({className:e,block:n,selectedValue:t,selectValue:a,tabValues:o}){const s=[],{blockElementScrollPositionUntilNextRender:l}=(0,i.a_)(),c=e=>{const n=e.currentTarget,r=s.indexOf(n),i=o[r].value;i!==t&&(l(n),a(i))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=s.indexOf(e.currentTarget)+1;n=s[t]??s[0];break}case"ArrowLeft":{const t=s.indexOf(e.currentTarget)-1;n=s[t]??s[s.length-1];break}}n?.focus()};return(0,w.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},e),children:o.map(({value:e,label:n,attributes:a})=>(0,w.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{s.push(e)},onKeyDown:d,onClick:c,...a,className:(0,r.A)("tabs__item",b.tabItem,a?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function x({lazy:e,children:n,selectedValue:t}){const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=i.find(e=>e.props.value===t);return e?(0,a.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,w.jsx)("div",{className:"margin-top--md",children:i.map((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function A(e){const n=f(e);return(0,w.jsxs)("div",{className:(0,r.A)("tabs-container",b.tabList),children:[(0,w.jsx)(y,{...n,...e}),(0,w.jsx)(x,{...n,...e})]})}function j(e){const n=(0,g.A)();return(0,w.jsx)(A,{...e,children:u(e.children)},String(n))}},19365:(e,n,t)=>{t.d(n,{A:()=>o});t(96540);var a=t(18215);const r={tabItem:"tabItem_Ymn6"};var i=t(74848);function o({children:e,hidden:n,className:t}){return(0,i.jsx)("div",{role:"tabpanel",className:(0,a.A)(r.tabItem,t),hidden:n,children:e})}},48678:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>R,contentTitle:()=>_,default:()=>L,frontMatter:()=>v,metadata:()=>a,toc:()=>I});const a=JSON.parse('{"id":"resources/complementary-topics/rag","title":"Build RAG Apps","description":"Learn how to use the Clarifai SDKs","source":"@site/docs/resources/complementary-topics/rag.md","sourceDirName":"resources/complementary-topics","slug":"/resources/complementary-topics/rag","permalink":"/resources/complementary-topics/rag","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"description":"Learn how to use the Clarifai SDKs","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Import Data with CSV and TSV Files","permalink":"/resources/complementary-topics/csv-tsv"},"next":{"title":"Patching","permalink":"/resources/complementary-topics/patching"}}');var r=t(74848),i=t(28453),o=t(11470),s=t(19365),l=t(73748);const c="# Import the RAG module from Clarifai for conversational AI tasks\nfrom clarifai.rag import RAG\n\n# Set the user ID for authentication (For creating a new App)\nUSER_ID = 'USER_ID'\n\n# Alternatively, initialize RAG system using an existing app's URL\nAPP_URL = 'APP_URL'\n\n# Define the URL of the Mistral-7B language model\nLLM_URL = 'https://clarifai.com/mistralai/completion/models/mistral-7B-Instruct'\n\n# Define a template string for generating prompts during inference\nRAG_PROMPT_TEMPLATE = \"<s>[INST] Context information is below:\\n{data.hits}\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {data.text.raw}\\nAnswer:  [/INST]\"\n\n# Setup a RAG object with specified parameters such as user ID, model URL, minimum score threshold, and prompt template\n\n# Option 1: Setup a RAG object with specified parameters using the user_id to create a new app\nrag_object_user = RAG.setup(\n    user_id=USER_ID,\n    pat=PAT,\n    llm_url=LLM_URL,\n    min_score=0.5,\n    max_results=2,\n    prompt_template=RAG_PROMPT_TEMPLATE\n)\n\n# Option 2: Alternatively, setup a RAG object using an existing app's URL\nrag_object_app = RAG.setup(\n    app_url=APP_URL,\n    pat=PAT,\n    llm_url=LLM_URL,\n    min_score=0.5,\n    max_results=2,\n    prompt_template=RAG_PROMPT_TEMPLATE\n)\n# Choose which initialization method to use based on your setup:\n# For new app creation:\nprint(rag_object_user.prompt_workflow)\n\n# For existing app initialization:\nprint(rag_object_app.prompt_workflow)",d='import { RAG } from "clarifai-nodejs";\n\n// Import the RAG module from Clarifai for conversational AI tasks\n\n// Define the URL of the Mistral-7B language model\nconst llmUrl =\n  "https://clarifai.com/mistralai/completion/models/mistral-7B-Instruct";\n\n// Define a template string for generating prompts during inference\nconst ragPromptTemplate =\n  "<s>[INST] Context information is below:\\n{data.hits}\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {data.text.raw}\\nAnswer:  [/INST]";\n\n// Setup a RAG object with specified parameters such as user ID, model URL, minimum score threshold, and prompt template\n\n// Option 1: Initialize using userId and create a new app\nconst ragObject = await RAG.setup({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n  },\n  llmUrl,\n  minScore: 0.5,\n  maxResults: 2,\n  promptTemplate: ragPromptTemplate,\n});\n\n// Option 2: Alternatively, initialize using an existing app\'s URL\nconst ragObjectApp = await RAG.setup({\n  authConfig: {\n    appUrl: process.env.CLARIFAI_APP_URL,\n    pat: process.env.CLARIFAI_PAT,\n  },\n  llmUrl,\n  minScore: 0.5,\n  maxResults: 2,\n  promptTemplate: ragPromptTemplate,\n});\n\n  // Choose which initialization method to use based on your setup:\n  // For new app creation:\n  console.log(ragObject.promptWorkflow);\n\n  // For existing app initialization:\n  console.log(ragObjectApp.promptWorkflow);\n',u='FILE_PATH="RAG/data/Crawfords_Auto_Repair_Guide.txt"\nrag_object.upload(file_path=FILE_PATH,chunk_size= 1024) #parameters to split the document into chunks',p='import { RAG } from "clarifai-nodejs";\nimport path from "path";\n\n// Import the RAG module from Clarifai for conversational AI tasks\n\n// Define the URL of the Mistral-7B language model\nconst llmUrl =\n  "https://clarifai.com/mistralai/completion/models/mistral-7B-Instruct";\n\n// Define a template string for generating prompts during inference\nconst ragPromptTemplate =\n  "<s>[INST] Context information is below:\\n{data.hits}\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {data.text.raw}\\nAnswer:  [/INST]";\n\n// Setup a RAG object with specified parameters such as user ID, model URL,\n// minimum score threshold, and prompt template\nconst ragObject = await RAG.setup({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n  },\n  llmUrl,\n  minScore: 0.5,\n  maxResults: 2,\n  promptTemplate: ragPromptTemplate,\n});\n\nconst filePath = path.resolve(__dirname, "../../assets/ragInput.txt");\nawait ragObject.upload({\n  filePath,\n  chunkSize: 1024,\n});\n',h='# Initiating a conversation with the RAG (Retrieval Augmented Generation) model object (`rag_object_gpt`).\n# Sending a message containing the query "How to change brake fluid" to the model and awaiting a response.\nresult = rag_object.chat(messages=[{"role": "human", "content": "How to change brake fluid"}])\n\n# Extracting the content of the response from the result.\nanswer = result[0]["content"]\n\n# Printing out the response\nprint(answer)',m='import { RAG } from "clarifai-nodejs";\nimport path from "path";\n\n// Import the RAG module from Clarifai for conversational AI tasks\n\n// Define the URL of the Mistral-7B language model\nconst llmUrl =\n  "https://clarifai.com/mistralai/completion/models/mistral-7B-Instruct";\n\n// Define a template string for generating prompts during inference\nconst ragPromptTemplate =\n  "<s>[INST] Context information is below:\\n{data.hits}\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {data.text.raw}\\nAnswer:  [/INST]";\n\n// Setup a RAG object with specified parameters such as user ID, model URL,\n// minimum score threshold, and prompt template\nconst ragObject = await RAG.setup({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n  },\n  llmUrl,\n  minScore: 0.5,\n  maxResults: 2,\n  promptTemplate: ragPromptTemplate,\n});\n\nconst filePath = path.resolve(__dirname, "../../assets/ragInput.txt");\nawait ragObject.upload({\n  filePath,\n  chunkSize: 1024,\n});\n\n// Initiating a conversation with the RAG (Retrieval Augmented Generation) model object (`ragObject`).\n// Sending a message containing the query "How to change brake fluid" to the model and awaiting a response.\nconst result = await ragObject.chat({\n  messages: [{ role: "human", content: "How to change brake fluid" }],\n});\n\n// Extracting the content of the response from the result.\nconst answer = result[1].content;\n\n// Printing out the response\nconsole.log(answer);\n\nconst result2 = await ragObject.chat({\n  messages: [\n    { role: "human", content: "procedure after following the above steps" },\n  ],\n});\n\nconst answer2 = result2[1].content;\n\n// Printing out the response\nconsole.log(answer2);\n',f='result=rag_object.chat(messages=[{"role":"human", "content":"procedure after following the above steps"}])\n\nanswer=result[0]["content"]\n\nprint(answer)',g="#initialize  RAG using workflow URL\nWORKFLOW_URL = 'workflow_URL'\nrag_object_from_url = RAG(workflow_url = WORKFLOW_URL)",b="#initialize  RAG using workflow ID\nUSER_ID = 'user_id'\nLLM_URL = 'https://clarifai.com/openai/chat-completion/models/GPT-4'\nRAG_PROMPT_TEMPLATE = \"Context information is below:\\n{data.hits}\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {data.text.raw}\\nAnswer: \"\nrag_object_gpt = RAG.setup(user_id=USER_ID,llm_url=LLM_URL, min_score=0.5, prompt_template=RAG_PROMPT_TEMPLATE,workflow_id=\"workflow_id\")",w='2024-03-20 10:34:02 INFO     clarifai.client.input:                                                    input.py:674\n\n                             Inputs Uploaded                                                                       \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             details: "All inputs successfully added"                                              \n\n                             req_id: "848c5233f9d67f1904da10c33a214ff9"                                            \n\n                                                                                                                   \n\nINFO:clarifai.client.input:\n\nInputs Uploaded\n\ncode: SUCCESS\n\ndescription: "Ok"\n\ndetails: "All inputs successfully added"\n\nreq_id: "848c5233f9d67f1904da10c33a214ff9"',y="To change the brake fluid, you will need to follow these steps: \n\n \n\n1. Locate the brake fluid reservoir in your vehicle. It is usually a clear plastic container with MAX and MIN markings on it. \n\n \n\n2. Use a turkey baster or a brake fluid pump to remove the old brake fluid from the reservoir. Be careful not to spill any brake fluid on the car's paint as it can damage the finish. \n\n \n\n3. Once the old fluid is removed, clean the reservoir with a lint-free cloth to ensure there is no contamination. \n\n \n\n4. Refill the reservoir with new brake fluid that is recommended for your specific vehicle. Make sure to use the type of brake fluid specified in your owner's manual. \n\n \n\n5. Slowly pour the new brake fluid into the reservoir up to the MAX marking. Avoid overfilling. \n\n \n\n6. After filling the reservoir, you may need to bleed the brake system to remove any air bubbles. This process may vary depending on your vehicle, so it's best to consult your owner's manual or a professional mechanic for guidance. \n\n \n\n7. Once the brake fluid is changed and the system is bled, check for any leaks or issues before driving the vehicle. \n\n \n\nRemember, if you are not comfortable or experienced with changing brake fluid, it is recommended to have this task done by a professional mechanic. Brake fluid is a critical component of your vehicle's braking system, and proper maintenance is essential for your safety on the road. ",x=" After following the steps to drain, flush, and pressure test the cooling system as described in the text, the next procedure would be to check for any leaks in the cooling system. This can be done by inspecting the entire cooling system, including the radiator, hoses, water pump, and heater core, for any signs of leaks. If there is less pressure on the gauge after the pressure test, there is probably a leak. Additionally, the engine should be started and the temperature gauge should be monitored to ensure that the cooling system is functioning properly. If the engine overheats or the temperature gauge reads high, further diagnosis and repair may be necessary.",A="2024-05-08 12:21:25 INFO     clarifai.rag.rag:                                                            rag.py:43\n                             workflow_url:https://clarifai.com/8tzpjy1a841y/unst-clf/workflows/rag                 \nINFO:clarifai.rag.rag:workflow_url:https://clarifai.com/8tzpjy1a841y/unst-clf/workflows/rag",j='2024-05-08 12:28:09 INFO     clarifai.client.app:                                                        app.py:431\n                             Workflow created                                                                      \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             req_id: "73cd1b5a80ba9e7280542b6b176213fe"                                            \n                                                                                                                   \nINFO:clarifai.client.app:\nWorkflow created\ncode: SUCCESS\ndescription: "Ok"\nreq_id: "73cd1b5a80ba9e7280542b6b176213fe"\n\n Input\n\u255a\u2550\u2550                                Node: rag-prompter                               \n    \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n    \u2503 id                       \u2503 model_type_id \u2503 app_id             \u2503 user_id      \u2503\n    \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n    \u2502 prompter-rag3-def6cc6378 \u2502 rag-prompter  \u2502 rag_app_def6cc6378 \u2502 8tzpjy1a841y \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u255a\u2550\u2550                       Node: llm                      \n        \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n        \u2503 id    \u2503 model_type_id \u2503 app_id          \u2503 user_id \u2503\n        \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n        \u2502 GPT-4 \u2502 text-to-text  \u2502 chat-completion \u2502 openai  \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518',v={description:"Learn how to use the Clarifai SDKs",sidebar_position:2},_="Build RAG Apps",R={},I=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Initializing RAG",id:"initializing-rag",level:2},{value:"Dataset Upload",id:"dataset-upload",level:2},{value:"Chat",id:"chat",level:2}];function k(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"build-rag-apps",children:"Build RAG Apps"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Use the Clarifai SDKs to build RAG Applications"})}),"\n",(0,r.jsx)("hr",{}),"\n",(0,r.jsx)(n.p,{children:"In the field of text generation, Retrieval-Augmented Generation (RAG) enhances the capabilities of Large Language Models (LLMs) by combining information retrieval with natural language generation."}),"\n",(0,r.jsx)(n.p,{children:"This approach addresses key limitations of LLMs by retrieving relevant data from external knowledge bases in real time, enriching responses with increased precision and contextual relevance."}),"\n",(0,r.jsx)(n.p,{children:"Clarifai SDKs streamline the creation of RAG-based applications by minimizing the complexity of integrating retrieval and generation steps. This makes it easier for developers to build powerful, context-aware AI solutions with improved accuracy and reliability."}),"\n",(0,r.jsxs)(n.p,{children:["Click ",(0,r.jsx)(n.a,{href:"https://www.clarifai.com/blog/what-is-rag-retrieval-augmented-generation",children:"here"})," to learn more about RAG."]}),"\n","\n","\n","\n","\n","\n","\n",(0,r.jsx)(n.admonition,{type:"info",children:(0,r.jsxs)(n.p,{children:["Before using the ",(0,r.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/python-sdk",children:"Python SDK"}),", ",(0,r.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/nodejs-sdk",children:"Node.js SDK"}),", or any of our ",(0,r.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/grpc-clients",children:"gRPC clients"}),", ensure they are properly installed on your machine. Refer to their respective installation guides for instructions on how to install and initialize them."]})}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["You need a PAT (Personal Access Token) key to authenticate your connection to the Clarifai platform. You can generate the PAT key in your personal settings page by navigating to the ",(0,r.jsx)(n.a,{href:"https://clarifai.com/settings/security",children:"Security section"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Clone the Clarifai Examples repository to get the data files required for the building RAG."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"!git clone https://github.com/Clarifai/examples.git\n%cd /content/examples/\n"})}),"\n",(0,r.jsx)(n.admonition,{type:"info",children:(0,r.jsx)(n.p,{children:"To run on a local system use: cd examples/"})}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["Before you proceed install ",(0,r.jsx)(n.code,{children:"llama_index"})," using ",(0,r.jsx)(n.code,{children:"pip install llama-index-core==0.10.24"})]})}),"\n",(0,r.jsx)(n.h2,{id:"initializing-rag",children:"Initializing RAG"}),"\n",(0,r.jsx)(n.p,{children:"The first step in building a RAG-based application is initializing the RAG object. You can do this in three ways:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Using User ID"})," \u2013 Automatically creates a new app."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Using App URL"})," \u2013 Initializes RAG with an existing app and its data."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Using Workflow URL or ID"})," \u2013 Uses a specific workflow that includes the RAG Prompter and LLM model for seamless integration."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.admonition,{type:"tip",children:(0,r.jsxs)(n.p,{children:["You can set a specific version of LLM like this: ",(0,r.jsx)(n.code,{children:"https://clarifai.com/mistralai/completion/models/mistral-7B-Instruct/model_version/version_id"}),"."]})}),"\n",(0,r.jsxs)(o.A,{groupId:"code",children:[(0,r.jsxs)(s.A,{value:"python",label:"Python SDK",children:[(0,r.jsx)(l.A,{className:"language-python",children:c}),(0,r.jsxs)(t,{children:[(0,r.jsx)("summary",{children:"Image Output"}),(0,r.jsx)("img",{src:"/img/python-sdk/rag_init.png"})]})]}),(0,r.jsx)(s.A,{value:"typescript",label:"Node.js SDK",children:(0,r.jsx)(l.A,{className:"language-typescript",children:d})})]}),"\n",(0,r.jsxs)(n.p,{children:["We're using Mistral-7B-Instruct as the LLM for this RAG setup, but you can choose from various LLMs available in the Clarifai Community models ",(0,r.jsx)(n.a,{href:"https://clarifai.com/explore/models?filterData=%5B%7B%22field%22%3A%22use_cases%22%2C%22value%22%3A%5B%22llm%22%5D%7D%5D&page=1&perPage=24",children:"platform"}),". The Clarifai SDKs let you configure parameters like ",(0,r.jsx)(n.code,{children:"min_score"}),", ",(0,r.jsx)(n.code,{children:"max_results"}),", and ",(0,r.jsx)(n.code,{children:"prompt_template"})," to fine-tune data retrieval."]}),"\n",(0,r.jsx)(n.p,{children:"You can also initialize RAG using a workflow created in the Clarifai Portal that includes a RAG Prompter. There are two ways to set this up \u2014 one is by providing the workflow URL as a parameter."}),"\n",(0,r.jsx)(n.admonition,{type:"info",children:(0,r.jsxs)(n.p,{children:["You should only use ",(0,r.jsx)(n.code,{children:"RAG(workflow_url)"})," or ",(0,r.jsx)(n.code,{children:"RAG(workflow)"})," when a rag workflow already exists in your app."]})}),"\n",(0,r.jsx)(o.A,{groupId:"code",children:(0,r.jsx)(s.A,{value:"python",label:"Python SDK",children:(0,r.jsx)(l.A,{className:"language-python",children:g})})}),"\n",(0,r.jsxs)(t,{children:[(0,r.jsx)("summary",{children:"Output"}),(0,r.jsx)(l.A,{className:"language-python",children:A})]}),"\n",(0,r.jsxs)(n.p,{children:["The next option is to pass ",(0,r.jsx)(n.code,{children:"workflow_id"})," parameter in ",(0,r.jsx)(n.code,{children:"RAG.setup()"}),". This will create a new workflow in your app with the defined parameters."]}),"\n",(0,r.jsx)(o.A,{groupId:"code",children:(0,r.jsx)(s.A,{value:"python",label:"Python SDK",children:(0,r.jsx)(l.A,{className:"language-python",children:b})})}),"\n",(0,r.jsxs)(t,{children:[(0,r.jsx)("summary",{children:"Output"}),(0,r.jsx)(l.A,{className:"language-python",children:j})]}),"\n",(0,r.jsx)(n.h2,{id:"dataset-upload",children:"Dataset Upload"}),"\n",(0,r.jsx)(n.p,{children:"Next, upload your dataset\u2014here, we're using a Vehicle Repair Manual as the RAG source. You can use the previously created RAG object to handle the upload. One key advantage of the Clarifai SDKs is that embeddings are automatically generated and stored in the vector database during upload, making the data instantly ready for retrieval."}),"\n",(0,r.jsx)(n.admonition,{type:"info",children:(0,r.jsx)(n.p,{children:"Supported formats for upload include: DOC, PDF, plain text files, folders containing PDFs or DOCs, and URLs pointing to PDF, DOC, or text files."})}),"\n",(0,r.jsxs)(o.A,{groupId:"code",children:[(0,r.jsxs)(s.A,{value:"python",label:"Python SDK",children:[(0,r.jsx)(l.A,{className:"language-python",children:u}),(0,r.jsxs)(t,{children:[(0,r.jsx)("summary",{children:"Output"}),(0,r.jsx)(l.A,{className:"language-python",children:w})]})]}),(0,r.jsx)(s.A,{value:"typescript",label:"Node.js SDK",children:(0,r.jsx)(l.A,{className:"language-typescript",children:p})})]}),"\n",(0,r.jsx)(n.h2,{id:"chat",children:"Chat"}),"\n",(0,r.jsx)(n.p,{children:"In the final step, we are going to perform information retrieval using RAG based on the data we provided."}),"\n",(0,r.jsxs)(o.A,{groupId:"code",children:[(0,r.jsxs)(s.A,{value:"python",label:"Python SDK",children:[(0,r.jsx)(l.A,{className:"language-python",children:h}),(0,r.jsxs)(t,{children:[(0,r.jsx)("summary",{children:"Output"}),(0,r.jsx)(l.A,{className:"language-python",children:y})]})]}),(0,r.jsx)(s.A,{value:"typescript",label:"Node.js SDK",children:(0,r.jsx)(l.A,{className:"language-typescript",children:m})})]}),"\n",(0,r.jsx)(n.p,{children:"Now let's ask questions that are related to the answer we received before so that we can be sure the RAG has understood the context properly."}),"\n",(0,r.jsx)(o.A,{groupId:"code",children:(0,r.jsx)(s.A,{value:"python",label:"Python SDK",children:(0,r.jsx)(l.A,{className:"language-python",children:f})})}),"\n",(0,r.jsxs)(t,{children:[(0,r.jsx)("summary",{children:"Output"}),(0,r.jsx)(l.A,{className:"language-python",children:x})]})]})}function L(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(k,{...e})}):k(e)}}}]);