"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[7685],{15680:(e,t,r)=>{r.d(t,{xA:()=>l,yg:()=>m});var o=r(96540);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function n(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,o)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?n(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):n(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function g(e,t){if(null==e)return{};var r,o,a=function(e,t){if(null==e)return{};var r,o,a={},n=Object.keys(e);for(o=0;o<n.length;o++)r=n[o],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(o=0;o<n.length;o++)r=n[o],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var s=o.createContext({}),p=function(e){var t=o.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},l=function(e){var t=p(e.components);return o.createElement(s.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},d=o.forwardRef((function(e,t){var r=e.components,a=e.mdxType,n=e.originalType,s=e.parentName,l=g(e,["components","mdxType","originalType","parentName"]),c=p(r),d=a,m=c["".concat(s,".").concat(d)]||c[d]||u[d]||n;return r?o.createElement(m,i(i({ref:t},l),{},{components:r})):o.createElement(m,i({ref:t},l))}));function m(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var n=r.length,i=new Array(n);i[0]=d;var g={};for(var s in t)hasOwnProperty.call(t,s)&&(g[s]=t[s]);g.originalType=e,g[c]="string"==typeof e?e:a,i[1]=g;for(var p=2;p<n;p++)i[p]=r[p];return o.createElement.apply(null,i)}return o.createElement.apply(null,r)}d.displayName="MDXCreateElement"},95795:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>u,frontMatter:()=>n,metadata:()=>g,toc:()=>p});var o=r(58168),a=(r(96540),r(15680));const n={description:"Learn about our aggregate operators",sidebar_position:5},i="Aggregate",g={unversionedId:"portal-guide/agent-system-operators/aggregate",id:"portal-guide/agent-system-operators/aggregate",title:"Aggregate",description:"Learn about our aggregate operators",source:"@site/docs/portal-guide/agent-system-operators/aggregate.md",sourceDirName:"portal-guide/agent-system-operators",slug:"/portal-guide/agent-system-operators/aggregate",permalink:"/portal-guide/agent-system-operators/aggregate",draft:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/portal-guide/agent-system-operators/aggregate.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{description:"Learn about our aggregate operators",sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"Push",permalink:"/portal-guide/agent-system-operators/push"},next:{title:"ML Predict",permalink:"/portal-guide/agent-system-operators/ml-predict"}},s={},p=[{value:"Text Aggregation Operator",id:"text-aggregation-operator",level:2},{value:"Object Counter",id:"object-counter",level:2},{value:"Track Representation Operator",id:"track-representation-operator",level:2},{value:"Tiling Region Aggregator Operator",id:"tiling-region-aggregator-operator",level:2}],l={toc:p},c="wrapper";function u(e){let{components:t,...r}=e;return(0,a.yg)(c,(0,o.A)({},l,r,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"aggregate"},"Aggregate"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Learn about our aggregate operators")),(0,a.yg)("hr",null),(0,a.yg)("p",null,"Aggregation operators consolidate multiple model outputs into a single output. Aggregation is important for a wide variety of image, video, and text use cases, and can help you count objects, connect individually detected words into sentences, or connect objects across multiple frames of video."),(0,a.yg)("h2",{id:"text-aggregation-operator"},"Text Aggregation Operator"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Output"),": Text"),(0,a.yg)("p",null,"This is an operator that combines text detections into a text body for the whole image. Detections are sorted from left to right first and then from top to bottom, using the top-left corner of the bounding box as a reference."),(0,a.yg)("h2",{id:"object-counter"},"Object Counter"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Output"),": Metadata"),(0,a.yg)("p",null,"It allows you to count the number of regions that match this model's active concepts frame by frame."),(0,a.yg)("h2",{id:"track-representation-operator"},"Track Representation Operator"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Output"),": Tracks"),(0,a.yg)("p",null,"The operator takes the embedding of each track frame and aggregates them to form a track embedding."),(0,a.yg)("h2",{id:"tiling-region-aggregator-operator"},"Tiling Region Aggregator Operator"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Output"),": Regions"),(0,a.yg)("p",null,"This operator is to be used as a follow-up to the image tiling operator and visual detector. It will transform the detections on each of the tiles back to the original image, and perform non-maximum suppression. Only the top-class prediction for each box is considered."))}u.isMDXComponent=!0}}]);