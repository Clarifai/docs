"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[2988],{37366:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>f,contentTitle:()=>m,default:()=>v,frontMatter:()=>h,metadata:()=>o,toc:()=>b});const o=JSON.parse('{"id":"sdk/Inference-from-AI-Models/Audio-as-Input","title":"Audio as Input","description":"Learn how to perform inference with audio as input using Clarifai SDKs","source":"@site/docs/sdk/Inference-from-AI-Models/Audio-as-Input.md","sourceDirName":"sdk/Inference-from-AI-Models","slug":"/sdk/Inference-from-AI-Models/Audio-as-Input","permalink":"/sdk/Inference-from-AI-Models/Audio-as-Input","draft":false,"unlisted":false,"editUrl":"https://github.com/Clarifai/docs/blob/main/docs/sdk/Inference-from-AI-Models/Audio-as-Input.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Text as Input","permalink":"/sdk/Inference-from-AI-Models/Text-as-Input"},"next":{"title":"MultiModal as Input","permalink":"/sdk/Inference-from-AI-Models/Multimodal-as-Input"}}');var a=t(74848),r=t(28453),i=t(65537),s=t(79329),l=t(58069);const u='from clarifai.client.model import Model\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\n# Specify the correct user_id/app_id pairings\n# Since you\'re making inferences outside your app\'s scope\n#USER_ID = "facebook"\n#APP_ID = "asr"\n\n# You can set the model using model URL or model ID.\n# Change these to whatever model you want to use\n# eg : MODEL_ID = \'asr-wav2vec2-base-960h-english\'\n# You can also set a particular model version by specifying the  version ID\n# eg: MODEL_VERSION_ID = \'model_version\'\n# Model class objects can be inititalised by providing its URL or also by defining respective user_id, app_id and model_id\n\n# eg : model = Model(user_id="clarifai", app_id="main", model_id=MODEL_ID)\n\naudio_url = "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav"\n\n# The predict API gives the flexibility to generate predictions for data provided through URL, Filepath and bytes format.\n\n# Example for prediction through Bytes:\n# model_prediction = model.predict_by_bytes(audio_bytes, input_type="audio")\n\n# Example for prediction through Filepath:\n# model_prediction = Model(model_url).predict_by_filepath(audio_filepath, input_type="audio")\n\nmodel_url = "https://clarifai.com/facebook/asr/models/asr-wav2vec2-large-robust-ft-swbd-300h-english"\n\nmodel_prediction = Model(url=model_url, pat="YOUR_PAT").predict_by_url(\n    audio_url, "audio"\n)\n\n# Print the output\nprint(model_prediction.outputs[0].data.text.raw)\n\n',c='import { Model } from "clarifai-nodejs";\n\n/**\n    Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    Specify the correct userId/appId pairings\n    Since you\'re making inferences outside your app\'s scope\n    USER_ID = "facebook"\n    APP_ID = "asr"\n\n    You can set the model using model URL or model ID.\n    Change these to whatever model you want to use\n    eg : MODEL_ID = \'asr-wav2vec2-base-960h-english\'\n    You can also set a particular model version by specifying the  version ID\n    eg: MODEL_VERSION_ID = "model_version"\n    Model class objects can be initialised by providing its URL or also by defining respective userId, appId and modelId\n\n    eg : \n    const model = new Model({\n        authConfig: {\n            userId: "clarifai",\n            appId: "main",\n            pat: process.env.CLARIFAI_PAT,\n        },\n        modelId: MODEL_ID,\n    });\n\n*/\n\nconst audioUrl =\n  "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav";\n\n/*\n        The predict API gives flexibility to generate predictions for data provided through URL, Filepath and bytes format.\n\n        Example for prediction through Bytes:\n        const modelPrediction = await model.predictByBytes({\n                                    inputBytes: Bytes,\n                                    inputType: "audio"\n                                });\n\n        Example for prediction through Filepath:\n        const modelPrediction = await model.predictByFilepath({\n                                    filepath,\n                                    inputType: "audio",\n                                });\n\n    */\n\nconst modelUrl =\n  "https://clarifai.com/facebook/asr/models/asr-wav2vec2-large-robust-ft-swbd-300h-english";\n\n\nconst model = new Model({\n  url: modelUrl,\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n  },\n});\nconst modelPrediction = await model.predictByUrl({\n  url: audioUrl,\n  inputType: "audio",\n});\n\n// Print the output\nconsole.log(modelPrediction?.[0]?.data?.text?.raw);\n',d="clarifai model predict --model_url https://clarifai.com/facebook/asr/models/asr-wav2vec2-large-robust-ft-swbd-300h-english --url https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav --input_type audio",p="GOOD MORNING I THINK THIS IS GOING TO BE A GREAT PRESENTATION",h={sidebar_position:3},m="Audio as Input",f={},b=[{value:"Audio to Text",id:"audio-to-text",level:2}];function g(e){const n={a:"a",admonition:"admonition",h1:"h1",h2:"h2",header:"header",p:"p",strong:"strong",...(0,r.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"audio-as-input",children:"Audio as Input"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Learn how to perform inference with audio as input using Clarifai SDKs"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsx)(n.p,{children:"The Clarifai SDKs for Audio Processing provides a comprehensive set of tools and functionalities, enabling you to process audio inputs with unparalleled ease and efficiency. Whether you're working on applications related to voice recognition, sound classification, or speech-to-text conversion, our SDK streamlines the development process, allowing you to focus on building cutting-edge functionalities."}),"\n",(0,a.jsx)(n.admonition,{title:"Clarifai CLI",type:"tip",children:(0,a.jsxs)(n.p,{children:["Learn how to use the Clarifai CLI (Command Line Interface) tool ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/sdk/cli",children:"here"}),"."]})}),"\n",(0,a.jsx)(n.h2,{id:"audio-to-text",children:"Audio to Text"}),"\n",(0,a.jsxs)(n.p,{children:["Harness the power of the Predict API to seamlessly transform audio files into text-based formats using our advanced Automatic Speech Recognition (ASR) ",(0,a.jsx)(n.a,{href:"https://clarifai.com/explore/models?page=1&perPage=24&filterData=%5B%7B%22field%22%3A%22model_type_id%22%2C%22value%22%3A%5B%22audio-to-text%22%5D%7D%5D",children:"model"}),". With this functionality, you can effortlessly transcribe spoken words from audio, opening up possibilities for diverse applications such as transcription services, voice command processing, and more."]}),"\n",(0,a.jsxs)(i.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:u}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:p})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:c})}),(0,a.jsx)(s.A,{value:"bash",label:"Bash",children:(0,a.jsx)(l.A,{className:"language-bash",children:d})})]})]})}function v(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(g,{...e})}):g(e)}},65537:(e,n,t)=>{t.d(n,{A:()=>w});var o=t(96540),a=t(18215),r=t(65627),i=t(56347),s=t(50372),l=t(30604),u=t(11861),c=t(78749);function d(e){return o.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(e){const{values:n,children:t}=e;return(0,o.useMemo)((()=>{const e=n??function(e){return d(e).map((e=>{let{props:{value:n,label:t,attributes:o,default:a}}=e;return{value:n,label:t,attributes:o,default:a}}))}(t);return function(e){const n=(0,u.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function h(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function m(e){let{queryString:n=!1,groupId:t}=e;const a=(0,i.W6)(),r=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,l.aZ)(r),(0,o.useCallback)((e=>{if(!r)return;const n=new URLSearchParams(a.location.search);n.set(r,e),a.replace({...a.location,search:n.toString()})}),[r,a])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:a}=e,r=p(e),[i,l]=(0,o.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!h({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const o=t.find((e=>e.default))??t[0];if(!o)throw new Error("Unexpected error: 0 tabValues");return o.value}({defaultValue:n,tabValues:r}))),[u,d]=m({queryString:t,groupId:a}),[f,b]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[a,r]=(0,c.Dv)(t);return[a,(0,o.useCallback)((e=>{t&&r.set(e)}),[t,r])]}({groupId:a}),g=(()=>{const e=u??f;return h({value:e,tabValues:r})?e:null})();(0,s.A)((()=>{g&&l(g)}),[g]);return{selectedValue:i,selectValue:(0,o.useCallback)((e=>{if(!h({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);l(e),d(e),b(e)}),[d,b,r]),tabValues:r}}var b=t(9136);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var v=t(74848);function I(e){let{className:n,block:t,selectedValue:o,selectValue:i,tabValues:s}=e;const l=[],{blockElementScrollPositionUntilNextRender:u}=(0,r.a_)(),c=e=>{const n=e.currentTarget,t=l.indexOf(n),a=s[t].value;a!==o&&(u(n),i(a))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return(0,v.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":t},n),children:s.map((e=>{let{value:n,label:t,attributes:r}=e;return(0,v.jsx)("li",{role:"tab",tabIndex:o===n?0:-1,"aria-selected":o===n,ref:e=>{l.push(e)},onKeyDown:d,onClick:c,...r,className:(0,a.A)("tabs__item",g.tabItem,r?.className,{"tabs__item--active":o===n}),children:t??n},n)}))})}function y(e){let{lazy:n,children:t,selectedValue:r}=e;const i=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=i.find((e=>e.props.value===r));return e?(0,o.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,v.jsx)("div",{className:"margin-top--md",children:i.map(((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==r})))})}function A(e){const n=f(e);return(0,v.jsxs)("div",{className:(0,a.A)("tabs-container",g.tabList),children:[(0,v.jsx)(I,{...n,...e}),(0,v.jsx)(y,{...n,...e})]})}function w(e){const n=(0,b.A)();return(0,v.jsx)(A,{...e,children:d(e.children)},String(n))}},79329:(e,n,t)=>{t.d(n,{A:()=>i});t(96540);var o=t(18215);const a={tabItem:"tabItem_Ymn6"};var r=t(74848);function i(e){let{children:n,hidden:t,className:i}=e;return(0,r.jsx)("div",{role:"tabpanel",className:(0,o.A)(a.tabItem,i),hidden:t,children:n})}}}]);