"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[9943],{11470:(e,n,t)=>{t.d(n,{A:()=>w});var o=t(96540),i=t(18215),l=t(17559),a=t(23104),r=t(56347),s=t(205),d=t(57485),c=t(31682),p=t(70679);function u(e){return o.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:n,children:t}=e;return(0,o.useMemo)(()=>{const e=n??function(e){return u(e).map(({props:{value:e,label:n,attributes:t,default:o}})=>({value:e,label:n,attributes:t,default:o}))}(t);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function m({value:e,tabValues:n}){return n.some(n=>n.value===e)}function y({queryString:e=!1,groupId:n}){const t=(0,r.W6)(),i=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,d.aZ)(i),(0,o.useCallback)(e=>{if(!i)return;const n=new URLSearchParams(t.location.search);n.set(i,e),t.replace({...t.location,search:n.toString()})},[i,t])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:i}=e,l=h(e),[a,r]=(0,o.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:l})),[d,c]=y({queryString:t,groupId:i}),[u,f]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,i]=(0,p.Dv)(n);return[t,(0,o.useCallback)(e=>{n&&i.set(e)},[n,i])]}({groupId:i}),g=(()=>{const e=d??u;return m({value:e,tabValues:l})?e:null})();(0,s.A)(()=>{g&&r(g)},[g]);return{selectedValue:a,selectValue:(0,o.useCallback)(e=>{if(!m({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);r(e),c(e),f(e)},[c,f,l]),tabValues:l}}var g=t(92303);const x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var j=t(74848);function b({className:e,block:n,selectedValue:t,selectValue:o,tabValues:l}){const r=[],{blockElementScrollPositionUntilNextRender:s}=(0,a.a_)(),d=e=>{const n=e.currentTarget,i=r.indexOf(n),a=l[i].value;a!==t&&(s(n),o(a))},c=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const t=r.indexOf(e.currentTarget)+1;n=r[t]??r[0];break}case"ArrowLeft":{const t=r.indexOf(e.currentTarget)-1;n=r[t]??r[r.length-1];break}}n?.focus()};return(0,j.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":n},e),children:l.map(({value:e,label:n,attributes:o})=>(0,j.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{r.push(e)},onKeyDown:c,onClick:d,...o,className:(0,i.A)("tabs__item",x.tabItem,o?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function v({lazy:e,children:n,selectedValue:t}){const l=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=l.find(e=>e.props.value===t);return e?(0,o.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,j.jsx)("div",{className:"margin-top--md",children:l.map((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function _(e){const n=f(e);return(0,j.jsxs)("div",{className:(0,i.A)(l.G.tabs.container,"tabs-container",x.tabList),children:[(0,j.jsx)(b,{...n,...e}),(0,j.jsx)(v,{...n,...e})]})}function w(e){const n=(0,g.A)();return(0,j.jsx)(_,{...e,children:u(e.children)},String(n))}},12326:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-12-822ee45e6df67d34eab5b5b5bf8b3fd5.png"},19365:(e,n,t)=>{t.d(n,{A:()=>a});t(96540);var o=t(18215);const i={tabItem:"tabItem_Ymn6"};var l=t(74848);function a({children:e,hidden:n,className:t}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,o.A)(i.tabItem,t),hidden:n,children:e})}},36130:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-13-2-c5592665567a6674383eb58a52ffa4dc.png"},52750:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-14-1-915d541817b2e34a3c33889e1dae42f8.png"},81071:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-13-ebcd049964e6241062011b26fd445c3c.png"},85200:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-14-074b9a81b40c35450ebdfa0eb6d636fb.png"},96093:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-11-d76c60aab534a45fd35981f6980dd706.png"},98721:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>f,contentTitle:()=>y,default:()=>j,frontMatter:()=>m,metadata:()=>o,toc:()=>g});const o=JSON.parse('{"id":"compute/deployments/deploy-model","title":"Deploy a Model","description":"Deploy a model into your created cluster and nodepool","source":"@site/docs/compute/deployments/deploy-model.md","sourceDirName":"compute/deployments","slug":"/compute/deployments/deploy-model","permalink":"/compute/deployments/deploy-model","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"description":"Deploy a model into your created cluster and nodepool","sidebar_position":2,"toc_max_heading_level":4},"sidebar":"tutorialSidebar","previous":{"title":"Create Clusters and Nodepools","permalink":"/compute/deployments/clusters-nodepools"},"next":{"title":"Manage Your Compute","permalink":"/compute/deployments/manage-compute"}}');var i=t(74848),l=t(28453),a=t(11470),r=t(19365),s=t(88149);const d='from clarifai.client.nodepool import Nodepool\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize the Nodepool instance\nnodepool = Nodepool(\n    user_id="YOUR_USER_ID_HERE",            \n    nodepool_id="test-nodepool"           \n)\n\n# Create a new deployment\ndeployment = nodepool.create_deployment(\n    deployment_id="test-deployment", \n    config_filepath="./configs/deployment_config.yaml"\n)',c="clarifai deployment create NODEPOOL_ID DEPLOYMENT_ID --config DEPLOYMENT-CONFIG-FILEPATH",p='from clarifai.client.deployment import Deployment\n\n# Initialize the deployment\ndeployment = Deployment(\n    user_id="YOUR_USER_ID_HERE", \n    deployment_id="test-deployment"\n)\n',u='curl -X PATCH "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models" \\\n-H "Authorization: Key YOUR_PAT_HERE" \\\n-H "Content-Type: application/json" \\\n-d \'{\n"models": [\n  {\n    "id": "YOUR_MODEL_ID_HERE",\n    "deploy_restriction": 2 \n  }\n],\n"action": "merge"\n}\' ',h='{\n    "status": {\n        "code": 10000,\n        "description": "Ok",\n        "req_id": "b6af331eac444e76b88abea88d2d4579"\n    },\n    "models": [{\n        "id": "upload55",\n        "name": "upload55",\n        "created_at": "2025-08-21T17:05:33.491470Z",\n        "modified_at": "2025-09-09T18:36:48.844230Z",\n        "app_id": "uploaded-models",\n        "model_version": {\n            "id": "991d5569b152462aad563cfc24faf477",\n            "created_at": "2025-08-21T17:05:34.086694Z",\n            "status": {\n                "code": 21100,\n                "description": "Model is trained and ready for deployment"\n            },\n            "completed_at": "2025-08-21T17:05:41.982881Z",\n            "visibility": {\n                "gettable": 10\n            },\n            "app_id": "uploaded-models",\n            "user_id": "alfrick",\n            "metadata": {},\n            "output_info": {\n                "output_config": {\n                    "max_concepts": 0,\n                    "min_value": 0\n                },\n                "message": "Show output_info with: GET /models/{model_id}/output_info",\n                "fields_map": {},\n                "params": {\n                    "max_tokens": 512,\n                    "secrets": [],\n                    "temperature": 1\n                }\n            },\n            "input_info": {\n                "fields_map": {}\n            },\n            "train_info": {},\n            "import_info": {},\n            "inference_compute_info": {\n                "cpu_limit": "1",\n                "cpu_memory": "13Gi",\n                "cpu_requests": "1",\n                "cpu_memory_requests": "2Gi",\n                "num_accelerators": 1,\n                "accelerator_memory": "15Gi",\n                "accelerator_type": ["NVIDIA-*"]\n            },\n            "method_signatures": [{\n                "name": "generate",\n                "method_type": 2,\n                "description": "This method streams multiple outputs instead of returning just one.\\nIt takes an input string and yields a sequence of outputs.",\n                "input_fields": [{\n                    "name": "text1",\n                    "type": 1\n                }],\n                "output_fields": [{\n                    "name": "return",\n                    "type": 1,\n                    "iterator": true\n                }]\n            }]\n        },\n        "user_id": "alfrick",\n        "model_type_id": "text-to-text",\n        "visibility": {\n            "gettable": 10\n        },\n        "metadata": {},\n        "presets": {},\n        "toolkits": [],\n        "use_cases": [],\n        "languages": [],\n        "languages_full": [],\n        "check_consents": [],\n        "workflow_recommended": false,\n        "featured_order": 0,\n        "deploy_restriction": 2,\n        "open_router_info": {\n            "params": {}\n        }\n    }]\n}',m={description:"Deploy a model into your created cluster and nodepool",sidebar_position:2,toc_max_heading_level:4},y="Deploy a Model",f={},g=[{value:"<strong>Via the UI</strong>",id:"via-the-ui",level:2},{value:"Step 1: Start Creating a Deployment",id:"step-1-start-creating-a-deployment",level:3},{value:"Step 2: Select a Model",id:"step-2-select-a-model",level:3},{value:"Step 3: Select Cluster and Nodepool",id:"step-3-select-cluster-and-nodepool",level:3},{value:"Step 4: Provide Deployment ID",id:"step-4-provide-deployment-id",level:3},{value:"Step 5: Configure Advanced Settings",id:"step-5-configure-advanced-settings",level:3},{value:"Step 6: Finalize and Create the Deployment",id:"step-6-finalize-and-create-the-deployment",level:3},{value:"<strong>Via the API</strong>",id:"via-the-api",level:2},{value:"Create a Deployment",id:"create-a-deployment",level:3},{value:"Restrict Deployments",id:"restrict-deployments",level:3}];function x(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components},{Details:o}=n;return o||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"deploy-a-model",children:"Deploy a Model"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Deploy a model into your created cluster and nodepool"})}),"\n",(0,i.jsx)("hr",{}),"\n",(0,i.jsx)(n.p,{children:"Clarifai\u2019s Compute Orchestration provides efficient capabilities for you to deploy any model on any compute infrastructure, at any scale."}),"\n",(0,i.jsx)(n.p,{children:"You can configure your compute environment and deploy your models into nodepools with your preferred settings, optimizing for both cost and scalability."}),"\n",(0,i.jsx)(n.p,{children:"With model deployment, you can quickly take a trained model and set it up for inference."}),"\n",(0,i.jsxs)(n.admonition,{type:"tip",children:[(0,i.jsx)(n.mdxAdmonitionTitle,{}),(0,i.jsxs)(n.p,{children:["Learn how deployment works when making a prediction using our Compute Orchestration capabilities ",(0,i.jsx)(n.a,{href:"https://docs.clarifai.com/compute/inference/#predict-with-compute-orchestration",children:"here"}),"."]})]}),"\n","\n","\n",(0,i.jsx)(n.h2,{id:"via-the-ui",children:(0,i.jsx)(n.strong,{children:"Via the UI"})}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsx)(n.p,{children:"Each model or workflow can only have one deployment per nodepool."})}),"\n",(0,i.jsx)(n.h3,{id:"step-1-start-creating-a-deployment",children:"Step 1: Start Creating a Deployment"}),"\n",(0,i.jsxs)(n.p,{children:["To create a deployment, go to the model\u2019s page and click the ",(0,i.jsx)(n.strong,{children:"Deploy Model"})," button."]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Note:"})," You can also open the ",(0,i.jsx)(n.strong,{children:"Compute"})," tab to check if the model is already running on any compute environments. This tab displays the compute requirements needed for successfully deploying the model, allowing you to choose a nodepool that meets those requirements."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:" ",src:t(12326).A+"",width:"4200",height:"2070"})}),"\n",(0,i.jsxs)(n.admonition,{title:"Alternatively",type:"note",children:[(0,i.jsxs)(n.p,{children:["To create a deployment, go to the specific cluster or nodepool where you want the deployment to run, then click the ",(0,i.jsx)(n.strong,{children:"Deploy Model"})," button on that page."]}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:" ",src:t(96093).A+"",width:"4200",height:"1996"})})]}),"\n",(0,i.jsx)(n.h3,{id:"step-2-select-a-model",children:"Step 2: Select a Model"}),"\n",(0,i.jsx)(n.p,{children:"You\u2019ll be redirected to a page where you can configure the compute settings for your deployment."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:" ",src:t(81071).A+"",width:"4180",height:"1886"})}),"\n",(0,i.jsx)(n.p,{children:"If you haven\u2019t already selected a trained model, you can do so here. By default, the latest version of the model will be used, unless you switch the version toggle off to manually select a different version."}),"\n",(0,i.jsx)(n.p,{children:"The model\u2019s compute requirements will also be displayed, helping you select a compatible cluster and nodepool that meet those specifications."}),"\n",(0,i.jsx)(n.h3,{id:"step-3-select-cluster-and-nodepool",children:"Step 3: Select Cluster and Nodepool"}),"\n",(0,i.jsx)(n.p,{children:"Choose an existing cluster and nodepool \u2014 or create new ones \u2014 based on your model\u2019s compute requirements and performance goals."}),"\n",(0,i.jsx)(n.p,{children:"Once selected, the details of the chosen cluster and nodepool will be displayed for your review. You'll also be notified if the nodepool is compatible with the selected model."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:" ",src:t(85200).A+"",width:"4200",height:"2064"})}),"\n",(0,i.jsx)(n.h3,{id:"step-4-provide-deployment-id",children:"Step 4: Provide Deployment ID"}),"\n",(0,i.jsx)(n.p,{children:"Provide a deployment ID to uniquely identify your deployment."}),"\n",(0,i.jsx)(n.p,{children:"You can also add an optional description to provide additional context and make it easier to recognize later."}),"\n",(0,i.jsx)(n.h3,{id:"step-5-configure-advanced-settings",children:"Step 5: Configure Advanced Settings"}),"\n",(0,i.jsx)(n.p,{children:"You can also configure advanced deployment settings if needed. If you choose not to, the default values will be applied automatically."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:" ",src:t(36130).A+"",width:"3656",height:"3636"})}),"\n",(0,i.jsx)("a",{id:"model-replica"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Model Replicas"})," \u2014 This specifies the minimum and maximum range of model replicas to deploy, adjusting based on your performance needs and anticipated workload. Adding replicas enables horizontal scaling, where the workload is distributed across several instances of the model rather than relying on a single one. However, increasing them consumes more resources and may lead to higher costs. Each node in your nodepool can host multiple replicas, depending on model size and available resources."]}),"\n"]}),"\n",(0,i.jsx)(n.admonition,{title:"node autoscaling range",type:"tip",children:(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/compute/deployments/clusters-nodepools#node-range",children:"Click here"})," to find out how to set up node autoscaling ranges to automatically adjust your infrastructure based on traffic demand."]})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Scale Up Delay"})," \u2014 This sets the waiting period (in seconds) before adding resources in response to rising demand."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Scale Down Delay"})," \u2014 This sets the waiting period (in seconds) before reducing resources after a demand decrease. Note that your nodepool will only scale down to the minimum number of replica(s) configured."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Scale To Zero Delay"})," \u2014 This sets the idle time (in seconds) before scaling down to zero replicas after inactivity."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Traffic History Timeframe"})," \u2014 This defines the traffic history period (in seconds) that your deployment will review before making scaling decisions."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Disable Nodepool Packing"})," \u2014 Packing refers to placing multiple replicas on the same node to improve resource utilization and reduce costs. When set to ",(0,i.jsx)(n.code,{children:"false"})," (default), replicas may be packed together for efficiency. When set to ",(0,i.jsx)(n.code,{children:"true"}),", deployments are restricted to a single model replica per node, which can improve isolation or meet specific performance needs, but may result in underutilized nodes and higher costs."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"step-6-finalize-and-create-the-deployment",children:"Step 6: Finalize and Create the Deployment"}),"\n",(0,i.jsxs)(n.p,{children:["After completing the setup, click the ",(0,i.jsx)(n.strong,{children:"Deploy Model"})," button to create the deployment. You\u2019ll be redirected to the nodepool page, where your deployed model will be listed."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:" ",src:t(52750).A+"",width:"4200",height:"1854"})}),"\n",(0,i.jsxs)(n.p,{children:["After creating the deployment, you can use it to run ",(0,i.jsx)(n.a,{href:"https://docs.clarifai.com/compute/inference/clarifai/ui",children:"inferences"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"via-the-api",children:(0,i.jsx)(n.strong,{children:"Via the API"})}),"\n",(0,i.jsx)(n.h3,{id:"create-a-deployment",children:"Create a Deployment"}),"\n",(0,i.jsxs)(n.p,{children:["To deploy a model within a nodepool you've created, provide the ",(0,i.jsx)(n.code,{children:"deployment_id"})," and ",(0,i.jsx)(n.code,{children:"config_filepath"})," parameters to the ",(0,i.jsx)(n.code,{children:"create_deployment"})," method of the ",(0,i.jsx)(n.code,{children:"Nodepool"})," class."]}),"\n",(0,i.jsxs)(n.p,{children:["You can learn how to create the ",(0,i.jsx)(n.code,{children:"deployment_config.yaml"})," file, which contains the deployment configuration details, ",(0,i.jsx)(n.a,{href:"/compute/deployments/clusters-nodepools#3-deployment_configyaml",children:"here"}),"."]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsx)(n.p,{children:"Each model or workflow can only have one deployment per nodepool."})}),"\n",(0,i.jsxs)(a.A,{groupId:"code",children:[(0,i.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(s.A,{className:"language-python",children:d})}),(0,i.jsx)(r.A,{value:"bash",label:"CLI",children:(0,i.jsx)(s.A,{className:"language-yaml",children:c})})]}),"\n",(0,i.jsxs)(o,{children:[(0,i.jsx)("summary",{children:"Example Output"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:'[INFO] 14:45:29.871319 Deployment with ID \'test-deployment\' is created:\ncode: SUCCESS\ndescription: "Ok"\nreq_id: "sdk-python-11.7.5-1eb407b9e125478287d552fb76bc37dd"\n'})})]}),"\n",(0,i.jsxs)(n.p,{children:["After creating it, initialize the ",(0,i.jsx)(n.code,{children:"Deployment"})," class by providing the ",(0,i.jsx)(n.code,{children:"user_id"})," and ",(0,i.jsx)(n.code,{children:"deployment_id"})," parameters."]}),"\n",(0,i.jsx)(a.A,{groupId:"code",children:(0,i.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(s.A,{className:"language-python",children:p})})}),"\n",(0,i.jsx)(n.h3,{id:"restrict-deployments",children:"Restrict Deployments"}),"\n",(0,i.jsxs)(n.p,{children:["You can specify the type of compute cluster an existing model you own is deployed to. By setting the ",(0,i.jsx)(n.code,{children:"deploy_restriction"})," value, you can patch a model and define whether it runs on shared or dedicated resources."]}),"\n",(0,i.jsx)(n.p,{children:"These are the values you can set:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"0"})," (",(0,i.jsx)(n.code,{children:"USAGE_RESTRICTION_NOT_SET"}),") \u2014 The default where no explicit restriction is set."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"1"})," (",(0,i.jsx)(n.code,{children:"NO_LIMITS"}),") \u2014 The model can be deployed on any kind of compute (shared or dedicated). There are no policy constraints."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"2"})," (",(0,i.jsx)(n.code,{children:"SHARED_COMPUTE_ONLY"}),") \u2014 The model can only run on shared compute resources. This is typically cheaper but may have lower isolation or performance guarantees."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"3"})," (",(0,i.jsx)(n.code,{children:"DEDICATED_COMPUTE_ONLY"}),") \u2014 The model can only run on dedicated compute resources. This is used when you need guaranteed performance, security isolation, or compliance."]}),"\n"]}),"\n",(0,i.jsx)(a.A,{groupId:"code",children:(0,i.jsx)(r.A,{value:"curl",label:"cURL",children:(0,i.jsx)(s.A,{className:"language-python",children:u})})}),"\n",(0,i.jsxs)(o,{children:[(0,i.jsx)("summary",{children:"Example Output"}),(0,i.jsx)(s.A,{className:"language-python",children:h})]})]})}function j(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(x,{...e})}):x(e)}}}]);