"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[9943],{11470:(e,n,t)=>{t.d(n,{A:()=>w});var o=t(96540),s=t(18215),i=t(17559),a=t(23104),r=t(56347),l=t(205),c=t(57485),d=t(31682),p=t(70679);function u(e){return o.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:n,children:t}=e;return(0,o.useMemo)(()=>{const e=n??function(e){return u(e).map(({props:{value:e,label:n,attributes:t,default:o}})=>({value:e,label:n,attributes:t,default:o}))}(t);return function(e){const n=(0,d.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function m({value:e,tabValues:n}){return n.some(n=>n.value===e)}function y({queryString:e=!1,groupId:n}){const t=(0,r.W6)(),s=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,c.aZ)(s),(0,o.useCallback)(e=>{if(!s)return;const n=new URLSearchParams(t.location.search);n.set(s,e),t.replace({...t.location,search:n.toString()})},[s,t])]}function g(e){const{defaultValue:n,queryString:t=!1,groupId:s}=e,i=h(e),[a,r]=(0,o.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:i})),[c,d]=y({queryString:t,groupId:s}),[u,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,s]=(0,p.Dv)(n);return[t,(0,o.useCallback)(e=>{n&&s.set(e)},[n,s])]}({groupId:s}),f=(()=>{const e=c??u;return m({value:e,tabValues:i})?e:null})();(0,l.A)(()=>{f&&r(f)},[f]);return{selectedValue:a,selectValue:(0,o.useCallback)(e=>{if(!m({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);r(e),d(e),g(e)},[d,g,i]),tabValues:i}}var f=t(92303);const x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var j=t(74848);function b({className:e,block:n,selectedValue:t,selectValue:o,tabValues:i}){const r=[],{blockElementScrollPositionUntilNextRender:l}=(0,a.a_)(),c=e=>{const n=e.currentTarget,s=r.indexOf(n),a=i[s].value;a!==t&&(l(n),o(a))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=r.indexOf(e.currentTarget)+1;n=r[t]??r[0];break}case"ArrowLeft":{const t=r.indexOf(e.currentTarget)-1;n=r[t]??r[r.length-1];break}}n?.focus()};return(0,j.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},e),children:i.map(({value:e,label:n,attributes:o})=>(0,j.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{r.push(e)},onKeyDown:d,onClick:c,...o,className:(0,s.A)("tabs__item",x.tabItem,o?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function _({lazy:e,children:n,selectedValue:t}){const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=i.find(e=>e.props.value===t);return e?(0,o.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,j.jsx)("div",{className:"margin-top--md",children:i.map((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function v(e){const n=g(e);return(0,j.jsxs)("div",{className:(0,s.A)(i.G.tabs.container,"tabs-container",x.tabList),children:[(0,j.jsx)(b,{...n,...e}),(0,j.jsx)(_,{...n,...e})]})}function w(e){const n=(0,f.A)();return(0,j.jsx)(v,{...e,children:u(e.children)},String(n))}},12326:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-12-cd1c0fb36e3982bf08fdaf57bf7e5cbe.png"},16646:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-13-6-063abca7a05cd1996ac53abe729c2818.png"},19365:(e,n,t)=>{t.d(n,{A:()=>a});t(96540);var o=t(18215);const s={tabItem:"tabItem_Ymn6"};var i=t(74848);function a({children:e,hidden:n,className:t}){return(0,i.jsx)("div",{role:"tabpanel",className:(0,o.A)(s.tabItem,t),hidden:n,children:e})}},24549:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-14-2-e6c1fc25b6b916bff5c9c0fe6ecfad3c.png"},26635:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-13-3-c72b5c3a3d91ac6d689735ca017c3194.png"},36130:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-13-2-8d52e8f886bbe4244c74fb2cd700bc28.png"},48108:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>f,contentTitle:()=>g,default:()=>b,frontMatter:()=>y,metadata:()=>o,toc:()=>x});const o=JSON.parse('{"id":"compute/deployments/deploy-model","title":"Deploy a Model","description":"Deploy a model into your created cluster and nodepool","source":"@site/docs/compute/deployments/deploy-model.md","sourceDirName":"compute/deployments","slug":"/compute/deployments/deploy-model","permalink":"/compute/deployments/deploy-model","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"description":"Deploy a model into your created cluster and nodepool","sidebar_position":2,"toc_max_heading_level":4},"sidebar":"tutorialSidebar","previous":{"title":"Create Clusters and Nodepools","permalink":"/compute/deployments/clusters-nodepools"},"next":{"title":"Manage Your Compute","permalink":"/compute/deployments/manage-compute"}}');var s=t(74848),i=t(28453),a=t(11470),r=t(19365),l=t(88149);const c='from clarifai.client.nodepool import Nodepool\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize the Nodepool instance\nnodepool = Nodepool(\n    user_id="YOUR_USER_ID_HERE",            \n    nodepool_id="test-nodepool"           \n)\n\n# Create a new deployment\ndeployment = nodepool.create_deployment(\n    deployment_id="test-deployment", \n    config_filepath="./configs/deployment_config.yaml"\n)',d="clarifai deployment create NODEPOOL_ID DEPLOYMENT_ID --config DEPLOYMENT-CONFIG-FILEPATH",p='from clarifai.client.deployment import Deployment\n\n# Initialize the deployment\ndeployment = Deployment(\n    user_id="YOUR_USER_ID_HERE", \n    deployment_id="test-deployment"\n)\n',u='curl -X PATCH "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models" \\\n-H "Authorization: Key YOUR_PAT_HERE" \\\n-H "Content-Type: application/json" \\\n-d \'{\n"models": [\n  {\n    "id": "YOUR_MODEL_ID_HERE",\n    "deploy_restriction": 2 \n  }\n],\n"action": "merge"\n}\' ',h='{\n    "status": {\n        "code": 10000,\n        "description": "Ok",\n        "req_id": "b6af331eac444e76b88abea88d2d4579"\n    },\n    "models": [{\n        "id": "upload55",\n        "name": "upload55",\n        "created_at": "2025-08-21T17:05:33.491470Z",\n        "modified_at": "2025-09-09T18:36:48.844230Z",\n        "app_id": "uploaded-models",\n        "model_version": {\n            "id": "991d5569b152462aad563cfc24faf477",\n            "created_at": "2025-08-21T17:05:34.086694Z",\n            "status": {\n                "code": 21100,\n                "description": "Model is trained and ready for deployment"\n            },\n            "completed_at": "2025-08-21T17:05:41.982881Z",\n            "visibility": {\n                "gettable": 10\n            },\n            "app_id": "uploaded-models",\n            "user_id": "alfrick",\n            "metadata": {},\n            "output_info": {\n                "output_config": {\n                    "max_concepts": 0,\n                    "min_value": 0\n                },\n                "message": "Show output_info with: GET /models/{model_id}/output_info",\n                "fields_map": {},\n                "params": {\n                    "max_tokens": 512,\n                    "secrets": [],\n                    "temperature": 1\n                }\n            },\n            "input_info": {\n                "fields_map": {}\n            },\n            "train_info": {},\n            "import_info": {},\n            "inference_compute_info": {\n                "cpu_limit": "1",\n                "cpu_memory": "13Gi",\n                "cpu_requests": "1",\n                "cpu_memory_requests": "2Gi",\n                "num_accelerators": 1,\n                "accelerator_memory": "15Gi",\n                "accelerator_type": ["NVIDIA-*"]\n            },\n            "method_signatures": [{\n                "name": "generate",\n                "method_type": 2,\n                "description": "This method streams multiple outputs instead of returning just one.\\nIt takes an input string and yields a sequence of outputs.",\n                "input_fields": [{\n                    "name": "text1",\n                    "type": 1\n                }],\n                "output_fields": [{\n                    "name": "return",\n                    "type": 1,\n                    "iterator": true\n                }]\n            }]\n        },\n        "user_id": "alfrick",\n        "model_type_id": "text-to-text",\n        "visibility": {\n            "gettable": 10\n        },\n        "metadata": {},\n        "presets": {},\n        "toolkits": [],\n        "use_cases": [],\n        "languages": [],\n        "languages_full": [],\n        "check_consents": [],\n        "workflow_recommended": false,\n        "featured_order": 0,\n        "deploy_restriction": 2,\n        "open_router_info": {\n            "params": {}\n        }\n    }]\n}',m='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/deployments/" \\\n  -H "Authorization: Key YOUR_PAT_HERE" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "deployments": [\n      {\n        "id": "test-deployment",\n        "description": "test deployment",\n        "user_id": "YOUR_USER_ID_HERE",\n        "autoscale_config": {\n          "min_replicas": 1,\n          "max_replicas": 20,\n          "traffic_history_seconds": 100,\n          "scale_down_delay_seconds": 30,\n          "scale_to_zero_delay_seconds": 30,\n          "scale_up_delay_seconds": 30,\n          "disable_packing": false\n        },\n        "worker": {\n          "model": {\n            "id": "Llama-3_2-3B-Instruct",\n            "model_version": {\n              "id": "fe271b43266a45a5b068766b6437687f"\n            },\n            "user_id": "meta",\n            "app_id": "Llama-3"\n          }\n        },\n        "scheduling_choice": 4,\n        "nodepools": [\n          {\n            "id": "test-nodepool",\n            "compute_cluster": {\n              "id": "test-compute-cluster",\n              "user_id": "YOUR_USER_ID"\n            }\n          }\n        ],\n        "visibility": {\n          "gettable": 10\n        }\n      }\n    ]\n  }\'\n',y={description:"Deploy a model into your created cluster and nodepool",sidebar_position:2,toc_max_heading_level:4},g="Deploy a Model",f={},x=[{value:"<strong>Via the UI</strong>",id:"via-the-ui",level:2},{value:"Step 1: Start Creating a Deployment",id:"step-1-start-creating-a-deployment",level:3},{value:"Step 2: Select a Model",id:"step-2-select-a-model",level:3},{value:"Step 3: Configure an Instance",id:"step-3-configure-an-instance",level:3},{value:"Step 4: Set Autoscaling",id:"step-4-set-autoscaling",level:3},{value:"Step 5: Set Required Credentials",id:"step-5-set-required-credentials",level:3},{value:"Step 6: Create a Deployment",id:"step-6-create-a-deployment",level:3},{value:"<strong>Via the API</strong>",id:"via-the-api",level:2},{value:"Create a Deployment",id:"create-a-deployment",level:3},{value:"Restrict Deployments",id:"restrict-deployments",level:3}];function j(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:o}=n;return o||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"deploy-a-model",children:"Deploy a Model"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Deploy a model into your created cluster and nodepool"})}),"\n",(0,s.jsx)("hr",{}),"\n",(0,s.jsx)(n.p,{children:"Clarifai\u2019s Compute Orchestration provides efficient capabilities for you to deploy any model on any compute infrastructure, at any scale."}),"\n",(0,s.jsx)(n.p,{children:"You can configure your compute environment and deploy your models into nodepools with your preferred settings, optimizing for both cost and scalability."}),"\n",(0,s.jsx)(n.p,{children:"With model deployment, you can quickly take a trained model and set it up for inference."}),"\n",(0,s.jsxs)(n.admonition,{type:"tip",children:[(0,s.jsx)(n.mdxAdmonitionTitle,{}),(0,s.jsxs)(n.p,{children:["Learn how deployment works when making a prediction using our Compute Orchestration capabilities ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/compute/inference/#predict-with-compute-orchestration",children:"here"}),"."]})]}),"\n","\n","\n","\n",(0,s.jsx)(n.h2,{id:"via-the-ui",children:(0,s.jsx)(n.strong,{children:"Via the UI"})}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsx)(n.p,{children:"Each model or workflow can only have one deployment per nodepool."})}),"\n",(0,s.jsx)(n.h3,{id:"step-1-start-creating-a-deployment",children:"Step 1: Start Creating a Deployment"}),"\n",(0,s.jsxs)(n.p,{children:["To create a deployment, go to the ",(0,s.jsx)(n.strong,{children:"Compute"})," option in the collapsible left sidebar. Then, select ",(0,s.jsx)(n.strong,{children:"Deployments"})," from the dropdown list."]}),"\n",(0,s.jsxs)(n.p,{children:["You'll be redirected to the ",(0,s.jsx)(n.strong,{children:"Deployments"})," page, where you can view and manage deployments across your Clarifai compute resources."]}),"\n",(0,s.jsxs)(n.p,{children:["To start creating a deployment, click the ",(0,s.jsx)(n.strong,{children:"Create Deployment"})," button in the upper-right corner of the page."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(12326).A+"",width:"4200",height:"1712"})}),"\n",(0,s.jsxs)(n.admonition,{title:"Alternatively",type:"note",children:[(0,s.jsxs)(n.p,{children:["You can create a deployment directly from other areas within the platform. To deploy from a specific model, go to the individual page of the model you want to deploy and click the ",(0,s.jsx)(n.strong,{children:"Deploy Model"})," button. You can also create a deployment from a particular cluster or nodepool by navigating to its page and clicking ",(0,s.jsx)(n.strong,{children:"Deploy Model"})," there."]}),(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note:"})," On an individual model page, you can also open the ",(0,s.jsx)(n.strong,{children:"Compute"})," tab to check if it is already running on any compute environments. This tab displays the compute requirements needed for successfully deploying the model, allowing you to choose a configuration that meets those requirements."]}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(96093).A+"",width:"4200",height:"2254"})})]}),"\n",(0,s.jsx)(n.h3,{id:"step-2-select-a-model",children:"Step 2: Select a Model"}),"\n",(0,s.jsx)(n.p,{children:"You\u2019ll be redirected to a page where you can configure your model's compute settings and deploy it in one click."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(81071).A+"",width:"3012",height:"3376"})}),"\n",(0,s.jsx)(n.p,{children:"If you haven\u2019t already selected a trained model, you can do so here."}),"\n",(0,s.jsxs)(n.p,{children:["When you click the ",(0,s.jsx)(n.strong,{children:"Search models..."})," field, a selection window appears, allowing you to choose which model to deploy. You can browse through the listed models or use the search bar to quickly find a specific one."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(26635).A+"",width:"3840",height:"3316"})}),"\n",(0,s.jsx)(n.p,{children:"In the upper-right corner of the window, there\u2019s an account selector that lets you switch between different sources \u2014 such as your personal workspace, any organizations you belong to, or the public Clarifai model library. Selecting a different source updates the list to show the available models from that account or library."}),"\n",(0,s.jsxs)(n.p,{children:["After selecting your desired model, it will be listed in the ",(0,s.jsx)(n.strong,{children:"Select a Model"})," field. By default, the latest version of the model will be used, unless you use the ",(0,s.jsx)(n.strong,{children:"Select Version"})," field to manually select a different version."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(76724).A+"",width:"3246",height:"1200"})}),"\n",(0,s.jsx)(n.h3,{id:"step-3-configure-an-instance",children:"Step 3: Configure an Instance"}),"\n",(0,s.jsx)(n.p,{children:"Next, choose a cloud instance type and hardware configuration that best fits your model\u2019s compute requirements and performance goals."}),"\n",(0,s.jsxs)(n.p,{children:["To do this, select ",(0,s.jsx)(n.strong,{children:"Choose an instance"})," or click the ",(0,s.jsx)(n.strong,{children:"Edit"})," button."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(97853).A+"",width:"3246",height:"828"})}),"\n",(0,s.jsxs)(n.p,{children:["A window will appear, allowing you to select an instance type for your deployment. You can pick from your existing instances listed under ",(0,s.jsx)(n.strong,{children:"Your Instances"}),", or select from the automatically pre-configured ",(0,s.jsx)(n.strong,{children:"Recommended Instances"})," provided based on your model\u2019s compatibility and resource needs."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(16646).A+"",width:"2700",height:"3236"})}),"\n",(0,s.jsx)(n.p,{children:"Each instance option displays key details such as GPU type, available memory, CPU cores, and cost per minute. Make sure the instance you select is compatible with your model \u2014 incompatible instances will be clearly labeled in red."}),"\n",(0,s.jsxs)(n.p,{children:["If you wish to use a premium instance, click ",(0,s.jsx)(n.strong,{children:"Contact Us"})," to reach our team for manual provisioning. You can also click ",(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/compute/deployments/clusters-nodepools",children:"Create Custom Instance"})})," in the upper-right corner to configure a new instance that matches your specific requirements."]}),"\n",(0,s.jsxs)(n.p,{children:["Once you\u2019ve selected your preferred instance, click ",(0,s.jsx)(n.strong,{children:"Save Changes"})," to apply the configuration. The chosen instance will then appear in the ",(0,s.jsx)(n.strong,{children:"Instance Configuration"})," field of your deployment setup."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(81839).A+"",width:"3246",height:"828"})}),"\n",(0,s.jsx)(n.h3,{id:"step-4-set-autoscaling",children:"Step 4: Set Autoscaling"}),"\n",(0,s.jsx)(n.p,{children:"Next, configure how your deployment scales based on usage and demand. You can either keep the default autoscaling settings provided or customize them to better suit your workload."}),"\n",(0,s.jsxs)(n.p,{children:["To adjust the settings, select the ",(0,s.jsx)(n.strong,{children:"Autoscaling"})," field or click the ",(0,s.jsx)(n.strong,{children:"Edit"})," button."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(36130).A+"",width:"3246",height:"832"})}),"\n",(0,s.jsx)(n.p,{children:"This opens a window where you can define how your deployment automatically scales up or down depending on traffic and resource utilization."}),"\n",(0,s.jsxs)(n.p,{children:["Once you\u2019ve configured your preferred scaling parameters, click ",(0,s.jsx)(n.strong,{children:"Save Changes"})," to apply the updates."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(85200).A+"",width:"2676",height:"3328"})}),"\n",(0,s.jsx)(n.p,{children:"These are the autoscaling settings you can configure:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scale To Zero"})," \u2014 Turn this on if you want your deployment to automatically pause and use no active instances when it\u2019s not in use."]}),"\n"]}),"\n",(0,s.jsx)("a",{id:"model-replica"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Min Replicas / Max Replicas"})," \u2014 This specifies the minimum and maximum range of model replicas to deploy, adjusting based on your performance needs and anticipated workload. Adding replicas enables horizontal scaling, where the workload is distributed across several instances of the model rather than relying on a single one. However, increasing them consumes more resources and may lead to higher costs. Each node in your nodepool can host multiple replicas, depending on model size and available resources."]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note:"})," Your nodepool must have enough capacity to support this range."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{title:"node autoscaling range",type:"tip",children:(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"/compute/deployments/clusters-nodepools#node-range",children:"Click here"})," to find out how to set up node autoscaling ranges to automatically adjust your infrastructure based on traffic demand."]})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scale To Zero Delay"})," \u2014 This sets the idle time (in seconds) before scaling down to zero replicas after inactivity."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scale Up Delay"})," \u2014 This sets the waiting period (in seconds) before adding replicas in response to rising demand. Shorter delays respond faster, but may over-provision."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scale Down Delay"})," \u2014 This sets the waiting period (in seconds) before removing replicas after a demand decrease. A longer delay helps avoid unnecessary scale-downs during brief drips in activity.\nNote that your nodepool will only scale down to the minimum number of replica(s) configured."]}),"\n"]}),"\n",(0,s.jsxs)(n.admonition,{title:"Advanced Deployment",type:"note",children:[(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.strong,{children:"Edit Autoscaling Configuration"})," window, you can click the ",(0,s.jsx)(n.strong,{children:"Advanced Deployment"})," link to access additional configuration options that provide greater control over your deployment behavior."]}),(0,s.jsxs)(o,{children:[(0,s.jsx)("summary",{children:"Advanced Deployment"}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(24549).A+"",width:"2940",height:"3544"})})]}),(0,s.jsx)(n.p,{children:"The following settings are available for customization:"}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Model"})," \u2014 Select the model (and optionally the version) you want to deploy, as described earlier."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Cluster"})," \u2014 Select the cluster you want to use."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Nodepool"})," \u2014 Choose a nodepool to run your model."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Deployment ID"})," \u2014 Provide a deployment ID to uniquely identify your deployment. You can also add an optional description to provide additional context and make it easier to recognize later."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Advanced Deployment Settings"})," \u2014 If needed, you can configure additional advanced deployment settings. In addition to the autoscaling options described earlier, the following settings are also available for customization:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Traffic History Timeframe"})," \u2014 This defines the traffic history period (in seconds) that your deployment will review before making scaling decisions."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Disable Nodepool Packing"})," \u2014 Packing refers to placing multiple replicas on the same node to improve resource utilization and reduce costs. When set to ",(0,s.jsx)(n.code,{children:"false"})," (default), replicas may be packed together for efficiency. When set to ",(0,s.jsx)(n.code,{children:"true"}),", deployments are restricted to a single model replica per node, which can improve isolation or meet specific performance needs, but may result in underutilized nodes and higher costs."]}),"\n"]}),"\n"]}),"\n"]})]}),"\n",(0,s.jsx)(n.h3,{id:"step-5-set-required-credentials",children:"Step 5: Set Required Credentials"}),"\n",(0,s.jsxs)(n.p,{children:["Select a ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/control/authentication/pat",children:"Personal Access Token"})," (PAT) to associate with your deployment. This token authorizes access to the resources your deployment needs to run."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(52750).A+"",width:"3492",height:"1356"})}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note:"})," Be cautious when modifying the PAT after the deployment has been created, as doing so may cause the associated compute resources to stop functioning properly."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"If you don\u2019t already have a suitable PAT, you can click the button provided to generate one for this deployment."}),"\n",(0,s.jsx)(n.h3,{id:"step-6-create-a-deployment",children:"Step 6: Create a Deployment"}),"\n",(0,s.jsxs)(n.p,{children:["After completing all configuration steps, click ",(0,s.jsx)(n.strong,{children:"Create a Deployment"})," to launch your deployment. If a cluster or nodepool does not already exist, they will be automatically created using your specified settings, and your model will be deployed within this infrastructure."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(95132).A+"",width:"3246",height:"902"})}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note:"})," Review the price range displayed on the page to understand the estimated deployment cost. You can learn more about pricing ",(0,s.jsx)(n.a,{href:"https://www.clarifai.com/pricing",children:"here"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Once the deployment is created, you\u2019ll be redirected to the nodepool page, where your deployed model will be listed. You can then start using the deployment to run ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/compute/inference/clarifai/ui",children:"inferences"}),"."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(95091).A+"",width:"4200",height:"1998"})}),"\n",(0,s.jsx)(n.h2,{id:"via-the-api",children:(0,s.jsx)(n.strong,{children:"Via the API"})}),"\n",(0,s.jsx)(n.h3,{id:"create-a-deployment",children:"Create a Deployment"}),"\n",(0,s.jsxs)(n.p,{children:["To deploy a model within a nodepool you've created, provide the ",(0,s.jsx)(n.code,{children:"deployment_id"})," and ",(0,s.jsx)(n.code,{children:"config_filepath"})," parameters to the ",(0,s.jsx)(n.code,{children:"create_deployment"})," method of the ",(0,s.jsx)(n.code,{children:"Nodepool"})," class."]}),"\n",(0,s.jsxs)(n.p,{children:["You can learn how to create the ",(0,s.jsx)(n.code,{children:"deployment_config.yaml"})," file, which contains the deployment configuration details, ",(0,s.jsx)(n.a,{href:"/compute/deployments/clusters-nodepools#3-deployment_configyaml",children:"here"}),"."]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Note:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Each model or workflow can only have one deployment per nodepool."}),"\n",(0,s.jsxs)(n.li,{children:["If you're creating a ",(0,s.jsx)(n.a,{href:"/compute/deployments/clusters-nodepools#multi-nodepool-deployment",children:"multi-nodepool deployment"})," using the Python SDK, initializing the ",(0,s.jsx)(n.code,{children:"Nodepool"})," instance with the first nodepool only is sufficient."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(a.A,{groupId:"code",children:[(0,s.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,s.jsx)(l.A,{className:"language-python",children:c})}),(0,s.jsx)(r.A,{value:"bash",label:"CLI",children:(0,s.jsx)(l.A,{className:"language-yaml",children:d})}),(0,s.jsx)(r.A,{value:"curl",label:"cURL",children:(0,s.jsx)(l.A,{className:"language-bash",children:m})})]}),"\n",(0,s.jsxs)(o,{children:[(0,s.jsx)("summary",{children:"Example Output"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:'[INFO] 14:45:29.871319 Deployment with ID \'test-deployment\' is created:\ncode: SUCCESS\ndescription: "Ok"\nreq_id: "sdk-python-11.7.5-1eb407b9e125478287d552fb76bc37dd"\n'})})]}),"\n",(0,s.jsxs)(n.p,{children:["After creating it, initialize the ",(0,s.jsx)(n.code,{children:"Deployment"})," class by providing the ",(0,s.jsx)(n.code,{children:"user_id"})," and ",(0,s.jsx)(n.code,{children:"deployment_id"})," parameters."]}),"\n",(0,s.jsx)(a.A,{groupId:"code",children:(0,s.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,s.jsx)(l.A,{className:"language-python",children:p})})}),"\n",(0,s.jsx)(n.h3,{id:"restrict-deployments",children:"Restrict Deployments"}),"\n",(0,s.jsxs)(n.p,{children:["You can specify the type of compute cluster an existing model you own is deployed to. By setting the ",(0,s.jsx)(n.code,{children:"deploy_restriction"})," value, you can patch a model and define whether it runs on shared or dedicated resources."]}),"\n",(0,s.jsx)(n.p,{children:"These are the values you can set:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"0"})," (",(0,s.jsx)(n.code,{children:"USAGE_RESTRICTION_NOT_SET"}),") \u2014 The default where no explicit restriction is set."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"1"})," (",(0,s.jsx)(n.code,{children:"NO_LIMITS"}),") \u2014 The model can be deployed on any kind of compute (shared or dedicated). There are no policy constraints."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"2"})," (",(0,s.jsx)(n.code,{children:"SHARED_COMPUTE_ONLY"}),") \u2014 The model can only run on shared compute resources. This is typically cheaper but may have lower isolation or performance guarantees."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"3"})," (",(0,s.jsx)(n.code,{children:"DEDICATED_COMPUTE_ONLY"}),") \u2014 The model can only run on dedicated compute resources. This is used when you need guaranteed performance, security isolation, or compliance."]}),"\n"]}),"\n",(0,s.jsx)(a.A,{groupId:"code",children:(0,s.jsx)(r.A,{value:"curl",label:"cURL",children:(0,s.jsx)(l.A,{className:"language-bash",children:u})})}),"\n",(0,s.jsxs)(o,{children:[(0,s.jsx)("summary",{children:"Example Output"}),(0,s.jsx)(l.A,{className:"language-python",children:h})]})]})}function b(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(j,{...e})}):j(e)}},52750:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-14-1-8fc59b95af2a0890166e4fa2a1eb3773.png"},76724:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-13-4-23f626518f3f5da2fee5670ad9267018.png"},81071:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-13-828c74a88925a96fe2ffbf14b7202224.png"},81839:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-13-7-adab21fff6e8a4fc560205f9990e00d3.png"},85200:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-14-97fe36841cf9dcf1eafdf72ffca6ea9d.png"},95091:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-14-4-66e5626190d8b6e5bee2246530972bda.png"},95132:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-14-3-d31094240f9cbc8298ab26d5e7190169.png"},96093:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-11-fbd12180f0a7def78a083e5dd6237634.png"},97853:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-13-5-b895087403a3f3c84fd3c4a7dadf2bcc.png"}}]);