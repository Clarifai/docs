"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[3023],{5283:(e,t,a)=>{a.d(t,{A:()=>n});const n='from clarifai.client.app import App\n\napp = App(app_id="YOUR_APP_ID_HERE", user_id="YOUR_USER_ID_HERE",pat="YOUR_PAT_HERE")\n# Provide the dataset name as parameter in the create_dataset function\ndataset = app.create_dataset(dataset_id="annotations_dataset")'},65537:(e,t,a)=>{a.d(t,{A:()=>T});var n=a(96540),i=a(18215),s=a(65627),o=a(56347),r=a(50372),l=a(30604),d=a(11861),c=a(78749);function h(e){return n.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,n.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(e){const{values:t,children:a}=e;return(0,n.useMemo)((()=>{const e=t??function(e){return h(e).map((e=>{let{props:{value:t,label:a,attributes:n,default:i}}=e;return{value:t,label:a,attributes:n,default:i}}))}(a);return function(e){const t=(0,d.XI)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,a])}function u(e){let{value:t,tabValues:a}=e;return a.some((e=>e.value===t))}function m(e){let{queryString:t=!1,groupId:a}=e;const i=(0,o.W6)(),s=function(e){let{queryString:t=!1,groupId:a}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:t,groupId:a});return[(0,l.aZ)(s),(0,n.useCallback)((e=>{if(!s)return;const t=new URLSearchParams(i.location.search);t.set(s,e),i.replace({...i.location,search:t.toString()})}),[s,i])]}function f(e){const{defaultValue:t,queryString:a=!1,groupId:i}=e,s=p(e),[o,l]=(0,n.useState)((()=>function(e){let{defaultValue:t,tabValues:a}=e;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!u({value:t,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${a.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const n=a.find((e=>e.default))??a[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:s}))),[d,h]=m({queryString:a,groupId:i}),[f,x]=function(e){let{groupId:t}=e;const a=function(e){return e?`docusaurus.tab.${e}`:null}(t),[i,s]=(0,c.Dv)(a);return[i,(0,n.useCallback)((e=>{a&&s.set(e)}),[a,s])]}({groupId:i}),g=(()=>{const e=d??f;return u({value:e,tabValues:s})?e:null})();(0,r.A)((()=>{g&&l(g)}),[g]);return{selectedValue:o,selectValue:(0,n.useCallback)((e=>{if(!u({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);l(e),h(e),x(e)}),[h,x,s]),tabValues:s}}var x=a(9136);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var _=a(74848);function j(e){let{className:t,block:a,selectedValue:n,selectValue:o,tabValues:r}=e;const l=[],{blockElementScrollPositionUntilNextRender:d}=(0,s.a_)(),c=e=>{const t=e.currentTarget,a=l.indexOf(t),i=r[a].value;i!==n&&(d(t),o(i))},h=e=>{let t=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const a=l.indexOf(e.currentTarget)+1;t=l[a]??l[0];break}case"ArrowLeft":{const a=l.indexOf(e.currentTarget)-1;t=l[a]??l[l.length-1];break}}t?.focus()};return(0,_.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":a},t),children:r.map((e=>{let{value:t,label:a,attributes:s}=e;return(0,_.jsx)("li",{role:"tab",tabIndex:n===t?0:-1,"aria-selected":n===t,ref:e=>{l.push(e)},onKeyDown:h,onClick:c,...s,className:(0,i.A)("tabs__item",g.tabItem,s?.className,{"tabs__item--active":n===t}),children:a??t},t)}))})}function A(e){let{lazy:t,children:a,selectedValue:s}=e;const o=(Array.isArray(a)?a:[a]).filter(Boolean);if(t){const e=o.find((e=>e.props.value===s));return e?(0,n.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,_.jsx)("div",{className:"margin-top--md",children:o.map(((e,t)=>(0,n.cloneElement)(e,{key:t,hidden:e.props.value!==s})))})}function v(e){const t=f(e);return(0,_.jsxs)("div",{className:(0,i.A)("tabs-container",g.tabList),children:[(0,_.jsx)(j,{...t,...e}),(0,_.jsx)(A,{...t,...e})]})}function T(e){const t=(0,x.A)();return(0,_.jsx)(v,{...e,children:h(e.children)},String(t))}},79329:(e,t,a)=>{a.d(t,{A:()=>o});a(96540);var n=a(18215);const i={tabItem:"tabItem_Ymn6"};var s=a(74848);function o(e){let{children:t,hidden:a,className:o}=e;return(0,s.jsx)("div",{role:"tabpanel",className:(0,n.A)(i.tabItem,o),hidden:a,children:t})}},80668:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>b,contentTitle:()=>y,default:()=>R,frontMatter:()=>T,metadata:()=>n,toc:()=>O});const n=JSON.parse('{"id":"sdk/data-utils/image-annotation-loader","title":"Image Annotation Loader","description":"Load existing annotated image datasets and convert between supported formats","source":"@site/docs/sdk/data-utils/image-annotation-loader.md","sourceDirName":"sdk/data-utils","slug":"/sdk/data-utils/image-annotation-loader","permalink":"/sdk/data-utils/image-annotation-loader","draft":false,"unlisted":false,"editUrl":"https://github.com/Clarifai/docs/blob/main/docs/sdk/data-utils/image-annotation-loader.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"Load existing annotated image datasets and convert between supported formats","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Data Utils","permalink":"/sdk/data-utils/"},"next":{"title":"Data Ingestion Pipelines","permalink":"/sdk/data-utils/ingestion-pipelines"}}');var i=a(74848),s=a(28453),o=a(65537),r=a(79329),l=a(58069),d=a(5283);const c='from clarifai_datautils.image import ImageAnnotations\n\n# Defining path and annotation format\nLOCAL_FOLDER_PATH = "./assets/annotation_formats/imagenet"\nANNOTATION_FORMAT = "imagenet"\n\n# Load dataset from the specified local folder\nimagenet_dataset = ImageAnnotations.import_from(path=LOCAL_FOLDER_PATH, format=ANNOTATION_FORMAT) \n\n# Get info about the dataset\ninfo = imagenet_dataset.get_info()\nprint(info)\n# Or, print the dataset details\n#print(imagenet_dataset)\n\n# Get detailed dataset information\nprint(f"Dataset size: {info[\'size\']}")\nprint(f"Annotation count: {info[\'annotations_count\']}")\nprint(f"Categories: {info[\'categories\']}")\n',h='from clarifai_datautils.image import ImageAnnotations\nfrom clarifai.client.dataset import Dataset\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" # replace with your own PAT key\n\n# Defining path and annotation format\nLOCAL_FOLDER_PATH = "./assets/annotation_formats/imagenet"\nANNOTATION_FORMAT = "imagenet"\n\n# Load dataset from the specified local folder\nimagenet_dataset = ImageAnnotations.import_from(path=LOCAL_FOLDER_PATH, format=ANNOTATION_FORMAT) \n\n# Use the Python SDK library to upload\ndataset = Dataset(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", dataset_id="YOUR_DATASET_ID_HERE")\n# Or, initialize with a dataset URL; example: https://clarifai.com/john/my-app/datasets/annotations_dataset\n#dataset = Dataset("DATASET_URL_HERE") \n\n# Upload dataset using the dataloader\ndataset.upload_dataset(dataloader=imagenet_dataset.dataloader)\n',p='import opendatasets as od\n\n# When prompted, insert your kaggle username and key\nod.download("https://www.kaggle.com/datasets/harishvutukuri/dogs-vs-wolves")\n',u='from clarifai_datautils.image import ImageAnnotations\nfrom clarifai.client.dataset import Dataset\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" # replace with your own PAT key\n\n# Defining path and annotation format\nLOCAL_FOLDER_PATH = "./dogs-vs-wolves/data/"\nANNOTATION_FORMAT = "imagenet"\n\n# Load dataset from the specified local folder\nkaggle_imagenet_dataset = ImageAnnotations.import_from(path=LOCAL_FOLDER_PATH, format=ANNOTATION_FORMAT) \n\n# Use the Python SDK library to upload\ndataset = Dataset(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", dataset_id="YOUR_DATASET_ID_HERE")\n# Or, initialize with a dataset URL; example: https://clarifai.com/john/my-app/datasets/annotations_dataset\n#dataset = Dataset("DATASET_URL_HERE") \n\n# Upload dataset using the dataloader\ndataset.upload_dataset(dataloader=kaggle_imagenet_dataset.dataloader)\n',m='from clarifai_datautils.image import ImageAnnotations\n\n# Defining import details\nIMPORT_LOCAL_FOLDER_PATH = "./assets/annotation_formats/coco"\nIMPORT_ANNOTATION_FORMAT = "coco_detection"\n\ncoco_dataset = ImageAnnotations.import_from(path=IMPORT_LOCAL_FOLDER_PATH, format=IMPORT_ANNOTATION_FORMAT) \n\n# Defining export details\nEXPORT_LOCAL_FOLDER_PATH = "./assets/annotation_formats/coco2voc"\nEXPORT_ANNOTATION_FORMAT = "voc_detection"\n\ncoco_dataset_export = coco_dataset.export_to(EXPORT_LOCAL_FOLDER_PATH, EXPORT_ANNOTATION_FORMAT)\n\n# save_images param will also save the images \n#coco_dataset_export = coco_dataset.export_to(EXPORT_LOCAL_FOLDER_PATH, EXPORT_ANNOTATION_FORMAT, save_images=True)\n',f='from clarifai.client.dataset import Dataset\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" # replace with your own PAT key\n\n# Initialize Dataset object for Clarifai\ndataset = Dataset(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", dataset_id="YOUR_DATASET_ID_HERE", dataset_version_id="YOUR_DATASET_VERSION_HERE")\n\n# Specify the path where the exported dataset will be saved\n# Optionally, you can also specify how the exported data will be split. Common splits include train, val, and test\ndataset.export(save_path="clarifai_export.zip", split="train")\n',x='# Extract the zip file and pass the folder to ImageAnnotations\n\nfrom clarifai_datautils.image import ImageAnnotations\n\n# Defining import details\nIMPORT_LOCAL_FOLDER_PATH = "./content/train"\nIMPORT_ANNOTATION_FORMAT = "clarifai"\n\ncoco_dataset = ImageAnnotations.import_from(path=IMPORT_LOCAL_FOLDER_PATH, format=IMPORT_ANNOTATION_FORMAT) \n\n# Defining export details\nEXPORT_LOCAL_FOLDER_PATH = "./content"\nEXPORT_ANNOTATION_FORMAT = "coco_detection"\n\ncoco_dataset_export = coco_dataset.export_to(EXPORT_LOCAL_FOLDER_PATH, EXPORT_ANNOTATION_FORMAT)\n\n# save_images param will also save the images \n#coco_dataset_export = coco_dataset.export_to(EXPORT_LOCAL_FOLDER_PATH, EXPORT_ANNOTATION_FORMAT, save_images=True)\n',g='from clarifai_datautils.image import ImageAnnotations\n\nformats = ImageAnnotations.list_formats()\n\nprint("Supported formats:", formats)\n',_='from clarifai_datautils.image import ImageAnnotations\n\n# Defining dataset path \nLOCAL_FOLDER_PATH = "./assets/annotation_formats/cifar-10"\n\n# Detecting the format\nformat = ImageAnnotations.detect_format(LOCAL_FOLDER_PATH)\n\nprint(f"Detected format: {format}")\n',j="{'size': 19, 'source_path': './assets/annotation_formats/imagenet', 'annotated_items_count': 19, 'annotations_count': 19, 'sub_folders': [\"default: # of items=19, # of annotated items=19, # of annotations=19, annotation types=['1']\\n\"], 'categories': [\"1: ['bullfrog', 'goldfish', 'kingsnake', 'llama', 'tench']\\n\"]}\nDataset size: 19\nAnnotation count: 19\nCategories: [\"1: ['bullfrog', 'goldfish', 'kingsnake', 'llama', 'tench']\\n\"]",A="Supported formats: ['coco_segmentation', 'voc_detection', 'yolo', 'cifar', 'coco_detection', 'cvat', 'imagenet', 'kitti', 'label_me', 'mnist', 'open_images', 'vgg_face2', 'lfw', 'cityscapes', 'ade20k2017', 'clarifai']",v="Detected format: cifar",T={description:"Load existing annotated image datasets and convert between supported formats",sidebar_position:1},y="Image Annotation Loader",b={},O=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Install Python SDK and Data Utils",id:"install-python-sdk-and-data-utils",level:3},{value:"Install Extra Dependencies",id:"install-extra-dependencies",level:3},{value:"Get a PAT",id:"get-a-pat",level:3},{value:"Create a Dataset",id:"create-a-dataset",level:3},{value:"Utility Features\u200b",id:"utility-features",level:2},{value:"Supported Formats",id:"supported-formats",level:3},{value:"Format Detection\u200b",id:"format-detection",level:3},{value:"Dataset Information\u200b",id:"dataset-information",level:3},{value:"Uploading to Clarifai",id:"uploading-to-clarifai",level:2},{value:"Uploading From Kaggle to Clarifai",id:"uploading-from-kaggle-to-clarifai",level:2},{value:"Convert Between Supported Formats",id:"convert-between-supported-formats",level:2},{value:"Export a Clarifai Dataset to Another Format",id:"export-a-clarifai-dataset-to-another-format",level:2}];function w(e){const t={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components},{Details:a}=t;return a||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"image-annotation-loader",children:"Image Annotation Loader"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.strong,{children:"Load existing annotated image datasets and convert between supported formats"})}),"\n",(0,i.jsx)("hr",{}),"\n",(0,i.jsxs)(t.p,{children:["The ",(0,i.jsx)(t.a,{href:"https://github.com/Clarifai/examples/blob/main/Data_Utils/Image%20Annotation/image_annotation_loader.ipynb",children:"Image Annotation Loader"})," framework, part of the Data Utils library, enables you to load already annotated image datasets and upload them to the Clarifai platform."]}),"\n",(0,i.jsx)(t.p,{children:"This framework eliminates the hurdle of format incompatibility by supporting a wide range of industry-standard annotation formats; you can also use it to convert between different annotation formats."}),"\n",(0,i.jsx)(t.p,{children:"This allows seamless integration of existing labeled datasets, regardless of the initial annotation tool used. It also facilitates a smooth upload process, enabling you to leverage the Clarifai platform's infrastructure for various use cases."}),"\n","\n","\n","\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsxs)(t.p,{children:["Run the following command to clone the repository containing various examples for using the Data Utils library: ",(0,i.jsx)(t.code,{children:"git clone https://github.com/Clarifai/examples.git"}),". After cloning, navigate to the ",(0,i.jsx)(t.strong,{children:"Data_Utils"})," folder to follow along with this tutorial."]})}),"\n",(0,i.jsx)(t.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(t.h3,{id:"install-python-sdk-and-data-utils",children:"Install Python SDK and Data Utils"}),"\n",(0,i.jsxs)(t.p,{children:["Install the latest version of the ",(0,i.jsx)(t.code,{children:"clarifai"})," Python SDK package. Also, install the Data Utils library."]}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"bash",label:"Bash",children:(0,i.jsx)(l.A,{className:"language-text",children:(0,i.jsx)(t.p,{children:"pip install --upgrade clarifai\npip install clarifai-datautils"})})})}),"\n",(0,i.jsx)(t.h3,{id:"install-extra-dependencies",children:"Install Extra Dependencies"}),"\n",(0,i.jsxs)(t.p,{children:["The Image Annotation Loader requires additional libraries to function properly. To keep the core library lightweight, we moved these optional dependencies under ",(0,i.jsx)(t.code,{children:"annotations"}),". ",(0,i.jsx)(t.em,{children:"(Python extras allow projects to specify additional dependencies for optional functionality.)"})]}),"\n",(0,i.jsx)(t.p,{children:"To install them, run:"}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"bash",label:"Bash",children:(0,i.jsx)(l.A,{className:"language-text",children:(0,i.jsx)(t.p,{children:"pip install clarifai-datautils[annotations]"})})})}),"\n",(0,i.jsxs)(t.p,{children:["The above command also installs ",(0,i.jsx)(t.a,{href:"https://github.com/openvinotoolkit/datumaro",children:"Datumaro"}),", a dataset management framework essential for the Image Annotation Loader. Note that Datumaro requires a ",(0,i.jsx)(t.a,{href:"https://www.rust-lang.org/",children:"Rust compiler"})," to be installed on your machine for a smooth installation."]}),"\n",(0,i.jsx)(t.h3,{id:"get-a-pat",children:"Get a PAT"}),"\n",(0,i.jsxs)(t.p,{children:["You need a PAT (Personal Access Token) key to authenticate your connection to the Clarifai platform. You can generate it in your Personal Settings page by navigating to the ",(0,i.jsx)(t.a,{href:"https://clarifai.com/settings/security",children:"Security section"}),"."]}),"\n",(0,i.jsx)(t.p,{children:"Then, set it as an environment variable in your script."}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:(0,i.jsx)(t.p,{children:'import os\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" # replace with your own PAT key'})})})}),"\n",(0,i.jsx)(t.h3,{id:"create-a-dataset",children:"Create a Dataset"}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/sdk/managing-datasets#creating-datasets",children:"Create a dataset"})," on the Clarifai platform to use for uploading your annotated image datasets."]}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:d.A})})}),"\n",(0,i.jsx)(t.h2,{id:"utility-features",children:"Utility Features\u200b"}),"\n",(0,i.jsx)(t.h3,{id:"supported-formats",children:"Supported Formats"}),"\n",(0,i.jsx)(t.p,{children:"You can retrieve and display all the annotation formats that the Image Annotation Loader framework supports."}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:g})})}),"\n",(0,i.jsx)(t.p,{children:"Note that:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["The ",(0,i.jsx)(t.code,{children:"ImageAnnotations"})," class is imported from the ",(0,i.jsx)(t.code,{children:"clarifai_datautils.image"})," package. This class provides utilities for working with annotated image datasets."]}),"\n"]}),"\n",(0,i.jsxs)(a,{children:[(0,i.jsx)("summary",{children:"Output Example"}),(0,i.jsx)(l.A,{className:"language-text",children:A})]}),"\n",(0,i.jsx)(t.p,{children:"Here is a table that illustrates the annotation formats that the framework supports."}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:"Annotation Type"}),(0,i.jsx)(t.th,{children:"Format"}),(0,i.jsx)(t.th,{children:"TASK"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"http://image-net.org/",children:"ImageNet"})}),(0,i.jsx)(t.td,{children:"imagenet"}),(0,i.jsx)(t.td,{children:"classification"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"https://www.cs.toronto.edu/~kriz/cifar.html",children:"CIFAR-10"})}),(0,i.jsx)(t.td,{children:"cifar"}),(0,i.jsx)(t.td,{children:"classification"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"http://yann.lecun.com/exdb/mnist/",children:"MNIST"})}),(0,i.jsx)(t.td,{children:"mnist"}),(0,i.jsx)(t.td,{children:"classification"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"https://github.com/ox-vgg/vgg_face2",children:"VGGFace2"})}),(0,i.jsx)(t.td,{children:"vgg_face2"}),(0,i.jsx)(t.td,{children:"classification"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"http://vis-www.cs.umass.edu/lfw/",children:"LFW"})}),(0,i.jsx)(t.td,{children:"lfw"}),(0,i.jsx)(t.td,{children:"classification"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/htmldoc/index.html",children:"PASCAL VOC"})}),(0,i.jsx)(t.td,{children:"voc_detection"}),(0,i.jsx)(t.td,{children:"detection"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"https://github.com/AlexeyAB/darknet#how-to-train-pascal-voc-data",children:"YOLO"})}),(0,i.jsx)(t.td,{children:"yolo"}),(0,i.jsx)(t.td,{children:"detection"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"http://cocodataset.org/#format-data",children:"COCO"})}),(0,i.jsx)(t.td,{children:"coco_detection"}),(0,i.jsx)(t.td,{children:"detection"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"https://opencv.github.io/cvat/docs/manual/advanced/xml_format/",children:"CVAT"})}),(0,i.jsx)(t.td,{children:"cvat"}),(0,i.jsx)(t.td,{children:"detection"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"http://www.cvlibs.net/datasets/kitti/index.php",children:"Kitti"})}),(0,i.jsx)(t.td,{children:"kitti"}),(0,i.jsx)(t.td,{children:"detection"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"http://labelme.csail.mit.edu/Release3.0",children:"LabelMe"})}),(0,i.jsx)(t.td,{children:"label_me"}),(0,i.jsx)(t.td,{children:"detection"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"https://storage.googleapis.com/openimages/web/download.html",children:"Open Images"})}),(0,i.jsx)(t.td,{children:"open_images"}),(0,i.jsx)(t.td,{children:"detection"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"https://github.com/Clarifai/examples/tree/main/Data_Utils",children:"Clarifai"})}),(0,i.jsx)(t.td,{children:"clarifai"}),(0,i.jsx)(t.td,{children:"detection"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"http://cocodataset.org/#format-data",children:"COCO(segmentation)"})}),(0,i.jsx)(t.td,{children:"coco_segmentation"}),(0,i.jsx)(t.td,{children:"segmentation"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"https://www.cityscapes-dataset.com/",children:"Cityscapes"})}),(0,i.jsx)(t.td,{children:"cityscapes"}),(0,i.jsx)(t.td,{children:"segmentation"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.a,{href:"https://ade20k.csail.mit.edu/",children:"ADE"})}),(0,i.jsx)(t.td,{children:"ade20k2017"}),(0,i.jsx)(t.td,{children:"segmentation"})]})]})]}),"\n",(0,i.jsx)(t.h3,{id:"format-detection",children:"Format Detection\u200b"}),"\n",(0,i.jsx)(t.p,{children:"You can identify the annotation format that a dataset uses."}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:_})})}),"\n",(0,i.jsx)(t.p,{children:"Note that:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["The ",(0,i.jsx)(t.code,{children:"LOCAL_FOLDER_PATH"})," parameter specifies the local directory path where the annotated dataset is stored."]}),"\n"]}),"\n",(0,i.jsxs)(a,{children:[(0,i.jsx)("summary",{children:"Output Example"}),(0,i.jsx)(l.A,{className:"language-text",children:v})]}),"\n",(0,i.jsx)(t.h3,{id:"dataset-information",children:"Dataset Information\u200b"}),"\n",(0,i.jsx)(t.p,{children:"You can get the details of a dataset you want to upload to the Clarifai platform."}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:c})})}),"\n",(0,i.jsx)(t.p,{children:"Note that:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["The ",(0,i.jsx)(t.code,{children:"import_from"})," method of the ",(0,i.jsx)(t.code,{children:"ImageAnnotations"})," class is used to load the dataset from the specified local folder."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["The ",(0,i.jsx)(t.code,{children:"format"})," parameter specifies the format of the annotations. You can specify any supported annotation type."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(a,{children:[(0,i.jsx)("summary",{children:"Output Example"}),(0,i.jsx)(l.A,{className:"language-text",children:j})]}),"\n",(0,i.jsx)(t.h2,{id:"uploading-to-clarifai",children:"Uploading to Clarifai"}),"\n",(0,i.jsxs)(t.p,{children:["To upload a pre-labeled dataset from your local environment to the Clarifai platform, you need to initialize the ",(0,i.jsx)(t.code,{children:"Dataset"})," object and specify where the dataset will be uploaded \u2014 using the Python SDK library."]}),"\n",(0,i.jsxs)(t.p,{children:["Then, call the ",(0,i.jsx)(t.code,{children:"upload_dataset()"})," method on the ",(0,i.jsx)(t.code,{children:"Dataset"})," object. This method takes a ",(0,i.jsx)(t.code,{children:"dataloader"})," as an argument, which iterates over the dataset and yield data in a format compatible with the Clarifai platform."]}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:h})})}),"\n",(0,i.jsx)(t.h2,{id:"uploading-from-kaggle-to-clarifai",children:"Uploading From Kaggle to Clarifai"}),"\n",(0,i.jsxs)(t.p,{children:["You can download a dataset from ",(0,i.jsx)(t.a,{href:"https://www.kaggle.com/datasets",children:"Kaggle"})," and upload it to the Clarifai platform. To begin, install the ",(0,i.jsx)(t.code,{children:"opendatasets"})," Python package, which enables direct dataset downloads from Kaggle."]}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"bash",label:"Bash",children:(0,i.jsx)(l.A,{className:"language-text",children:(0,i.jsx)(t.p,{children:"pip install -q opendatasets"})})})}),"\n",(0,i.jsxs)(t.p,{children:["Next, download the dataset from Kaggle. For example, here is how you could download this ",(0,i.jsx)(t.a,{href:"https://www.kaggle.com/datasets/harishvutukuri/dogs-vs-wolves",children:"dogs-vs-wolves"})," dataset."]}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:p})})}),"\n",(0,i.jsx)(t.p,{children:"Then, you can upload it to Clarifai."}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:u})})}),"\n",(0,i.jsx)(t.h2,{id:"convert-between-supported-formats",children:"Convert Between Supported Formats"}),"\n",(0,i.jsx)(t.p,{children:"You can convert datasets between various annotation formats in your local development environment. For example, you can convert a dataset from COCO format to VOC format."}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:m})})}),"\n",(0,i.jsx)(t.h2,{id:"export-a-clarifai-dataset-to-another-format",children:"Export a Clarifai Dataset to Another Format"}),"\n",(0,i.jsx)(t.p,{children:"You can export a dataset version from the Clarifai platform and convert it into various formats. This process involves two simple steps."}),"\n",(0,i.jsx)(t.p,{children:"First, use the Clarifai SDK to export the dataset from the platform. The dataset will be downloaded as a ZIP file to your specified local directory. If the directory does not already exist, it will be automatically created for you."}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:f})})}),"\n",(0,i.jsxs)(t.p,{children:["Next, extract the contents of the ZIP file to a folder. Then, pass the folder path to ",(0,i.jsx)(t.code,{children:"ImageAnnotations"})," and convert the dataset into your desired format."]}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsx)(r.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:x})})})]})}function R(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(w,{...e})}):w(e)}}}]);