"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[3181],{40601:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>r,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>l,toc:()=>d});var i=n(74848),a=n(28453);const s={description:"Learn about the labeling methods on the Input-Viewer",sidebar_position:3},o="Label Types",l={id:"portal-guide/input-viewer/label-types",title:"Label Types",description:"Learn about the labeling methods on the Input-Viewer",source:"@site/docs/portal-guide/input-viewer/label-types.md",sourceDirName:"portal-guide/input-viewer",slug:"/portal-guide/input-viewer/label-types",permalink:"/portal-guide/input-viewer/label-types",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/portal-guide/input-viewer/label-types.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{description:"Learn about the labeling methods on the Input-Viewer",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Predictions",permalink:"/portal-guide/input-viewer/predictions"},next:{title:"AI-Assisted Labeling",permalink:"/portal-guide/input-viewer/ai-assist"}},r={},d=[{value:"Manual Labeling on Input-Viewer Page",id:"manual-labeling-on-input-viewer-page",level:2},{value:"Classification",id:"classification",level:2},{value:"Image Classification",id:"image-classification",level:3},{value:"Text Classification",id:"text-classification",level:3},{value:"Video Classification",id:"video-classification",level:3},{value:"Detection",id:"detection",level:2},{value:"Detection for Still Images",id:"detection-for-still-images",level:3},{value:"Detection for Video",id:"detection-for-video",level:3},{value:"Segmentation",id:"segmentation",level:2},{value:"Masks",id:"masks",level:2}];function c(e){const t={a:"a",admonition:"admonition",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{id:"label-types",children:"Label Types"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.strong,{children:"Learn about the labeling methods on the Input-Viewer"})}),"\n",(0,i.jsx)("hr",{}),"\n",(0,i.jsx)(t.p,{children:"We support different types of labeling methods, each suited for different tasks and data characteristics. This lets you create high-quality training data depending on the objective you want your machine learning model to achieve."}),"\n",(0,i.jsx)(t.p,{children:"We provide the following label types for your images, videos, and texts:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Classification"})," \u2014 Categorizes images, videos, and texts into categories;"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Detection"})," \u2014 Detects where an object of interest is and draws a bounding box around it;"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Segmentation"})," (polygons for segmentation) \u2014 Outlines the exact shape or contour of the object;"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Masks"})," \u2014  A type of image segmentation that defines the exact boundaries of an object at a pixel level."]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"You can use any of the labeling types to complete your tasks easily and quickly. These label types provide increasing levels of granularity to support the needs of your specific use case."}),"\n",(0,i.jsx)(t.p,{children:"Let's illustrate how you can carry out each label type on the Input-Viewer page."}),"\n",(0,i.jsx)(t.admonition,{title:"Scribe Labeler",type:"warning",children:(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/annotate/labeling-tools",children:"Click here"})," to learn how to use the Scribe Labeling Tasks tool to carry out each of the different label types."]})}),"\n",(0,i.jsx)(t.h2,{id:"manual-labeling-on-input-viewer-page",children:"Manual Labeling on Input-Viewer Page"}),"\n",(0,i.jsx)(t.p,{children:"The Input-Viewer page is the main page that showcases the details of a single input available in your app. If you click an input listed on the Input-Manager page, you'll be redirected to the viewer page for that input, where you can see its details."}),"\n",(0,i.jsx)(t.admonition,{type:"info",children:(0,i.jsx)(t.p,{children:"You can download the original asset directly from the Input-Viewer page. If you right-click on the canvas area, a button will appear, which allows you to download the original input."})}),"\n",(0,i.jsxs)(t.p,{children:["After navigating to the Input-Viewer, ensure the page's mode is set to ",(0,i.jsx)(t.strong,{children:"Annotate"}),", which is the default status. You can find the mode settings at the upper-right corner of the page."]}),"\n",(0,i.jsx)(t.p,{children:"Here is an example:"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(77092).A+"",width:"1918",height:"910"})}),"\n",(0,i.jsx)(t.p,{children:"The page has the following assistive tools to help you make the most of the labeling exercise:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Select / Edit"})," \u2014 Use this tool to navigate and interact with the interface. You can use it to select already defined bounding boxes or polygons;"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Bounding Box"})," \u2014 Use this tool to draw a rectangle on an image to define a region of interest. It's useful for identifying objects in images;"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Polygon"})," \u2014 Use this tool to draw custom, multi-sided shapes on an image. It's ideal for annotating irregularly shaped areas or objects;"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Hand"})," \u2014 Use this tool to click and drag an image in order to pan or move it around the workspace. It's useful for examining different areas of a large or zoomed-in image without changing the zoom level;"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Zoom"})," \u2014 Use this tool to zoom an image in or out."]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"The left sidebar shows a film strip of images you can scroll through to get the specific image you want to annotate. If you click any image on the sidebar, it'll appear on the main workspace."}),"\n",(0,i.jsx)(t.admonition,{title:"AI-assisted labeling",type:"warning",children:(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/annotate/ai-assist",children:"Click here"})," to learn how to carry out AI-assisted labeling on the Input-Viewer."]})}),"\n",(0,i.jsx)(t.h2,{id:"classification",children:"Classification"}),"\n",(0,i.jsx)(t.p,{children:"The classification label type lets you assign annotations to an entire image, a single frame of video, or a piece of text."}),"\n",(0,i.jsx)(t.h3,{id:"image-classification",children:"Image Classification"}),"\n",(0,i.jsxs)(t.p,{children:["To manually classify an image on the Input-Viewer page, first click the ",(0,i.jsx)(t.strong,{children:"Select / Edit"})," tool (it's selected by default) on the navigation bar."]}),"\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsxs)(t.p,{children:["The keyboard shortcut for the ",(0,i.jsx)(t.strong,{children:"Select / Edit"})," tool is ",(0,i.jsx)(t.strong,{children:"V"}),"."]})}),"\n",(0,i.jsxs)(t.p,{children:["Next, click the ",(0,i.jsx)(t.strong,{children:"Add annotation tags..."})," field and select the concept you want to use to annotate the image from the drop-down list \u2014 that is, if the concept already exists in your app."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(62367).A+"",width:"1294",height:"758"})}),"\n",(0,i.jsxs)(t.p,{children:["If you want to annotate an input with a new concept that does not already exist in your app, click the ",(0,i.jsx)(t.strong,{children:"Add annotation tags..."})," field and type the concept's name. Then, click the drop-down box that appears with the concept name beneath that field."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(24918).A+"",width:"1282",height:"811"})}),"\n",(0,i.jsx)(t.p,{children:"The new annotation will be added to your app and labeled with your input."}),"\n",(0,i.jsxs)(t.p,{children:["You can add as many annotations as you want. The added annotations will appear in the ",(0,i.jsx)(t.strong,{children:"Add annotation tags..."})," field as well as on the right sidebar of the page."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(74889).A+"",width:"1911",height:"827"})}),"\n",(0,i.jsx)(t.h3,{id:"text-classification",children:"Text Classification"}),"\n",(0,i.jsx)(t.p,{children:"You can classify your text inputs into pre-defined categories \u2014 just as with image classification described above."}),"\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsxs)(t.p,{children:["Ensure you select the appropriate ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/workflows/base-workflows",children:"base workflow"})," when creating an app for text inputs."]})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(50688).A+"",width:"1909",height:"909"})}),"\n",(0,i.jsx)(t.h3,{id:"video-classification",children:"Video Classification"}),"\n",(0,i.jsx)(t.p,{children:"Support for video labeling is coming soon."}),"\n",(0,i.jsx)(t.h2,{id:"detection",children:"Detection"}),"\n",(0,i.jsx)(t.p,{children:"The detection label type lets you identify the objects in your inputs and also draw bounding boxes around them."}),"\n",(0,i.jsx)(t.h3,{id:"detection-for-still-images",children:"Detection for Still Images"}),"\n",(0,i.jsxs)(t.p,{children:["To manually add detection labels on the Input-Viewer page, first click the ",(0,i.jsx)(t.strong,{children:"Bounding Box"})," tool on the navigation bar."]}),"\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsxs)(t.p,{children:["The keyboard shortcut for the ",(0,i.jsx)(t.strong,{children:"Bounding box"})," tool is ",(0,i.jsx)(t.strong,{children:"B"}),"."]})}),"\n",(0,i.jsxs)(t.p,{children:["Next, click the ",(0,i.jsx)(t.strong,{children:"Add annotation tags..."})," field and select the concept you want to use from the drop-down list \u2014 that is, if the concept is already existing in your app. If it's not already existing, you'll need to add it as described earlier."]}),"\n",(0,i.jsx)(t.p,{children:"Next, draw a rectangle as closely as possible around the image's region of interest."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(31899).A+"",width:"1812",height:"837"})}),"\n",(0,i.jsxs)(t.p,{children:["You can add as many detection annotations as you want. The added annotations will appear in the ",(0,i.jsx)(t.strong,{children:"Add annotation tags..."})," field as well as on the right sidebar of the page."]}),"\n",(0,i.jsx)(t.h3,{id:"detection-for-video",children:"Detection for Video"}),"\n",(0,i.jsx)(t.p,{children:"Support for video labeling is coming soon."}),"\n",(0,i.jsx)(t.h2,{id:"segmentation",children:"Segmentation"}),"\n",(0,i.jsx)(t.p,{children:"The segmentation label type lets you outline a boundary of an object using a series of vertices that define a closed polygonal shape. It's ideal for annotating irregularly shaped areas or objects."}),"\n",(0,i.jsxs)(t.p,{children:["To manually add segmentation labels on an image on the Input-Viewer page, first click the ",(0,i.jsx)(t.strong,{children:"Polygon"})," tool on the navigation bar."]}),"\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsxs)(t.p,{children:["The keyboard shortcut for the ",(0,i.jsx)(t.strong,{children:"Polygon"})," tool is ",(0,i.jsx)(t.strong,{children:"P"}),"."]})}),"\n",(0,i.jsxs)(t.p,{children:["Next, click the ",(0,i.jsx)(t.strong,{children:"Add annotation tags..."})," field and select the concept you want to use from the drop-down list \u2014 that is, if the concept is already existing in your app. If it's not already existing, you'll need to add it as described earlier."]}),"\n",(0,i.jsx)(t.p,{children:"Next, use the dots to draw a contour as closely as possible around the image's region of interest."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(39509).A+"",width:"1909",height:"891"})}),"\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsx)(t.p,{children:"After creating the initial shape by placing your dots, you'll need to close the loop. Simply click on the first dot you made again, and this action will close the loop, completing the polygon."})}),"\n",(0,i.jsxs)(t.p,{children:["You can add as many detection annotations as you want. The added annotations will appear in the ",(0,i.jsx)(t.strong,{children:"Add annotation tags..."})," field as well as on the right sidebar of the page."]}),"\n",(0,i.jsx)(t.h2,{id:"masks",children:"Masks"}),"\n",(0,i.jsx)(t.p,{children:"The masks label type lets you label each pixel within the region of interest. It provides pixel-level labeling that allows you to precisely identify and delineate objects within an image."}),"\n",(0,i.jsx)(t.p,{children:"Currently, you can only minimally review existing image mask annotations on the Input-Viewer page. After creating mask images via the API and uploading them on the platform, you can view them on the page."}),"\n",(0,i.jsx)(t.admonition,{type:"note",children:(0,i.jsx)(t.p,{children:"You can delete an entire image mask annotation on an input on the Input-Viewer page. However, we currently do not support creating and editing mask annotations on the page."})}),"\n",(0,i.jsx)(t.admonition,{type:"info",children:(0,i.jsxs)(t.p,{children:["Click ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/api-guide/annotate/annotations#annotate-images-with-mask",children:"here"})," to learn how to add mask annotation in images using API."]})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(10354).A+"",width:"893",height:"201"})})]})}function h(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},77092:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/label-types-1-6dc85df682ee9f53cfcb1944c2f324a8.png"},62367:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/label-types-2-41659a5008ef8d891bedbba8a64b53ac.png"},24918:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/label-types-3-97e8ecbf9cb79b9edac3f40e2596c18c.png"},74889:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/label-types-4-8c01c2c16d550e7218e66fb073919598.png"},50688:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/label-types-5-62e1ad84e3693f9029bcf41de741ad0f.png"},31899:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/label-types-6-4adb43505c1a7f8f71af25469b841613.png"},10354:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/label-types-7-af07f85fc948f62aed1c033ab86332f8.png"},39509:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/label-types-8-a4acb6cedfee4d0d23419457ad119001.png"},28453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>l});var i=n(96540);const a={},s=i.createContext(a);function o(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);