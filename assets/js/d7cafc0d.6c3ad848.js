"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[9937],{55540:(e,o,n)=>{n.r(o),n.d(o,{assets:()=>d,contentTitle:()=>l,default:()=>p,frontMatter:()=>i,metadata:()=>r,toc:()=>a});var t=n(74848),s=n(28453);const i={description:"Deploy any model anywhere, at any scale",sidebar_position:2},l="How to Deploy a Model",r={id:"portal-guide/compute-orchestration/deploy-model",title:"How to Deploy a Model",description:"Deploy any model anywhere, at any scale",source:"@site/docs/portal-guide/compute-orchestration/deploy-model.md",sourceDirName:"portal-guide/compute-orchestration",slug:"/portal-guide/compute-orchestration/deploy-model",permalink:"/portal-guide/compute-orchestration/deploy-model",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/portal-guide/compute-orchestration/deploy-model.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{description:"Deploy any model anywhere, at any scale",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Clusters and Nodepools",permalink:"/portal-guide/compute-orchestration/set-up-compute"},next:{title:"Managing Your Compute",permalink:"/portal-guide/compute-orchestration/manage"}},d={},a=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Make a Deployment",id:"make-a-deployment",level:2},{value:"Use Deployed Model",id:"use-deployed-model",level:2}];function c(e){const o={a:"a",admonition:"admonition",blockquote:"blockquote",em:"em",h1:"h1",h2:"h2",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(o.h1,{id:"how-to-deploy-a-model",children:"How to Deploy a Model"}),"\n",(0,t.jsx)(o.p,{children:(0,t.jsx)(o.strong,{children:"Deploy any model anywhere, at any scale"})}),"\n",(0,t.jsx)("hr",{}),"\n",(0,t.jsx)(o.admonition,{type:"note",children:(0,t.jsxs)(o.p,{children:["Compute Orchestration is currently in ",(0,t.jsx)(o.a,{href:"https://docs.clarifai.com/product-updates/changelog/release-types",children:"Public Preview"}),". To request access, please contact us ",(0,t.jsx)(o.a,{href:"https://www.clarifai.com/explore/contact-us-co",children:"here"}),"."]})}),"\n",(0,t.jsx)(o.p,{children:"Clarifai\u2019s Compute Orchestration provides efficient capabilities for you to deploy any model on any compute infrastructure, at any scale."}),"\n",(0,t.jsx)(o.p,{children:"This new platform capability brings the convenience of serverless autoscaling to any compute, regardless of where it\u2019s deployed and what hardware it\u2019s running on, and scale automatically to meet workload demands."}),"\n",(0,t.jsx)(o.p,{children:"Compute Orchestration allows you to upload a model, configure your SaaS or self-managed compute, and then deploy your model into your nodepools with your preferred settings cost-efficiently and scalably."}),"\n",(0,t.jsx)(o.admonition,{title:"info",type:"tip",children:(0,t.jsxs)(o.p,{children:["For the Compute Orchestration Public Preview, deployment is only supported for models that users have uploaded to our platform via the Python SDK. We plan to expand this functionality to include out-of-the-box and custom-trained models on our platform in the future. You can learn how to upload models ",(0,t.jsx)(o.a,{href:"https://docs.clarifai.com/sdk/compute-orchestration/model-upload",children:"here"}),"."]})}),"\n",(0,t.jsx)(o.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(o.ul,{children:["\n",(0,t.jsxs)(o.li,{children:["Set up a compute cluster and nodepool. You can follow the instructions provided ",(0,t.jsx)(o.a,{href:"https://docs.clarifai.com/portal-guide/compute-orchestration/set-up-compute",children:"here"}),"."]}),"\n",(0,t.jsxs)(o.li,{children:[(0,t.jsx)(o.a,{href:"https://docs.clarifai.com/sdk/compute-orchestration/model-upload",children:"Upload"})," a model you'd like to use for running inferences."]}),"\n"]}),"\n",(0,t.jsx)(o.h2,{id:"make-a-deployment",children:"Make a Deployment"}),"\n",(0,t.jsx)(o.admonition,{type:"note",children:(0,t.jsx)(o.p,{children:"Each model or workflow can only have one deployment per nodepool."})}),"\n",(0,t.jsxs)(o.p,{children:["To deploy a model, navigate to your cluster or nodepool page and click the ",(0,t.jsx)(o.strong,{children:"Deploy a model"})," button in the upper-right corner."]}),"\n",(0,t.jsx)(o.p,{children:(0,t.jsx)(o.img,{alt:" ",src:n(96093).A+"",width:"1902",height:"576"})}),"\n",(0,t.jsxs)(o.blockquote,{children:["\n",(0,t.jsx)(o.p,{children:(0,t.jsxs)(o.em,{children:["Alternatively, navigate to your model's page, go to the ",(0,t.jsx)(o.strong,{children:"Deployments"})," tab, and click the ",(0,t.jsx)(o.strong,{children:"Deploy model"})," or ",(0,t.jsx)(o.strong,{children:"Deploy this model"})," button."]})}),"\n"]}),"\n",(0,t.jsxs)(o.blockquote,{children:["\n",(0,t.jsx)(o.p,{children:(0,t.jsx)(o.img,{alt:" ",src:n(12326).A+"",width:"1816",height:"809"})}),"\n"]}),"\n",(0,t.jsx)(o.p,{children:"You\u2019ll be redirected to a page where you can customize the compute configurations for deploying your model."}),"\n",(0,t.jsx)(o.p,{children:(0,t.jsx)(o.img,{alt:" ",src:n(81071).A+"",width:"1250",height:"1206"})}),"\n",(0,t.jsxs)(o.ul,{children:["\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Deployment details"})," \u2014 Create a deployment ID and description that helps identify your model version and selected compute combination."]}),"\n"]}),"\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Model and version"})," \u2014 Select an already trained model and the version you want to deploy."]}),"\n"]}),"\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Cluster"})," \u2014Select or create a cluster."]}),"\n"]}),"\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Nodepool"})," \u2014 Select or create a nodepool to deploy your model considering your performance goals. The details of the dedicated cluster and nodepool you\u2019ve selected will be displayed."]}),"\n"]}),"\n",(0,t.jsxs)(o.li,{children:["\n",(0,t.jsxs)(o.p,{children:[(0,t.jsx)(o.strong,{children:"Advanced settings"})," \u2014 Optionally, you can click the collapsible section to configure the following settings:"]}),"\n",(0,t.jsxs)(o.ul,{children:["\n",(0,t.jsxs)(o.li,{children:[(0,t.jsx)(o.strong,{children:"Model replicas"})," \u2014 Specify the minimum and maximum range of model replicas to deploy, adjusting based on your performance needs and anticipated workload. Adding replicas enables horizontal scaling, where the workload is distributed across several instances of the model rather than relying on a single one. However, increasing them consumes more resources and may lead to higher costs. Each node in your nodepool can host multiple replicas, depending on model size and available resources."]}),"\n",(0,t.jsxs)(o.li,{children:[(0,t.jsx)(o.strong,{children:"Scale down delay"})," \u2014 This sets the waiting period before reducing resources after a demand decrease, ensuring stability by only scaling down to the preconfigured minimum replica(s)."]}),"\n",(0,t.jsxs)(o.li,{children:[(0,t.jsx)(o.strong,{children:"Scaling timeframe"})," \u2014 This defines the traffic history period that your deployment will review before making scaling decisions."]}),"\n",(0,t.jsxs)(o.li,{children:[(0,t.jsx)(o.strong,{children:"Scale up delay"})," \u2014 This is the waiting period before adding resources in response to rising demand."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(o.p,{children:["After completing the setup, click the ",(0,t.jsx)(o.strong,{children:"Deploy model"})," button at the bottom of the page to initiate the deployment."]}),"\n",(0,t.jsx)(o.p,{children:"You\u2019ll then be redirected to the nodepool page, where your deployed model will be listed."}),"\n",(0,t.jsx)(o.p,{children:(0,t.jsx)(o.img,{alt:" ",src:n(85200).A+"",width:"1909",height:"707"})}),"\n",(0,t.jsx)(o.h2,{id:"use-deployed-model",children:"Use Deployed Model"}),"\n",(0,t.jsxs)(o.p,{children:["Once your model is deployed, you can start utilizing it to run inferences. To access your deployments, navigate to the model\u2019s individual page and select the ",(0,t.jsx)(o.strong,{children:"Deployments"})," tab."]}),"\n",(0,t.jsx)(o.p,{children:"Here, you\u2019ll find a table listing all deployments associated with the model, including details such as the cluster and nodepool. You can also sort the table alphabetically (A\u2013Z or Z\u2013A) based on your preferences."}),"\n",(0,t.jsx)(o.p,{children:(0,t.jsx)(o.img,{alt:" ",src:n(86946).A+"",width:"1807",height:"699"})}),"\n",(0,t.jsxs)(o.p,{children:["To select a deployment, click the ",(0,t.jsx)(o.strong,{children:"Deployment"})," button."]}),"\n",(0,t.jsxs)(o.p,{children:["A dropdown list will appear, showing your available deployments. Choose the one you want to use to direct traffic to a specific cluster and nodepool. If no selection is made, the default ",(0,t.jsx)(o.strong,{children:"Clarifai Shared"})," deployment will be used."]}),"\n",(0,t.jsx)(o.p,{children:(0,t.jsx)(o.img,{alt:" ",src:n(953).A+"",width:"1803",height:"721"})}),"\n",(0,t.jsx)(o.admonition,{title:"Why Deployment Selection Matters",type:"warning",children:(0,t.jsx)(o.p,{children:"Choosing the right deployment ensures efficient routing and execution of prediction requests. For example, you can route requests to a GCP cluster by selecting a corresponding deployment ID, use a different deployment ID for an AWS cluster, and yet another for an on-premises deployment. This gives you full control over performance, costs, and security, allowing you to focus on building cutting-edge AI solutions while we handle the infrastructure complexity."})}),"\n",(0,t.jsxs)(o.p,{children:["Once you\u2019ve selected a deployment ID, go to the ",(0,t.jsx)(o.strong,{children:"Overview"})," pane to use it for making ",(0,t.jsx)(o.a,{href:"https://docs.clarifai.com/portal-guide/ppredict/",children:"prediction requests"}),". When inferencing using a deployed model, the request is routed to the nodepool within the cloud region specified in the cluster, and the model\u2019s predictions are returned as output."]}),"\n",(0,t.jsx)(o.p,{children:(0,t.jsx)(o.img,{alt:" ",src:n(49952).A+"",width:"1800",height:"724"})})]})}function p(e={}){const{wrapper:o}={...(0,s.R)(),...e.components};return o?(0,t.jsx)(o,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},96093:(e,o,n)=>{n.d(o,{A:()=>t});const t=n.p+"assets/images/compute-11-a75ddfe748a234aa847d30a06c59a6e0.png"},12326:(e,o,n)=>{n.d(o,{A:()=>t});const t=n.p+"assets/images/compute-12-c9af4d1860530fca61916efff35a0960.png"},81071:(e,o,n)=>{n.d(o,{A:()=>t});const t=n.p+"assets/images/compute-13-54b17041a3e4bd71be6da521e10d3259.png"},85200:(e,o,n)=>{n.d(o,{A:()=>t});const t=n.p+"assets/images/compute-14-1a54d549dcc272f5d67245b5a0aadd31.png"},953:(e,o,n)=>{n.d(o,{A:()=>t});const t=n.p+"assets/images/compute-15-b2ec24ec4c2e441ed50db2bc2bb41588.png"},86946:(e,o,n)=>{n.d(o,{A:()=>t});const t=n.p+"assets/images/compute-16-d494cda51557496842412891eccad19c.png"},49952:(e,o,n)=>{n.d(o,{A:()=>t});const t=n.p+"assets/images/compute-21-89b2acfe03ac265bfc634c7397fc22f6.png"},28453:(e,o,n)=>{n.d(o,{R:()=>l,x:()=>r});var t=n(96540);const s={},i=t.createContext(s);function l(e){const o=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function r(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(i.Provider,{value:o},e.children)}}}]);