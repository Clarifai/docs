"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[7457],{85162:(e,n,t)=>{t.d(n,{Z:()=>r});var a=t(67294),o=t(86010);const s={tabItem:"tabItem_Ymn6"};function r(e){let{children:n,hidden:t,className:r}=e;return a.createElement("div",{role:"tabpanel",className:(0,o.Z)(s.tabItem,r),hidden:t},n)}},74866:(e,n,t)=>{t.d(n,{Z:()=>b});var a=t(87462),o=t(67294),s=t(86010),r=t(12466),i=t(16550),l=t(91980),u=t(67392),p=t(50012);function c(e){return function(e){return o.Children.map(e,(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:n,label:t,attributes:a,default:o}}=e;return{value:n,label:t,attributes:a,default:o}}))}function d(e){const{values:n,children:t}=e;return(0,o.useMemo)((()=>{const e=n??c(t);return function(e){const n=(0,u.l)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function _(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function m(e){let{queryString:n=!1,groupId:t}=e;const a=(0,i.k6)(),s=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,l._X)(s),(0,o.useCallback)((e=>{if(!s)return;const n=new URLSearchParams(a.location.search);n.set(s,e),a.replace({...a.location,search:n.toString()})}),[s,a])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:a}=e,s=d(e),[r,i]=(0,o.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!_({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const a=t.find((e=>e.default))??t[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:n,tabValues:s}))),[l,u]=m({queryString:t,groupId:a}),[c,f]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[a,s]=(0,p.Nk)(t);return[a,(0,o.useCallback)((e=>{t&&s.set(e)}),[t,s])]}({groupId:a}),E=(()=>{const e=l??c;return _({value:e,tabValues:s})?e:null})();(0,o.useLayoutEffect)((()=>{E&&i(E)}),[E]);return{selectedValue:r,selectValue:(0,o.useCallback)((e=>{if(!_({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);i(e),u(e),f(e)}),[u,f,s]),tabValues:s}}var E=t(72389);const I={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function D(e){let{className:n,block:t,selectedValue:i,selectValue:l,tabValues:u}=e;const p=[],{blockElementScrollPositionUntilNextRender:c}=(0,r.o5)(),d=e=>{const n=e.currentTarget,t=p.indexOf(n),a=u[t].value;a!==i&&(c(n),l(a))},_=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const t=p.indexOf(e.currentTarget)+1;n=p[t]??p[0];break}case"ArrowLeft":{const t=p.indexOf(e.currentTarget)-1;n=p[t]??p[p.length-1];break}}n?.focus()};return o.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.Z)("tabs",{"tabs--block":t},n)},u.map((e=>{let{value:n,label:t,attributes:r}=e;return o.createElement("li",(0,a.Z)({role:"tab",tabIndex:i===n?0:-1,"aria-selected":i===n,key:n,ref:e=>p.push(e),onKeyDown:_,onClick:d},r,{className:(0,s.Z)("tabs__item",I.tabItem,r?.className,{"tabs__item--active":i===n})}),t??n)})))}function h(e){let{lazy:n,children:t,selectedValue:a}=e;const s=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=s.find((e=>e.props.value===a));return e?(0,o.cloneElement)(e,{className:"margin-top--md"}):null}return o.createElement("div",{className:"margin-top--md"},s.map(((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==a}))))}function g(e){const n=f(e);return o.createElement("div",{className:(0,s.Z)("tabs-container",I.tabList)},o.createElement(D,(0,a.Z)({},e,n)),o.createElement(h,(0,a.Z)({},e,n)))}function b(e){const n=(0,E.Z)();return o.createElement(g,(0,a.Z)({key:String(n)},e))}},25731:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>k,contentTitle:()=>U,default:()=>Y,frontMatter:()=>y,metadata:()=>v,toc:()=>M});var a=t(87462),o=(t(67294),t(3905)),s=t(74866),r=t(85162),i=t(90814);const l="##########################################################################\n# In this section, we set the user authentication, app ID, model ID, and\n# concept IDs. Change these strings to run your own example.\n##########################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to create your own visual classifier\nMODEL_ID = 'lawrence-1591638385' \nCONCEPT_ID_1 = 'ferrari23' \nCONCEPT_ID_2 = 'outdoors23' \n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\nfrom google.protobuf.struct_pb2 import Struct\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\ntrain_params = Struct()\ntrain_params.update(\n{\n  \"template\": \"classification_cifar10_v1\",\n  \"num_epochs\": 2\n}\n)\n\npost_models_response = stub.PostModels(\nservice_pb2.PostModelsRequest(\n  user_app_id=userDataObject,\n  models=[\n    resources_pb2.Model(\n      id=MODEL_ID,\n      model_type_id=\"visual-classifier\",\n      train_info=resources_pb2.TrainInfo(params=train_params),\n      output_info=resources_pb2.OutputInfo(\n        data=resources_pb2.Data(\n          concepts=[\n            resources_pb2.Concept(id=CONCEPT_ID_1),\n            resources_pb2.Concept(id=CONCEPT_ID_2)\n          ]\n        ),\n        output_config=resources_pb2.OutputConfig(closed_environment=True)\n      )\n    )\n  ]\n),\nmetadata=metadata\n)\n\nif post_models_response.status.code != status_code_pb2.SUCCESS:\n    print(post_models_response.status)\n    raise Exception(\"Post models failed, status: \" + post_models_response.status.description)\n",u="##########################################################################\n# In this section, we set the user authentication, app ID, model ID, and\n# concept IDs. Change these strings to run your own example.\n##########################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to create your own visual detector\nMODEL_ID = 'detection-test-1591638385' \nCONCEPT_ID_1 = 'ferrari23' \nCONCEPT_ID_2 = 'outdoors23' \n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\nfrom google.protobuf.struct_pb2 import Struct\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\ntrain_params = Struct()\ntrain_params.update(\n    {\n        \"template\": \"Clarifai_InceptionV2\",\n        \"num_epochs\": 2\n    }\n)\n\npost_models_response = stub.PostModels(\n    service_pb2.PostModelsRequest(\n        user_app_id=userDataObject,\n        models=[\n            resources_pb2.Model(\n                id=MODEL_ID,\n                model_type_id=\"visual-detector\",\n                train_info=resources_pb2.TrainInfo(params=train_params),\n                output_info=resources_pb2.OutputInfo(\n                    data=resources_pb2.Data(\n                        concepts=[\n                            resources_pb2.Concept(id=CONCEPT_ID_1),\n                            resources_pb2.Concept(id=CONCEPT_ID_2)\n                        ]\n                    ),\n                    output_config=resources_pb2.OutputConfig(closed_environment=True)\n                )\n            )\n        ]\n    ),\n    metadata=metadata\n)\n\nif post_models_response.status.code != status_code_pb2.SUCCESS:\n    print(post_models_response.status)\n    raise Exception(\"Post models failed, status: \" + post_models_response.status.description)\n",p="##########################################################################\n# In this section, we set the user authentication, app ID, model ID, and\n# concept IDs. Change these strings to run your own example.\n##########################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to create your own visual embedder\nMODEL_ID = 'embed-test-1591638385' \nCONCEPT_ID_1 = 'ferrari23' \nCONCEPT_ID_2 = 'outdoors23' \n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\nfrom google.protobuf.struct_pb2 import Struct\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\ntrain_params = Struct()\ntrain_params.update(\n    {\n        \"template\": \"classification_basemodel_v1_embed\",\n        \"num_epochs\": 2\n    }\n)\n\npost_models_response = stub.PostModels(\n    service_pb2.PostModelsRequest(\n        user_app_id=userDataObject,\n        models=[\n            resources_pb2.Model(\n                id=MODEL_ID,\n                model_type_id=\"visual-embedder\",\n                train_info=resources_pb2.TrainInfo(params=train_params),\n                output_info=resources_pb2.OutputInfo(\n                    data=resources_pb2.Data(\n                        concepts=[\n                            resources_pb2.Concept(id=CONCEPT_ID_1),\n                            resources_pb2.Concept(id=CONCEPT_ID_2)\n                        ]\n                    ),\n                    output_config=resources_pb2.OutputConfig(closed_environment=True)\n                )\n            )\n        ]\n      ),\n      metadata=metadata\n)\n\nif post_models_response.status.code != status_code_pb2.SUCCESS:\n    print(post_models_response.status)\n    raise Exception(\"Post models failed, status: \" + post_models_response.status.description)\n",c="###################################################################################\n# In this section, we set the user authentication, app ID, and the details we want\n# to use to create a workflow. Change these strings to run your own example.\n###################################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to create your own workflow\nWORKFLOW_ID = 'my-new-workflow-id' \nEMBED_MODEL_ID = 'YOUR_EMBED_MODEL_ID'\nEMBED_MODEL_VERSION_ID = 'YOUR_EMBED_MODEL_VERSION_ID'\nWORKFLOWNODE_ID = 'my-custom-model' \nCUSTOM_MODEL_ID = 'YOUR_CUSTOM_MODEL_ID'\nCUSTOM_MODEL_VERSION_ID = 'YOUR_CUSTOM_MODEL_VERSION_ID'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\npost_workflows_response = stub.PostWorkflows(\n    service_pb2.PostWorkflowsRequest(\n        user_app_id=userDataObject,\n        workflows=[\n            resources_pb2.Workflow(\n                id=WORKFLOW_ID,\n                nodes=[\n                    resources_pb2.WorkflowNode(\n                        id=\"embed\",\n                        model=resources_pb2.Model(\n                            id=EMBED_MODEL_ID,\n                            model_version=resources_pb2.ModelVersion(\n                                id=EMBED_MODEL_VERSION_ID\n                            )\n                        )\n                    ),\n                    resources_pb2.WorkflowNode(\n                        id=WORKFLOWNODE_ID,\n                        model=resources_pb2.Model(\n                            id=CUSTOM_MODEL_ID,\n                            model_version=resources_pb2.ModelVersion(\n                                id=CUSTOM_MODEL_VERSION_ID\n                            )\n                        ),\n                        node_inputs=[\n                            resources_pb2.NodeInput(node_id=\"embed\")\n                        ]\n                    ),\n                ]\n            )\n        ]\n    ),\n    metadata=metadata\n)\n\nif  post_workflows_response.status.code != status_code_pb2.SUCCESS:\n    print(post_workflows_response.status)\n    raise Exception(\"Post workflows failed, status: \" +  post_workflows_response.status.description)",d="########################################################################\n# In this section, we set the user authentication, app ID, and default\n# workflow ID. Change these strings to run your own example.\n########################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change this to update your default workflow\nDEFAULT_WORKFlOW_ID = 'auto-annotation-workflow-id'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\npatch_apps_response = stub.PatchApps(\n    service_pb2.PatchAppsRequest(\n        user_app_id=userDataObject,\n        action=\"overwrite\",\n        apps=[\n            resources_pb2.App(\n                id=APP_ID,\n                default_workflow_id=DEFAULT_WORKFlOW_ID\n            )\n        ]\n    ),\n    metadata=metadata\n)\n\nif patch_apps_response.status.code != status_code_pb2.SUCCESS:\n    print(patch_apps_response.status)\n    raise Exception(\"Patch apps failed, status: \" + patch_apps_response.status.description) \n",_="##########################################################################\n# In this section, we set the user authentication, app ID, model ID, and\n# concept IDs. Change these strings to run your own example.\n##########################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to create your own text classifier\nMODEL_ID = 'text-test-1591638385' \nCONCEPT_ID_1 = 'ferrari23' \nCONCEPT_ID_2 = 'outdoors23' \n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\nfrom google.protobuf.struct_pb2 import Struct\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\ntrain_params = Struct()\ntrain_params.update(\n{\n  \"template\": \"HuggingFace\",\n  \"num_gpus\": 1\n}\n)\n\npost_models_response = stub.PostModels(\nservice_pb2.PostModelsRequest(\n  user_app_id=userDataObject,\n  models=[\n    resources_pb2.Model(\n      id=MODEL_ID,\n      model_type_id=\"text-classifier\",\n      train_info=resources_pb2.TrainInfo(params=train_params),\n      output_info=resources_pb2.OutputInfo(\n        data=resources_pb2.Data(\n          concepts=[\n            resources_pb2.Concept(id=CONCEPT_ID_1),\n            resources_pb2.Concept(id=CONCEPT_ID_2)\n          ]\n        ),\n        output_config=resources_pb2.OutputConfig(closed_environment=True)\n      )\n    )\n  ]\n),\nmetadata=metadata\n)\n\nif post_models_response.status.code != status_code_pb2.SUCCESS:\n    print(post_models_response.status)\n    raise Exception(\"Post models failed, status: \" + post_models_response.status.description)\n\n",m="##########################################################################\n# In this section, we set the user authentication, app ID, model ID, and\n# concept IDs. Change these strings to run your own example.\n##########################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to create your own visual segmenter\nMODEL_ID = 'visual-segmenter-test-1591638385' \nCONCEPT_ID_1 = 'ferrari23' \nCONCEPT_ID_2 = 'outdoors23' \n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\nfrom google.protobuf.struct_pb2 import Struct\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\ntrain_params = Struct()\ntrain_params.update(\n{\n  \"template\": \"MMSegmentation\",\n  \"num_gpus\": 1\n}\n)\n\npost_models_response = stub.PostModels(\nservice_pb2.PostModelsRequest(\n  user_app_id=userDataObject,\n  models=[\n    resources_pb2.Model(\n      id=MODEL_ID,\n      model_type_id=\"visual-segmenter\",\n      train_info=resources_pb2.TrainInfo(params=train_params),\n      output_info=resources_pb2.OutputInfo(\n        data=resources_pb2.Data(\n          concepts=[\n            resources_pb2.Concept(id=CONCEPT_ID_1),\n            resources_pb2.Concept(id=CONCEPT_ID_2)\n          ]\n        ),\n        output_config=resources_pb2.OutputConfig(closed_environment=True)\n      )\n    )\n  ]\n),\nmetadata=metadata\n)\n\nif post_models_response.status.code != status_code_pb2.SUCCESS:\n    print(post_models_response.status)\n    raise Exception(\"Post models failed, status: \" + post_models_response.status.description)\n",f="##########################################################################\n# In this section, we set the user authentication, app ID, model ID, and\n# concept IDs. Change these strings to run your own example.\n##########################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to create your own visual anomaly heatmap\nMODEL_ID = 'visual-anomaly-test-1591638385' \nCONCEPT_ID_1 = 'ferrari23' \nCONCEPT_ID_2 = 'outdoors23' \n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\nfrom google.protobuf.struct_pb2 import Struct\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\ntrain_params = Struct()\ntrain_params.update(\n{\n  \"template\": \"Anomalib_PatchCore\",\n  \"anomalib_config_json\": \"\"\n}\n)\n\npost_models_response = stub.PostModels(\nservice_pb2.PostModelsRequest(\n  user_app_id=userDataObject,\n  models=[\n    resources_pb2.Model(\n      id=MODEL_ID,\n      model_type_id=\"visual-anomaly-heatmap\",\n      train_info=resources_pb2.TrainInfo(params=train_params),\n      output_info=resources_pb2.OutputInfo(\n        data=resources_pb2.Data(\n          concepts=[\n            resources_pb2.Concept(id=CONCEPT_ID_1),\n            resources_pb2.Concept(id=CONCEPT_ID_2)\n          ]\n        ),\n        output_config=resources_pb2.OutputConfig(closed_environment=True)\n      )\n    )\n  ]\n),\nmetadata=metadata\n)\n\nif post_models_response.status.code != status_code_pb2.SUCCESS:\n    print(post_models_response.status)\n    raise Exception(\"Post models failed, status: \" + post_models_response.status.description)\n",E='//index.js file\n\n////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, model ID, and\n// concept IDs. Change these strings to run your own example.\n////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = \'YOUR_USER_ID_HERE\';\n// Your PAT (Personal Access Token) can be found in the portal under Authentification\nconst PAT = \'YOUR_PAT_HERE\';\nconst APP_ID = \'YOUR_APP_ID_HERE\';\n// Change these to create your own visual classifier\nconst MODEL_ID = \'lawrence-1591638385\';\nconst CONCEPT_ID_1 = \'ferrari23\';\nconst CONCEPT_ID_2 = \'outdoors23\';\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\nstub.PostModels(\n  {\n    user_app_id: {\n      user_id: USER_ID,\n      app_id: APP_ID\n    },\n    models: [\n      {\n        id: MODEL_ID,\n        model_type_id: "visual-classifier",\n        train_info: {\n          params: {\n            num_epoch: 2,\n            template: "classification_cifar10_v1"\n          }\n        },\n        output_info: {\n          data: {\n            concepts: [\n              { id: CONCEPT_ID_1 },\n              { id: CONCEPT_ID_2 }\n            ]\n          },\n          output_config: {\n            closed_environment: true\n          }\n        }\n      }\n    ]\n  },\n  metadata,\n  (err, response) => {\n    if (err) {\n      throw new Error(err);\n    }\n\n    if (response.status.code !== 10000) {\n      throw new Error("Received status: " + response.status.description + "\\n" + response.status.details);\n    }\n  }\n);',I='//index.js file\n\n////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, model ID, and\n// concept IDs. Change these strings to run your own example.\n////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = \'YOUR_USER_ID_HERE\';\n// Your PAT (Personal Access Token) can be found in the portal under Authentification\nconst PAT = \'YOUR_PAT_HERE\';\nconst APP_ID = \'YOUR_APP_ID_HERE\';\n// Change these to create your own visual detector\nconst MODEL_ID = \'detection-test-1591638385\';\nconst CONCEPT_ID_1 = \'ferrari23\';\nconst CONCEPT_ID_2 = \'outdoors23\';\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\nstub.PostModels(\n    {\n        user_app_id: {\n            user_id: USER_ID,\n            app_id: APP_ID\n        },\n        models: [\n            {\n                id: MODEL_ID,\n                model_type_id: "visual-detector",\n                train_info: {\n                    params: {\n                        num_epoch: 2,\n                        template: "Clarifai_InceptionV2"\n                    }\n                },\n                output_info: {\n                    data: {\n                        concepts: [\n                            { id: CONCEPT_ID_1 },\n                            { id: CONCEPT_ID_2 }\n                        ]\n                    },\n                    output_config: {\n                        closed_environment: true\n                    }\n                }\n            }\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error("Received status: " + response.status.description + "\\n" + response.status.details);\n        }\n    }\n);',D='//index.js file\n\n////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, model ID, and\n// concept IDs. Change these strings to run your own example.\n////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = \'YOUR_USER_ID_HERE\';\n// Your PAT (Personal Access Token) can be found in the portal under Authentification\nconst PAT = \'YOUR_PAT_HERE\';\nconst APP_ID = \'YOUR_APP_ID_HERE\';\n// Change these to create your own visual embedder\nconst MODEL_ID = \'embed-test-1591638385\';\nconst CONCEPT_ID_1 = \'ferrari23\';\nconst CONCEPT_ID_2 = \'outdoors23\';\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\nstub.PostModels(\n    {\n        user_app_id: {\n            user_id: USER_ID,\n            app_id: APP_ID\n        },\n        models: [\n            {\n                id: MODEL_ID,\n                model_type_id: "visual-embedder",\n                train_info: {\n                    params: {\n                        num_epoch: 2,\n                        template: "classification_basemodel_v1_embed"\n                    }\n                },\n                output_info: {\n                    data: {\n                        concepts: [\n                            { id: CONCEPT_ID_1 },\n                            { id: CONCEPT_ID_2 }\n                        ]\n                    },\n                    output_config: {\n                        closed_environment: true\n                    }\n                }\n            }\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error("Received status: " + response.status.description + "\\n" + response.status.details);\n        }\n    }\n);',h="//index.js file\n\n//////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, and the details we want\n// to use to create a workflow. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = 'YOUR_USER_ID_HERE';\n// Your PAT (Personal Access Token) can be found in the portal under Authentification\nconst PAT = 'YOUR_PAT_HERE';\nconst APP_ID = 'YOUR_APP_ID_HERE';\n// Change these to create your own workflow\nconst WORKFLOW_ID = 'my-new-workflow-id';\nconst EMBED_MODEL_ID = 'YOUR_EMBED_MODEL_ID';\nconst EMBED_MODEL_VERSION_ID = 'YOUR_EMBED_MODEL_VERSION_ID';\nconst WORKFLOWNODE_ID = 'my-custom-model';\nconst CUSTOM_MODEL_ID = 'YOUR_CUSTOM_MODEL_ID';\nconst CUSTOM_MODEL_VERSION_ID = 'YOUR_CUSTOM_MODEL_VERSION_ID';\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require(\"clarifai-nodejs-grpc\");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set(\"authorization\", \"Key \" + PAT);\n\nstub.PostWorkflows(\n    {\n        user_app_id: {\n            \"user_id\": USER_ID,\n            \"app_id\": APP_ID\n        },\n        workflows: [\n            {\n                id: WORKFLOW_ID,\n                nodes: [\n                    {\n                        id: \"embed\",\n                        model: {\n                            id: EMBED_MODEL_ID,\n                            model_version: {\n                                id: EMBED_MODEL_VERSION_ID\n                            }\n                        }\n                    },\n                    {\n                        id: WORKFLOWNODE_ID,\n                        model: {\n                            id: CUSTOM_MODEL_ID,\n                            model_version: {\n                                id: CUSTOM_MODEL_VERSION_ID\n                            }\n                        },\n                        node_inputs: [\n                            { node_id: \"embed\" }\n                        ]\n                    }\n                ]\n            }\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            console.log(response.status);\n            throw new Error(\"Post workflows failed, status: \" + response.status.description);\n        }\n    }\n);",g='//index.js file\n\n/////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, and default\n// workflow ID. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = \'YOUR_USER_ID_HERE\';\n// Your PAT (Personal Access Token) can be found in the portal under Authentification\nconst PAT = \'YOUR_PAT_HERE\';\nconst APP_ID = \'YOUR_APP_ID_HERE\';\n// Change this to update your default workflow\nconst DEFAULT_WORKFlOW_ID = \'auto-annotation-workflow-id\';\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\nstub.PatchApps(\n    {\n        user_app_id: {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        action: "overwrite",\n        apps: [\n            {\n                id: APP_ID,\n                default_workflow_id: DEFAULT_WORKFlOW_ID\n            }\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            console.log(response.status);\n            throw new Error("Patch apps failed, status: " + response.status.description);\n        }\n    }\n);',b='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\nimport com.google.protobuf.Struct;\nimport com.google.protobuf.Value;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\n\npublic class ClarifaiExample {\n\n    ////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and\n    // concept IDs. Change these strings to run your own example.\n    ////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to create your own visual classifier\n    static final String MODEL_ID = "lawrence-1591638385";\n    static final String CONCEPT_ID_1 = "ferrari23";\n    static final String CONCEPT_ID_2 = "outdoors23";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n            .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        Struct.Builder trainInfoParams = Struct.newBuilder()\n            .putFields(\n                "num_epochs", Value.newBuilder().setNumberValue(2).build()\n\n            )\n            .putFields(\n                "template", Value.newBuilder().setStringValue("classification_cifar10_v1").build()\n            );\n\n        SingleModelResponse postModelsResponse = stub.postModels(\n            PostModelsRequest.newBuilder()\n            .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n            .addModels(\n                Model.newBuilder()\n                .setId(MODEL_ID)\n                .setModelTypeId("visual-classifier")\n                .setTrainInfo(TrainInfo.newBuilder().setParams(trainInfoParams))\n                .setOutputInfo(\n                    OutputInfo.newBuilder()\n                    .setData(\n                        Data.newBuilder()\n                        .addConcepts(Concept.newBuilder().setId(CONCEPT_ID_1))\n                        .addConcepts(Concept.newBuilder().setId(CONCEPT_ID_2))\n                    )\n                    .setOutputConfig(\n                        OutputConfig.newBuilder()\n                        .setClosedEnvironment(true)\n                    )\n                )\n            )\n            .build()\n        );\n\n        if (postModelsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post models failed, status: " + postModelsResponse.getStatus());\n        }\n\n    }\n\n}',C='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\nimport com.google.protobuf.Struct;\nimport com.google.protobuf.Value;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\n\npublic class ClarifaiExample {\n\n    ////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and\n    // concept IDs. Change these strings to run your own example.\n    ////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\t\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to create your own visual detector\n    static final String MODEL_ID = "detection-test-1591638385";\n    static final String CONCEPT_ID_1 = "ferrari23";\n    static final String CONCEPT_ID_2 = "outdoors23";\n\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n            .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        Struct.Builder trainInfoParams = Struct.newBuilder()\n            .putFields(\n                "num_epochs", Value.newBuilder().setNumberValue(2).build()\n\n            )\n            .putFields(\n                "template", Value.newBuilder().setStringValue("Clarifai_InceptionV2").build()\n            );\n\n        SingleModelResponse postModelsResponse = stub.postModels(\n            PostModelsRequest.newBuilder()\n            .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n            .addModels(\n                Model.newBuilder()\n                .setId(MODEL_ID)\n                .setModelTypeId("visual-detector")\n                .setTrainInfo(TrainInfo.newBuilder().setParams(trainInfoParams))\n                .setOutputInfo(\n                    OutputInfo.newBuilder()\n                    .setData(\n                        Data.newBuilder()\n                        .addConcepts(Concept.newBuilder().setId(CONCEPT_ID_1))\n                        .addConcepts(Concept.newBuilder().setId(CONCEPT_ID_2))\n                    )\n                    .setOutputConfig(\n                        OutputConfig.newBuilder()\n                        .setClosedEnvironment(true)\n                    )\n                )\n            )\n            .build()\n        );\n\n        if (postModelsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post models failed, status: " + postModelsResponse.getStatus());\n        }\n\n    }\n\n}',T='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\nimport com.google.protobuf.Struct;\nimport com.google.protobuf.Value;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\n\npublic class ClarifaiExample {\n\n    ////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and\n    // concept IDs. Change these strings to run your own example.\n    ////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to create your own visual embedder\n    static final String MODEL_ID = "embed-test-1591638385";\n    static final String CONCEPT_ID_1 = "ferrari23";\n    static final String CONCEPT_ID_2 = "outdoors23";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n            .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        Struct.Builder trainInfoParams = Struct.newBuilder()\n            .putFields(\n                "num_epochs", Value.newBuilder().setNumberValue(2).build()\n\n            )\n            .putFields(\n                "template", Value.newBuilder().setStringValue("classification_basemodel_v1_embed").build()\n            );\n\n        SingleModelResponse postModelsResponse = stub.postModels(\n            PostModelsRequest.newBuilder()\n            .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n            .addModels(\n                Model.newBuilder()\n                .setId(MODEL_ID)\n                .setModelTypeId("visual-embedder")\n                .setTrainInfo(TrainInfo.newBuilder().setParams(trainInfoParams))\n                .setOutputInfo(\n                    OutputInfo.newBuilder()\n                    .setData(\n                        Data.newBuilder()\n                        .addConcepts(Concept.newBuilder().setId(CONCEPT_ID_1))\n                        .addConcepts(Concept.newBuilder().setId(CONCEPT_ID_2))\n                    )\n                    .setOutputConfig(\n                        OutputConfig.newBuilder()\n                        .setClosedEnvironment(true)\n                    )\n                )\n            )\n            .build()\n        );\n\n        if (postModelsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post models failed, status: " + postModelsResponse.getStatus());\n        }\n\n    }\n\n}',O='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\n\npublic class ClarifaiExample {\n\n    //////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, and the details we want\n    // to use to create a workflow. Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to create your own workflow\n    static final String WORKFLOW_ID = "my-new-workflow-id";\n    static final String EMBED_MODEL_ID = "YOUR_EMBED_MODEL_ID";\n    static final String EMBED_MODEL_VERSION_ID = "YOUR_EMBED_MODEL_VERSION_ID";\n    static final String WORKFLOWNODE_ID = "my-custom-model";\n    static final String CUSTOM_MODEL_ID = "YOUR_CUSTOM_MODEL_ID";\n    static final String CUSTOM_MODEL_VERSION_ID = "YOUR_CUSTOM_MODEL_VERSION_ID";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n            .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        MultiWorkflowResponse postWorkflowsResponse = stub.postWorkflows(\n            PostWorkflowsRequest.newBuilder()\n            .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n            .addWorkflows(\n                Workflow.newBuilder()\n                .setId(WORKFLOW_ID)\n                .addNodes(\n                    WorkflowNode.newBuilder()\n                    .setId("embed")\n                    .setModel(\n                        Model.newBuilder()\n                        .setId(EMBED_MODEL_ID)\n                        .setModelVersion(\n                            ModelVersion.newBuilder()\n                            .setId(EMBED_MODEL_VERSION_ID)\n                        )\n                    )\n                )\n                .addNodes(\n                    WorkflowNode.newBuilder()\n                    .setId(WORKFLOWNODE_ID)\n                    .setModel(\n                        Model.newBuilder()\n                        .setId(CUSTOM_MODEL_ID)\n                        .setModelVersion(\n                            ModelVersion.newBuilder()\n                            .setId(CUSTOM_MODEL_VERSION_ID)\n                        )\n                    )\n                    .addNodeInputs(NodeInput.newBuilder().setNodeId("embed"))\n                )\n            )\n            .build()\n        );\n\n        if (postWorkflowsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post workflows failed, status: " + postWorkflowsResponse.getStatus());\n        }\n\n    }\n\n}',P='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\n\npublic class ClarifaiExample {\n\n    /////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, and default\n    // workflow ID. Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change this to update your default workflow\n    static final String DEFAULT_WORKFlOW_ID = "auto-annotation-workflow-id";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n            .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        MultiAppResponse patchAppsResponse = stub.patchApps(\n            PatchAppsRequest.newBuilder()\n            .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n            .setAction("overwrite")\n            .addApps(\n                App.newBuilder()\n                .setId(APP_ID)\n                .setDefaultWorkflowId(DEFAULT_WORKFlOW_ID)\n            ).build()\n        );\n\n        if (patchAppsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Patch apps failed, status: " + patchAppsResponse.getStatus());\n        }\n\n    }\n\n}',w='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models" \\\n    -H "Authorization: Key YOUR_PAT_HERE" \\\n    -H "Content-Type: application/json" \\\n    --data-raw \'{\n        "model": {\n            "id": "lawrence-1591638385",\n            "model_type_id": "visual-classifier",\n            "train_info": {\n                "params": {\n                    "template": "classification_cifar10_v1",\n                    "num_epochs": 2\n                }\n            },\n            "output_info": {\n                "data": {\n                    "concepts": [\n                        {"id":"ferrari23"},\n                        {"id":"outdoors23"}\n                    ]\n                },\n                "output_config": {\n                  "closed_environment" : true\n                }\n            }\n        }\n    }\'',S='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models" \\\n    -H "Authorization: Key YOUR_PAT_HERE" \\\n    -H "Content-Type: application/json" \\\n    --data-raw \'{\n        "model": {\n            "id": "detection-test-1591638385",\n            "model_type_id": "visual-detector",\n            "train_info": {\n                "params": {\n                    "template": "Clarifai_InceptionV2",\n                    "num_epochs": 2\n                }\n            },\n            "output_info": {\n                "data": {\n                    "concepts": [\n                        {"id":"ferrari23"},\n                        {"id":"outdoors23"}\n                    ]\n                },\n                "output_config": {\n                  "closed_environment" : true\n                }\n            }\n        }\n    }\'',R='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models" \\\n    -H "Authorization: Key YOUR_PAT_HERE" \\\n    -H "Content-Type: application/json" \\\n    --data-raw \'{\n        "model": {\n            "id": "embed-test-1591638385",\n            "model_type_id": "visual-embedder",\n            "train_info": {\n                "params": {\n                    "template": "classification_basemodel_v1_embed",\n                    "num_epochs": 2\n                }\n            },\n            "output_info": {\n                "data": {\n                    "concepts": [\n                        {"id":"ferrari23"},\n                        {"id":"outdoors23"}\n                    ]\n                },\n                "output_config": {\n                  "closed_environment" : true\n                }\n            }\n        }\n    }\'',A='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/workflows" \\\n    -H "Authorization: Key YOUR_PAT_HERE" \\\n    -H "Content-Type: application/json" \\\n    --data-raw \'{\n        "workflows": [\n            {\n                "id": "my-new-workflow-id",\n                "nodes": [\n                    {\n                        "id": "embed",\n                        "model": {\n                            "id": "YOUR_EMBED_MODEL_ID_HERE",\n                            "model_version": {\n                                "id": "YOUR_EMBED_MODEL_VERSION_ID_HERE"\n                            }\n                        }\n                    },\n                    {\n                        "id": "my-custom-model",\n                        "model": {\n                            "id": "YOUR_CUSTOM_MODEL_ID_HERE",\n                            "model_version": {\n                                "id": "YOUR_CUSTOM_MODEL_VERSION_ID_HERE"\n                            }\n                        },\n                        "node_inputs": [\n                            {\n                                "node_id": "embed"\n                            }\n                        ]\n                    }\n                ]\n            }\n        ]\n    }\'',N='curl -X PATCH "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/" \\\n    -H "Authorization: Key YOUR_PAT_HERE" \\\n    -H "Content-Type: application/json" \\\n    --data-raw \'{\n        "action": "overwrite",\n        "apps": [\n            {\n                "id": "YOUR_APP_ID_HERE",\n                "default_workflow_id": "auto-annotation-workflow-ID"\n            }\n        ]\n    }\'',y={description:"Train the complete graph of your model.",sidebar_position:6},U="Deep Fine-Tuning",v={unversionedId:"api-guide/model/deep-training",id:"api-guide/model/deep-training",title:"Deep Fine-Tuning",description:"Train the complete graph of your model.",source:"@site/docs/api-guide/model/deep-training.md",sourceDirName:"api-guide/model",slug:"/api-guide/model/deep-training",permalink:"/api-guide/model/deep-training",draft:!1,tags:[],version:"current",sidebarPosition:6,frontMatter:{description:"Train the complete graph of your model.",sidebar_position:6},sidebar:"tutorialSidebar",previous:{title:"Create, Train, Get, Update, Delete",permalink:"/api-guide/model/create-get-update-and-delete"},next:{title:"Evaluating Models",permalink:"/api-guide/evaluate/"}},k={},M=[{value:"Template Types",id:"template-types",level:2},{value:"Create Models",id:"create-models",level:2},{value:"Create a Visual Classifier",id:"create-a-visual-classifier",level:3},{value:"Create a Visual Detector",id:"create-a-visual-detector",level:3},{value:"Create a Visual Embedder",id:"create-a-visual-embedder",level:3},{value:"Create a Text Classifier",id:"create-a-text-classifier",level:3},{value:"Create a Visual Segmenter",id:"create-a-visual-segmenter",level:3},{value:"Create a Visual Anomaly Heatmap",id:"create-a-visual-anomaly-heatmap",level:3},{value:"Create a Workflow",id:"create-a-workflow",level:3},{value:"Update",id:"update",level:2},{value:"Update Your Default Workflow",id:"update-your-default-workflow",level:3}],H={toc:M},L="wrapper";function Y(e){let{components:n,...t}=e;return(0,o.kt)(L,(0,a.Z)({},H,t,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"deep-fine-tuning"},"Deep Fine-Tuning"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Train the complete graph of your model")),(0,o.kt)("hr",null),(0,o.kt)("p",null,'Clarifai offers a variety of prebuilt models that are designed to help you create AI solutions quickly and efficiently. Clarifai Models are the recommended starting points for many users because they offer incredibly fast training times when you customize them using the "Context-Based Classifier" type found in the Portal\'s Model Mode.'),(0,o.kt)("p",null,'But there are many cases where accuracy and the ability to carefully target solutions take priority over speed and ease of use. Additionally, you may need a model to learn new features, not recognized by existing Clarifai Models. For these cases, it is possible to "deep fine-tune" your custom models and integrate them directly within your workflows.'),(0,o.kt)("p",null,"In general, deep trained models need more data than those trained on top of Clarifai Models. For most applications, you\u2019ll need at least 1000 training inputs, but it could be much more than this, depending on your specific use case."),(0,o.kt)("p",null,"You might consider deep training if you have:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"A custom tailored dataset")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Accurate labels")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Expertise and time to fine-tune models"))),(0,o.kt)("h2",{id:"template-types"},"Template Types"),(0,o.kt)("p",null,"You can take advantage of a variety of templates when building your deep trained models. Templates give you the control to choose the specific architecture used by your neural network, and also define a set of hyperparameters that you can use to fine-tune the way your model learns."),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/model/deep-training/#template-types"},"Click here")," to learn more about the template types we offer\u2014alongside their hyperparameters. "),(0,o.kt)("admonition",{type:"info"},(0,o.kt)("p",{parentName:"admonition"},"The initialization code used in the following examples is outlined in detail on the ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/api-guide/api-overview/api-clients/#client-installation-instructions"},"client installation page."))),(0,o.kt)("h2",{id:"create-models"},"Create Models"),(0,o.kt)("h3",{id:"create-a-visual-classifier"},"Create a Visual Classifier"),(0,o.kt)("p",null,"Use a visual classifier model if you would like to classify images and video frames into a set of concepts."),(0,o.kt)(s.Z,{mdxType:"Tabs"},(0,o.kt)(r.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-python",mdxType:"CodeBlock"},l)),(0,o.kt)(r.Z,{value:"nodejs",label:"NodeJS",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-javascript",mdxType:"CodeBlock"},E)),(0,o.kt)(r.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-java",mdxType:"CodeBlock"},b)),(0,o.kt)(r.Z,{value:"curl",label:"cURL",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-bash",mdxType:"CodeBlock"},w))),(0,o.kt)("h3",{id:"create-a-visual-detector"},"Create a Visual Detector"),(0,o.kt)("p",null,"Create a visual detector model to detect bounding box regions in images or video frames and then classify the detected images. You can also send the image regions to an image cropper model to create a new cropped image."),(0,o.kt)(s.Z,{mdxType:"Tabs"},(0,o.kt)(r.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-python",mdxType:"CodeBlock"},u)),(0,o.kt)(r.Z,{value:"nodejs",label:"NodeJS",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-javascript",mdxType:"CodeBlock"},I)),(0,o.kt)(r.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-java",mdxType:"CodeBlock"},C)),(0,o.kt)(r.Z,{value:"curl",label:"cURL",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-bash",mdxType:"CodeBlock"},S))),(0,o.kt)("h3",{id:"create-a-visual-embedder"},"Create a Visual Embedder"),(0,o.kt)("p",null,'Create a visual embedding model to transform images and video frames into "high level" vector representation understood by our AI models. These embeddings enable visual search and can be used as base models to train other models.'),(0,o.kt)(s.Z,{mdxType:"Tabs"},(0,o.kt)(r.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-python",mdxType:"CodeBlock"},p)),(0,o.kt)(r.Z,{value:"nodejs",label:"NodeJS",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-javascript",mdxType:"CodeBlock"},D)),(0,o.kt)(r.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-java",mdxType:"CodeBlock"},T)),(0,o.kt)(r.Z,{value:"curl",label:"cURL",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-bash",mdxType:"CodeBlock"},R))),(0,o.kt)("h3",{id:"create-a-text-classifier"},"Create a Text Classifier"),(0,o.kt)("p",null,"Create a text classifier model to classify text into a set of concepts."),(0,o.kt)(s.Z,{mdxType:"Tabs"},(0,o.kt)(r.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-python",mdxType:"CodeBlock"},_))),(0,o.kt)("h3",{id:"create-a-visual-segmenter"},"Create a Visual Segmenter"),(0,o.kt)("p",null,"Create a visual segmenter model to segment a per-pixel mask in images where things are and then classify objects, descriptive words, or topics within the masks."),(0,o.kt)(s.Z,{mdxType:"Tabs"},(0,o.kt)(r.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-python",mdxType:"CodeBlock"},m))),(0,o.kt)("h3",{id:"create-a-visual-anomaly-heatmap"},"Create a Visual Anomaly Heatmap"),(0,o.kt)("p",null,"Create a visual anomaly model to perform visual anomaly detection with image-level score and anomaly heatmap."),(0,o.kt)(s.Z,{mdxType:"Tabs"},(0,o.kt)(r.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-python",mdxType:"CodeBlock"},f))),(0,o.kt)("h3",{id:"create-a-workflow"},"Create a Workflow"),(0,o.kt)("p",null,"Put your new deep-trained model to work by adding it to a workflow. Below is an example of how to create a workflow with a deep trained model."),(0,o.kt)(s.Z,{mdxType:"Tabs"},(0,o.kt)(r.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-python",mdxType:"CodeBlock"},c)),(0,o.kt)(r.Z,{value:"nodejs",label:"NodeJS",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-javascript",mdxType:"CodeBlock"},h)),(0,o.kt)(r.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-java",mdxType:"CodeBlock"},O)),(0,o.kt)(r.Z,{value:"curl",label:"cURL",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-bash",mdxType:"CodeBlock"},A))),(0,o.kt)("h2",{id:"update"},"Update"),(0,o.kt)("h3",{id:"update-your-default-workflow"},"Update Your Default Workflow"),(0,o.kt)("p",null,"Index your inputs with a deep trained model by updating your default workflow. You can also use your deep trained embeddings as the basis for clustering and search."),(0,o.kt)("p",null,"Below is an example of how to update your default workflow with a deep trained model."),(0,o.kt)(s.Z,{mdxType:"Tabs"},(0,o.kt)(r.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-python",mdxType:"CodeBlock"},d)),(0,o.kt)(r.Z,{value:"nodejs",label:"NodeJS",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-javascript",mdxType:"CodeBlock"},g)),(0,o.kt)(r.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-java",mdxType:"CodeBlock"},P)),(0,o.kt)(r.Z,{value:"curl",label:"cURL",mdxType:"TabItem"},(0,o.kt)(i.Z,{className:"language-bash",mdxType:"CodeBlock"},N))))}Y.isMDXComponent=!0}}]);