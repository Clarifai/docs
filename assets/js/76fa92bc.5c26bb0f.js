"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[2903],{14795:(e,t,n)=>{n.d(t,{A:()=>b});n(96540);var i=n(18215),r=n(26972),o=n(28774),s=n(53465),l=n(16654),d=n(21312),c=n(51107);const a={cardContainer:"cardContainer_fWXF",cardTitle:"cardTitle_rnsV",cardDescription:"cardDescription_PWke"};var h=n(74848);function u({className:e,href:t,children:n}){return(0,h.jsx)(o.A,{href:t,className:(0,i.A)("card padding--lg",a.cardContainer,e),children:n})}function p({className:e,href:t,icon:n,title:r,description:o}){return(0,h.jsxs)(u,{href:t,className:e,children:[(0,h.jsxs)(c.A,{as:"h2",className:(0,i.A)("text--truncate",a.cardTitle),title:r,children:[n," ",r]}),o&&(0,h.jsx)("p",{className:(0,i.A)("text--truncate",a.cardDescription),title:o,children:o})]})}function m({item:e}){const t=(0,r.Nr)(e),n=function(){const{selectMessage:e}=(0,s.W)();return t=>e(t,(0,d.T)({message:"1 item|{count} items",id:"theme.docs.DocCard.categoryDescription.plurals",description:"The default description for a category card in the generated index about how many items this category includes"},{count:t}))}();return t?(0,h.jsx)(p,{className:e.className,href:t,icon:"\ud83d\uddc3\ufe0f",title:e.label,description:e.description??n(e.items.length)}):null}function f({item:e}){const t=(0,l.A)(e.href)?"\ud83d\udcc4\ufe0f":"\ud83d\udd17",n=(0,r.cC)(e.docId??void 0);return(0,h.jsx)(p,{className:e.className,href:e.href,icon:t,title:e.label,description:e.description??n?.description})}function x({item:e}){switch(e.type){case"link":return(0,h.jsx)(f,{item:e});case"category":return(0,h.jsx)(m,{item:e});default:throw new Error(`unknown item type ${JSON.stringify(e)}`)}}const j={docCardListItem:"docCardListItem_W1sv"};function y({className:e}){const t=(0,r.a4)();return(0,h.jsx)(b,{items:t,className:e})}function g({item:e}){return(0,h.jsx)("article",{className:(0,i.A)(j.docCardListItem,"col col--6"),children:(0,h.jsx)(x,{item:e})})}function b(e){const{items:t,className:n}=e;if(!t)return(0,h.jsx)(y,{...e});const o=(0,r.d1)(t);return(0,h.jsx)("section",{className:(0,i.A)("row",n),children:o.map((e,t)=>(0,h.jsx)(g,{item:e},t))})}},28453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>l});var i=n(96540);const r={},o=i.createContext(r);function s(e){const t=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(o.Provider,{value:t},e.children)}},53465:(e,t,n)=>{n.d(t,{W:()=>c});var i=n(96540),r=n(44586);const o=["zero","one","two","few","many","other"];function s(e){return o.filter(t=>e.includes(t))}const l={locale:"en",pluralForms:s(["one","other"]),select:e=>1===e?"one":"other"};function d(){const{i18n:{currentLocale:e}}=(0,r.A)();return(0,i.useMemo)(()=>{try{return function(e){const t=new Intl.PluralRules(e);return{locale:e,pluralForms:s(t.resolvedOptions().pluralCategories),select:e=>t.select(e)}}(e)}catch(t){return console.error(`Failed to use Intl.PluralRules for locale "${e}".\nDocusaurus will fallback to the default (English) implementation.\nError: ${t.message}\n`),l}},[e])}function c(){const e=d();return{selectMessage:(t,n)=>function(e,t,n){const i=e.split("|");if(1===i.length)return i[0];i.length>n.pluralForms.length&&console.error(`For locale=${n.locale}, a maximum of ${n.pluralForms.length} plural forms are expected (${n.pluralForms.join(",")}), but the message contains ${i.length}: ${e}`);const r=n.select(t),o=n.pluralForms.indexOf(r);return i[Math.min(o,i.length-1)]}(n,t,e)}}},64602:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>a,contentTitle:()=>c,default:()=>p,frontMatter:()=>d,metadata:()=>i,toc:()=>h});const i=JSON.parse('{"id":"compute/inference/README","title":"Model Inference","description":"Perform predictions with models","source":"@site/docs/compute/inference/README.mdx","sourceDirName":"compute/inference","slug":"/compute/inference/","permalink":"/compute/inference/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"Perform predictions with models","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Supported Cloud Instances","permalink":"/compute/deployments/cloud-instances"},"next":{"title":"Model Inference","permalink":"/compute/inference/clarifai/"}}');var r=n(74848),o=n(28453),s=n(14795),l=n(95068);const d={description:"Perform predictions with models",sidebar_position:1},c="Model Inference",a={},h=[{value:"Predict With Compute Orchestration",id:"predict-with-compute-orchestration",level:2},{value:"Structure of Prediction Methods",id:"structure-of-prediction-methods",level:2},{value:"Predict With OpenAI-Compatible Format",id:"predict-with-openai-compatible-format",level:2}];function u(e){const t={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"model-inference",children:"Model Inference"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Perform predictions with models"})}),"\n",(0,r.jsx)("hr",{}),"\n",(0,r.jsx)(t.p,{children:"Clarifai\u2019s Compute Orchestration capabilities enable you to make prediction calls efficiently, tailored to a variety of use cases. You can use these features to run inferences seamlessly and get results from your model with ease."}),"\n",(0,r.jsx)(t.admonition,{type:"tip",children:(0,r.jsxs)(t.p,{children:["Check out ",(0,r.jsx)(t.a,{href:"https://github.com/toswari-ai/demo-clarifai-api",children:"this repository"})," for beginner-friendly examples on using Clarifai AI models for text, image, audio, and multimodal inference tasks."]})}),"\n",(0,r.jsx)(t.h2,{id:"predict-with-compute-orchestration",children:"Predict With Compute Orchestration"}),"\n",(0,r.jsxs)(t.p,{children:["To make a prediction request using our Compute Orchestration capabilities, you'll need to ",(0,r.jsx)(t.a,{href:"https://docs.clarifai.com/compute/deployments/clusters-nodepools",children:"set up a cluster"}),", create a nodepool, and ",(0,r.jsx)(t.a,{href:"https://docs.clarifai.com/compute/deployments/deploy-model",children:"deploy your model"})," to it."]}),"\n",(0,r.jsxs)(t.p,{children:["Once deployed, you\u2019ll need to reference the model\u2019s ",(0,r.jsx)(t.code,{children:"deployment_id"})," \u2014 or alternatively, specify both the ",(0,r.jsx)(t.code,{children:"compute_cluster_id"})," and ",(0,r.jsx)(t.code,{children:"nodepool_id"}),". These parameters ensure that your prediction request is routed correctly to the intended compute resources."]}),"\n",(0,r.jsx)(t.p,{children:"For example, you can route requests to a GCP cluster by selecting a corresponding deployment ID, use a different deployment ID for an AWS cluster, and yet another for an on-premises deployment."}),"\n",(0,r.jsx)(t.p,{children:"This gives you full control over performance, costs, and security, allowing you to focus on building cutting-edge AI solutions while we handle the infrastructure complexity."}),"\n",(0,r.jsx)(t.p,{children:"Here's how prediction requests are routed:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Prioritized deployment routing"})," \u2014 If you specify a deployment ID in the prediction request, Clarifai will route it directly to the associated nodepool."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Owner-defined default routing"})," \u2014  If you do not specify a deployment ID, but the model owner has pre-configured a deployment for that model version, the request will be routed to the nodepool specified in that deployment."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Fallback to shared routing"})," \u2014 If neither condition above is met and the model is uploaded and owned by Clarifai, the request defaults to the most cost-effective Clarifai shared compute nodepool."]}),"\n"]}),"\n",(0,r.jsxs)(t.blockquote,{children:["\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Note:"})," Shared compute is not available for user-uploaded models \u2014 you must set up a deployment when uploading your own models."]}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"structure-of-prediction-methods",children:"Structure of Prediction Methods"}),"\n",(0,r.jsx)(t.admonition,{title:"Supported Input and Output Data Types",type:"note",children:(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.a,{href:"https://docs.clarifai.com/compute/models/model-upload/data-types",children:"Click here"})," to explore the wide range of input and output data types supported by Clarifai\u2019s model framework. You'll also find client-side examples that show how to work with these rich data formats effectively."]})}),"\n",(0,r.jsxs)(t.p,{children:["Clarifai models are mostly built using three primary files: ",(0,r.jsx)(t.code,{children:"model.py"}),", ",(0,r.jsx)(t.code,{children:"requirements.txt"}),", and ",(0,r.jsx)(t.code,{children:"config.yaml"}),". As described ",(0,r.jsx)(t.a,{href:"https://docs.clarifai.com/compute/models/model-upload/#b-prediction-methods",children:"here"}),", the core prediction logic resides in ",(0,r.jsx)(t.code,{children:"model.py"}),", which defines how your model processes inputs and generates outputs."]}),"\n",(0,r.jsxs)(t.p,{children:["When making predictions on the client side, the structure of the prediction methods directly reflects the method signatures defined in the ",(0,r.jsx)(t.code,{children:"model.py"})," file. This one-to-one mapping allows you to make custom predictions with flexible naming and argument structures, giving you full control over how you invoke models."]}),"\n",(0,r.jsx)(t.p,{children:"Here are some examples of this method mapping approach:"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsxs)(t.th,{children:[(0,r.jsx)(t.code,{children:"model.py"})," Model Implementation"]}),(0,r.jsx)(t.th,{children:"Client-Side Usage Pattern"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"@ModelClass.method def predict(...)"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"model.predict(...)"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"@ModelClass.method def generate(...)"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"model.generate(...)"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"@ModelClass.method def stream(...)"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"model.stream(...)"})})]})]})]}),"\n",(0,r.jsxs)(t.p,{children:["This design provides flexibility in how to make model predictions. For example, a method could be defined as ",(0,r.jsx)(t.code,{children:"@ModelClass.method def analyze_video(...)"})," in ",(0,r.jsx)(t.code,{children:"model.py"}),", and then you can call it on the client side using ",(0,r.jsx)(t.code,{children:"model.analyze_video(...)"}),"."]}),"\n",(0,r.jsx)(t.p,{children:"Here are some key characteristics of this design:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Method names must match exactly between ",(0,r.jsx)(t.code,{children:"model.py"})," and client usage."]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"Parameters retain the same names and types as defined in the method."}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(t.p,{children:"Return types follow the structure defined by the model's outputs."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"predict-with-openai-compatible-format",children:"Predict With OpenAI-Compatible Format"}),"\n",(0,r.jsx)(t.p,{children:"Clarifai supports various providers that you can use to interact with different models. We offer an OpenAI-compatible API endpoint, allowing any OpenAI-compatible library or client to seamlessly send requests directly to Clarifai."}),"\n",(0,r.jsx)(t.admonition,{type:"info",children:(0,r.jsxs)(t.p,{children:["Base URL for Clarifai's OpenAI endpoint: ",(0,r.jsx)(t.code,{children:"https://api.clarifai.com/v2/ext/openai/v1"}),"."]})}),"\n",(0,r.jsx)(t.p,{children:"This integration capability offers several advantages, including:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Access to diverse models"})," \u2014 Harness Clarifai's rich array of models directly within your OpenAI projects, expanding your AI capabilities."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Standardized interaction"})," \u2014 Interact with Clarifai-hosted models using familiar OpenAI API patterns and interfaces, reducing the learning curve and streamlining development."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Enhanced flexibility"})," \u2014 Leverage the power of Clarifai's platform while maintaining the flexibility of your chosen OpenAI development environment."]}),"\n"]}),"\n",(0,r.jsx)(t.admonition,{type:"note",children:(0,r.jsx)(t.p,{children:"Usage-based billing is handled directly through Clarifai \u2014 not through OpenAI or any other provider. Also, while most OpenAI parameters are supported, certain advanced features may be unavailable depending on the specific model or endpoint."})}),"\n","\n",(0,r.jsx)(s.A,{items:(0,l.$S)().items})]})}function p(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(u,{...e})}):u(e)}},95068:(e,t,n)=>{n.d(t,{$S:()=>i});n(44586);function i(...e){return n(48295).$S(...e)}}}]);