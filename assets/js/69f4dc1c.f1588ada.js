"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[2445],{10205:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-2-4e67d00492953f287ec3d4469b3d2d4d.png"},11470:(e,n,t)=>{t.d(n,{A:()=>v});var o=t(96540),s=t(18215),i=t(23104),r=t(56347),l=t(205),a=t(57485),c=t(31682),d=t(70679);function h(e){return o.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function u(e){const{values:n,children:t}=e;return(0,o.useMemo)(()=>{const e=n??function(e){return h(e).map(({props:{value:e,label:n,attributes:t,default:o}})=>({value:e,label:n,attributes:t,default:o}))}(t);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function p({value:e,tabValues:n}){return n.some(n=>n.value===e)}function m({queryString:e=!1,groupId:n}){const t=(0,r.W6)(),s=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,a.aZ)(s),(0,o.useCallback)(e=>{if(!s)return;const n=new URLSearchParams(t.location.search);n.set(s,e),t.replace({...t.location,search:n.toString()})},[s,t])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:s}=e,i=u(e),[r,a]=(0,o.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!p({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:i})),[c,h]=m({queryString:t,groupId:s}),[f,x]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,s]=(0,d.Dv)(n);return[t,(0,o.useCallback)(e=>{n&&s.set(e)},[n,s])]}({groupId:s}),g=(()=>{const e=c??f;return p({value:e,tabValues:i})?e:null})();(0,l.A)(()=>{g&&a(g)},[g]);return{selectedValue:r,selectValue:(0,o.useCallback)(e=>{if(!p({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);a(e),h(e),x(e)},[h,x,i]),tabValues:i}}var x=t(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var y=t(74848);function j({className:e,block:n,selectedValue:t,selectValue:o,tabValues:r}){const l=[],{blockElementScrollPositionUntilNextRender:a}=(0,i.a_)(),c=e=>{const n=e.currentTarget,s=l.indexOf(n),i=r[s].value;i!==t&&(a(n),o(i))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return(0,y.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},e),children:r.map(({value:e,label:n,attributes:o})=>(0,y.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{l.push(e)},onKeyDown:d,onClick:c,...o,className:(0,s.A)("tabs__item",g.tabItem,o?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function b({lazy:e,children:n,selectedValue:t}){const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=i.find(e=>e.props.value===t);return e?(0,o.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,y.jsx)("div",{className:"margin-top--md",children:i.map((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function _(e){const n=f(e);return(0,y.jsxs)("div",{className:(0,s.A)("tabs-container",g.tabList),children:[(0,y.jsx)(j,{...n,...e}),(0,y.jsx)(b,{...n,...e})]})}function v(e){const n=(0,x.A)();return(0,y.jsx)(_,{...e,children:h(e.children)},String(n))}},19365:(e,n,t)=>{t.d(n,{A:()=>r});t(96540);var o=t(18215);const s={tabItem:"tabItem_Ymn6"};var i=t(74848);function r({children:e,hidden:n,className:t}){return(0,i.jsx)("div",{role:"tabpanel",className:(0,o.A)(s.tabItem,t),hidden:n,children:e})}},25168:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-7-55e16dc00ea5eae7af2f051bd13416e8.png"},29642:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-3-1-78af04ec08e5a1b9062082dab00ad521.png"},33808:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>b,contentTitle:()=>j,default:()=>w,frontMatter:()=>y,metadata:()=>o,toc:()=>_});const o=JSON.parse('{"id":"compute/deployments/clusters-nodepools","title":"Create Clusters and Nodepools","description":"Set up capabilities that match your computational needs","source":"@site/docs/compute/deployments/clusters-nodepools.md","sourceDirName":"compute/deployments","slug":"/compute/deployments/clusters-nodepools","permalink":"/compute/deployments/clusters-nodepools","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"Set up capabilities that match your computational needs","sidebar_position":1,"toc_max_heading_level":5},"sidebar":"tutorialSidebar","previous":{"title":"Deployments","permalink":"/compute/deployments/"},"next":{"title":"Deploy a Model","permalink":"/compute/deployments/deploy-model"}}');var s=t(74848),i=t(28453),r=t(11470),l=t(19365),a=t(73748);const c='from clarifai.client.user import User\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize the client\nclient = User(\n    user_id="YOUR_USER_ID_HERE"   \n)\n\n# Create a new compute cluster\ncompute_cluster = client.create_compute_cluster(\n    compute_cluster_id="test-compute-cluster",\n    config_filepath="./configs/compute_cluster_config.yaml"\n)\n',d="clarifai computecluster create COMPUTE_CLUSTER_ID --config COMPUTE-CLUSTER-CONFIG-FILEPATH",h='from clarifai.client.compute_cluster import ComputeCluster\n\n# Initialize the ComputeCluster instance\ncompute_cluster = ComputeCluster(\n    user_id="YOUR_USER_ID_HERE",           \n    compute_cluster_id="test-compute-cluster"        \n)\n',u='from clarifai.client.compute_cluster import ComputeCluster\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize the ComputeCluster instance\ncompute_cluster = ComputeCluster(\n    user_id="YOUR_USER_ID_HERE",\n    compute_cluster_id="test-compute-cluster"    \n)\n\n# Create a new nodepool \nnodepool = compute_cluster.create_nodepool(\n    nodepool_id="test-nodepool",\n    config_filepath="./configs/nodepool_config.yaml"\n)\n',p="clarifai nodepool create COMPUTE_CLUSTER_ID NODEPOOL_ID --config NODEPOOL-CONFIG-FILEPATH",m='from clarifai.client.nodepool import Nodepool\n\n# Initialize the Nodepool instance\nnodepool = Nodepool(\n    user_id="YOUR_USER_ID_HERE",            \n    nodepool_id="test-nodepool"         \n)\n',f='compute_cluster:\n  id: "test-compute-cluster"\n  description: "My AWS compute cluster"\n  cloud_provider:\n      id: "aws"\n  region: "us-east-1"\n  managed_by: "clarifai"\n  cluster_type: "dedicated"\n  visibility:\n    gettable: 10',x='nodepool:\n  id: "test-nodepool"\n  compute_cluster:\n    id: "test-compute-cluster"\n  description: "First nodepool in AWS in a proper compute cluster"\n  instance_types:\n    - id: "g5.2xlarge"\n      compute_info:\n        cpu_limit: "8"\n        cpu_memory: "28Gi"\n        accelerator_type:\n          - "a10"\n        num_accelerators: 1\n        accelerator_memory: "40Gi"\n  node_capacity_type:\n    capacity_types:\n      - 1\n  min_instances: 0\n  max_instances: 1',g='deployment:\n id: "test-deployment"\n description: "some random deployment"\n autoscale_config:\n   min_replicas: 0\n   max_replicas: 5\n   traffic_history_seconds: 300\n   scale_down_delay_seconds: 300\n   scale_to_zero_delay_seconds: 1800\n   scale_up_delay_seconds: 300\n   disable_packing: false\n worker:\n   model:\n     id: "Llama-3_2-3B-Instruct"\n     model_version:\n       id: "fe271b43266a45a5b068766b6437687f"\n     user_id: "meta"\n     app_id: "Llama-3"\n scheduling_choice: 4\n nodepools:\n   - id: "test-nodepool"\n     compute_cluster:\n         id: "test-compute-cluster"\n',y={description:"Set up capabilities that match your computational needs",sidebar_position:1,toc_max_heading_level:5},j="Create Clusters and Nodepools",b={},_=[{value:"<strong>Via the UI</strong>",id:"via-the-ui",level:2},{value:"Step 1: Start Creating a Cluster",id:"step-1-start-creating-a-cluster",level:3},{value:"Step 2: Select an Instance",id:"step-2-select-an-instance",level:3},{value:"Step 3: Set Node Autoscaling Range",id:"step-3-set-node-autoscaling-range",level:3},{value:"Step 4: Enable Spot Instances",id:"step-4-enable-spot-instances",level:3},{value:"Step 5: Provide Cluster and Nodepool Details",id:"step-5-provide-cluster-and-nodepool-details",level:3},{value:"Step 6: Finalize and Create the Cluster",id:"step-6-finalize-and-create-the-cluster",level:3},{value:"<strong>Via the API</strong>",id:"via-the-api",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Installation",id:"installation",level:4},{value:"Get a PAT",id:"get-a-pat",level:4},{value:"Set up Project Directory",id:"set-up-project-directory",level:4},{value:"1. <code>compute_cluster_config.yaml</code>",id:"1-compute_cluster_configyaml",level:5},{value:"2. <code>nodepool_config.yaml</code>",id:"2-nodepool_configyaml",level:5},{value:"3. <code>deployment_config.yaml</code>",id:"3-deployment_configyaml",level:5},{value:"Create a Cluster",id:"create-a-cluster",level:3},{value:"Create a Nodepool",id:"create-a-nodepool",level:3}];function v(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:o}=n;return o||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"create-clusters-and-nodepools",children:"Create Clusters and Nodepools"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Set up capabilities that match your computational needs"})}),"\n",(0,s.jsx)("hr",{}),"\n",(0,s.jsx)(n.p,{children:"A compute cluster serves as the main environment where models are deployed, whether for training or inference. Each cluster can contain multiple nodepools, which are groups of virtual machine instances with similar configurations (such as CPU/GPU type, memory)."}),"\n",(0,s.jsx)(n.p,{children:"After creating a custom cluster, you can configure nodepools within it to optimize resource usage. These nodepools will help tailor the infrastructure to meet the specific hardware, performance, cost, or regulatory compliance of your machine learning needs."}),"\n",(0,s.jsx)(n.p,{children:"For example, you may create a nodepool for GPU-intensive tasks and another for lighter workloads running on CPUs."}),"\n",(0,s.jsxs)(n.p,{children:["With clusters and nodepools, you can organize and manage (",(0,s.jsx)(n.em,{children:"orchestrate"}),") the compute resources necessary for running your models and workflows."]}),"\n",(0,s.jsx)(n.admonition,{title:"Connect Your Own Cloud",type:"info",children:(0,s.jsxs)(n.p,{children:["You can connect your existing AWS, Google Cloud (GCP), or Oracle infrastructure to leverage your current investments. This lets you maintain full control over your data while optimizing for cost and flexibility. ",(0,s.jsx)(n.a,{href:"https://www.clarifai.com/explore/contact-us",children:"Contact"})," our support team for assistance."]})}),"\n",(0,s.jsx)(n.h2,{id:"via-the-ui",children:(0,s.jsx)(n.strong,{children:"Via the UI"})}),"\n",(0,s.jsx)(n.h3,{id:"step-1-start-creating-a-cluster",children:"Step 1: Start Creating a Cluster"}),"\n",(0,s.jsxs)(n.p,{children:["Log in to the Clarifai platform and select the ",(0,s.jsx)(n.strong,{children:"Compute"})," option in the collapsible left sidebar."]}),"\n",(0,s.jsx)(n.p,{children:"You\u2019ll be redirected to the Compute Overview page, where you can view and create clusters, nodepools, and deployments."}),"\n",(0,s.jsxs)(n.p,{children:["Click the ",(0,s.jsx)(n.strong,{children:"Create a Cluster"})," button to begin setting up a new cluster along with its associated nodepool."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(10205).A+"",width:"4200",height:"2060"})}),"\n",(0,s.jsx)(n.p,{children:"You\u2019ll be redirected to a page, where you can specify the configurations for your new cluster and nodepool."}),"\n",(0,s.jsx)(n.h3,{id:"step-2-select-an-instance",children:"Step 2: Select an Instance"}),"\n",(0,s.jsx)(n.p,{children:"Select an instance type that aligns with your specific requirements. The table displays essential details for each instance type, which helps you make an informed decision."}),"\n",(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsxs)(n.p,{children:["See ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/compute/deployments/cloud-instances",children:"Supported Cloud Instances"})," to learn more about the instance types we provide."]})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(29642).A+"",width:"4200",height:"2062"})}),"\n",(0,s.jsx)(n.p,{children:"You can narrow down the displayed options using the filters and tools provided in the top bar:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Search bar"})," \u2014 Quickly find instance types by name."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Provider filter"})," \u2014 Choose from available cloud providers to match your preferred infrastructure."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Region filter"})," \u2014 Select the geographic location for the instance. Choosing a region closer to your users can reduce latency and improve performance."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Instance type filter"})," \u2014 Directly filter for a specific instance type if you already know what you're looking for."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Hardware filter"})," \u2014 Filter based on the instance's available hardware, such as CPU or GPU."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Price/hour filter"})," \u2014 Filter instances by their hourly cost, helping you manage your budget."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Sorting controls"})," \u2014 Click the sorting arrows next to each column header to sort values in ascending or descending order, making comparisons easier."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Before making your final choice, here are some key considerations to make:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Workload requirements (CPU and memory)"})," \u2014 For applications demanding significant processing power, opt for instances with a higher number of CPU cores. For example, a ",(0,s.jsx)(n.code,{children:"t3a.2xlarge"})," offers ",(0,s.jsx)(n.code,{children:"7.6 cores"}),", considerably more than a ",(0,s.jsx)(n.code,{children:"t3a.medium"})," with ",(0,s.jsx)(n.code,{children:"1.6 cores"}),". Also, the ",(0,s.jsx)(n.code,{children:"Gi"})," value displayed alongside the core count (such as ",(0,s.jsx)(n.code,{children:"2.99Gi"}),") indicates the amount of RAM in Gigabytes. A higher ",(0,s.jsx)(n.code,{children:"Gi"})," value signifies more available memory."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Cost sensitivity"})," \u2014 The ",(0,s.jsx)(n.code,{children:"PRICE/HR"})," column helps you evaluate cost. Choose an instance that balances price and performance according to your budget."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"GPU requirements"})," \u2014 If your workload involves intensive tasks like running models for video processing or other GPU-heavy tasks, you'll need to select instances equipped with GPUs."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Regulatory compliance"})," \u2013 Ensure the chosen region and instance type comply with any relevant data residency or industry-specific regulations."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Once you've found the right instance, click the circular radio button to the left of the row to select it."}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note:"})," For this example, let's select the AWS ",(0,s.jsx)(n.code,{children:"g4dn.xlarge"})," instance in the ",(0,s.jsx)(n.code,{children:"us-east-1"})," region. For the remaining details to be filled, we'll use the already provided default options. After selecting an instance, you can click the\xa0",(0,s.jsx)(n.a,{href:"#step-6-finalize-and-create-the-cluster",children:(0,s.jsx)(n.strong,{children:"Create Cluster"})}),"\xa0button to complete creating your cluster and nodepool. Otherwise, you can customize the rest of the settings to meet your needs."]}),"\n"]}),"\n",(0,s.jsx)("a",{id:"node-range"}),"\n",(0,s.jsx)(n.h3,{id:"step-3-set-node-autoscaling-range",children:"Step 3: Set Node Autoscaling Range"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(25168).A+"",width:"4180",height:"962"})}),"\n",(0,s.jsx)(n.p,{children:"Define the minimum and maximum number of nodes your nodepool can scale to based on workload demand. This ensures your system automatically adjusts its capacity by adding nodes during high traffic and scaling down during low usage, which balances performance and cost."}),"\n",(0,s.jsxs)(n.p,{children:["For example, setting the autoscaling range to ",(0,s.jsx)(n.strong,{children:"1\u20135"})," nodes allows the nodepool to scale up to handle more requests and scale down when demand drops."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Setting a minimum of ",(0,s.jsx)(n.strong,{children:"1"})," ensures that at least one node is always running. This helps avoid cold start delays after periods of inactivity, which is crucial for maintaining low-latency response times. However, it also means incurring continuous compute costs."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Setting a minimum of ",(0,s.jsx)(n.strong,{children:"0"})," reduces costs during idle periods, as no nodes will be running. Keep in mind this can introduce cold starts when traffic resumes, potentially impacting response times."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Choose your range based on the balance you need between cost-efficiency and responsiveness."}),"\n",(0,s.jsx)(n.admonition,{title:"model replicas",type:"info",children:(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"/compute/deployments/deploy-model#model-replica",children:"Click here"})," to learn how to configure model replicas to distribute your workload efficiently across multiple instances of a model."]})}),"\n",(0,s.jsx)(n.h3,{id:"step-4-enable-spot-instances",children:"Step 4: Enable Spot Instances"}),"\n",(0,s.jsxs)(n.p,{children:["You can enable this option  (",(0,s.jsx)(n.em,{children:"default is off"}),") if you want to rent spare, unused compute capacity at significantly lower prices compared to regular on-demand instances."]}),"\n",(0,s.jsx)(n.p,{children:"These spot instances are sourced from the underlying cloud provider (such as AWS or GCP) based on the region and instance type you've selected."}),"\n",(0,s.jsx)(n.p,{children:"If spot instances are unavailable, Clarifai will automatically fall back to on-demand instances to maintain service continuity."}),"\n",(0,s.jsx)(n.p,{children:"Keep in mind that spot instances can be terminated at any time if the capacity is reclaimed by the provider, which may cause temporary disruptions. For higher reliability and uninterrupted service, it's recommended to leave this option disabled and use on-demand instances only."}),"\n",(0,s.jsx)(n.h3,{id:"step-5-provide-cluster-and-nodepool-details",children:"Step 5: Provide Cluster and Nodepool Details"}),"\n",(0,s.jsx)(n.p,{children:"Fill out the form to specify the details for your cluster and nodepool."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(41527).A+"",width:"4180",height:"2316"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Cluster ID"})," \u2014 Enter a unique identifier for your cluster. This ID is used when deploying models and should reflect the cluster\u2019s purpose or workload. It is auto-filled based on your selected instance type, but you can modify it as needed."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Cluster Description"})," \u2014 Optionally, provide a short description that summarizes the details related to the cluster."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Nodepool ID"})," \u2014 Enter a unique identifier for your nodepool. This ID is used when deploying models and should reflect the nodepool\u2019s purpose or workload. It is auto-filled based on your selected instance type, but you can modify it as needed."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Nodepool Description"})," \u2014 Optionally, provide a short description that summarizes the details related to the nodepool."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Personal Access Token (PAT)"})," \u2014 Use a ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/control/authentication/pat",children:"PAT"})," to authenticate your identity when connecting to the cluster. Click the dropdown to choose from existing tokens, or create a new one by selecting ",(0,s.jsx)(n.strong,{children:"Create a new Personal Access Token"})," or by visiting the ",(0,s.jsx)(n.strong,{children:"Security"})," section in your personal settings.","\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note:"})," The token must have the required permissions to manage compute resources. Also, if the selected PAT is deleted, any associated compute functionality will stop working."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"step-6-finalize-and-create-the-cluster",children:"Step 6: Finalize and Create the Cluster"}),"\n",(0,s.jsxs)(n.p,{children:["Before you enter the required details for creating a cluster, the ",(0,s.jsx)(n.strong,{children:"Create Cluster"})," button in the upper-right corner will be disabled (greyed out). After providing the details, the button will become active."]}),"\n",(0,s.jsx)(n.p,{children:"Click it to launch your cluster and nodepool."}),"\n",(0,s.jsx)(n.p,{children:"You'll then be redirected to your newly created cluster's page, where its associated nodepool will be listed in a table."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(42030).A+"",width:"4180",height:"1266"})}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note:"})," ",(0,s.jsxs)(n.em,{children:["Alternatively, you can create a new nodepool from an existing cluster by clicking the ",(0,s.jsx)(n.strong,{children:"Create Nodepool"})," button in the upper-right corner of the cluster's page.You\u2019ll be redirected to a page where you can specify the configurations for your new nodepool."]})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"If you click on a nodepool listed in the table, you'll be taken to its individual page, where you can view its detailed information, such as the cluster type, instance type, and any resource deployments associated with it."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" ",src:t(58612).A+"",width:"4180",height:"1246"})}),"\n",(0,s.jsx)(n.h2,{id:"via-the-api",children:(0,s.jsx)(n.strong,{children:"Via the API"})}),"\n","\n","\n","\n",(0,s.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsx)(n.h4,{id:"installation",children:"Installation"}),"\n",(0,s.jsxs)(n.p,{children:["To begin, install the latest version of the ",(0,s.jsx)(n.code,{children:"clarifai"})," Python package. This will also install the Clarifai ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/resources/api-overview/cli/#clarifai-login",children:"Command Line Interface"})," (CLI), which we'll also use to demonstrate how to create clusters and nodepools."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:"pip install --upgrade clarifai\n"})}),"\n",(0,s.jsx)(n.h4,{id:"get-a-pat",children:"Get a PAT"}),"\n",(0,s.jsxs)(n.p,{children:["You need a ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/control/authentication/pat",children:"PAT (Personal Access Token)"})," key to authenticate with the Clarifai platform. You can generate one from your personal settings page under the ",(0,s.jsx)(n.strong,{children:"Security"})," section."]}),"\n",(0,s.jsx)(n.p,{children:"After generating it, set the token as an environment variable."}),"\n",(0,s.jsxs)(r.A,{groupId:"code",children:[(0,s.jsx)(l.A,{value:"bash",label:"Unix-Like Systems",children:(0,s.jsx)(a.A,{className:"language-bash",children:" export CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE "})}),(0,s.jsx)(l.A,{value:"bash2",label:"Windows",children:(0,s.jsx)(a.A,{className:"language-bash",children:" set CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE "})})]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note"}),": When you set the PAT as an environment variable, you don\u2019t need to hardcode it in your code. This also ensures that your CLI session is automatically authenticated with Clarifai."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"set-up-project-directory",children:"Set up Project Directory"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Create an overarching directory to store your project files."}),"\n",(0,s.jsx)(n.li,{children:"Inside this directory, create a Python file for your Compute Orchestration code."}),"\n",(0,s.jsxs)(n.li,{children:["Create a ",(0,s.jsx)(n.code,{children:"configs"})," folder to store your YAML configuration files for clusters, nodepools, and deployments."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Here\u2019s the structure of the directory:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"project-directory/               # Overarching project folder\n\u2502\n\u251c\u2500\u2500 compute_orchestration.py     # Python file for your orchestration code\n\u2502\n\u2514\u2500\u2500 configs/                     # Folder for configuration files\n    \u251c\u2500\u2500 compute_cluster_config.yaml\n    \u251c\u2500\u2500 nodepool_config.yaml\n    \u2514\u2500\u2500 deployment_config.yaml\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Then, add the following code snippets to their corresponding files in the ",(0,s.jsx)(n.code,{children:"configs"})," folder."]}),"\n",(0,s.jsxs)(n.h5,{id:"1-compute_cluster_configyaml",children:["1. ",(0,s.jsx)(n.code,{children:"compute_cluster_config.yaml"})]}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(l.A,{value:"yaml",label:"YAML",children:(0,s.jsx)(a.A,{className:"language-yaml",children:f})})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"compute_cluster"})," \u2014 Defines the top-level configuration for the compute cluster."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"compute_cluster.id"})," \u2014 A unique identifier for the cluster within the Clarifai workspace (here, named ",(0,s.jsx)(n.em,{children:"test-compute-cluster"}),")."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"compute_cluster.description"})," \u2014 A human-readable description of the cluster."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"compute_cluster.cloud_provider.id"})," \u2014 The cloud provider that will host the cluster. Clarifai supports a wide range of providers, such as ",(0,s.jsx)(n.code,{children:"aws"})," and ",(0,s.jsx)(n.code,{children:"gcp"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"compute_cluster.region"})," \u2014 Geographic region for the resources. Must be a region supported by the selected provider. Choosing the right region reduces latency to your data and can affect cost."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"compute_cluster.managed_by"})," \u2014 Who is responsible for lifecycle management. ",(0,s.jsx)(n.code,{children:"clarifai"})," means the platform will automatically handle patching, scaling, and health\u2011checks, rather than self-managed."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"compute_cluster.cluster_type"})," \u2014 Mode of operation. ",(0,s.jsx)(n.code,{children:"dedicated"})," means the cluster\u2019s compute resources are reserved exclusively for your workloads (not shared)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"compute_cluster.visibility.gettable"})," \u2014 A numeric permission level that defines who can see or access the cluster. ",(0,s.jsx)(n.code,{children:"10"})," means it's visible privately."]}),"\n"]}),"\n",(0,s.jsxs)(n.h5,{id:"2-nodepool_configyaml",children:["2. ",(0,s.jsx)(n.code,{children:"nodepool_config.yaml"})]}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(l.A,{value:"yaml",label:"YAML",children:(0,s.jsx)(a.A,{className:"language-yaml",children:x})})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool"})," \u2014 Defines the top-level configuration for the nodepool."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.id"})," \u2014 A unique identifier for the nodepool within the workspace (here, named ",(0,s.jsx)(n.em,{children:"test-nodepool"}),")."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.compute_cluster.id"})," \u2014 The ID of the parent compute cluster that this nodepool belongs to. The cluster must already exist."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.description"})," \u2014 A human-readable description of the nodepool."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.instance_types"})," \u2014 A list that details the types of instances (virtual machines) that will make up this nodepool."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.instance_types[0].id"})," \u2014 Specifies the type of instance to use; in this case, ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/compute/deployments/cloud-instances/#g5-instances",children:'"g5.2xlarge,"'})," which is a type of GPU-optimized instance from AWS."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.instance_types[0].compute_info"})," \u2014 A nested object that provides detailed specifications for the instance."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.instance_types[0].compute_info.cpu_limit"})," \u2014 Number of virtual CPUs the instance provides. It's stored as a string (follows ",(0,s.jsx)(n.a,{href:"https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/quantity/",children:"Kubernetes notation"}),"), and the value must match the provider\u2019s specification for the chosen type."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.instance_types[0].compute_info.cpu_memory"})," \u2014 Amount of system memory (RAM) available to the node. The value can be expressed in gigabytes (Gi) or other supported memory units."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.instance_types[0].compute_info.accelerator_type"})," \u2014 A list specifying the type of accelerator. In this case, it's an NVIDIA A10."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.instance_types[0].compute_info.num_accelerators"})," \u2014 The number of accelerators (GPUs) per instance."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.instance_types[0].compute_info.accelerator_memory"})," \u2014 The memory of the accelerator."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.node_capacity_type.capacity_types"})," \u2014 A list of numerical values specifying allowed capacity modes for the nodepool. In this case, ",(0,s.jsx)(n.code,{children:"1"}),' correspond to "on-demand" instances (standard pricing) and ',(0,s.jsx)(n.code,{children:"2"}),' for "spot" instances (lower cost, but can be reclaimed).']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.min_instances"})," \u2014 The minimum number of instances that must run in the nodepool at any time. A value of ",(0,s.jsx)(n.code,{children:"0"})," allows the pool to scale down to zero instances when idle."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"nodepool.max_instances"})," \u2014 The maximum number of instances the nodepool can scale to. A value of ",(0,s.jsx)(n.code,{children:"0"})," disables the pool, while higher values (e.g., ",(0,s.jsx)(n.code,{children:"10"}),") allow scaling out as demand increases."]}),"\n"]}),"\n",(0,s.jsxs)(n.h5,{id:"3-deployment_configyaml",children:["3. ",(0,s.jsx)(n.code,{children:"deployment_config.yaml"})]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.em,{children:["We'll use this later to ",(0,s.jsx)(n.a,{href:"/compute/deployments/deploy-model#via-the-api",children:"deploy the model"}),"."]})}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(l.A,{value:"yaml",label:"YAML",children:(0,s.jsx)(a.A,{className:"language-yaml",children:g})})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment"})," \u2014 Defines the top-level deployment configuration, which specifies how a model runs in a compute environment."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.id"})," \u2014 A unique identifier for this deployment. (here, named ",(0,s.jsx)(n.em,{children:"test-deployment"}),")."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.description"})," \u2014 A human-readable description of the deployment."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.autoscale_config"})," \u2014 This section dictates how the deployment will automatically adjust its resources based on demand."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.autoscale_config.min_replicas"})," \u2014 The minimum number of running replicas the deployment is allowed to have. Setting it to 0 means the service can shut down completely when there is no traffic, saving costs."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.autoscale_config.max_replicas"})," \u2014 The maximum number of concurrent replicas. Setting it to 1 means the deployment will never have more than one copy of the model running."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.autoscale_config.traffic_history_seconds"})," \u2014 Length of the sliding window (in seconds) that the autoscaler looks at to decide whether to scale up or down. A longer window smooths out spikes; a shorter window reacts faster."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.autoscale_config.scale_down_delay_seconds"})," \u2014 The waiting period (in seconds) before scaling down after low traffic. This prevents \u201cthrashing\u201d when traffic briefly dips."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.autoscale_config.scale_to_zero_delay_seconds"})," \u2014 The waiting period (in seconds) before scaling all the way down to zero replicas after traffic stops. It must be greater than or equal to ",(0,s.jsx)(n.code,{children:"scale_down_delay_seconds"})," to ensure that normal scale-down events happen before the system completely shuts down idle workers."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.autoscale_config.scale_up_delay_seconds"})," \u2014  The waiting period (in seconds) before scaling up after detecting higher demand. This gives the system a chance to see if the spike is sustained."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.autoscale_config.disable_packing"})," \u2014 Packing means placing multiple replicas on the same node when possible (to improve bin\u2011packing and reduce costs). ",(0,s.jsx)(n.code,{children:"false"})," means packing is allowed (the default). Set to ",(0,s.jsx)(n.code,{children:"true"})," if you want each replica on a dedicated node for isolation."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.worker"})," \u2014 This section specifies the core component of the deployment, which is the machine learning model itself."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.worker.model"})," \u2014 Specifies which model this deployment serves."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.worker.model.id"})," \u2014 The model ID."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.worker.model.model_version.id"})," \u2014 Refers to a specific version of the model."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.worker.model.user_id"})," \u2014 The model owner\u2019s Clarifai user ID."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.worker.model.app_id"})," \u2014 The application (or project) under which the model lives."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.scheduling_choice"})," \u2014 An integer that maps to a pre\u2011defined scheduling policy. Typical mapping: 1\u202f=\u202fSpread (maximise fault\u2011tolerance), < 2\u202f=\u202fPack, < 3\u202f=\u202fSpot\u2011first, 4\u202f=\u202fHybrid (prefer on\u2011demand, fall back to spot), etc."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.nodepools"})," \u2014 Lists the nodepools where the deployment\u2019s workers can run."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.nodepools[0].id"})," \u2014 Refers to the specific nodepool where the deployment will be hosted."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"deployment.nodepools[0].compute_cluster.id"})," \u2014 Ensures this deployment is tied to the right, parent compute cluster."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"create-a-cluster",children:"Create a Cluster"}),"\n",(0,s.jsxs)(n.p,{children:["To create a new compute cluster, pass the ",(0,s.jsx)(n.code,{children:"compute_cluster_id"})," and ",(0,s.jsx)(n.code,{children:"config_filepath"})," as arguments to the ",(0,s.jsx)(n.code,{children:"create_compute_cluster"})," method of the ",(0,s.jsx)(n.code,{children:"User"})," class."]}),"\n",(0,s.jsxs)(r.A,{groupId:"code",children:[(0,s.jsx)(l.A,{value:"python",label:"Python SDK",children:(0,s.jsx)(a.A,{className:"language-python",children:c})}),(0,s.jsx)(l.A,{value:"bash",label:"CLI",children:(0,s.jsx)(a.A,{className:"language-yaml",children:d})})]}),"\n",(0,s.jsxs)(o,{children:[(0,s.jsx)("summary",{children:"Example Output"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:'[INFO] 22:41:42.362861 Compute Cluster with ID \'test-compute-cluster\' is created:\ncode: SUCCESS\ndescription: "Ok"\nreq_id: "sdk-python-11.7.5-1a5ceed7df3346dbb2451f2501f37f66"\n'})})]}),"\n",(0,s.jsxs)(n.p,{children:["After creating it, initialize the ",(0,s.jsx)(n.code,{children:"ComputeCluster"})," class by providing the ",(0,s.jsx)(n.code,{children:"user_id"})," and ",(0,s.jsx)(n.code,{children:"compute_cluster_id"})," parameters."]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note:"})," Initialization is essential because it establishes the specific user and compute cluster context, which allows the subsequent operations to accurately target and manage the intended resources."]}),"\n"]}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(l.A,{value:"python",label:"Python SDK",children:(0,s.jsx)(a.A,{className:"language-python",children:h})})}),"\n",(0,s.jsx)(n.h3,{id:"create-a-nodepool",children:"Create a Nodepool"}),"\n",(0,s.jsxs)(n.p,{children:["To create a new nodepool within an already existing cluster, use the ",(0,s.jsx)(n.code,{children:"create_nodepool"})," method with the ",(0,s.jsx)(n.code,{children:"nodepool_id"})," and ",(0,s.jsx)(n.code,{children:"config_filepath"})," parameters."]}),"\n",(0,s.jsxs)(r.A,{groupId:"code",children:[(0,s.jsx)(l.A,{value:"python",label:"Python SDK",children:(0,s.jsx)(a.A,{className:"language-python",children:u})}),(0,s.jsx)(l.A,{value:"bash",label:"CLI",children:(0,s.jsx)(a.A,{className:"language-yaml",children:p})})]}),"\n",(0,s.jsxs)(o,{children:[(0,s.jsx)("summary",{children:"Example Output"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:'[INFO] 23:09:07.978155 Nodepool with ID \'test-nodepool\' is created:\ncode: SUCCESS\ndescription: "Ok"\nreq_id: "sdk-python-11.7.5-99ad19030249400cabd9be8ade0df602"\n'})})]}),"\n",(0,s.jsxs)(n.p,{children:["After creating it, initialize the ",(0,s.jsx)(n.code,{children:"Nodepool"})," class by providing the ",(0,s.jsx)(n.code,{children:"user_id"})," and ",(0,s.jsx)(n.code,{children:"nodepool_id"})," parameters."]}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(l.A,{value:"python",label:"Python SDK",children:(0,s.jsx)(a.A,{className:"language-python",children:m})})})]})}function w(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(v,{...e})}):v(e)}},41527:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-8-17029ba2156167c1979a21f5a92f29af.png"},42030:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-9-64fc5862b79d21275b5051bfbee98aa3.png"},58612:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute-10-f18f7d64c385c0c20f1c95297740dc49.png"}}]);