"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[8086],{10354:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-7-af07f85fc948f62aed1c033ab86332f8.png"},24918:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-3-4c77455383f746187b5511ca297dd530.png"},28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>l});var i=t(96540);const a={},s=i.createContext(a);function o(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:n},e.children)}},29464:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/create_annotations_2-39c99d2ac823b2de2e25a119c84776df.png"},31899:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-6-7a263e2ec8999af0f31464e561be89b0.png"},32878:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/create_annotations_4-cd79ab0e962a9288db54b296fe3eba21.png"},39509:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-8-4f99446c141bab643451998a8746e0ab.png"},47880:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>r});const i=JSON.parse('{"id":"create/labeling/ui/create","title":"Create Annotations","description":"Learn how to create annotations","source":"@site/docs/create/labeling/ui/create.md","sourceDirName":"create/labeling/ui","slug":"/create/labeling/ui/create","permalink":"/create/labeling/ui/create","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"Learn how to create annotations","sidebar_position":1,"toc_max_heading_level":5},"sidebar":"tutorialSidebar","previous":{"title":"Labeling via the UI","permalink":"/create/labeling/ui/"},"next":{"title":"Bulk Labeling","permalink":"/create/labeling/ui/bulk"}}');var a=t(74848),s=t(28453);const o={description:"Learn how to create annotations",sidebar_position:1,toc_max_heading_level:5},l="Create Annotations",c={},r=[{value:"Label on Inputs-Manager Page",id:"label-on-inputs-manager-page",level:2},{value:"Classification Labeling",id:"classification-labeling",level:3},{value:"Label on Input-Viewer Page",id:"label-on-input-viewer-page",level:2},{value:"Classification Labeling",id:"classification-labeling-1",level:3},{value:"Image Classification",id:"image-classification",level:4},{value:"Text Classification",id:"text-classification",level:4},{value:"Video Classification",id:"video-classification",level:4},{value:"Detection Labeling",id:"detection-labeling",level:3},{value:"Detection for Still Images",id:"detection-for-still-images",level:4},{value:"Detection for Video",id:"detection-for-video",level:4},{value:"Segmentation Labeling",id:"segmentation-labeling",level:3},{value:"Masks Labeling",id:"masks-labeling",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"create-annotations",children:"Create Annotations"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Learn how to create annotations"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsx)(n.p,{children:"We support different types of labeling methods, each suited for different tasks and data characteristics. This lets you create high-quality training data depending on the objective you want your AI model to achieve."}),"\n",(0,a.jsx)(n.p,{children:"These are the different types of labels we support for your image, video, and text inputs:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Classification"})," \u2014 Categorizes images, videos, and texts into categories;"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Detection"})," \u2014 Detects where an object of interest is and draws a bounding box around it;"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Segmentation"})," (polygons for segmentation) \u2014 Outlines the exact shape or contour of the object;"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Masks"})," \u2014  A type of image segmentation that defines the exact boundaries of an object at a pixel level."]}),"\n"]}),"\n",(0,a.jsx)(n.admonition,{title:"AI-assisted labeling",type:"info",children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/annotate/ai-assist",children:"Click here"})," to learn how to use the AI-assisted labeling feature to carry out different label types."]})}),"\n",(0,a.jsx)(n.admonition,{title:"Labeling Tasks Tool",type:"info",children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/annotate/labeling-tools",children:"Click here"})," to learn how to use the Labeling Tasks tool to carry out different label types."]})}),"\n",(0,a.jsx)(n.h2,{id:"label-on-inputs-manager-page",children:"Label on Inputs-Manager Page"}),"\n",(0,a.jsxs)(n.p,{children:["To label your inputs, head to your application's individual page. Then, select the ",(0,a.jsx)(n.strong,{children:"Inputs"})," option in the collapsible left sidebar."]}),"\n",(0,a.jsx)(n.p,{children:"You'll be redirected to the Input Mode of the Inputs-Manager page, where you can create and manage the annotations of your inputs. It is the default mode of the Inputs-Manager page."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(75219).A+"",width:"1858",height:"817"})}),"\n",(0,a.jsx)(n.p,{children:"You can use different ways to label your inputs."}),"\n",(0,a.jsx)(n.h3,{id:"classification-labeling",children:"Classification Labeling"}),"\n",(0,a.jsx)(n.p,{children:"To label an image input for classification tasks on the Inputs-Manager page, hover over it and click the small empty box in the upper-left corner to select it."}),"\n",(0,a.jsx)(n.admonition,{title:"multi-select feature",type:"tip",children:(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Mouse click"}),": Selects a single item or input."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Shift + mouse click"}),": Selects a range of inputs between the first and last clicked item."]}),"\n"]})}),"\n",(0,a.jsxs)(n.p,{children:["Next, click the ",(0,a.jsx)(n.strong,{children:"Label as\u2026"})," button that appears at the bottom section of the page."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(29464).A+"",width:"1872",height:"826"})}),"\n",(0,a.jsx)(n.p,{children:"The small window that pops up allows you to annotate the selected input(s) with concepts."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(32878).A+"",width:"1780",height:"801"})}),"\n",(0,a.jsxs)(n.p,{children:["Select the ",(0,a.jsx)(n.strong,{children:"Add"})," option, which lets you add annotations to your inputs (the option is selected by default)."]}),"\n",(0,a.jsx)(n.p,{children:"If you want to create a new concept and use it for labeling your inputs:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Click the plus sign (",(0,a.jsx)(n.strong,{children:"+"}),") next to the ",(0,a.jsx)(n.strong,{children:"Select or add concepts"})," search field;"]}),"\n",(0,a.jsx)(n.li,{children:"Type the new concept name in the search field. The new name you've typed will appear underneath the search field;"}),"\n",(0,a.jsxs)(n.li,{children:["Click the ",(0,a.jsx)(n.strong,{children:"Add new concept"})," button to create the concept. The new concept will be successfully added to your app;"]}),"\n",(0,a.jsxs)(n.li,{children:["Finally, click the ",(0,a.jsx)(n.strong,{children:"Add to inputs"})," button at the bottom of the pop-up window to complete labeling your inputs with the newly created concept."]}),"\n"]}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:["If you select the ",(0,a.jsx)(n.strong,{children:"Apply to all search results"})," button, all the inputs that are visually similar to the one(s) you've initially selected will also be annotated. This allows you to label your inputs easily and fast."]})}),"\n",(0,a.jsxs)(n.p,{children:["If you've already created concepts and want to use them for annotating your input(s), simply select them from the ",(0,a.jsx)(n.strong,{children:"Concepts"})," field."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(50593).A+"",width:"1805",height:"799"})}),"\n",(0,a.jsxs)(n.p,{children:["After selecting the already existing concepts, click the ",(0,a.jsx)(n.strong,{children:"Add to inputs"})," button at the bottom of the pop-up window to complete labeling your inputs with them."]}),"\n",(0,a.jsx)(n.h2,{id:"label-on-input-viewer-page",children:"Label on Input-Viewer Page"}),"\n",(0,a.jsx)(n.p,{children:"If you click an input listed on the Inputs-Manager page, you'll be redirected to the viewer page for that input, where you can view and interact with it."}),"\n",(0,a.jsxs)(n.p,{children:["To carry out manual annotation on the Input-Viewer page, ensure the page's mode is set to ",(0,a.jsx)(n.strong,{children:"Annotate"}),", which is the default status. You can find the mode settings in the upper-left corner of the page."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(77092).A+"",width:"1906",height:"902"})}),"\n",(0,a.jsx)(n.h3,{id:"classification-labeling-1",children:"Classification Labeling"}),"\n",(0,a.jsx)(n.p,{children:"The classification label type lets you assign annotations to an entire image, a single frame of video, or a piece of text."}),"\n",(0,a.jsx)(n.h4,{id:"image-classification",children:"Image Classification"}),"\n",(0,a.jsxs)(n.p,{children:["To manually classify an image on the Input-Viewer page, start by clicking the ",(0,a.jsx)(n.strong,{children:"Select / Edit"})," tool in the navigation bar (this tool is selected by default)."]}),"\n",(0,a.jsxs)(n.p,{children:["Next, use the ",(0,a.jsx)(n.strong,{children:"Select label"})," menu  that drops down to select the concept you want to use to annotate the image \u2014 that is, if the concept already exists in your app."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(62367).A+"",width:"1907",height:"886"})}),"\n",(0,a.jsxs)(n.p,{children:["If you want to annotate an image with a new concept that does not already exist in your app, click the ",(0,a.jsx)(n.strong,{children:"+"})," (plus) button in the dropdown menu and type the concept's name in the field. Then, click the dropdown box that appears with the concept name beneath that field."]}),"\n",(0,a.jsx)(n.p,{children:"The new concept will be added to your app and labeled with your input."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(24918).A+"",width:"1320",height:"903"})}),"\n",(0,a.jsxs)(n.p,{children:["You can add as many annotations as you want. The added annotations will appear in the ",(0,a.jsx)(n.strong,{children:"Select label"})," dropdown menu as well as in the ",(0,a.jsx)(n.strong,{children:"Classifications"})," pane in the right sidebar of the page."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(74889).A+"",width:"1904",height:"887"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Alternatively, you can manually classify an image on the Input-Viewer page by navigating to the ",(0,a.jsx)(n.strong,{children:"Classifications"})," pane. Then, use the ",(0,a.jsx)(n.strong,{children:"Select or add concepts"})," search box to choose or add concepts for annotating your inputs, as described earlier."]})}),"\n",(0,a.jsx)(n.h4,{id:"text-classification",children:"Text Classification"}),"\n",(0,a.jsx)(n.p,{children:"You can classify your text inputs into predefined categories in the same way as described earlier for image classification."}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Ensure you select the appropriate ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/workflows/base-workflows",children:"base workflow"})," when creating an app for text inputs."]})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(50688).A+"",width:"1910",height:"894"})}),"\n",(0,a.jsx)(n.h4,{id:"video-classification",children:"Video Classification"}),"\n",(0,a.jsxs)(n.p,{children:["Support for video labeling within this tool is coming soon. If you need to label videos, you can create a ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/labeling-tasks/create-a-task",children:"Labeling Task"})," and label a dataset with videos."]}),"\n",(0,a.jsx)(n.h3,{id:"detection-labeling",children:"Detection Labeling"}),"\n",(0,a.jsx)(n.p,{children:"The detection label type lets you identify the objects in your inputs and also draw bounding boxes around them."}),"\n",(0,a.jsx)(n.h4,{id:"detection-for-still-images",children:"Detection for Still Images"}),"\n",(0,a.jsxs)(n.p,{children:["To manually add detection labels on the Input-Viewer page, start by clicking the ",(0,a.jsx)(n.strong,{children:"Bounding Box"})," tool in the navigation bar."]}),"\n",(0,a.jsxs)(n.p,{children:["Next, use the ",(0,a.jsx)(n.strong,{children:"Select label"})," menu that drops down to select the concept you want to use to annotate the image \u2014 that is, if the concept already exists in your app. If it's not already existing, you'll need to add it as described earlier."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(98284).A+"",width:"1908",height:"896"})}),"\n",(0,a.jsx)(n.p,{children:"Next, draw a rectangle as accurately as possible around the region of interest in the image. You can also create cascading bounding boxes; that is, a hierarchy of annotations where one bounding box is nested or dependent on another."}),"\n",(0,a.jsx)(n.p,{children:"After creating the bounding box, you can edit it by clicking on it until dotted lines appear around the edges. This will enable you to resize, reposition, or adjust the bounding box to better suit your needs."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(31899).A+"",width:"1892",height:"893"})}),"\n",(0,a.jsx)(n.admonition,{title:"drawing mode",type:"note",children:(0,a.jsxs)(n.p,{children:["After selecting a concept for labeling, the drawing mode will be activated, allowing you to draw bounding boxes to annotate your image(s) easily. The drawing mode box, located in the upper-right corner of the canvas, displays the concept currently in use for detection labeling. To exit drawing mode, simply click the ",(0,a.jsx)(n.strong,{children:"Exit"})," button."]})}),"\n",(0,a.jsxs)(n.p,{children:["You can add as many detection annotations as you want for each concept. The added annotations will appear in the ",(0,a.jsx)(n.strong,{children:"Select label"})," dropdown menu as well as in the ",(0,a.jsx)(n.strong,{children:"Objects"})," pane in the right sidebar of the page."]}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.strong,{children:"Objects"})," pane displays categories of concepts used for annotations, along with individual annotation instances. It supports several detection labeling activities, including:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Annotation count display"}),' \u2014 The pane shows the number of annotations for each instance. For example, "Objects(2)" indicates that two concept categories were used for the detection annotations in the image, while "sheep(4)" means that four instances are labeled with the ',(0,a.jsx)(n.code,{children:"sheep"}),' concept. Individual annotations are numbered sequentially. For example, "sheep.1" represents the first annotation labeled with the ',(0,a.jsx)(n.code,{children:"sheep"}),' concept, "sheep.2" the second annotation, and so on.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Hotkey assignment"}),' \u2014 Each concept is assigned a hotkey. Pressing a hotkey initiates labeling for that concept. For example, pressing "1" enables you to draw bounding boxes labeled with the ',(0,a.jsx)(n.code,{children:"sheep"})," concept. Up to 20 hotkeys can be assigned to your concepts."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Category-specific actions"})," \u2014 These are the actions you can complete on an annotation category:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Clicking the bounding box icon in a category field activates the drawing mode, which allows you to create annotations with the selected concept."}),"\n",(0,a.jsx)(n.li,{children:"Hovering over a category of annotations reveals these icons: pencil icon for updating the concept name (as described earlier), eye icon for hiding all the annotations in that category, and delete icon for removing all the annotations in that category."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Instance-specific actions"})," \u2014 These are the actions you can complete on an individual annotation instance:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"To delete an individual annotation, deselect its checkmark."}),"\n",(0,a.jsx)(n.li,{children:"Hovering over the person icon on an annotation instance shows the annotator(s) responsible for that annotation. The number displayed represents how many annotators labeled the input."}),"\n",(0,a.jsx)(n.li,{children:"Hovering over an individual annotation instance reveals these icons: pencil icon for reassigning the annotation to a different concept, eye icon for hiding the specific annotation instance, and delete icon for removing the specific annotation instance."}),"\n",(0,a.jsx)(n.li,{children:"Clicking an individual annotation instance highlights its corresponding bounding box in the canvas, enabling easy editing or deletion (by clicking the delete button on the keyboard)."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"detection-for-video",children:"Detection for Video"}),"\n",(0,a.jsx)(n.p,{children:"Support for video labeling is coming soon."}),"\n",(0,a.jsx)(n.admonition,{title:"object mode",type:"info",children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/inputs-manager/#object-mode",children:"Click here"})," to learn how to get the objects that have been labeled on your inputs using the Object Mode of the Inputs-Manager page."]})}),"\n",(0,a.jsx)(n.h3,{id:"segmentation-labeling",children:"Segmentation Labeling"}),"\n",(0,a.jsx)(n.p,{children:"The segmentation label type lets you outline a boundary of an object using a series of vertices that define a closed polygonal shape. It's ideal for annotating irregularly shaped areas or objects."}),"\n",(0,a.jsxs)(n.p,{children:["To manually add segmentation labels to an image on the Input-Viewer page, first click the ",(0,a.jsx)(n.strong,{children:"Polygon"})," tool on the navigation bar."]}),"\n",(0,a.jsxs)(n.p,{children:["Next, use the ",(0,a.jsx)(n.strong,{children:"Select label"})," menu that drops down to select the concept you want to use to annotate the image \u2014 that is, if the concept already exists in your app. If it's not already existing, you'll need to add it as described earlier."]}),"\n",(0,a.jsx)(n.p,{children:"Next, use the dots to draw a contour as closely as possible around the image's region of interest."}),"\n",(0,a.jsx)(n.p,{children:"After creating the initial shape by placing your dots, you'll need to close the loop. Simply click on the first dot you made again, and this action will close the loop, completing the polygon."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(39509).A+"",width:"1913",height:"885"})}),"\n",(0,a.jsx)(n.p,{children:"Note that segmentation labeling works just as the previously described detection labeling. For example, if you click the polygon icon in an annotation category field, the drawing mode will be activated, enabling you to create annotations with the selected concept."}),"\n",(0,a.jsx)(n.h3,{id:"masks-labeling",children:"Masks Labeling"}),"\n",(0,a.jsx)(n.p,{children:"The mask label type lets you label each pixel within the region of interest. It provides pixel-level labeling that allows you to precisely identify and delineate objects within an image."}),"\n",(0,a.jsx)(n.p,{children:"Currently, you can only minimally review existing image mask annotations on the Input-Viewer page. After creating mask images via the API and uploading them to our platform, you can view them on that page."}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/api-guide/annotate/annotations#annotate-images-with-mask",children:"Click here"})," to learn how to add image mask annotations using our API."]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:"You can delete an entire image mask annotation for an input directly from the Input-Viewer page. However, the Input-Viewer page does not currently support creating or editing mask annotations."})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(10354).A+"",width:"893",height:"201"})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},50593:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/create_annotations_3-4fce00d397fc6affb41f7192c36c115d.png"},50688:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-5-d60c6153d773120214321e7d42920d33.png"},62367:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-2-fbcbffa8014f1056541ae4d1dc3bd7b7.png"},74889:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-4-c0faf6c73f44c937a70f75d5d9b3c94a.png"},75219:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/create_annotations_1-f99733537fc58d56ebe327ae021b6acc.png"},77092:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-1-b17db9297e8491d3d892616119996d3e.png"},98284:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/annotate-9-4ee8926346be1a0dc77228b630ee032b.png"}}]);