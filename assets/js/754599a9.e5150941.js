"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[8798],{49952:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/compute-21-ed55030b37b9db591cb877577243849e.png"},65297:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/compute-28-95e4aa0fe0993a129a036629fe742ed5.png"},65537:(e,n,t)=>{t.d(n,{A:()=>x});var i=t(96540),r=t(18215),s=t(65627),a=t(56347),o=t(50372),l=t(30604),d=t(11861),c=t(78749);function u(e){return i.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(e){const{values:n,children:t}=e;return(0,i.useMemo)((()=>{const e=n??function(e){return u(e).map((e=>{let{props:{value:n,label:t,attributes:i,default:r}}=e;return{value:n,label:t,attributes:i,default:r}}))}(t);return function(e){const n=(0,d.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function m(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function h(e){let{queryString:n=!1,groupId:t}=e;const r=(0,a.W6)(),s=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,l.aZ)(s),(0,i.useCallback)((e=>{if(!s)return;const n=new URLSearchParams(r.location.search);n.set(s,e),r.replace({...r.location,search:n.toString()})}),[s,r])]}function _(e){const{defaultValue:n,queryString:t=!1,groupId:r}=e,s=p(e),[a,l]=(0,i.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!m({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const i=t.find((e=>e.default))??t[0];if(!i)throw new Error("Unexpected error: 0 tabValues");return i.value}({defaultValue:n,tabValues:s}))),[d,u]=h({queryString:t,groupId:r}),[_,g]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[r,s]=(0,c.Dv)(t);return[r,(0,i.useCallback)((e=>{t&&s.set(e)}),[t,s])]}({groupId:r}),y=(()=>{const e=d??_;return m({value:e,tabValues:s})?e:null})();(0,o.A)((()=>{y&&l(y)}),[y]);return{selectedValue:a,selectValue:(0,i.useCallback)((e=>{if(!m({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),g(e)}),[u,g,s]),tabValues:s}}var g=t(9136);const y={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var f=t(74848);function E(e){let{className:n,block:t,selectedValue:i,selectValue:a,tabValues:o}=e;const l=[],{blockElementScrollPositionUntilNextRender:d}=(0,s.a_)(),c=e=>{const n=e.currentTarget,t=l.indexOf(n),r=o[t].value;r!==i&&(d(n),a(r))},u=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return(0,f.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":t},n),children:o.map((e=>{let{value:n,label:t,attributes:s}=e;return(0,f.jsx)("li",{role:"tab",tabIndex:i===n?0:-1,"aria-selected":i===n,ref:e=>{l.push(e)},onKeyDown:u,onClick:c,...s,className:(0,r.A)("tabs__item",y.tabItem,s?.className,{"tabs__item--active":i===n}),children:t??n},n)}))})}function b(e){let{lazy:n,children:t,selectedValue:s}=e;const a=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=a.find((e=>e.props.value===s));return e?(0,i.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,f.jsx)("div",{className:"margin-top--md",children:a.map(((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==s})))})}function I(e){const n=_(e);return(0,f.jsxs)("div",{className:(0,r.A)("tabs-container",y.tabList),children:[(0,f.jsx)(E,{...n,...e}),(0,f.jsx)(b,{...n,...e})]})}function x(e){const n=(0,g.A)();return(0,f.jsx)(I,{...e,children:u(e.children)},String(n))}},71432:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/compute-29-70c14a07bb41b28552b10fa61af576a8.png"},79329:(e,n,t)=>{t.d(n,{A:()=>a});t(96540);var i=t(18215);const r={tabItem:"tabItem_Ymn6"};var s=t(74848);function a(e){let{children:n,hidden:t,className:a}=e;return(0,s.jsx)("div",{role:"tabpanel",className:(0,i.A)(r.tabItem,a),hidden:t,children:n})}},86946:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/compute-16-b44b5ff30506ca7b0fafa9905800b190.png"},87990:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/compute-27-b79759e88b88f3ae8ca7393873f14e64.png"},92996:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>y,contentTitle:()=>g,default:()=>b,frontMatter:()=>_,metadata:()=>i,toc:()=>f});const i=JSON.parse('{"id":"compute/models/model-inference","title":"Model Inference","description":"Perform predictions using your deployed models","source":"@site/docs/compute/models/model-inference.md","sourceDirName":"compute/models","slug":"/compute/models/model-inference","permalink":"/compute/models/model-inference","draft":false,"unlisted":false,"editUrl":"https://github.com/Clarifai/docs/blob/main/docs/compute/models/model-inference.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"Perform predictions using your deployed models","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Models","permalink":"/compute/models/"},"next":{"title":"Model Uploading","permalink":"/compute/models/model-upload/"}}');var r=t(74848),s=t(28453),a=t(65537),o=t(79329),l=t(58069);const d='##################################################################################################\n# Change these strings to run your own example\n##################################################################################################\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "YOUR_USER_ID_HERE"\nIMAGE_URL = "https://samples.clarifai.com/birds.jpg"\nMODEL_URL = "https://clarifai.com/qwen/qwen-VL/models/Qwen2_5-VL-7B-Instruct"\nDEPLOYMENT_ID = "YOUR_DEPLOYMENT_ID_HERE"\n\n##################################################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##################################################################################################\n\nfrom clarifai.client.model import Model\n\n# Initialize the model\nmodel = Model(\n    url=MODEL_URL, # Or, use model_id="YOUR_MODEL_ID_HERE"\n    pat=PAT\n)\n\n# Make a unary-unary prediction using the image URL\nmodel_prediction = model.predict_by_url(\n    IMAGE_URL,\n    input_type="image",\n    user_id=USER_ID,\n    deployment_id=DEPLOYMENT_ID\n)\n\n# Output the model\'s response\nprint(model_prediction.outputs[0].data.text.raw)\n\n##################################################################################################\n# ADDITIONAL EXAMPLES\n##################################################################################################\n\n# Example prediction using a cluster and nodepool (no deployment ID needed):\n# model_prediction = Model(url=MODEL_URL, pat="YOUR_PAT_HERE").predict_by_url("INPUT_URL_HERE", input_type="image", user_id="YOUR_USER_ID_HERE", compute_cluster_id="YOUR_CLUSTER_ID_HERE", nodepool_id="YOUR_NODEPOOL_ID_HERE")\n\n# Example prediction via bytes:\n# model_prediction = Model(url=MODEL_URL, pat="YOUR_PAT_HERE").predict_by_bytes("INPUT_TEXT_HERE".encode(), input_type="text", user_id="YOUR_USER_ID_HERE", deployment_id="YOUR_DEPLOYMENT_ID_HERE")\n\n# Example prediction via filepath:\n# model_prediction = Model(url=MODEL_URL, pat="YOUR_PAT_HERE").predict_by_filepath("INPUT_FILEPATH_HERE", input_type="text", user_id="YOUR_USER_ID_HERE", deployment_id="YOUR_DEPLOYMENT_ID_HERE")\n',c='# Use the CLI to log in to the Clarifai platform first: https://docs.clarifai.com/additional-resources/api-overview/cli#login\n\nclarifai model predict --model_url https://clarifai.com/qwen/qwen-VL/models/Qwen2_5-VL-7B-Instruct --url https://samples.clarifai.com/birds.jpg --input_type image --deployment_id "YOUR_DEPLOYMENT_ID_HERE"\n',u='##################################################################################################\n# Change these strings to run your own example\n##################################################################################################\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "YOUR_USER_ID_HERE"\nPROMPT = "What is the future of AI?"\nMODEL_URL = "https://clarifai.com/meta/Llama-3/models/Llama-3_2-3B-Instruct"\nDEPLOYMENT_ID = "YOUR_DEPLOYMENT_ID_HERE"\n\n##################################################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##################################################################################################\n\nfrom clarifai.client.model import Model\n\n# Initialize the model\nmodel = Model(\n    url=MODEL_URL,  # Or, use model_id="YOUR_MODEL_ID_HERE"\n    pat=PAT\n)\n\n# Make a unary-stream prediction using the prompt as bytes\nresponse_stream = model.generate_by_bytes(\n    PROMPT.encode(),\n    input_type="text",\n    user_id=USER_ID,\n    deployment_id=DEPLOYMENT_ID\n)\n\n# Iterate through streamed responses and print them\nfor response in response_stream:\n    if response.outputs and response.outputs[0].data.text:\n        print(response.outputs[0].data.text.raw)\n\n# Print a newline at the end for better formatting\nprint()\n\n##################################################################################################\n# ADDITIONAL EXAMPLES\n##################################################################################################\n\n# Example stream prediction using a cluster and nodepool (no deployment ID needed):\n# for response in Model(url=MODEL_URL, pat="YOUR_PAT_HERE").generate_by_bytes("YOUR_PROMPT_HERE".encode(), input_type="text", user_id="YOUR_USER_ID_HERE", compute_cluster_id="YOUR_CLUSTER_ID", nodepool_id="YOUR_NODEPOOL_ID"):\n#     print(response.outputs[0].data.text.raw)\n\n# Example unary-stream prediction via URL:\n# for response in Model(url=MODEL_URL, pat="YOUR_PAT_HERE").generate_by_url("INPUT_URL_HERE", input_type="text", user_id="YOUR_USER_ID_HERE", deployment_id="YOUR_DEPLOYMENT_ID_HERE"):\n#     print(response.outputs[0].data.text.raw)\n\n# Example unary-stream prediction via filepath:\n# for response in Model(url=MODEL_URL, pat="YOUR_PAT_HERE").generate_by_filepath("INPUT_FILEPATH_HERE", input_type="text", user_id="YOUR_USER_ID_HERE", deployment_id="YOUR_DEPLOYMENT_ID_HERE"):\n#     print(response.outputs[0].data.text.raw)\n',p='##################################################################################################\n# Change these strings to run your own example\n##################################################################################################\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "YOUR_USER_ID_HERE"\nPROMPTS = [\n    "What is the future of AI?",\n    "Explain quantum computing in simple terms.",\n    "How does climate change affect global economies?"\n]\nMODEL_URL = "https://clarifai.com/meta/Llama-3/models/Llama-3_2-3B-Instruct"\nDEPLOYMENT_ID = "YOUR_DEPLOYMENT_ID_HERE"\n\n##################################################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##################################################################################################\n\nfrom clarifai.client.model import Model\n\n# Initialize the model\nmodel = Model(\n    url=MODEL_URL, # Or, use model_id="YOUR_MODEL_ID_HERE"\n    pat=PAT\n)\n\n# Prepare input iterator: each item is a bytes-encoded prompt\ninput_stream = (prompt.encode() for prompt in PROMPTS)\n\n# Stream-stream prediction using bytes\nresponse_stream = model.stream_by_bytes(\n    input_stream,\n    input_type="text",\n    user_id=USER_ID,\n    deployment_id=DEPLOYMENT_ID\n)\n\n# Iterate through streamed responses and print them\nfor response in response_stream:\n    if response.outputs and response.outputs[0].data.text:\n        print(response.outputs[0].data.text.raw)\n\n# Print a newline at the end for better formatting\nprint()\n\n##################################################################################################\n# ADDITIONAL EXAMPLES\n##################################################################################################\n\n# Example stream prediction using a cluster and nodepool (no deployment ID needed):\n# response_stream = Model(url=MODEL_URL, pat="YOUR_PAT_HERE").stream_by_bytes((prompt.encode() for prompt in PROMPTS), input_type="text", user_id="YOUR_USER_ID_HERE", compute_cluster_id="YOUR_CLUSTER_ID", nodepool_id="YOUR_NODEPOOL_ID")\n# for response in response_stream:\n#     print(response.outputs[0].data.text.raw)\n\n# Example stream prediction via URL:\n# response_stream = Model(url=MODEL_URL, pat="YOUR_PAT_HERE").stream_by_url(["INPUT_URL_1", "INPUT_URL_2"], input_type="text", user_id="YOUR_USER_ID_HERE", deployment_id="YOUR_DEPLOYMENT_ID_HERE")\n# for response in response_stream:\n#     print(response.outputs[0].data.text.raw)\n\n# Example stream prediction via filepath:\n# response_stream = Model(url=MODEL_URL, pat="YOUR_PAT_HERE").stream_by_filepath(["file1.txt", "file2.txt"], input_type="text", user_id="YOUR_USER_ID_HERE", deployment_id="YOUR_DEPLOYMENT_ID_HERE")\n# for response in response_stream:\n#     print(response.outputs[0].data.text.raw)\n',m="2025-04-04 13:27:15.990657 INFO     Qwen2_5-VL-7B-Instruct model is still deploying, please wait...         model.py:443\n2025-04-04 13:27:30.233847 INFO     Qwen2_5-VL-7B-Instruct model is still deploying, please wait...         model.py:443\n2025-04-04 13:27:45.624827 INFO     Qwen2_5-VL-7B-Instruct model is still deploying, please wait...         model.py:443\n2025-04-04 13:28:02.551081 INFO     Qwen2_5-VL-7B-Instruct model is still deploying, please wait...         model.py:443\nThis image captures three seagulls in flight over a body of water, likely a lake or river. The background is a natural setting with dry grass and trees, suggesting it might be late autumn or early spring. The seagulls appear to be gliding close to the water's surface, possibly searching for food. The lighting indicates it could be a sunny day. This scene is typical of coastal or lakeside environments where seagulls often congregate.\n",h="2025-04-04 15:10:09.952752 INFO     Llama-3_2-3B-Instruct model is still     model.py:726\n                                    deploying, please wait...\n2025-04-04 15:10:24.522422 INFO     Llama-3_2-3B-Instruct model is still     model.py:726\n                                    deploying, please wait...\nThe\n future\n of\n Artificial\n Intelligence\n (\nAI\n)\n is\n vast\n and\n rapidly\n evolving\n.\n Based\n on\n current\n trends\n and\n advancements\n,\n here\n are\n some\n potential\n developments\n that\n may\n shape\n the\n future\n of\n AI\n:\n\n\n**\nShort\n-term\n (\n202\n5\n-\n203\n0\n)**\n\n\n\n1\n.\n **\nIncreased\n Adoption\n**:\n AI\n will\n become\n more\n ubiquitous\n in\n various\n industries\n,\n including\n healthcare\n,\n finance\n,\n transportation\n,\n and\n education\n.\n\n2\n.\n **\nImproved\n Natural\n Language\n Processing\n (\nN\nLP\n)**\n:\n N\nLP\n will\n continue\n to\n advance\n,\n enabling\n more\n accurate\n and\n effective\n human\n-com\nputer\n interactions\n.\n\n3\n.\n **\nEnh\nanced\n Machine\n Learning\n (\nML\n)**\n:\n ML\n will\n become\n more\n sophisticated\n,\n allowing\n for\n more\n accurate\n predictions\n and\n decision\n-making\n.\n\n4\n.\n **\nR\nise\n of\n Explain\nable\n AI\n (\nX\nAI\n)**\n:\n X\nAI\n will\n become\n more\n prominent\n,\n enabling\n users\n to\n understand\n the\n reasoning\n behind\n AI\n decisions\n.\n\n\n**\nMid\n-term\n (\n203\n0\n-\n204\n0\n)**\n\n\n\n1\n.\n **\nArt\nificial\n General\n Intelligence\n (\nAG\nI\n)**\n:\n AG\nI\n,\n which\n refers\n to\n AI\n systems\n that\n can\n perform\n any\n intellectual\n task\n,\n may\n emerge\n.\n\n2\n.\n **\nQuant\num\n AI\n**:\n Quantum\n computing\n will\n be\n integrated\n with\n AI\n,\n leading\n to\n exponential\n advancements\n in\n processing\n power\n and\n AI\n capabilities\n.\n\n3\n.\n **\nEdge\n AI\n**:\n Edge\n AI\n will\n become\n more\n prevalent\n,\n enabling\n AI\n to\n be\n deployed\n at\n the\n edge\n of\n networks\n,\n reducing\n latency\n,\n and\n improving\n real\n-time\n decision\n-making\n.\n\n4\n.\n **\nHuman\n-A\nI\n Collaboration\n**:\n Humans\n and\n AI\n systems\n will\n collaborate\n more\n effectively\n,\n leading\n to\n increased\n productivity\n and\n innovation\n.\n\n\n**\nLong\n-term\n (\n204\n0\n-\n205\n0\n)**\n\n\n\n1\n.\n **\nM\nerging\n of\n Human\n and\n Machine\n Intelligence\n**:\n The\n line\n between\n human\n and\n machine\n intelligence\n will\n blur\n,\n leading\n to\n new\n forms\n of\n intelligence\n and\n cognition\n.\n\n2\n.\n **\nAut\nonomous\n Systems\n**:\n Autonomous\n systems\n,\n such\n as\n self\n-driving\n cars\n and\n drones\n,\n will\n become\n more\n common\n,\n revolution\nizing\n industries\n like\n transportation\n and\n logistics\n.\n\n3\n.\n **\nC\nognitive\n Architect\nures\n**:\n Cognitive\n architectures\n,\n which\n aim\n to\n create\n AI\n systems\n that\n can\n reason\n and\n learn\n like\n humans\n,\n will\n emerge\n.\n\n4\n.\n **\nAI\n Ethics\n and\n Governance\n**:\n As\n AI\n becomes\n more\n pervasive\n,\n there\n will\n be\n a\n growing\n need\n for\n AI\n ethics\n and\n governance\n frameworks\n to\n ensure\n responsible\n AI\n development\n and\n deployment\n.\n\n\n**\nPotential\n Ris\nks\n and\n Challenges\n**\n\n\n1\n.\n **\nJob\n Dis\nplacement\n**:\n AI\n may\n dis\nplace\n certain\n jobs\n,\n leading\n to\n significant\n social\n and\n economic\n impacts\n.\n\n2\n.\n **\nBias\n and\n Fair\nness\n**:\n AI\n systems\n may\n perpet\nuate\n existing\n biases\n and\n inequalities\n,\n highlighting\n the\n need\n for\n more\n diverse\n and\n inclusive\n AI\n development\n.\n\n3\n.\n **\nSecurity\n and\n Safety\n**:\n AI\n systems\n may\n pose\n new\n security\n and\n safety\n risks\n,\n such\n as\n autonomous\n systems\n malfunction\ning\n or\n being\n exploited\n.\n\n4\n.\n **\nValue\n Alignment\n**:\n AI\n systems\n may\n not\n align\n with\n human\n",_={description:"Perform predictions using your deployed models",sidebar_position:1},g="Model Inference",y={},f=[{value:"<strong>Via the API</strong>",id:"via-the-api",level:2},{value:"Unary-Unary Predict Call",id:"unary-unary-predict-call",level:3},{value:"Unary-Stream Predict Call",id:"unary-stream-predict-call",level:3},{value:"Stream-Stream Predict Call",id:"stream-stream-predict-call",level:3},{value:"<strong>Via the UI</strong>",id:"via-the-ui",level:2},{value:"Model Playground",id:"model-playground",level:3},{value:"Predictions Within Input-Viewer",id:"predictions-within-input-viewer",level:3}];function E(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components},{Details:i}=n;return i||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"model-inference",children:"Model Inference"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Perform predictions using your deployed models"})}),"\n",(0,r.jsx)("hr",{}),"\n",(0,r.jsx)(n.p,{children:"Clarifai's Compute Orchestration capabilities provide efficient ways to make prediction calls to suit various use cases. Once your model is deployed, you can use it to perform inferences seamlessly."}),"\n",(0,r.jsx)(n.admonition,{title:"Deploy model first",type:"warning",children:(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Before making the following prediction requests, ensure you have ",(0,r.jsx)(n.a,{href:"https://docs.clarifai.com/compute/deployments/clusters-nodepools",children:"set up a cluster"}),", created a nodepool, and ",(0,r.jsx)(n.a,{href:"https://docs.clarifai.com/compute/deployments/deploy-model",children:"deployed your model"})," in it. Once the model is deployed, you'll specify its ",(0,r.jsx)(n.code,{children:"deployment_id"})," parameter, which is essential for proper routing and execution of your prediction request."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["If you do not specify the ",(0,r.jsx)(n.code,{children:"deployment_id"})," parameter, the prediction will default to the ",(0,r.jsx)(n.code,{children:"Clarifai Shared"})," deployment type."]}),"\n"]}),"\n"]})}),"\n",(0,r.jsx)(n.admonition,{title:"Why Deployment Selection Matters",type:"note",children:(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"deployment_id"})," parameter is vital in directing prediction requests to the appropriate cluster and nodepool. For example, you can route requests to a GCP cluster by selecting a corresponding deployment ID, use a different deployment ID for an AWS cluster, and yet another for an on-premises deployment. This gives you full control over performance, costs, and security, allowing you to focus on building cutting-edge AI solutions while we handle the infrastructure complexity."]})}),"\n","\n","\n","\n",(0,r.jsx)(n.h2,{id:"via-the-api",children:(0,r.jsx)(n.strong,{children:"Via the API"})}),"\n",(0,r.jsx)(n.h3,{id:"unary-unary-predict-call",children:"Unary-Unary Predict Call"}),"\n",(0,r.jsx)(n.p,{children:"This is the simplest type of prediction. In this method, a single input is sent to the model, and it returns a single response. This is ideal for tasks where a quick, non-streaming prediction is required, such as classifying an image."}),"\n",(0,r.jsx)(n.p,{children:"It supports the following prediction methods:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"predict_by_url"}),"  \u2014 Use a publicly accessible URL for the input."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"predict_by_bytes"})," \u2014 Pass raw input data directly."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"predict_by_filepath"})," \u2014 Provide the local file path for the input."]}),"\n"]}),"\n",(0,r.jsxs)(a.A,{children:[(0,r.jsx)(o.A,{value:"python",label:"Python",children:(0,r.jsx)(l.A,{className:"language-python",children:d})}),(0,r.jsx)(o.A,{value:"bash",label:"CLI",children:(0,r.jsx)(l.A,{className:"language-yaml",children:c})})]}),"\n",(0,r.jsxs)(i,{children:[(0,r.jsx)("summary",{children:"Example Output"}),(0,r.jsx)(l.A,{className:"language-text",children:m})]}),"\n",(0,r.jsx)(n.h3,{id:"unary-stream-predict-call",children:"Unary-Stream Predict Call"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.strong,{children:"Unary-Stream"})," predict call processes a single input, but returns a stream of responses. It is particularly useful for tasks where multiple outputs are generated from a single input, such as generating text completions from a prompt."]}),"\n",(0,r.jsx)(n.p,{children:"It supports the following prediction methods:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"generate_by_url"}),"  \u2014 Provide a publicly accessible URL and handle the streamed responses iteratively."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"generate_by_bytes"})," \u2014 Use raw input data."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"generate_by_filepath"})," \u2014 Use a local file path for the input."]}),"\n"]}),"\n",(0,r.jsx)(a.A,{children:(0,r.jsx)(o.A,{value:"python",label:"Python",children:(0,r.jsx)(l.A,{className:"language-python",children:u})})}),"\n",(0,r.jsxs)(i,{children:[(0,r.jsx)("summary",{children:"Example Output"}),(0,r.jsx)(l.A,{className:"language-text",children:h})]}),"\n",(0,r.jsx)(n.h3,{id:"stream-stream-predict-call",children:"Stream-Stream Predict Call"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.strong,{children:"stream-stream"})," predict call enables bidirectional streaming of both inputs and outputs, making it highly effective for processing large datasets or real-time applications."]}),"\n",(0,r.jsx)(n.p,{children:"In this setup, multiple inputs can be continuously sent to the model, and the corresponding multiple predictions are streamed back in real-time. This is ideal for tasks like real-time video processing/predictions or live sensor data analysis."}),"\n",(0,r.jsx)(n.p,{children:"It supports the following prediction methods:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"stream_by_url"})," \u2014 Stream a list of publicly accessible URLs and receive a stream of predictions. It takes an iterator of inputs and returns a stream of predictions."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"stream_by_bytes"})," \u2014 Stream raw input data."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"stream_by_filepath"})," \u2014 Stream inputs from local file paths."]}),"\n"]}),"\n",(0,r.jsx)(a.A,{children:(0,r.jsx)(o.A,{value:"python",label:"Python",children:(0,r.jsx)(l.A,{className:"language-python",children:p})})}),"\n",(0,r.jsx)(n.h2,{id:"via-the-ui",children:(0,r.jsx)(n.strong,{children:"Via the UI"})}),"\n",(0,r.jsx)(n.h3,{id:"model-playground",children:"Model Playground"}),"\n",(0,r.jsxs)(n.p,{children:["To access your deployments, navigate to the model\u2019s playground page and select the ",(0,r.jsx)(n.strong,{children:"Deployments"})," tab."]}),"\n",(0,r.jsxs)(n.p,{children:["Here, you\u2019ll find a ",(0,r.jsx)(n.strong,{children:"Deployments & Usage"})," table listing all deployments associated with the model, including details such as the cluster and nodepool. You can also sort the table alphabetically (A\u2013Z or Z\u2013A) based on your preferences."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:" ",src:t(86946).A+"",width:"1795",height:"777"})}),"\n",(0,r.jsxs)(n.p,{children:["To select a deployment, click the ",(0,r.jsx)(n.strong,{children:"Deployment"})," button. A dropdown list will appear, showing your available deployments. Choose the one you want to use to direct traffic to a specific cluster and nodepool."]}),"\n",(0,r.jsxs)(n.p,{children:["Once you\u2019ve selected a deployment ID, go to the ",(0,r.jsx)(n.strong,{children:"Overview"})," pane to use it for making prediction requests."]}),"\n",(0,r.jsx)(n.p,{children:"When inferencing using a deployed model, the request is routed to the nodepool within the cloud region specified in the cluster, and the model\u2019s predictions are returned as output in real time."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:" ",src:t(49952).A+"",width:"1809",height:"655"})}),"\n",(0,r.jsx)(n.h3,{id:"predictions-within-input-viewer",children:"Predictions Within Input-Viewer"}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["The single Input-Viewer is the main page that showcases the details of a single input available in your app. If you click an input listed on the ",(0,r.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/inputs-manager/",children:"Inputs-Manager"})," page, you'll be redirected to the viewer page for that input, where you can view and interact with it."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["To make predictions on an input, switch to predict mode by toggling the ",(0,r.jsx)(n.strong,{children:"Predict"})," button located in the top-right corner of the page. Next, click the ",(0,r.jsx)(n.strong,{children:"Choose a model or workflow"})," button in the right-hand sidebar to select the model you want to use."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:" ",src:t(87990).A+"",width:"1917",height:"902"})}),"\n",(0,r.jsxs)(n.p,{children:["In the window that appears, choose your desired model and then select a deployment from the ",(0,r.jsx)(n.strong,{children:"Deployment"})," dropdown. If needed, you can also create a new deployment from this window."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:" ",src:t(65297).A+"",width:"1906",height:"900"})}),"\n",(0,r.jsxs)(n.p,{children:["Lastly, click the ",(0,r.jsx)(n.strong,{children:"Predict"})," button at the bottom of the sidebar. The model will process the input and return predictions in real time, allowing you to immediately view the results within the Input-Viewer screen."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:" ",src:t(71432).A+"",width:"1915",height:"821"})})]})}function b(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(E,{...e})}):E(e)}}}]);