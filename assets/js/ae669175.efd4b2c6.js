"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[2867],{66492:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>x,contentTitle:()=>N,default:()=>k,frontMatter:()=>C,metadata:()=>U,toc:()=>v});var o=t(74848),s=t(28453),a=t(11470),r=t(19365),i=t(21432);const l="##########################################################################################\n# In this section, we set the user authentication, app ID, model ID, and model type ID.\n# Change these strings to run your own example.\n#########################################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the Account's Security section\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to create your own model\nMODEL_ID = 'my-prompter-model'\nMODEL_TYPE_ID = 'prompter'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\npost_models_response = stub.PostModels(\n    service_pb2.PostModelsRequest(\n        user_app_id=userDataObject,\n        models=[\n            resources_pb2.Model(\n                id=MODEL_ID,\n                model_type_id=MODEL_TYPE_ID             \n            )\n        ]\n    ),\n    metadata=metadata\n)\n\nif post_models_response.status.code != status_code_pb2.SUCCESS:\n    print(post_models_response.status)\n    raise Exception(\"Post models failed, status: \" + post_models_response.status.description)\n",c="\x3c!--index.html file--\x3e\n\n<script>\n    ///////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and model type ID.\n    // Change these strings to run your own example.\n    //////////////////////////////////////////////////////////////////////////////////////////\n\n    const USER_ID = 'YOUR_USER_ID_HERE';\n    // Your PAT (Personal Access Token) can be found in the Account's Security section\n    const PAT = 'YOUR_PAT_HERE';\n    const APP_ID = 'YOUR_APP_ID_HERE';\n    // Change these to create your own model\n    const MODEL_ID = 'my-prompter-model';\n    const MODEL_TYPE_ID = 'prompter';\n    \n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    const raw = JSON.stringify({\n        \"user_app_id\": {\n            \"user_id\": USER_ID,\n            \"app_id\": APP_ID\n        },\n        \"model\": {\n            \"id\": MODEL_ID,\n            \"model_type_id\": MODEL_TYPE_ID         \n        }\n    });\n\n    const requestOptions = {\n        method: 'POST',\n        headers: {\n            'Accept': 'application/json',\n            'Authorization': 'Key ' + PAT\n        },\n        body: raw\n    };\n\n    fetch(\"https://api.clarifai.com/v2/models\", requestOptions)\n        .then(response => response.text())\n        .then(result => console.log(result))\n        .catch(error => console.log('error', error));\n\n<\/script>",p='//index.js file\n\n////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, model ID, and model type ID.\n// Change these strings to run your own example.\n///////////////////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = \'YOUR_USER_ID_HERE\';\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\nconst PAT = \'YOUR_PAT_HERE\';\nconst APP_ID = \'YOUR_APP_ID_HERE\';\n// Change these to create your own model\nconst MODEL_ID = \'my-prompter-model\';\nconst MODEL_TYPE_ID = \'prompter\';\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\nstub.PostModels(\n    {\n        user_app_id: {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        models: [\n            {\n                id: MODEL_ID,\n                model_type_id: MODEL_TYPE_ID               \n            }\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error("Post models failed, status: " + response.status.description);\n        }\n    }\n);',u='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.status.StatusCode;\n\npublic class ClarifaiExample {\n\n    ////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and model type ID.\n    // Change these strings to run your own example.\n    ///////////////////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to create your own model    \n    static final String MODEL_ID = "my-prompter-model";\n    static final String MODEL_TYPE_ID = "prompter";\n    \n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\t\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n            .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        SingleModelResponse postModelsResponse = stub.postModels(\n            PostModelsRequest.newBuilder()\n            .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n            .addModels(\n                Model.newBuilder()\n                .setId(MODEL_ID)\n                .setModelTypeId(MODEL_TYPE_ID)              \n            ).build()\n        );\n\n        if (postModelsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post models failed, status: " + postModelsResponse.getStatus());\n        }\n\n    }\n\n}',d='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models" \\\n  -H "Authorization: Key YOUR_PAT_HERE" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model": {\n      "id": "my-prompter-model",\n      "model_type_id": "prompter"\n    }\n  }\'',_='<?php\n\nrequire __DIR__ . "/vendor/autoload.php";\n\n/////////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, model ID, and model type ID.\n// Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////////////\n\n$USER_ID = "YOUR_USER_ID_HERE";\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\n$PAT = "YOUR_PAT_HERE";\n$APP_ID = "YOUR_APP_ID_HERE";\n// Change these to create your own model\n$MODEL_ID = "my-prompter-model";\n$MODEL_TYPE_ID = "prompter";\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nuse Clarifai\\ClarifaiClient;\nuse Clarifai\\Api\\Model;\nuse Clarifai\\Api\\PostModelsRequest;\nuse Clarifai\\Api\\Status\\StatusCode;\nuse Clarifai\\Api\\UserAppIDSet;\n\n$client = ClarifaiClient::grpc();\n\n$metadata = ["Authorization" => ["Key " . $PAT]];\n\n$userDataObject = new UserAppIDSet([\n    "user_id" => $USER_ID,\n    "app_id" => $APP_ID,\n]);\n\n// Let\'s make a RPC call to the Clarifai platform. It uses the opened gRPC client channel to communicate a\n// request and then wait for the response\n[$response, $status] = $client->PostModels(\n        // The request object carries the request along with the request status and other metadata related to the request itself\n        new PostModelsRequest([\n            "user_app_id" => $userDataObject,\n            "models" => [\n                new Model([                    \n                    "id" => $MODEL_ID,\n                    "model_type_id" => $MODEL_TYPE_ID,\n                ]),\n            ],\n        ]),\n        $metadata\n    )->wait();\n\n// A response is returned and the first thing we do is check the status of it\n// A successful response will have a status code of 0; otherwise, there is some error\nif ($status->code !== 0) {\n    throw new Exception("Error: {$status->details}");\n}\n// In addition to the RPC response status, there is a Clarifai API status that reports if the operation was a success or failure\n// (not just that the communication was successful)\nif ($response->getStatus()->getCode() != StatusCode::SUCCESS) {\n    throw new Exception("Failure response: " . $response->getStatus()->getDescription() . " " . $response->getStatus()->getDetails());\n}\n\n?>',E='###############################################################################################\n# In this section, we set the user authentication, app ID, model ID, and prompter details.\n# Change these strings to run your own example.\n###############################################################################################\n\nUSER_ID = "YOUR_USER_ID_HERE"\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nAPP_ID = "YOUR_APP_ID_HERE"\n# Change these to train your own model\nMODEL_ID = "my-prompter-model"\nPROMPTER_DESCRIPTION = "Positive or negative sentiment classifier prompter"\nPROMPT_TEMPLATE = "Classify whether the sentiment of the given text is positive or negative {data.text.raw}"\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\nfrom google.protobuf.struct_pb2 import Struct\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nparams = Struct()\nparams.update({\n    "prompt_template": PROMPT_TEMPLATE\n    })\n\nmetadata = (("authorization", "Key " + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\npost_model_versions = stub.PostModelVersions(\n    service_pb2.PostModelVersionsRequest(\n        user_app_id=userDataObject,\n        model_id=MODEL_ID,\n        description=PROMPTER_DESCRIPTION,\n        model_versions=[\n            resources_pb2.ModelVersion(\n                output_info=resources_pb2.OutputInfo(params=params)\n            )\n        ],\n    ),\n    metadata=metadata,\n)\n\nif post_model_versions.status.code != status_code_pb2.SUCCESS:\n    print(post_model_versions.status)\n    raise Exception("Post models versions failed, status: " + post_model_versions.status.description)\n\nprint(post_model_versions)\n',h='\x3c!--index.html file--\x3e\n\n<script>\n    ////////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and prompter details.\n    // Change these strings to run your own example.\n    //////////////////////////////////////////////////////////////////////////////////////////////\n\n    const USER_ID = "YOUR_USER_ID_HERE";\n    // Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    const PAT = "YOUR_PAT_HERE";\n    const APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to train your own model\n    const MODEL_ID = "my-prompter-model";\n    const PROMPTER_DESCRIPTION = "Positive or negative sentiment classifier prompter";\n    const PROMPT_TEMPLATE = "Classify whether the sentiment of the given text is positive or negative {data.text.raw}";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    const raw = JSON.stringify({\n        "user_app_id": {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        "description": PROMPTER_DESCRIPTION,\n        "model_versions": [{\n            "output_info": {\n                "params": {\n                    "prompt_template": PROMPT_TEMPLATE\n                }\n            }\n        }]\n\n    });\n\n    const requestOptions = {\n        method: "POST",\n        headers: {\n            "Content-Type": "application/json",\n            "Authorization": "Key " + PAT\n        },\n        body: raw\n    };\n\n    fetch(`https://api.clarifai.com/v2/models/${MODEL_ID}/versions`, requestOptions)\n        .then(response => response.text())\n        .then(result => console.log(result))\n        .catch(error => console.log("error", error));\n\n<\/script>',m='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.status.StatusCode;\nimport com.google.protobuf.Struct;\nimport com.google.protobuf.Value;\n\npublic class ClarifaiExample {\n\n    //////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and prompter details.\n    // Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    // Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to train your own model\n    static final String MODEL_ID = "my-prompter-model";\n    static final String PROMPTER_DESCRIPTION = "Positive or negative sentiment classifier prompter";\n    static final String PROMPT_TEMPLATE = "Classify whether the sentiment of the given text is positive or negative {data.text.raw}";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\t\n\n    public static void main(String[] args) {\n        \n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n                .withCallCredentials(new ClarifaiCallCredentials(PAT));\n        \n        Struct.Builder params = Struct.newBuilder()\n                .putFields("prompt_template", Value.newBuilder().setStringValue(PROMPT_TEMPLATE).build());\n        \n        SingleModelResponse postModelVersionsResponse = stub.postModelVersions(\n                PostModelVersionsRequest.newBuilder()\n                        .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n                        .setModelId(MODEL_ID)\n                        .setDescription(PROMPTER_DESCRIPTION)\n                        .addModelVersions(ModelVersion.newBuilder()\n                                .setOutputInfo(OutputInfo.newBuilder()\n                                        .setParams(params)\n                                )\n                        )\n                        .build()\n        );\n        \n        if (postModelVersionsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post model outputs failed, status: " + postModelVersionsResponse.getStatus());\n        }\n        \n    }\n}\n',f='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models/my-prompter-model/versions" \\\n  -H "Authorization: Key YOUR_PAT_HERE" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "description": "Positive or negative sentiment classifier prompter",\n    "model_versions": [{\n       "output_info": {\n          "params": {\n             "prompt_template": "Classify whether the sentiment of the given text is positive or negative {data.text.raw}"\n          }\n       }\n    }]\n}\'',I="########################################################################################\n# In this section, we set the user authentication, app ID, and the details of the new\n# custom workflow. Change these strings to run your own example.\n########################################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the Account's Security section\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to create your own custom workflow\nWORKFLOW_ID = 'my-custom-prompter-workflow'\n\nNODE_ID_1 = 'prompter-model'\nPROMPTER_MODEL_ID = 'my-prompter-model'\nPROMPTER_MODEL_USER_ID = 'YOUR_USER_ID_HERE'\nPROMPTER_MODEL_APP_ID = 'my-custom-app'\nPROMPTER_MODEL_VERSION_ID = 'e851fb99a3b14df788ce11accee45c19'\n\nNODE_ID_2 = 'text-to-text'\nLLM_MODEL_ID = 'GPT-4'\nLLM_MODEL_USER_ID = 'openai'\nLLM_MODEL_APP_ID = 'chat-completion'\nLLM_MODEL_VERSION = '5d7a50b44aec4a01a9c492c5a5fcf387'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID) # The userDataObject is required when using a PAT\n\npost_workflows_response = stub.PostWorkflows(\n    service_pb2.PostWorkflowsRequest(\n      user_app_id=userDataObject,  \n      workflows=[\n        resources_pb2.Workflow(\n          id=WORKFLOW_ID,\n          nodes=[\n            resources_pb2.WorkflowNode(\n              id=NODE_ID_1,\n              model=resources_pb2.Model(\n                id=PROMPTER_MODEL_ID,\n                user_id=PROMPTER_MODEL_USER_ID,\n                app_id=PROMPTER_MODEL_APP_ID,\n                model_version=resources_pb2.ModelVersion(\n                  id=PROMPTER_MODEL_VERSION_ID\n                )\n              )\n            ),\n            resources_pb2.WorkflowNode(\n              id=NODE_ID_2,\n              model=resources_pb2.Model(\n                id=LLM_MODEL_ID,\n                user_id=LLM_MODEL_USER_ID,\n                app_id=LLM_MODEL_APP_ID,\n                model_version=resources_pb2.ModelVersion(\n                  id=LLM_MODEL_VERSION\n                )\n              ),\n              node_inputs=[\n                resources_pb2.NodeInput(node_id=NODE_ID_1)\n                ]\n            ),\n          ]\n        )\n      ]\n    ),\n    metadata=metadata\n)               \n\nif post_workflows_response.status.code != status_code_pb2.SUCCESS:\n    print(post_workflows_response.status)\n    raise Exception(\"Post workflows failed, status: \" + post_workflows_response.status.description) \n\nprint(post_workflows_response)\n",D='\x3c!--index.html file--\x3e\n\n<script>\n    //////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, and the details of the new\n    // custom workflow. Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////////////////\n\n    const USER_ID = "YOUR_USER_ID_HERE";\n    // Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    const PAT = "YOUR_PAT_HERE";\n    const APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to create your own custom workflow\n    const WORKFLOW_ID = "my-custom-prompter-workflow";\n\n    const NODE_ID_1 = "prompter-model";\n    const PROMPTER_MODEL_ID = "my-prompter-model";\n    const PROMPTER_MODEL_USER_ID = "YOUR_USER_ID_HERE";\n    const PROMPTER_MODEL_APP_ID = "my-custom-app";\n    const PROMPTER_MODEL_VERSION_ID = "e851fb99a3b14df788ce11accee45c19";\n\n    const NODE_ID_2 = "text-to-text";\n    const LLM_MODEL_ID = "GPT-4";\n    const LLM_MODEL_USER_ID = "openai";\n    const LLM_MODEL_APP_ID = "chat-completion";\n    const LLM_MODEL_VERSION = "5d7a50b44aec4a01a9c492c5a5fcf387";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////   \n\n    const raw = JSON.stringify({\n        "user_app_id": {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        "workflows": [{\n            "id": WORKFLOW_ID,\n            "nodes": [\n                {\n                    "id": NODE_ID_1,\n                    "model": {\n                        "id": PROMPTER_MODEL_ID,\n                        "user_id": PROMPTER_MODEL_USER_ID,\n                        "app_id": PROMPTER_MODEL_APP_ID,\n                        "model_version": {\n                            "id": PROMPTER_MODEL_VERSION_ID\n                        }\n                    }\n                },\n                {\n                    "id": NODE_ID_2,\n                    "model": {\n                        "id": LLM_MODEL_ID,\n                        "user_id": LLM_MODEL_USER_ID,\n                        "app_id": LLM_MODEL_APP_ID,\n                        "model_version": {\n                            "id": LLM_MODEL_VERSION\n                        }\n                    },\n                        "node_inputs": [\n                            {\n                                "node_id": NODE_ID_1\n                            }\n                        ]\n                }\n            ]\n        }]\n    });\n\n    const requestOptions = {\n        method: \'POST\',\n        headers: {\n            \'Accept\': \'application/json\',\n            \'Authorization\': \'Key \' + PAT\n        },\n        body: raw\n    };\n\n    fetch(`https://api.clarifai.com/v2/workflows`, requestOptions)\n        .then(response => response.text())\n        .then(result => console.log(result))\n        .catch(error => console.log(\'error\', error));\n\n<\/script>',w='//index.js file\n\n//////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, and the details of the new\n// custom workflow. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = "YOUR_USER_ID_HERE";\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\nconst PAT = "YOUR_PAT_HERE";\nconst APP_ID = "YOUR_APP_ID_HERE";\n// Change these to create your own custom workflow\nconst WORKFLOW_ID = "my-custom-prompter-workflow";\n\nconst NODE_ID_1 = "prompter-model";\nconst PROMPTER_MODEL_ID = "my-prompter-model";\nconst PROMPTER_MODEL_USER_ID = "YOUR_USER_ID_HERE";\nconst PROMPTER_MODEL_APP_ID = "my-custom-app";\nconst PROMPTER_MODEL_VERSION_ID = "e851fb99a3b14df788ce11accee45c19";\n\nconst NODE_ID_2 = "text-to-text";\nconst LLM_MODEL_ID = "GPT-4";\nconst LLM_MODEL_USER_ID = "openai";\nconst LLM_MODEL_APP_ID = "chat-completion";\nconst LLM_MODEL_VERSION = "5d7a50b44aec4a01a9c492c5a5fcf387";\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\nstub.PostWorkflows(\n    {\n        user_app_id: {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        workflows: [\n            {\n                id: WORKFLOW_ID,\n                nodes: [\n                    {\n                        id: NODE_ID_1,\n                        model: {\n                            id: PROMPTER_MODEL_ID,\n                            user_id: PROMPTER_MODEL_USER_ID,\n                            app_id: PROMPTER_MODEL_APP_ID,\n                            model_version: {\n                                id: PROMPTER_MODEL_VERSION_ID\n                            }\n                        }\n                    },\n                    {\n                        id: NODE_ID_2,\n                        model: {\n                            id: LLM_MODEL_ID,\n                            user_id: LLM_MODEL_USER_ID,\n                            app_id: LLM_MODEL_APP_ID,\n                            model_version: {\n                                id: LLM_MODEL_VERSION\n                            }\n                        },\n                        node_inputs: [\n                            {\n                                node_id: NODE_ID_1 \n                            }\n                        ]\n                    }\n                ]\n            }\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error("Post workflows failed, status: " + response.status.description);\n        }\n\n        console.log(response);\n    }\n);',O='package com.clarifai.example;\n\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\n\npublic class ClarifaiExample {\n\n    //////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, and the details of the new\n    // custom workflow. Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////////////////\n    \n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to create your own custom workflow\n    static final String WORKFLOW_ID = "my-custom-prompter-workflow";\n\n    static final String NODE_ID_1 = "prompter-model";\n    static final String PROMPTER_MODEL_ID = "my-prompter-model";\n    static final String PROMPTER_MODEL_USER_ID = "YOUR_USER_ID_HERE";\n    static final String PROMPTER_MODEL_APP_ID = "my-custom-app";\n    static final String PROMPTER_MODEL_VERSION_ID = "e851fb99a3b14df788ce11accee45c19";\n\n    static final String NODE_ID_2 = "text-to-text";\n    static final String LLM_MODEL_ID = "GPT-4";\n    static final String LLM_MODEL_USER_ID = "openai";\n    static final String LLM_MODEL_APP_ID = "chat-completion";\n    static final String LLM_MODEL_VERSION = "5d7a50b44aec4a01a9c492c5a5fcf387";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n                .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        MultiWorkflowResponse postWorkflowsResponse = stub.postWorkflows(\n                PostWorkflowsRequest.newBuilder()\n                        .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n                        .addWorkflows(\n                                Workflow.newBuilder()\n                                        .setId(WORKFLOW_ID)\n                                        .addNodes(\n                                                WorkflowNode.newBuilder()\n                                                        .setId(NODE_ID_1)\n                                                        .setModel(\n                                                                Model.newBuilder()\n                                                                        .setId(PROMPTER_MODEL_ID)\n                                                                        .setUserId(PROMPTER_MODEL_USER_ID)\n                                                                        .setAppId(PROMPTER_MODEL_APP_ID)\n                                                                        .setModelVersion(ModelVersion.newBuilder().setId(PROMPTER_MODEL_VERSION_ID))\n                                                        )\n                                        )\n                                        .addNodes(\n                                                WorkflowNode.newBuilder()\n                                                        .setId(NODE_ID_2)\n                                                        .setModel(\n                                                                Model.newBuilder()\n                                                                        .setId(LLM_MODEL_ID)\n                                                                        .setUserId(LLM_MODEL_USER_ID)\n                                                                        .setAppId(LLM_MODEL_APP_ID)\n                                                                        .setModelVersion(ModelVersion.newBuilder().setId(LLM_MODEL_VERSION))\n                                                        )\n                                                        .addNodeInputs(NodeInput.newBuilder().setNodeId(NODE_ID_1))\n                                        )\n                        ).build()\n        );\n\n        if (postWorkflowsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post workflows failed, status: " + postWorkflowsResponse.getStatus());\n        }\n\n    }\n\n}\n',R='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/workflows" \\\n    -H "Content-Type: application/json" \\\n    -H "Authorization: Key YOUR_PAT_HERE" \\\n    --data-raw \'{\n      "workflows": [{\n        "id": "my-custom-prompter-workflow",\n        "nodes": [\n          {\n            "id": "prompter-model",\n            "model": {\n              "id": "my-prompter-model",\n              "user_id": "YOUR_USER_ID_HERE",\n              "app_id": "my-custom-app",\n              "model_version": {\n                "id": "e851fb99a3b14df788ce11accee45c19"\n              }\n            }\n          },\n          {\n            "id": "text-to-text",\n            "model": {\n              "id": "GPT-4",\n              "user_id": "openai",\n              "app_id": "chat-completion",\n              "model_version": {\n                "id": "5d7a50b44aec4a01a9c492c5a5fcf387"\n              }\n            },\n              "node_inputs": [\n                {\n                  "node_id": "prompter-model"\n                }\n              ]\n          }\n        ]\n      }]\n    }\'',P='<?php\n\nrequire __DIR__ . "/vendor/autoload.php";\n\n//////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, and the details of the new\n// custom workflow. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////\n\n$USER_ID = "YOUR_USER_ID_HERE";\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\n$PAT = "YOUR_PAT_HERE";\n$APP_ID = "YOUR_APP_ID_HERE";\n// Change these to create your own custom workflow\n$WORKFLOW_ID = "my-custom-prompter-workflow";\n\n$NODE_ID_1 = "prompter-model";\n$PROMPTER_MODEL_ID = "my-prompter-model";\n$PROMPTER_MODEL_USER_ID = "YOUR_USER_ID_HERE";\n$PROMPTER_MODEL_APP_ID = "my-custom-app";\n$PROMPTER_MODEL_VERSION_ID = "e851fb99a3b14df788ce11accee45c19";\n\n$NODE_ID_2 = "text-to-text";\n$LLM_MODEL_ID = "GPT-4";\n$LLM_MODEL_USER_ID = "openai";\n$LLM_MODEL_APP_ID = "chat-completion";\n$LLM_MODEL_VERSION = "5d7a50b44aec4a01a9c492c5a5fcf387";\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nuse Clarifai\\ClarifaiClient;\nuse Clarifai\\Api\\PostWorkflowsRequest;\nuse Clarifai\\Api\\Workflow;\nuse Clarifai\\Api\\WorkflowNode;\nuse Clarifai\\Api\\NodeInput;\nuse Clarifai\\Api\\Model;\nuse Clarifai\\Api\\ModelVersion;\nuse Clarifai\\Api\\Status\\StatusCode;\nuse Clarifai\\Api\\UserAppIDSet;\n\n$client = ClarifaiClient::grpc();\n\n$metadata = ["Authorization" => ["Key " . $PAT]]; \n\n$userDataObject = new UserAppIDSet([\n    "user_id" => $USER_ID,\n    "app_id" => $APP_ID\n]);\n\n// Let\'s make a RPC call to the Clarifai platform. It uses the opened gRPC client channel to communicate a\n// request and then wait for the response\n[$response, $status] = $client->PostWorkflows(\n        // The request object carries the request along with the request status and other metadata related to the request itself\n        new PostWorkflowsRequest([\n            "user_app_id" => $userDataObject,\n            "workflows" => [\n                new Workflow([\n                    "id"=> $WORKFLOW_ID,\n                    "nodes" => [\n                        new WorkflowNode([\n                            "id" => $NODE_ID_1,                            \n                            "model" => new Model([\n                                "id" => $PROMPTER_MODEL_ID,\n                                "user_id" => $PROMPTER_MODEL_USER_ID,\n                                "app_id" => $PROMPTER_MODEL_APP_ID,\n                                "model_version" => new ModelVersion([\n                                    "id" => $PROMPTER_MODEL_VERSION_ID\n                                ])\n                            ])\n\n                        ]),\n                        new WorkflowNode([\n                            "id" => $NODE_ID_2,\n                            "model"=> new Model([\n                                "id" => $LLM_MODEL_ID,\n                                "user_id" => $LLM_MODEL_ID,\n                                "app_id" => $LLM_MODEL_APP_ID,\n                                "model_version" => new ModelVersion([\n                                    "id" => $LLM_MODEL_VERSION\n                                ])\n                            ]),\n                            "node_inputs" => [\n                                new NodeInput([\n                                    "node_id"=> $NODE_ID_1\n                                ])\n                            ]\n                        ])                       \n                    ]\n                ])\n            ]\n        ]),\n        $metadata\n    )->wait();\n\n// A response is returned and the first thing we do is check the status of it\n// A successful response will have a status code of 0; otherwise, there is some error\nif ($status->code !== 0) {\n    throw new Exception("Error: {$status->details}");\n}\n// In addition to the RPC response status, there is a Clarifai API status that reports if the operation was a success or failure \n// (not just that the communication was successful)\nif ($response->getStatus()->getCode() != StatusCode::SUCCESS) {\n    print $response->getStatus()->getDetails();\n    throw new Exception("Failure response: " . $response->getStatus()->getDescription());\n}\n\n?>',T='######################################################################################################\n# In this section, we set the user authentication, app ID, workflow ID, and the text \n# we want as an input. Change these strings to run your own example.\n######################################################################################################\n\nUSER_ID = \'YOUR_USER_ID_HERE\'\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = \'YOUR_PAT_HERE\'\nAPP_ID = \'YOUR_APP_ID_HERE\'\n# Change these to make your own predictions\nWORKFLOW_ID = "my-custom-prompter-workflow"\nRAW_TEXT = "I love your product very much"\n# To use a hosted text file, assign the URL variable\n# TEXT_FILE_URL = "https://samples.clarifai.com/negative_sentence_12.txt"\n# Or, to use a local text file, assign the location variable\n# TEXT_FILE_LOCATION = "YOUR_TEXT_FILE_LOCATION_HERE"\n\n############################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n############################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (("authorization", "Key " + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\n# To use a local text file, uncomment the following lines\n# with open(TEXT_FILE_LOCATION, "rb") as f:\n#    file_bytes = f.read()\n\npost_workflow_results_response = stub.PostWorkflowResults(\n    service_pb2.PostWorkflowResultsRequest(\n        user_app_id=userDataObject,\n        workflow_id=WORKFLOW_ID,\n        inputs=[\n            resources_pb2.Input(\n                data=resources_pb2.Data(\n                    text=resources_pb2.Text(\n                        raw=RAW_TEXT\n                        # url=TEXT_FILE_URL\n                        # raw=file_bytes\n                    )\n                )\n            )\n        ],\n    ),\n    metadata=metadata,\n)\nif post_workflow_results_response.status.code != status_code_pb2.SUCCESS:\n    print(post_workflow_results_response.status)\n    raise Exception("Post workflow results failed, status: " + post_workflow_results_response.status.description)\n\n# We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here one WorkflowResult\nresults = post_workflow_results_response.results[0]\n\n# Each model we have in the workflow will produce one output.\nfor output in results.outputs:\n    model = output.model\n\n    print("Predicted output for the model: `%s`" % model.id)       \n    print(output.data.text.raw)\n\n# Uncomment this line to print the full Response JSON\n# print(results)',g='\x3c!--index.html file--\x3e\n\n<script>\n    ////////////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, workflow ID, and the text \n    // we want as an input. Change these strings to run your own example.\n    ///////////////////////////////////////////////////////////////////////////////////////////////////\n  \n    // Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    const USER_ID = "YOUR_USER_ID_HERE";\n    // Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    const PAT = "YOUR_PAT_HERE";\n    const APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to make your own predictions\n    const WORKFLOW_ID = "my-custom-prompter-workflow";\n    const RAW_TEXT = "I love your product very much";\n    // To use a hosted text file, assign the URL variable\n    // const TEXT_FILE_URL = "https://samples.clarifai.com/negative_sentence_12.txt";\n  \n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    /////////////////////////////////////////////////////////////////////////////////// \n  \n    const raw = JSON.stringify({\n      "user_app_id": {\n        "user_id": USER_ID,\n        "app_id": APP_ID\n      },\n      "inputs": [\n        {\n          "data": {\n            "text": {\n              "raw": RAW_TEXT\n              // "url": TEXT_FILE_URL\n            }\n          }\n        }\n      ]\n    });\n  \n    const requestOptions = {\n      method: "POST",\n      headers: {\n        "Accept": "application/json",\n        "Authorization": "Key " + PAT\n      },\n      body: raw\n    };\n  \n    fetch(`https://api.clarifai.com/v2/workflows/${WORKFLOW_ID}/results`, requestOptions)\n      .then(response => response.text())\n      .then(result => console.log(result))\n      .catch(error => console.log("error", error));\n  \n  <\/script>',A='//index.js file\n\n//////////////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, workflow ID, and the text \n// we want as an input. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = \'YOUR_USER_ID_HERE\';\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\nconst PAT = \'YOUR_PAT_HERE\';\nconst APP_ID = \'YOUR_APP_ID_HERE\';\n// Change these to make your own predictions\nconst WORKFLOW_ID = "my-custom-prompter-workflow";\nconst RAW_TEXT = "I love your product very much";\n// To use a hosted text file, assign the URL variable\n// const TEXT_FILE_URL = "https://samples.clarifai.com/negative_sentence_12.txt"\n// Or, to use a local text file, assign the location variable\n// TEXT_FILE_LOCATION = "YOUR_TEXT_FILE_LOCATION_HERE"\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\n// To use a local text file, uncomment the following lines\n// const fs = require("fs");\n// const fileBytes = fs.readFileSync(TEXT_FILE_LOCATION);\n\nstub.PostWorkflowResults({\n    user_app_id: {\n        "user_id": USER_ID,\n        "app_id": APP_ID,\n    },\n    workflow_id: WORKFLOW_ID,\n    inputs: [{\n        data: {\n            text: {\n                raw: RAW_TEXT\n                // url: TEXT_FILE_URL,\n                // raw: fileBytes\n            }\n        }\n    }],\n},\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error(\n                "Post workflow results failed, status: " + response.status.description\n            );\n        }\n\n        // We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here \n        // one WorkflowResult\n        const results = response.results[0];\n\n        // Each model we have in the workflow will produce one output.\n        for (const output of results.outputs) {\n            const model = output.model;\n\n            console.log(`Predicted concepts for the model \'${model.id}\'`);\n            console.log(output.data.text.raw);\n\n        }\n        // Uncomment this line to print the full Response JSON\n        // console.log(results);\n    }\n);',S='package com.clarifai.example;\n\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\n\nimport com.google.protobuf.ByteString;\nimport java.io.File;\nimport java.io.IOException;\nimport java.nio.file.Files;\n\npublic class ClarifaiExample {\n\n    /////////////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, workflow ID, and the text \n    // we want as an input. Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////////////////////////////\n    \n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to make your own predictions\n    static final String WORKFLOW_ID = "my-custom-prompter-workflow";\n    static final String RAW_TEXT = "I love your product very much";    \n    // To use a hosted text file, assign the URL variable\n    // static final String TEXT_FILE_URL = "https://samples.clarifai.com/negative_sentence_12.txt";\n    // Or, to use a local text file, assign the location variable\n    // static final String TEXT_FILE_LOCATION = "YOUR_TEXT_FILE_LOCATION_HERE";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n    \n    public static void main(String[] args) throws IOException {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n                .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        PostWorkflowResultsResponse postWorkflowResultsResponse = stub.postWorkflowResults(\n                PostWorkflowResultsRequest.newBuilder()\n                        .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n                        .setWorkflowId(WORKFLOW_ID)\n                        .addInputs(\n                                Input.newBuilder().setData(\n                                        Data.newBuilder().setText(\n                                                Text.newBuilder().setRaw(RAW_TEXT)\n                                                // Text.newBuilder().setUrl(TEXT_FILE_URL)\n                                                // Text.newBuilder().setRawBytes(ByteString.copyFrom(Files.readAllBytes(\n                                                       // new File(TEXT_FILE_LOCATION).toPath()\n                                                //)))\n                                        )\n                                )\n                        )\n                        .build()\n        );\n\n        if (postWorkflowResultsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post workflow results failed, status: " + postWorkflowResultsResponse.getStatus());\n        }\n\n        // We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here\n        // one WorkflowResult\n        WorkflowResult results = postWorkflowResultsResponse.getResults(0);\n\n        // Each model we have in the workflow will produce its output       \n        for (Output output : results.getOutputsList()) {\n            Model model = output.getModel();\n\n            System.out.println("Predicted concepts for the model \'" + model.getId() + "\'");\n            \n            System.out.println(output.getData().getText().getRaw());\n \n        }\n\n        // Uncomment this line to print the full Response JSON\n        // System.out.println(results);\n    }\n\n}',L='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/workflows/my-custom-prompter-workflow/results" \\\n  -H "authorization: Key YOUR_PAT_HERE" \\\n  -H "content-type: application/json" \\\n  -d \'{\n    "inputs": [\n        {\n          "data": {\n            "text": {\n              "raw": "I love your product very much"\n          }\n        }\n      }\n    ]\n}\'',M='<?php\n\nrequire __DIR__ . "/vendor/autoload.php";\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, user and app ID, workflow ID, and the text \n// we want as an input. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////////////////\n\n$USER_ID = "YOUR_USER_ID_HERE";\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\n$PAT = "YOUR_PAT_HERE";\n$APP_ID = "YOUR_APP_ID_HERE";\n// Change these to make your own predictions\n$WORKFLOW_ID = "my-custom-prompter-workflow";\n$RAW_TEXT = "I love your product very much";\n// To use a hosted text file, assign the URL variable\n// $TEXT_FILE_URL = "https://samples.clarifai.com/negative_sentence_12.txt";\n// Or, to use a local text file, assign the location variable\n// $TEXT_FILE_LOCATION = "YOUR_TEXT_FILE_LOCATION_HERE";\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nuse Clarifai\\ClarifaiClient;\nuse Clarifai\\Api\\Data;\nuse Clarifai\\Api\\Text;\nuse Clarifai\\Api\\Input;\nuse Clarifai\\Api\\PostWorkflowResultsRequest;\nuse Clarifai\\Api\\Status\\StatusCode;\nuse Clarifai\\Api\\UserAppIDSet;\n\n$client = ClarifaiClient::grpc();\n\n$metadata = ["Authorization" => ["Key " . $PAT]];\n\n$userDataObject = new UserAppIDSet([\n    "user_id" => $USER_ID,\n    "app_id" => $APP_ID,\n]);\n\n// To use a local text file, uncomment the following lines\n// $textData = file_get_contents($TEXT_FILE_LOCATION); \n\n// Let\'s make a RPC call to the Clarifai platform. It uses the opened gRPC client channel to communicate a\n// request and then wait for the response\n[$response, $status] = $client\n    ->PostWorkflowResults(\n        // The request object carries the request along with the request status and other metadata related to the request itself\n        new PostWorkflowResultsRequest([\n            "user_app_id" => $userDataObject,\n            "workflow_id" => $WORKFLOW_ID,\n            "inputs" => [\n                new Input([\n                    // The Input object wraps the Data object in order to meet the API specification\n                    "data" => new Data([\n                        // The Data object is constructed around the Image object. It offers a container that has additional image independent\n                        // metadata. In this particular use case, no other metadata is needed to be specified\n                        "text" => new Text([\n                            // In the Clarifai platform, a text is defined by a special Text object\n                            "raw" => $RAW_TEXT\n                            // "url" => $TEXT_FILE_URL \n                            // "raw" => $textData \n                        ]),\n                    ]),\n                ]),\n            ],\n        ]),\n        $metadata\n    )\n    ->wait();\n\n// A response is returned and the first thing we do is check the status of it\n// A successful response will have a status code of 0; otherwise, there is some error\nif ($status->code !== 0) {\n    throw new Exception("Error: {$status->details}");\n}\n// In addition to the RPC response status, there is a Clarifai API status that reports if the operation was a success or failure\n// (not just that the communication was successful)\nif ($response->getStatus()->getCode() != StatusCode::SUCCESS) {\n    throw new Exception(\n        "Failure response: " .\n            $response->getStatus()->getDescription() .\n            " " .\n            $response->getStatus()->getDetails()\n    );\n}\n\n// We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here one WorkflowResult\n$results = $response->getResults()[0];\n\n// Each model we have in the workflow will produce one output\nforeach ($results->getOutputs() as $output) {\n    $model = $output->getModel();\n\n    echo "Predicted concepts for the model \'{$model->getId()}\'" . "\\n";\n\n    $convertDataToJSONString = $output->getData()->getText()->getRaw();\n\n    echo  $convertDataToJSONString . "\\n";\n}\n\n// Uncomment this line to print the full Response JSON\n// print_r($results);\n\n?>',b="Predicted output for the model: `my-prompter-model`\nClassify whether the sentiment of the given text is positive or negative I love your product very much\n\nPredicted output for the model: `GPT-4`\nThe sentiment of the given text is positive.",C={description:"Learn how to integrate a prompter model into an LLM workflow",sidebar_position:5},N="Custom Prompter Model",U={id:"api-guide/workflows/common-workflows/prompter-model",title:"Custom Prompter Model",description:"Learn how to integrate a prompter model into an LLM workflow",source:"@site/docs/api-guide/workflows/common-workflows/prompter-model.md",sourceDirName:"api-guide/workflows/common-workflows",slug:"/api-guide/workflows/common-workflows/prompter-model",permalink:"/api-guide/workflows/common-workflows/prompter-model",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/api-guide/workflows/common-workflows/prompter-model.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{description:"Learn how to integrate a prompter model into an LLM workflow",sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"Visual Text Recognition",permalink:"/api-guide/workflows/common-workflows/visual-text-recognition-walkthrough"},next:{title:"Base Workflow",permalink:"/api-guide/workflows/base-workflows"}},x={},v=[{value:"Create a Prompter Model",id:"create-a-prompter-model",level:2},{value:"Train a Prompter Model",id:"train-a-prompter-model",level:2},{value:"Add to a Workflow",id:"add-to-a-workflow",level:2},{value:"Workflow Predict",id:"workflow-predict",level:2}];function y(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",p:"p",strong:"strong",...(0,s.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"custom-prompter-model",children:"Custom Prompter Model"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Integrate a prompter model into an LLM workflow"})}),"\n",(0,o.jsx)("hr",{}),"\n",(0,o.jsxs)(n.p,{children:["A ",(0,o.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/agent-system-operators/prompter",children:"prompter model"})," is a type of language model specifically designed to craft instructions that guide the output of large language models (LLMs). It helps in prompt engineering, focusing on optimizing the responses of LLMs to prompts."]}),"\n",(0,o.jsxs)(n.p,{children:["Let's demonstrate how you can create your own prompter model and connect it to an LLM in a ",(0,o.jsx)(n.a,{href:"https://docs.clarifai.com/api-guide/workflows/",children:"workflow"}),"."]}),"\n",(0,o.jsx)(n.admonition,{type:"info",children:(0,o.jsxs)(n.p,{children:["The initialization code used in the following examples is outlined in detail on the ",(0,o.jsx)(n.a,{href:"https://docs.clarifai.com/api-guide/api-overview/api-clients/#client-installation-instructions",children:"client installation page."})]})}),"\n","\n","\n","\n","\n","\n","\n",(0,o.jsx)(n.h2,{id:"create-a-prompter-model",children:"Create a Prompter Model"}),"\n",(0,o.jsxs)(a.A,{children:[(0,o.jsx)(r.A,{value:"grpc_python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:l})}),(0,o.jsx)(r.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,o.jsx)(i.A,{className:"language-javascript",children:c})}),(0,o.jsx)(r.A,{value:"grpc_nodejs",label:"NodeJS",children:(0,o.jsx)(i.A,{className:"language-javascript",children:p})}),(0,o.jsx)(r.A,{value:"grpc_java",label:"Java",children:(0,o.jsx)(i.A,{className:"language-java",children:u})}),(0,o.jsx)(r.A,{value:"php",label:"PHP",children:(0,o.jsx)(i.A,{className:"language-php",children:_})}),(0,o.jsx)(r.A,{value:"curl",label:"cURL",children:(0,o.jsx)(i.A,{className:"language-bash",children:d})})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Output Example"}),(0,o.jsx)(i.A,{className:"language-js",children:b})]}),"\n",(0,o.jsx)(n.h2,{id:"train-a-prompter-model",children:"Train a Prompter Model"}),"\n",(0,o.jsx)(n.p,{children:"When training a prompter model, you need to provide a prompt template, which serves as a pre-configured piece of text for instructing an LLM."}),"\n",(0,o.jsxs)(n.p,{children:["Note that your prompt template should include at least one instance of the placeholder ",(0,o.jsx)(n.code,{children:"{data.text.raw}"}),". When you input your text data at inference time, all occurrences of ",(0,o.jsx)(n.code,{children:"{data.text.raw}"})," within the template will be replaced with the provided text."]}),"\n",(0,o.jsxs)(a.A,{children:[(0,o.jsx)(r.A,{value:"grpc_python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:E})}),(0,o.jsx)(r.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,o.jsx)(i.A,{className:"language-javascript",children:h})}),(0,o.jsx)(r.A,{value:"grpc_java",label:"Java",children:(0,o.jsx)(i.A,{className:"language-java",children:m})}),(0,o.jsx)(r.A,{value:"curl",label:"cURL",children:(0,o.jsx)(i.A,{className:"language-bash",children:f})})]}),"\n",(0,o.jsx)(n.h2,{id:"add-to-a-workflow",children:"Add to a Workflow"}),"\n",(0,o.jsx)(n.p,{children:"After training your prompter model, you can now put it to work by integrating it into an LLM workflow and using it to accomplish various tasks."}),"\n",(0,o.jsxs)(n.p,{children:["Below is an example of how to connect a prompter model to an LLM like ",(0,o.jsx)(n.a,{href:"https://clarifai.com/openai/chat-completion/models/GPT-4",children:"GPT-4"})," for text-to-text tasks."]}),"\n",(0,o.jsxs)(a.A,{children:[(0,o.jsx)(r.A,{value:"grpc_python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:I})}),(0,o.jsx)(r.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,o.jsx)(i.A,{className:"language-javascript",children:D})}),(0,o.jsx)(r.A,{value:"grpc_nodejs",label:"NodeJS",children:(0,o.jsx)(i.A,{className:"language-javascript",children:w})}),(0,o.jsx)(r.A,{value:"grpc_java",label:"Java",children:(0,o.jsx)(i.A,{className:"language-java",children:O})}),(0,o.jsx)(r.A,{value:"php",label:"PHP",children:(0,o.jsx)(i.A,{className:"language-php",children:P})}),(0,o.jsx)(r.A,{value:"curl",label:"cURL",children:(0,o.jsx)(i.A,{className:"language-bash",children:R})})]}),"\n",(0,o.jsx)(n.h2,{id:"workflow-predict",children:"Workflow Predict"}),"\n",(0,o.jsx)(n.p,{children:"After creating the workflow, let's now use it to perform a text sentiment prediction task."}),"\n",(0,o.jsxs)(a.A,{children:[(0,o.jsx)(r.A,{value:"grpc_python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:T})}),(0,o.jsx)(r.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,o.jsx)(i.A,{className:"language-javascript",children:g})}),(0,o.jsx)(r.A,{value:"grpc_nodejs",label:"NodeJS",children:(0,o.jsx)(i.A,{className:"language-javascript",children:A})}),(0,o.jsx)(r.A,{value:"grpc_java",label:"Java",children:(0,o.jsx)(i.A,{className:"language-java",children:S})}),(0,o.jsx)(r.A,{value:"php",label:"PHP",children:(0,o.jsx)(i.A,{className:"language-php",children:M})}),(0,o.jsx)(r.A,{value:"curl",label:"cURL",children:(0,o.jsx)(i.A,{className:"language-bash",children:L})})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Output Example"}),(0,o.jsx)(i.A,{className:"language-js",children:b})]}),"\n",(0,o.jsxs)(n.p,{children:["As you can see on the output above, the response contains the predictions of each model in the workflow. The prompt text starts with the earlier provided template text, and the ",(0,o.jsx)(n.code,{children:"{data.text.raw}"})," placeholder is substituted with the provided input text. That is what is used as a prompt for the GPT-4 model."]}),"\n",(0,o.jsx)(n.p,{children:"And the model correctly predicts the sentiment of the provided input text."})]})}function k(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(y,{...e})}):y(e)}},19365:(e,n,t)=>{t.d(n,{A:()=>r});t(96540);var o=t(18215);const s={tabItem:"tabItem_Ymn6"};var a=t(74848);function r(e){let{children:n,hidden:t,className:r}=e;return(0,a.jsx)("div",{role:"tabpanel",className:(0,o.A)(s.tabItem,r),hidden:t,children:n})}},11470:(e,n,t)=>{t.d(n,{A:()=>R});var o=t(96540),s=t(18215),a=t(23104),r=t(56347),i=t(205),l=t(57485),c=t(31682),p=t(70679);function u(e){return o.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function d(e){const{values:n,children:t}=e;return(0,o.useMemo)((()=>{const e=n??function(e){return u(e).map((e=>{let{props:{value:n,label:t,attributes:o,default:s}}=e;return{value:n,label:t,attributes:o,default:s}}))}(t);return function(e){const n=(0,c.X)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function _(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function E(e){let{queryString:n=!1,groupId:t}=e;const s=(0,r.W6)(),a=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,l.aZ)(a),(0,o.useCallback)((e=>{if(!a)return;const n=new URLSearchParams(s.location.search);n.set(a,e),s.replace({...s.location,search:n.toString()})}),[a,s])]}function h(e){const{defaultValue:n,queryString:t=!1,groupId:s}=e,a=d(e),[r,l]=(0,o.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!_({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const o=t.find((e=>e.default))??t[0];if(!o)throw new Error("Unexpected error: 0 tabValues");return o.value}({defaultValue:n,tabValues:a}))),[c,u]=E({queryString:t,groupId:s}),[h,m]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[s,a]=(0,p.Dv)(t);return[s,(0,o.useCallback)((e=>{t&&a.set(e)}),[t,a])]}({groupId:s}),f=(()=>{const e=c??h;return _({value:e,tabValues:a})?e:null})();(0,i.A)((()=>{f&&l(f)}),[f]);return{selectedValue:r,selectValue:(0,o.useCallback)((e=>{if(!_({value:e,tabValues:a}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),m(e)}),[u,m,a]),tabValues:a}}var m=t(92303);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var I=t(74848);function D(e){let{className:n,block:t,selectedValue:o,selectValue:r,tabValues:i}=e;const l=[],{blockElementScrollPositionUntilNextRender:c}=(0,a.a_)(),p=e=>{const n=e.currentTarget,t=l.indexOf(n),s=i[t].value;s!==o&&(c(n),r(s))},u=e=>{let n=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return(0,I.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":t},n),children:i.map((e=>{let{value:n,label:t,attributes:a}=e;return(0,I.jsx)("li",{role:"tab",tabIndex:o===n?0:-1,"aria-selected":o===n,ref:e=>l.push(e),onKeyDown:u,onClick:p,...a,className:(0,s.A)("tabs__item",f.tabItem,a?.className,{"tabs__item--active":o===n}),children:t??n},n)}))})}function w(e){let{lazy:n,children:t,selectedValue:s}=e;const a=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=a.find((e=>e.props.value===s));return e?(0,o.cloneElement)(e,{className:"margin-top--md"}):null}return(0,I.jsx)("div",{className:"margin-top--md",children:a.map(((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==s})))})}function O(e){const n=h(e);return(0,I.jsxs)("div",{className:(0,s.A)("tabs-container",f.tabList),children:[(0,I.jsx)(D,{...n,...e}),(0,I.jsx)(w,{...n,...e})]})}function R(e){const n=(0,m.A)();return(0,I.jsx)(O,{...e,children:u(e.children)},String(n))}}}]);