"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[1796],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>g});var n=a(67294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var r=n.createContext({}),c=function(e){var t=n.useContext(r),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(r.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,i=e.originalType,r=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=c(a),g=o,h=u["".concat(r,".").concat(g)]||u[g]||d[g]||i;return a?n.createElement(h,l(l({ref:t},p),{},{components:a})):n.createElement(h,l({ref:t},p))}));function g(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=a.length,l=new Array(i);l[0]=u;var s={};for(var r in t)hasOwnProperty.call(t,r)&&(s[r]=t[r]);s.originalType=e,s.mdxType="string"==typeof e?e:o,l[1]=s;for(var c=2;c<i;c++)l[c]=a[c];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},68654:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>r,contentTitle:()=>l,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>c});var n=a(87462),o=(a(67294),a(3905));const i={description:"Learn about the different types of labels that are possible with Scribe",sidebar_position:3},l="Label Types",s={unversionedId:"portal-guide/annotate/label-types",id:"portal-guide/annotate/label-types",title:"Label Types",description:"Learn about the different types of labels that are possible with Scribe",source:"@site/docs/portal-guide/annotate/label-types.md",sourceDirName:"portal-guide/annotate",slug:"/portal-guide/annotate/label-types",permalink:"/portal-guide/annotate/label-types",draft:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{description:"Learn about the different types of labels that are possible with Scribe",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Create a Task",permalink:"/portal-guide/annotate/create-a-task"},next:{title:"Labeling Tools",permalink:"/portal-guide/annotate/labeling-tools"}},r={},c=[{value:"How to Choose a Label Type",id:"how-to-choose-a-label-type",level:2},{value:"Classification Label Type",id:"classification-label-type",level:2},{value:"Detection Label Type (Bounding Box Detection)",id:"detection-label-type-bounding-box-detection",level:2},{value:"Detection for Still Images",id:"detection-for-still-images",level:3},{value:"Detection for Video",id:"detection-for-video",level:3},{value:"Polygon Detection",id:"polygon-detection",level:2}],p={toc:c};function d(e){let{components:t,...i}=e;return(0,o.kt)("wrapper",(0,n.Z)({},p,i,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"label-types"},"Label Types"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Learn about the different types of labels that are possible with Scribe")),(0,o.kt)("hr",null),(0,o.kt)("p",null,"The Scribe Label lets you create high-quality training data for building powerful machine learning models. You can use the automated data labeling tool to annotate unstructured image, video, and text data faster and more accurately\u2014something which could be laborious and time-consuming if done manually. "),(0,o.kt)("p",null,"It's a unique automated label prefilling technique that allows you to assign concepts for faster dataset annotation and speed labeling projects 100x. "),(0,o.kt)("p",null,"Scribe provides the following three basic label types for your images, videos, and texts:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Classification\u2014categorizes images, videos, and texts into categories;"),(0,o.kt)("li",{parentName:"ul"},"Detection\u2014detects where an object of interest is and draws a bounding box around it;"),(0,o.kt)("li",{parentName:"ul"},"Segmentation (polygons for segmentation)\u2014outlines the exact shape or contour of an object. ")),(0,o.kt)("p",null,"You can use any of the label types to complete your labeling tasks easily and quickly. These label types provide increasing levels of granularity to support the needs of your specific use case."),(0,o.kt)("h2",{id:"how-to-choose-a-label-type"},"How to Choose a Label Type"),(0,o.kt)("p",null,"You can choose the label type you want to use when creating a new labeling task. To create a new task, go to the individual page for your app, and select the ",(0,o.kt)("strong",{parentName:"p"},"Labeling")," option on the collapsible left sidebar. You'll be redirected to the ",(0,o.kt)("strong",{parentName:"p"},"Tasks")," manager page. "),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"task manager page",src:a(71497).Z,width:"1889",height:"821"})),(0,o.kt)("p",null,"Next, click the ",(0,o.kt)("strong",{parentName:"p"},"Create New Task")," button at the upper-right corner of the page, and you'll be redirected to the ",(0,o.kt)("strong",{parentName:"p"},"New Labeling Task")," page, where you can provide the details for creating a new task. "),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"new labeling task page",src:a(71169).Z,width:"1823",height:"839"})),(0,o.kt)("p",null,"Under the ",(0,o.kt)("strong",{parentName:"p"},"Task Type")," option, you can select your desired type of label. "),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"You can read ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/annotate/create-a-task"},"here")," to learn more about how to create a new labeling task. ")),(0,o.kt)("p",null,"After creating a new task, it will be listed on the ",(0,o.kt)("strong",{parentName:"p"},"Tasks")," manager page. To access your assigned tasks and start labeling using Scribe, click the ",(0,o.kt)("strong",{parentName:"p"},"LABEL")," button. "),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"new labeling task page",src:a(81074).Z,width:"1917",height:"537"})),(0,o.kt)("p",null,"Next, you'll be redirected to the Scribe tasks labeler page, where you can use any of the label types you selected when creating a task to complete your assigned labeling work. "),(0,o.kt)("h2",{id:"classification-label-type"},"Classification Label Type"),(0,o.kt)("p",null,"With the classification label type, you can provide annotations for an entire image or a single frame of video. On the right sidebar, you can find a list of the ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/annotate/create-a-task#concepts"},"concepts")," you created when you assigned a new labeling task. "),(0,o.kt)("p",null,"To classify an image, just click the tick button next to the concept you want to label the image with. "),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"classify an image",src:a(15138).Z,width:"1907",height:"943"})),(0,o.kt)("p",null,"You can also click the cross button to explicitly label the image as not having the concept. "),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"label with cross button",src:a(61804).Z,width:"1863",height:"765"})),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"Clicking an already clicked tick or cross button removes the label.")),(0,o.kt)("p",null,"You can also apply multiple labels to the same image. Let's say you have two classes that might be easily confused by your model, such as cats and dogs, you can specifically indicate that a cat is present and a dog is not present. This can improve the performance of your model, but also result in longer labeling times."),(0,o.kt)("p",null,'In the following screenshot, the tick button has been clicked, indicating that the image has been labeled with the "cat" concept. Also, the cross button has been clicked, indicating that the image has been expressly labeled as not having the "dog" concept.'),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"cat and dog label",src:a(7464).Z,width:"1901",height:"947"})),(0,o.kt)("p",null,"If you enabled AI Assist when you created a new labeling task, you'll notice the concepts that the Clarifai AI has suggested, which could be present in the image you want to label\u2014alongside their probabilities. You can accept the highlighted suggestions to help you label your images quickly and fast. You can also adjust the slider to a prediction probability threshold you desire. "),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"label with AI assist",src:a(46883).Z,width:"1863",height:"841"})),(0,o.kt)("p",null,"Finally, click the ",(0,o.kt)("strong",{parentName:"p"},"Submit")," button on the lower-right corner of the page to complete the labeling exercise. "),(0,o.kt)("h2",{id:"detection-label-type-bounding-box-detection"},"Detection Label Type (Bounding Box Detection)"),(0,o.kt)("p",null,"With the detection label type, you can provide annotation within a single box-shaped region of an image or a video. To use bounding box detection, you need to select a workflow that offers detection capabilities when creating a new labeling task. "),(0,o.kt)("p",null,"On the Scribe tasks labeler page, you can accept or modify the detected regions that the Clarifai's AI Assist technology has suggested for labeling\u2014that is, if you enabled AI Assist when you created a new labeling task. "),(0,o.kt)("p",null,"You can also click the plus (",(0,o.kt)("strong",{parentName:"p"},"+"),") button next to the concept you want to use for labeling to start drawing your own bounding boxes. "),(0,o.kt)("h3",{id:"detection-for-still-images"},"Detection for Still Images"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"detection for still images",src:a(83417).Z,width:"1881",height:"925"})),(0,o.kt)("h3",{id:"detection-for-video"},"Detection for Video"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Bounding box detection for video",src:a(96945).Z,width:"1000",height:"562"})),(0,o.kt)("h2",{id:"polygon-detection"},"Polygon Detection"),(0,o.kt)("p",null,"Provide annotation within any polygon-shaped region of an image or video."),(0,o.kt)("p",null,(0,o.kt)("img",{src:a(1923).Z,width:"1000",height:"562"})))}d.isMDXComponent=!0},71497:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/label_types_1-4506bf33a44c2c5e2107200d9322daa7.png"},71169:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/label_types_2-42a87883e162bf86825f42aefd69e545.png"},81074:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/label_types_3-312b27a272664885ad7e3a9bc0cfbd3f.png"},7464:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/label_types_4-2757869eb60dd31c5f2ec30cb44b5cf2.png"},15138:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/label_types_5-053a6dd26acc893cafac6f70fa2352d7.png"},61804:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/label_types_6-db0acc130cc3c04f699d99019db58878.png"},46883:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/label_types_7-0ab25a7c4a806fe6c0f166327eff36c9.png"},83417:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/label_types_8-e1f140a4d108a7bdadf873e325357d3b.png"},1923:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/polygon-18128a6f04319c765e53c28fa70d5382.jpg"},96945:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/video_detector-a224ae3f78fcfd41b2715f5c37da89a3.jpg"}}]);