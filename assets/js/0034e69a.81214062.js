"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[8941],{85162:(t,e,a)=>{a.d(e,{Z:()=>s});var n=a(67294),o=a(86010);const i={tabItem:"tabItem_Ymn6"};function s(t){let{children:e,hidden:a,className:s}=t;return n.createElement("div",{role:"tabpanel",className:(0,o.Z)(i.tabItem,s),hidden:a},e)}},74866:(t,e,a)=>{a.d(e,{Z:()=>v});var n=a(87462),o=a(67294),i=a(86010),s=a(12466),l=a(16550),r=a(91980),d=a(67392),u=a(50012);function p(t){return function(t){return o.Children.map(t,(t=>{if(!t||(0,o.isValidElement)(t)&&function(t){const{props:e}=t;return!!e&&"object"==typeof e&&"value"in e}(t))return t;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof t.type?t.type:t.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(t).map((t=>{let{props:{value:e,label:a,attributes:n,default:o}}=t;return{value:e,label:a,attributes:n,default:o}}))}function c(t){const{values:e,children:a}=t;return(0,o.useMemo)((()=>{const t=e??p(a);return function(t){const e=(0,d.l)(t,((t,e)=>t.value===e.value));if(e.length>0)throw new Error(`Docusaurus error: Duplicate values "${e.map((t=>t.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(t),t}),[e,a])}function m(t){let{value:e,tabValues:a}=t;return a.some((t=>t.value===e))}function f(t){let{queryString:e=!1,groupId:a}=t;const n=(0,l.k6)(),i=function(t){let{queryString:e=!1,groupId:a}=t;if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:e,groupId:a});return[(0,r._X)(i),(0,o.useCallback)((t=>{if(!i)return;const e=new URLSearchParams(n.location.search);e.set(i,t),n.replace({...n.location,search:e.toString()})}),[i,n])]}function h(t){const{defaultValue:e,queryString:a=!1,groupId:n}=t,i=c(t),[s,l]=(0,o.useState)((()=>function(t){let{defaultValue:e,tabValues:a}=t;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${a.map((t=>t.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=a.find((t=>t.default))??a[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:e,tabValues:i}))),[r,d]=f({queryString:a,groupId:n}),[p,h]=function(t){let{groupId:e}=t;const a=function(t){return t?`docusaurus.tab.${t}`:null}(e),[n,i]=(0,u.Nk)(a);return[n,(0,o.useCallback)((t=>{a&&i.set(t)}),[a,i])]}({groupId:n}),y=(()=>{const t=r??p;return m({value:t,tabValues:i})?t:null})();(0,o.useLayoutEffect)((()=>{y&&l(y)}),[y]);return{selectedValue:s,selectValue:(0,o.useCallback)((t=>{if(!m({value:t,tabValues:i}))throw new Error(`Can't select invalid tab value=${t}`);l(t),d(t),h(t)}),[d,h,i]),tabValues:i}}var y=a(72389);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function b(t){let{className:e,block:a,selectedValue:l,selectValue:r,tabValues:d}=t;const u=[],{blockElementScrollPositionUntilNextRender:p}=(0,s.o5)(),c=t=>{const e=t.currentTarget,a=u.indexOf(e),n=d[a].value;n!==l&&(p(e),r(n))},m=t=>{let e=null;switch(t.key){case"Enter":c(t);break;case"ArrowRight":{const a=u.indexOf(t.currentTarget)+1;e=u[a]??u[0];break}case"ArrowLeft":{const a=u.indexOf(t.currentTarget)-1;e=u[a]??u[u.length-1];break}}e?.focus()};return o.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.Z)("tabs",{"tabs--block":a},e)},d.map((t=>{let{value:e,label:a,attributes:s}=t;return o.createElement("li",(0,n.Z)({role:"tab",tabIndex:l===e?0:-1,"aria-selected":l===e,key:e,ref:t=>u.push(t),onKeyDown:m,onClick:c},s,{className:(0,i.Z)("tabs__item",g.tabItem,s?.className,{"tabs__item--active":l===e})}),a??e)})))}function k(t){let{lazy:e,children:a,selectedValue:n}=t;const i=(Array.isArray(a)?a:[a]).filter(Boolean);if(e){const t=i.find((t=>t.props.value===n));return t?(0,o.cloneElement)(t,{className:"margin-top--md"}):null}return o.createElement("div",{className:"margin-top--md"},i.map(((t,e)=>(0,o.cloneElement)(t,{key:e,hidden:t.props.value!==n}))))}function _(t){const e=h(t);return o.createElement("div",{className:(0,i.Z)("tabs-container",g.tabList)},o.createElement(b,(0,n.Z)({},t,e)),o.createElement(k,(0,n.Z)({},t,e)))}function v(t){const e=(0,y.Z)();return o.createElement(_,(0,n.Z)({key:String(e)},t))}},52421:(t,e,a)=>{a.r(e),a.d(e,{assets:()=>j,contentTitle:()=>A,default:()=>L,frontMatter:()=>B,metadata:()=>E,toc:()=>q});var n=a(87462),o=(a(67294),a(3905)),i=a(74866),s=a(85162),l=a(90814);const r='from clarifai.client.app import App\n\napp = App(app_id="test_app", user_id="user_id",pat=\u201dYOUR_PAT\u201d)\n# Provide the dataset name as parameter in the create_dataset function\ndataset = app.create_dataset(dataset_id="first_dataset")',d="from clarifai.client.dataset import Dataset\n# Create a dataset object\ndataset = Dataset(dataset_id='first_dataset', user_id='user_id', app_id='test_app',pat=\u2019YOUR_PAT\u2019)\n# Create a new version of the dataset\ndataset_version = dataset.create_version(description='dataset_version_description')",u='from clarifai.client.dataset import Dataset\n\n\n# Create a dataset object\ndataset = Dataset(user_id="user_id", app_id="test_app", dataset_id="first_dataset",pat=\u201dYOUR_PAT\u201d)\n#To upload without concepts(labels=False)\n#upload data from folder\ndataset.upload_from_folder(folder_path=\'./images\', input_type=\'image\', labels=True)',p='from clarifai.client.dataset import Dataset\n\n# Create the dataset object\ndataset = Dataset(user_id="user_id", app_id="test_app", dataset_id="first_dataset",pat=\u201dYOUR_PAT\u201d)\n#To upload without concepts(labels=False)\n# upload dataset from folder\ndataset.upload_from_folder(folder_path=\'./data\', input_type=\'text\', labels=True)',c="from clarifai.client.dataset import Dataset\n\n\n#Create a dataset object\ndataset = Dataset(user_id=\"user_id\", app_id=\"test_app\", dataset_id=\"first_dataset\",pat=\u201dYOUR_PAT\u201d)\n#To upload without concepts(labels=False)\n#Upload data from csv\ndataset.upload_from_csv(csv_path='/Users/adithyansukumar/Desktop/data/test.csv', input_type='audio',csv_type='url', labels=True)",m='from clarifai.client.input import Inputs\n\n\nurl = "https://samples.clarifai.com/BarackObama.jpg"\n#replace your "user_id", "app_id", "dataset_id".\ninput_object = Inputs(user_id="user_id", app_id="test_app",pat=\u201dYOUR_PAT\u201d)\n\n# Upload image data from a specified URL with a unique input ID "bbox"\ninput_object.upload_from_url(input_id="bbox", image_url=url)\n\n# Define bounding box coordinates for the annotation (left, top, right, bottom)\nbbox_points = [.1, .1, .8, .9]\n\n# Generate a bounding box annotation proto with specified label ("face") and bounding box coordinates\nannotation = input_object.get_bbox_proto(input_id="bbox", label="face", bbox=bbox_points)\n\n# Upload the generated annotation to associate with the previously uploaded image\ninput_object.upload_annotations([annotation])\n',f='from clarifai.client.input import Inputs\n\nurl = "https://samples.clarifai.com/beer.mp4"\n#replace your "user_id", "app_id", "dataset_id".\ninput_object = Inputs(user_id="user_id", app_id="test_app",pat=\u201dYOUR_PAT\u201d)\n\n# Upload an image from a URL with a specified input ID\ninput_object.upload_from_url(input_id="bbox", video_url=url)\n\n# Define bounding box coordinates for annotation\nbbox_points = [.1, .1, .8, .9]\n\n# Create an annotation using the bounding box coordinates\nannotation = input_object.get_bbox_proto(input_id="video_bbox", label="glass", bbox=bbox_points)\n\n# Upload the annotation associated with the image\ninput_object.upload_annotations([annotation])\n',h='from clarifai.client.input import Inputs\n\nurl = "https://samples.clarifai.com/featured-models/Llama2_Conversational-agent.txt"\nconcepts = ["mobile","camera"]\n#replace your "user_id", "app_id", "dataset_id".\ninput_object = Inputs(user_id="user_id", app_id="test_app",pat=\u201dYOUR_PAT\u201d)\n#Upload data from url with annotation\ninput_object.upload_from_url(input_id="text1",text_url=url, labels=concepts)\n',y='from clarifai.client.dataset import Dataset\nfrom clarifai.datasets.upload.utils import load_module_dataloader\n\n\n#replace your "user_id", "app_id", "dataset_id".\ndataset = Dataset(user_id="user_id", app_id="test_app", dataset_id="first_dataset")\n#create dataloader object\ncifar_dataloader = load_module_dataloader(\'./image_classification/cifar10\')\n#set get_upload_status=True for showing upload status\ndataset.upload_dataset(dataloader=cifar_dataloader,get_upload_status=True)\n',g="from clarifai.client.dataset import Dataset\n\n# The \u201cclarifai-data-protobuf.zip\u201d file can be downloaded from the dataset section in the portal.\nDataset().export(save_path='output.zip', local_archive_path='clarifai-data-protobuf.zip')",b="from clarifai.client.input import Inputs\ninput_obj = Inputs( user_id='user_id', app_id='test_app')\n\n#listing inputs\ninput_generator = input_obj.list_inputs(page_no=1,per_page=1,input_type='image')\ninputs_list = list(input_generator)\n\n#downloading_inputs\ninput_bytes = input_obj.download_inputs(inputs_list)\nwith open('demo.jpg','wb') as f:\n  f.write(input_bytes[0])",k="from clarifai.client.dataset import Dataset\n\n\n#Create dataset object\ndataset = Dataset(dataset_id='first_dataset', user_id='user_id', app_id='test_app')\n#Delete dataset version\ndataset.delete_version(version_id='dataset_version')",_='from clarifai.client.app import App\n\napp = App(app_id="test_app", user_id="user_id")\n# Provide the dataset name as parameter in delete_dataset function\napp.delete_dataset(dataset_id="demo_dataset")',v='#importing load_module_dataloader for calling the dataloader object in dataset.py in the local data folder\nfrom clarifai.datasets.upload.utils import load_module_dataloader\nfrom clarifai.client.dataset import Dataset\n\n\n#replace your "user_id", "app_id", "dataset_id".\ndataset = Dataset(user_id="user_id", app_id="app_id", dataset_id="dataset_id")\n\ncifar_dataloader = load_module_dataloader(\'./image_classification/cifar10\')\n\ndataset.retry_upload_from_logs(dataloader=cifar_dataloader, log_file_path=\'path to log file\', retry_duplicates=True, log_warnings=True)',x='2024-01-19 14:22:26 INFO     clarifai.client.app:                                                        app.py:310\n                             Dataset created                                                                       \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             req_id: "1dd6eeb1a82394a9a92becee55faf50e"  \n',T='2024-01-19 14:26:31 INFO     clarifai:                                                                dataset.py:96\n\n                             Dataset Version created                                                               \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             req_id: "14802ff0826d6487dc454aa39877667e"  ',w="Uploading inputs: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:04&lt;00:00,  4.44s/it]",I="Uploading inputs: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:02&lt;00:00,  2.68s/it]",D="Uploading inputs: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:03&lt;00:00,  3.22s/it]",C='2024-01-19 16:16:28 INFO     clarifai.client.input:                                                    input.py:696\n\n                             Annotations Uploaded                                                                  \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             req_id: "b5ca21ebc19cbbfe0c21706b4c1cd909" ',N='[input_id: "video_bbox"\n\n data {\n\n   regions {\n\n     region_info {\n\n       bounding_box {\n\n         top_row: 0.1\n\n         left_col: 0.1\n\n         bottom_row: 0.9\n\n         right_col: 0.8\n\n       }\n\n     }\n\n     data {\n\n       concepts {\n\n         id: "id-glass"\n\n         name: "glass"\n\n         value: 1\n\n       }\n\n     }\n\n   }\n\n }]',Z='2024-01-19 16:23:54 INFO     clarifai.client.input:                                                    input.py:669\n\n                             Inputs Uploaded                                                                       \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             details: "All inputs successfully added"                                              \n\n                             req_id: "d5baa282c87ac0f91f0ef4083644ea82" ',S="Uploading Dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:17&lt;00:00, 17.99s/it]",U="2024-01-22 15:14:03 INFO     clarifai.datasets.export.inputs_annotations:  path:           inputs_annotations.py:48\n\n                             Downloads/clarifai-data-protobuf.zip                           \n\n2024-01-22 15:14:03 INFO     clarifai.datasets.export.inputs_annotations:  path:           inputs_annotations.py:48\n\n                             Downloads/clarifai-data-protobuf.zip                           \n\n                    INFO     clarifai.datasets.export.inputs_annotations:  Obtained file   inputs_annotations.py:56\n\n                             name list. 1 entries.                                                                 \n\n                    INFO     clarifai.datasets.export.inputs_annotations:  Obtained file   inputs_annotations.py:56\n\n                             name list. 1 entries.                                                                 \n\nDownloading Dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13/13 [00:00&lt;00:00, 6486.55it/s]\n\n2024-01-22 15:14:04 INFO     clarifai.datasets.export.inputs_annotations:  Downloaded 0   inputs_annotations.py:221\n\n                             inputs+annotations to output.zip                                                      \n\n2024-01-22 15:14:04 INFO     clarifai.datasets.export.inputs_annotations:  Downloaded 0   inputs_annotations.py:221\n\n                             inputs+annotations to output.zip                                                      \n\n                    INFO     clarifai.datasets.export.inputs_annotations:  closing file    inputs_annotations.py:92\n\n                             objects.                                                                              \n\n                    INFO     clarifai.datasets.export.inputs_annotations:  closing file    inputs_annotations.py:92\n\n                             objects.                                                                             \n",O='Output\n2024-01-22 15:22:25 INFO     clarifai:                                                               dataset.py:124\n                             Dataset Version Deleted                                                               \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             details: "Dataset version \\\'a4b032e9083f4cbfbdfe5617b1a4d5e7\\\' deleted"               \n                             req_id: "1fac439af87c37dae27684fcbe49b80b"  \n',P='2024-01-22 15:24:29 INFO     clarifai.client.app:                                                        app.py:617\n\n                             Dataset Deleted                                                                       \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             details: "Dataset \\\'demo_dataset\\\' deleted"                                           \n\n                             req_id: "97a8c49418da156d1b0227f9fa5f8dda" ',V="WARNING:root:Retrying upload for 9 duplicate inputs...\n\nUploading Dataset: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:24<00:00, 24.32s/it]",B={sidebar_position:4},A="Managing Datasets",E={unversionedId:"python-sdk/managing-datasets",id:"python-sdk/managing-datasets",title:"Managing Datasets",description:"Learn how to interact with datasets using Clarifai Python SDK",source:"@site/docs/python-sdk/managing-datasets.md",sourceDirName:"python-sdk",slug:"/python-sdk/managing-datasets",permalink:"/python-sdk/managing-datasets",draft:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/python-sdk/managing-datasets.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Creating your AI Apps",permalink:"/python-sdk/create-apps"},next:{title:"Managing Inputs",permalink:"/python-sdk/managing-inputs"}},j={},q=[{value:"Creating Datasets",id:"creating-datasets",level:2},{value:"Create a Dataset version",id:"create-a-dataset-version",level:2},{value:"Upload Image",id:"upload-image",level:2},{value:"Upload Text",id:"upload-text",level:2},{value:"Upload Audio",id:"upload-audio",level:2},{value:"Upload Video",id:"upload-video",level:2},{value:"Upload Image with Annotation",id:"upload-image-with-annotation",level:2},{value:"Upload Video with Annotation",id:"upload-video-with-annotation",level:2},{value:"Upload Text with Annotation",id:"upload-text-with-annotation",level:2},{value:"Batch Upload Image data while tracking status",id:"batch-upload-image-data-while-tracking-status",level:2},{value:"Retry Upload From Log File",id:"retry-upload-from-log-file",level:2},{value:"Export Dataset",id:"export-dataset",level:2},{value:"SDH Enabled Inputs Download",id:"sdh-enabled-inputs-download",level:2},{value:"Delete Dataset Version",id:"delete-dataset-version",level:2},{value:"Delete Dataset",id:"delete-dataset",level:2}],z={toc:q},F="wrapper";function L(t){let{components:e,...a}=t;return(0,o.kt)(F,(0,n.Z)({},z,a,{components:e,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"managing-datasets"},"Managing Datasets"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Learn how to interact with datasets using Clarifai Python SDK")),(0,o.kt)("hr",null),(0,o.kt)("p",null,"Effectively navigate the complexities of dataset management using the Clarifai Python SDK, where a suite of robust tools empowers you to handle datasets with unparalleled efficiency. This comprehensive set of functionalities enables you to seamlessly organize, modify, and analyze your image data. Whether you are creating new datasets from scratch, updating existing ones with fresh information, or fine-tuning your data for optimal model performance, the SDK delivers a seamless and intuitive interface."),(0,o.kt)("p",null,"Our SDK goes beyond mere dataset manipulation; it offers a complete solution for every step of your data journey. With the ability to effortlessly upload new datasets, swiftly delete redundant ones, and manipulate existing datasets according to your specific needs, you gain full control over your data pipeline. This ensures a fluid and adaptable workflow, allowing you to focus on deriving meaningful insights and maximizing the potential of your image data."),(0,o.kt)("h2",{id:"creating-datasets"},"Creating Datasets"),(0,o.kt)("p",null,"Leverage the robust capabilities of the Clarifai Python SDK to seamlessly generate datasets within your application. Through the API, you can initiate the creation of a dataset by specifying a unique dataset ID. This process empowers you to tailor your datasets to the specific needs of your application, ensuring a customized and efficient data."),(0,o.kt)("p",null,"Visit  this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"link")," for more information."),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},r))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},x)),(0,o.kt)("h2",{id:"create-a-dataset-version"},"Create a Dataset version"),(0,o.kt)("p",null,"Leveraging the power of the Clarifai Python SDK, you can effortlessly generate a new dataset version tailored to your specific needs. This process involves utilizing the API to initiate the creation of a version for a designated dataset, identified by its unique dataset ID. By seamlessly integrating this functionality into your workflow, you gain the ability to manage and track different iterations of your datasets effectively."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},d))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},T)),(0,o.kt)("h2",{id:"upload-image"},"Upload Image"),(0,o.kt)("p",null,"Simplify your image data upload process with the Clarifai API's DataLoader functionality. This versatile feature allows you to effortlessly upload image data in bulk, streamlining your workflow for enhanced efficiency. Whether you prefer uploading images directly from a folder or leveraging the convenience of a CSV format, our DataLoader seamlessly accommodates both methods."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},u))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},w)),(0,o.kt)("h2",{id:"upload-text"},"Upload Text"),(0,o.kt)("p",null,"Leverage the power of the Clarifai API to seamlessly upload text data with our versatile dataloader. Whether you prefer the convenience of organizing your text data in folders or opt for the structured approach offered by the CSV format, our API accommodates both methods. By utilizing the dataloader, you can effortlessly streamline the process of uploading text data, ensuring a smooth integration into your workflow."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},p))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},I)),(0,o.kt)("h2",{id:"upload-audio"},"Upload Audio"),(0,o.kt)("p",null,"Seamlessly upload your audio datasets using the versatile dataloader feature, providing you with two convenient options: uploading audio files directly from a folder or utilizing the efficiency of a CSV format. This flexibility in data upload empowers you to effortlessly incorporate diverse audio datasets into your applications, ensuring a smooth and streamlined workflow."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},c))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},D)),(0,o.kt)("h2",{id:"upload-video"},"Upload Video"),(0,o.kt)("p",null,"Elevate your multimedia analysis capabilities with the Clarifai Python SDK, enabling you to effortlessly upload video data using the versatile dataloader. Seamlessly integrate video data into your projects by leveraging the dataloader, which supports uploading videos either directly from a folder or in the convenient CSV format."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},c))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},D)),(0,o.kt)("h2",{id:"upload-image-with-annotation"},"Upload Image with Annotation"),(0,o.kt)("p",null,"Leverage the full potential of the Clarifai API by seamlessly uploading images with annotations. This advanced functionality allows you to enrich your image data by providing bounding box coordinates along with the image itself. By incorporating annotations, you enhance the depth and context of your visual data."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},m))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},C)),(0,o.kt)("h2",{id:"upload-video-with-annotation"},"Upload Video with Annotation"),(0,o.kt)("p",null,"Using our API, you have the capability to seamlessly upload videos enriched with annotations. This process involves more than just submitting the video file; you can enhance the contextual understanding by providing bounding box coordinates that precisely define the regions of interest within the video frames. By including this annotation data, you add valuable context to your video content."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},f))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},N)),(0,o.kt)("h2",{id:"upload-text-with-annotation"},"Upload Text with Annotation"),(0,o.kt)("p",null,"This functionality enables you to provide context and additional information alongside your text, enhancing the understanding and relevance of the uploaded content. Whether you're attaching metadata, categorizing content, or incorporating detailed annotations, the API effortlessly accommodates your specific needs. This feature not only streamlines the process of inputting annotated text but also enriches the dataset, allowing for more nuanced and accurate analysis."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},h))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},Z)),(0,o.kt)("h2",{id:"batch-upload-image-data-while-tracking-status"},"Batch Upload Image data while tracking status"),(0,o.kt)("p",null,"With our robust capabilities, you can actively monitor the status of your dataset upload, ensuring transparency and control throughout the entire operation. This feature provides valuable visibility into the progress of your data transfer, allowing you to track and analyze the status effortlessly."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},y))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},S)),(0,o.kt)("h2",{id:"retry-upload-from-log-file"},"Retry Upload From Log File"),(0,o.kt)("p",null,"This feature is used to retry upload from logs for failed inputs. When using ",(0,o.kt)("inlineCode",{parentName:"p"},"upload_dataset")," function the failed inputs can be logged into file and later can be used to resume the upload process. "),(0,o.kt)("admonition",{type:"info"},(0,o.kt)("p",{parentName:"admonition"},"Set ",(0,o.kt)("inlineCode",{parentName:"p"},"retry_duplicates")," to ",(0,o.kt)("inlineCode",{parentName:"p"},"True")," if you want to retry duplicate with new Input_id in current dataset.")),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},v))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},V)),(0,o.kt)("h2",{id:"export-dataset"},"Export Dataset"),(0,o.kt)("p",null,"With our API, you can efficiently retrieve your datasets in a compressed zip file format, streamlining the process of data retrieval and enhancing your dataset management capabilities. Whether you're archiving your data for backup, sharing datasets across applications, or conducting in-depth analyses externally, the export functionality provides a convenient and efficient solution."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},g))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},U)),(0,o.kt)("h2",{id:"sdh-enabled-inputs-download"},"SDH Enabled Inputs Download"),(0,o.kt)("p",null,"This functionality empowers users to seamlessly retrieve and download inputs that have been enhanced or optimized through SDH technology. By harnessing the power of SDH, this feature ensures a superior and efficient download experience for inputs, providing a level of performance and flexibility that aligns with modern computing demands."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},b))),(0,o.kt)("h2",{id:"delete-dataset-version"},"Delete Dataset Version"),(0,o.kt)("p",null,"Within the Clarifai Python SDK, you have the capability to precisely manage your datasets by removing specific versions with ease. This feature empowers you to selectively delete a particular version of your dataset through the API. Whether you are refining your dataset collection, optimizing storage resources, or ensuring data accuracy, this functionality provides a targeted and efficient solution."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)("admonition",{type:"caution"},(0,o.kt)("p",{parentName:"admonition"},"Be certain that you want to delete a particular dataset version as the operation cannot be undone.")),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},k))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},O)),(0,o.kt)("h2",{id:"delete-dataset"},"Delete Dataset"),(0,o.kt)("p",null,"Within the Clarifai Python SDK, removing a dataset is a straightforward process enabled by the API. By supplying the unique identifier, known as the dataset ID, you gain the capability to seamlessly eliminate a dataset from your Clarifai account. It's essential to note that this functionality extends beyond a singular dataset removal; it also initiates the deletion of all associated dataset versions."),(0,o.kt)("p",null,"Visit this ",(0,o.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"page")," for more information."),(0,o.kt)("admonition",{type:"caution"},(0,o.kt)("p",{parentName:"admonition"}," Be certain that you want to delete a particular dataset as the operation cannot be undone.")),(0,o.kt)(i.Z,{mdxType:"Tabs"},(0,o.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,o.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},_))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Output"),(0,o.kt)(l.Z,{className:"language-text",mdxType:"CodeBlock"},P)))}L.isMDXComponent=!0}}]);