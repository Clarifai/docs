"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[7135],{58215:function(n,e,a){var t=a(67294);e.Z=function(n){var e=n.children,a=n.hidden,o=n.className;return t.createElement("div",{role:"tabpanel",hidden:a,className:o},e)}},26396:function(n,e,a){a.d(e,{Z:function(){return d}});var t=a(87462),o=a(67294),i=a(72389),s=a(79443);var r=function(){var n=(0,o.useContext)(s.Z);if(null==n)throw new Error('"useUserPreferencesContext" is used outside of "Layout" component.');return n},l=a(63616),u=a(86010),p="tabItem_vU9c";function c(n){var e,a,i,s=n.lazy,c=n.block,d=n.defaultValue,m=n.values,f=n.groupId,_=n.className,w=o.Children.map(n.children,(function(n){if((0,o.isValidElement)(n)&&void 0!==n.props.value)return n;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof n.type?n.type:n.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})),v=null!=m?m:w.map((function(n){var e=n.props;return{value:e.value,label:e.label,attributes:e.attributes}})),h=(0,l.lx)(v,(function(n,e){return n.value===e.value}));if(h.length>0)throw new Error('Docusaurus error: Duplicate values "'+h.map((function(n){return n.value})).join(", ")+'" found in <Tabs>. Every value needs to be unique.');var k=null===d?d:null!=(e=null!=d?d:null==(a=w.find((function(n){return n.props.default})))?void 0:a.props.value)?e:null==(i=w[0])?void 0:i.props.value;if(null!==k&&!v.some((function(n){return n.value===k})))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+k+'" but none of its children has the corresponding value. Available values are: '+v.map((function(n){return n.value})).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");var g=r(),b=g.tabGroupChoices,y=g.setTabGroupChoices,R=(0,o.useState)(k),E=R[0],I=R[1],T=[],N=(0,l.o5)().blockElementScrollPositionUntilNextRender;if(null!=f){var P=b[f];null!=P&&P!==E&&v.some((function(n){return n.value===P}))&&I(P)}var C=function(n){var e=n.currentTarget,a=T.indexOf(e),t=v[a].value;t!==E&&(N(e),I(t),null!=f&&y(f,t))},S=function(n){var e,a=null;switch(n.key){case"ArrowRight":var t=T.indexOf(n.currentTarget)+1;a=T[t]||T[0];break;case"ArrowLeft":var o=T.indexOf(n.currentTarget)-1;a=T[o]||T[T.length-1]}null==(e=a)||e.focus()};return o.createElement("div",{className:"tabs-container"},o.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,u.Z)("tabs",{"tabs--block":c},_)},v.map((function(n){var e=n.value,a=n.label,i=n.attributes;return o.createElement("li",(0,t.Z)({role:"tab",tabIndex:E===e?0:-1,"aria-selected":E===e,key:e,ref:function(n){return T.push(n)},onKeyDown:S,onFocus:C,onClick:C},i,{className:(0,u.Z)("tabs__item",p,null==i?void 0:i.className,{"tabs__item--active":E===e})}),null!=a?a:e)}))),s?(0,o.cloneElement)(w.filter((function(n){return n.props.value===E}))[0],{className:"margin-vert--md"}):o.createElement("div",{className:"margin-vert--md"},w.map((function(n,e){return(0,o.cloneElement)(n,{key:e,hidden:n.props.value!==E})}))))}function d(n){var e=(0,i.Z)();return o.createElement(c,(0,t.Z)({key:String(e)},n))}},28970:function(n,e,a){a.r(e),a.d(e,{contentTitle:function(){return c},default:function(){return _},frontMatter:function(){return p},metadata:function(){return d},toc:function(){return m}});var t=a(87462),o=a(63366),i=(a(67294),a(3905)),s=a(26396),r=a(58215),l=a(19055),u=["components"],p={description:"Make model predictions in your workflows.",sidebar_position:1},c="Workflow Predict",d={unversionedId:"api-guide/workflows/common-workflows/workflow-predict",id:"api-guide/workflows/common-workflows/workflow-predict",title:"Workflow Predict",description:"Make model predictions in your workflows.",source:"@site/docs/api-guide/workflows/common-workflows/workflow-predict.md",sourceDirName:"api-guide/workflows/common-workflows",slug:"/api-guide/workflows/common-workflows/workflow-predict",permalink:"/api-guide/workflows/common-workflows/workflow-predict",tags:[],version:"current",sidebarPosition:1,frontMatter:{description:"Make model predictions in your workflows.",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Common Workflows",permalink:"/api-guide/workflows/common-workflows/"},next:{title:"Auto Annotation",permalink:"/api-guide/workflows/common-workflows/auto-annotation-walkthrough"}},m=[{value:"Predict",id:"predict",children:[],level:2}],f={toc:m};function _(n){var e=n.components,p=(0,o.Z)(n,u);return(0,i.kt)("wrapper",(0,t.Z)({},f,p,{components:e,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"workflow-predict"},"Workflow Predict"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Make model predictions in your workflows")),(0,i.kt)("hr",null),(0,i.kt)("p",null,"The Workflow Predict API allows you to predict using one or more model","(","s",")",", regardless of them being Clarifai or custom, within a single API call. The max number of inputs processed at once with any given workflow is 32."),(0,i.kt)("p",null,"After you're set up, you can predict under a workflow using the ",(0,i.kt)("inlineCode",{parentName:"p"},"POST /v2/workflows/{workflow_id}/results")," endpoint. Your ",(0,i.kt)("inlineCode",{parentName:"p"},"{workflow-id}")," currently is whatever you set as your ID. Then as far as your request body, nothing has changed with how you would normally do a predict. In the response body, you will see a ",(0,i.kt)("inlineCode",{parentName:"p"},"results")," object and each object will be the response from the models in the same ordering from the workflow you set up."),(0,i.kt)("p",null,"You can also use the Explorer feature in the Clarifai Portal to see the results of your workflow's predictions on a given input."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Image showing the Portal&#39;s workflow prediction results",src:a(23866).Z})),(0,i.kt)("p",{align:"center"},"Image showing the Portal's workflow prediction results"),(0,i.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,i.kt)("div",{parentName:"div",className:"admonition-heading"},(0,i.kt)("h5",{parentName:"div"},(0,i.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,i.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,i.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"info")),(0,i.kt)("div",{parentName:"div",className:"admonition-content"},(0,i.kt)("p",{parentName:"div"},"The initialization code used in the following example is outlined in detail on the ",(0,i.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/api-guide/api-overview/api-clients/#client-installation-instructions"},"client installation page.")))),(0,i.kt)("h2",{id:"predict"},"Predict"),(0,i.kt)(s.Z,{mdxType:"Tabs"},(0,i.kt)(r.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,i.kt)(l.Z,{className:"language-python",mdxType:"CodeBlock"},"##############################################################################\n# In this section, we set the user authentication, app ID, workflow ID, and  \n# image URL. Change these strings to run your own example.\n##############################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to make your own predictions\nWORKFLOW_ID = 'my-custom-workflow'\nIMAGE_URL = 'https://samples.clarifai.com/metro-north.jpg'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID) # The userDataObject is required when using a PAT\n\npost_workflow_results_response = stub.PostWorkflowResults(\n    service_pb2.PostWorkflowResultsRequest(\n        user_app_id=userDataObject,  \n        workflow_id=WORKFLOW_ID,\n        inputs=[\n            resources_pb2.Input(\n                data=resources_pb2.Data(\n                    image=resources_pb2.Image(\n                        url=IMAGE_URL\n                    )\n                )\n            )\n        ]\n    ),\n    metadata=metadata\n)\nif post_workflow_results_response.status.code != status_code_pb2.SUCCESS:\n    print(post_workflow_results_response.status)\n    raise Exception(\"Post workflow results failed, status: \" + post_workflow_results_response.status.description)\n\n# We'll get one WorkflowResult for each input we used above. Because of one input, we have here one WorkflowResult\nresults = post_workflow_results_response.results[0]\n\n# Each model we have in the workflow will produce one output.\nfor output in results.outputs:\n    model = output.model\n\n    print(\"Predicted concepts for the model `%s`\" % model.name)\n    for concept in output.data.concepts:\n        print(\"\\t%s %.2f\" % (concept.name, concept.value))\n\n# Uncomment this line to print the full Response JSON\n#print(results)")),(0,i.kt)(r.Z,{value:"nodejs",label:"NodeJS",mdxType:"TabItem"},(0,i.kt)(l.Z,{className:"language-javascript",mdxType:"CodeBlock"},'//index.js file\n\n/////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, workflow ID, and  \n// image URL. Change these strings to run your own example.\n////////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = \'YOUR_USER_ID_HERE\';\n// Your PAT (Personal Access Token) can be found in the portal under Authentification\nconst PAT = \'YOUR_PAT_HERE\';\nconst APP_ID = \'YOUR_APP_ID_HERE\';\n// Change these to make your own predictions\nconst WORKFLOW_ID = \'my-custom-workflow\';\nconst IMAGE_URL = \'https://samples.clarifai.com/metro-north.jpg\';\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\nstub.PostWorkflowResults(\n    {\n        user_app_id: {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        workflow_id: WORKFLOW_ID,\n        inputs: [\n            { data: { image: { url: IMAGE_URL } } }\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error("Post workflow results failed, status: " + response.status.description);\n        }\n\n        // We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here\n        // one WorkflowResult.\n        const results = response.results[0];\n\n        // Each model we have in the workflow will produce one output.\n        for (const output of results.outputs) {\n            const model = output.model;\n\n            console.log("Predicted concepts for the model `" + model.name + "`:");\n            for (const concept of output.data.concepts) {\n                console.log("\\t" + concept.name + " " + concept.value);\n            }\n        }\n    }\n);\n')),(0,i.kt)(r.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},'import com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.*;\n\n// Insert here the initialization code as outlined on this page:\n// https://docs.clarifai.com/api-guide/api-overview/api-clients#client-installation-instructions\n\nPostWorkflowResultsResponse postWorkflowResultsResponse = stub.postWorkflowResults(\n    PostWorkflowResultsRequest.newBuilder()\n        .setWorkflowId("{YOUR_WORKFLOW_ID}")\n        .addInputs(\n            Input.newBuilder().setData(\n                Data.newBuilder().setImage(\n                    Image.newBuilder().setUrl(\n                        "https://samples.clarifai.com/metro-north.jpg"\n                    )\n                )\n            )\n        )\n        .build()\n);\n\nif (postWorkflowResultsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n  throw new RuntimeException("Post workflow results failed, status: " + postWorkflowResultsResponse.getStatus());\n}\n\n// We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here\n// one WorkflowResult.\nWorkflowResult results = postWorkflowResultsResponse.getResults(0);\n\n// Each model we have in the workflow will produce one output.\nfor (Output output : results.getOutputsList()) {\n    Model model = output.getModel();\n\n    System.out.println("Predicted concepts for the model `" + model.getName() + "`:");\n    for (Concept concept : output.getData().getConceptsList()) {\n        System.out.printf("\\t%s %.2f%n", concept.getName(), concept.getValue());\n    }\n}\n'))),(0,i.kt)(r.Z,{value:"curl",label:"cURL",mdxType:"TabItem"},(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'curl -X POST \\\n  -H \'authorization: Key YOUR_API_KEY\' \\\n  -H \'content-type: application/json\' \\\n  -d \'{\n    "inputs": [\n        {\n          "data": {\n            "image": {\n              "url": "https://samples.clarifai.com/metro-north.jpg"\n          }\n        }\n      }\n    ]\n}\'\\\nhttps://api.clarifai.com/v2/workflows/{YOUR_WORKFLOW_ID}/results\n')))),(0,i.kt)("details",null,(0,i.kt)("summary",null,"Code Output Example"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-text"},"Predicted concepts for the model `food-items-v1.0`\n    wine 0.95\n    beer 0.90\n    pizza 0.84\n    coffee 0.66\n    meat 0.63\n    barbecue 0.61\n    beef 0.56\n    fish 0.56\n    steak 0.55\n    gastronomy 0.53\n    chicken 0.49\n    water 0.46\n    lobster 0.45\n    oil 0.43\n    tea 0.43\n    pork 0.42\n    cheese 0.39\n    tuna 0.37\n    olive 0.37\n    turkey 0.35\nPredicted concepts for the model `general`\n    train 1.00\n    railway 1.00\n    transportation system 1.00\n    locomotive 0.99\n    station 0.99\n    travel 0.99\n    subway system 0.98\n    commuter 0.97\n    traffic 0.97\n    blur 0.96\n    urban 0.96\n    no person 0.96\n    platform 0.96\n    business 0.96\n    track 0.94\n    city 0.94\n    fast 0.94\n    road 0.93\n    terminal 0.92\n    public 0.92\n"))),(0,i.kt)("details",null,(0,i.kt)("summary",null,"JSON Output Example"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-javascript"},'status {\n  code: SUCCESS\n  description: "Ok"\n}\ninput {\n  id: "0a799c6f1dd94588afd392b8f8cae1a0"\n  data {\n    image {\n      url: "https://samples.clarifai.com/metro-north.jpg"\n    }\n  }\n}\noutputs {\n  id: "74620e2daafa4fa1a890f13e22ad4080"\n  status {\n    code: SUCCESS\n    description: "Ok"\n  }\n  created_at {\n    seconds: 1648216884\n    nanos: 284812988\n  }\n  model {\n    id: "food-item-v1-recognition"\n    name: "food-items-v1.0"\n    created_at {\n      seconds: 1474150739\n      nanos: 955626000\n    }\n    app_id: "main"\n    output_info {\n      output_config {\n      }\n      message: "Show output_info with: GET /models/{model_id}/output_info"\n      fields_map {\n        fields {\n          key: "concepts"\n          value {\n            string_value: "softmax"\n          }\n        }\n      }\n    }\n    model_version {\n      id: "dfebc169854e429086aceb8368662641"\n      created_at {\n        seconds: 1474150739\n        nanos: 955626000\n      }\n      status {\n        code: MODEL_TRAINED\n        description: "Model is trained and ready"\n      }\n      visibility {\n        gettable: PUBLIC\n      }\n      app_id: "main"\n      user_id: "clarifai"\n      metadata {\n      }\n    }\n    display_name: "food-items-v1-visual-classifier"\n    user_id: "clarifai"\n    input_info {\n      fields_map {\n        fields {\n          key: "image"\n          value {\n            string_value: "images"\n          }\n        }\n      }\n    }\n    train_info {\n    }\n    model_type_id: "visual-classifier"\n    visibility {\n      gettable: PUBLIC\n    }\n    modified_at {\n      seconds: 1634712785\n      nanos: 568020000\n    }\n    import_info {\n    }\n  }\n  data {\n    concepts {\n      id: "ai_kTsPMX36"\n      name: "wine"\n      value: 0.9537787437438965\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_r2Fbdv8L"\n      name: "beer"\n      value: 0.9002427458763123\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_fZsLlGwm"\n      name: "pizza"\n      value: 0.8410654067993164\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_f1zKlGnc"\n      name: "coffee"\n      value: 0.6570742726325989\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_KWmFf1fn"\n      name: "meat"\n      value: 0.6265882849693298\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_7f0n1q5Q"\n      name: "barbecue"\n      value: 0.6149417161941528\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_XVpwLB09"\n      name: "beef"\n      value: 0.5626139640808105\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_69JKJjSz"\n      name: "fish"\n      value: 0.561673104763031\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_hmjcV7cH"\n      name: "steak"\n      value: 0.5533789396286011\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_05mwq5v5"\n      name: "gastronomy"\n      value: 0.5272657871246338\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_jvVxlhLh"\n      name: "chicken"\n      value: 0.49488314986228943\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_G58V132Z"\n      name: "water"\n      value: 0.46317076683044434\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_jsmJGj7n"\n      name: "lobster"\n      value: 0.45476287603378296\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_dHhR5NW4"\n      name: "oil"\n      value: 0.42813917994499207\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_CFS37srh"\n      name: "tea"\n      value: 0.4275510907173157\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_TRbv6FWL"\n      name: "pork"\n      value: 0.4154187738895416\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_FnZCSVMH"\n      name: "cheese"\n      value: 0.38525062799453735\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_5sLb6bK5"\n      name: "tuna"\n      value: 0.3674249053001404\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_61Tqv85G"\n      name: "olive"\n      value: 0.3656860589981079\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_b4b4hLRV"\n      name: "turkey"\n      value: 0.3539673686027527\n      app_id: "main"\n    }\n  }\n}\noutputs {\n  id: "cbea4f2cb08f4bf59a1295d5b0ddabfa"\n  status {\n    code: SUCCESS\n    description: "Ok"\n  }\n  created_at {\n    seconds: 1648216884\n    nanos: 291465486\n  }\n  model {\n    id: "general-image-recognition"\n    name: "general"\n    created_at {\n      seconds: 1457543499\n      nanos: 608845000\n    }\n    app_id: "main"\n    output_info {\n      output_config {\n      }\n      message: "Show output_info with: GET /models/{model_id}/output_info"\n      fields_map {\n        fields {\n          key: "concepts"\n          value {\n            string_value: "softmax"\n          }\n        }\n      }\n    }\n    model_version {\n      id: "aa9ca48295b37401f8af92ad1af0d91d"\n      created_at {\n        seconds: 1468372752\n        nanos: 147644000\n      }\n      status {\n        code: MODEL_TRAINED\n        description: "Model is trained and ready"\n      }\n      visibility {\n        gettable: PUBLIC\n      }\n      app_id: "main"\n      user_id: "clarifai"\n      metadata {\n      }\n    }\n    user_id: "clarifai"\n    input_info {\n      fields_map {\n        fields {\n          key: "image"\n          value {\n            string_value: "images"\n          }\n        }\n      }\n    }\n    train_info {\n    }\n    model_type_id: "visual-classifier"\n    visibility {\n      gettable: PUBLIC\n    }\n    modified_at {\n      seconds: 1648153319\n      nanos: 760183000\n    }\n    import_info {\n    }\n  }\n  data {\n    concepts {\n      id: "ai_HLmqFqBf"\n      name: "train"\n      value: 0.9987074136734009\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_fvlBqXZR"\n      name: "railway"\n      value: 0.9971307516098022\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_Xxjc3MhT"\n      name: "transportation system"\n      value: 0.9954404830932617\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_RRXLczch"\n      name: "locomotive"\n      value: 0.9914677143096924\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_6kTjGfF6"\n      name: "station"\n      value: 0.9910657405853271\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_VRmbGVWh"\n      name: "travel"\n      value: 0.9873164296150208\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_SHNDcmJ3"\n      name: "subway system"\n      value: 0.9797887802124023\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_jlb9q33b"\n      name: "commuter"\n      value: 0.967644214630127\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_tr0MBp64"\n      name: "traffic"\n      value: 0.9670584201812744\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_l4WckcJN"\n      name: "blur"\n      value: 0.9639896154403687\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_CpFBRWzD"\n      name: "urban"\n      value: 0.958390474319458\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_786Zr311"\n      name: "no person"\n      value: 0.957963764667511\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_2gkfMDsM"\n      name: "platform"\n      value: 0.9577903747558594\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_6lhccv44"\n      name: "business"\n      value: 0.9567283987998962\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_971KsJkn"\n      name: "track"\n      value: 0.9446062445640564\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_WBQfVV0p"\n      name: "city"\n      value: 0.9392585158348083\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_dSCKh8xv"\n      name: "fast"\n      value: 0.9364041686058044\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_TZ3C79C6"\n      name: "road"\n      value: 0.930669903755188\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_VSVscs9k"\n      name: "terminal"\n      value: 0.9190886616706848\n      app_id: "main"\n    }\n    concepts {\n      id: "ai_mcSHVRfS"\n      name: "public"\n      value: 0.9154675006866455\n      app_id: "main"\n    }\n  }\n}\n  \n'))))}_.isMDXComponent=!0},23866:function(n,e,a){e.Z=a.p+"assets/images/preview-workflows-new-7376708b5787ab7f7ba14a50dc4cf232.png"}}]);