"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[6735],{3905:(e,t,o)=>{o.d(t,{Zo:()=>d,kt:()=>f});var a=o(67294);function i(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function n(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,a)}return o}function r(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?n(Object(o),!0).forEach((function(t){i(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):n(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function s(e,t){if(null==e)return{};var o,a,i=function(e,t){if(null==e)return{};var o,a,i={},n=Object.keys(e);for(a=0;a<n.length;a++)o=n[a],t.indexOf(o)>=0||(i[o]=e[o]);return i}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(a=0;a<n.length;a++)o=n[a],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(i[o]=e[o])}return i}var l=a.createContext({}),c=function(e){var t=a.useContext(l),o=t;return e&&(o="function"==typeof e?e(t):r(r({},t),e)),o},d=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},u="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var o=e.components,i=e.mdxType,n=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),u=c(o),m=i,f=u["".concat(l,".").concat(m)]||u[m]||p[m]||n;return o?a.createElement(f,r(r({ref:t},d),{},{components:o})):a.createElement(f,r({ref:t},d))}));function f(e,t){var o=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var n=o.length,r=new Array(n);r[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:i,r[1]=s;for(var c=2;c<n;c++)r[c]=o[c];return a.createElement.apply(null,r)}return a.createElement.apply(null,o)}m.displayName="MDXCreateElement"},5786:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>n,metadata:()=>s,toc:()=>c});var a=o(87462),i=(o(67294),o(3905));const n={description:"Learn about our visual detector model type",sidebar_position:3},r="Visual Detector",s={unversionedId:"portal-guide/model/model-types/visual-detector",id:"portal-guide/model/model-types/visual-detector",title:"Visual Detector",description:"Learn about our visual detector model type",source:"@site/docs/portal-guide/model/model-types/visual-detector.md",sourceDirName:"portal-guide/model/model-types",slug:"/portal-guide/model/model-types/visual-detector",permalink:"/portal-guide/model/model-types/visual-detector",draft:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/portal-guide/model/model-types/visual-detector.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{description:"Learn about our visual detector model type",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Visual Classifier",permalink:"/portal-guide/model/model-types/visual-classifier"},next:{title:"Visual Segmenter",permalink:"/portal-guide/model/model-types/visual-segmenter"}},l={},c=[{value:"Example use case",id:"example-use-case",level:2}],d={toc:c},u="wrapper";function p(e){let{components:t,...o}=e;return(0,i.kt)(u,(0,a.Z)({},d,o,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"visual-detector"},"Visual Detector"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Learn about our visual detector model type")),(0,i.kt)("hr",null),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Input"),": Images and videos"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Output"),": Regions"),(0,i.kt)("p",null,"Visual detector, also known as object detection, is a type of deep fine-tuned model designed to identify and locate objects within images or video frames. It goes beyond simple image classification, where the goal is to assign a single label to an entire image."),(0,i.kt)("p",null,'Instead, an object detection model can identify multiple objects of different classes within an image and provide their corresponding bounding box coordinates. They help answer the question "Where" are objects in your data. '),(0,i.kt)("p",null,"The primary task of a visual detector model is twofold:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Object localization"),": The model identifies the location of objects within an image by predicting bounding box coordinates that tightly enclose each object."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Object classification"),": The model classifies each detected object into one of several predefined classes or categories.")),(0,i.kt)("admonition",{type:"info"},(0,i.kt)("p",{parentName:"admonition"},"The visual detector model type also comes with various ",(0,i.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/model/deep-training/visual-detection-templates"},"templates")," that give you the control to choose the specific architecture used by your neural network, as well as define a set of hyperparameters you can use to fine-tune the way your model learns.")),(0,i.kt)("p",null,"Visual detector models have a wide range of applications, including:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Object detection"),": This is the task of identifying and localizing objects in images. Visual detector models are used in a variety of applications, such as self-driving cars, security cameras, and robotics."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Image classification"),': This is the task of classifying images into categories, such as "dog," "cat," or "tree." Visual detector models can be used to improve the accuracy of image classification models by providing them with information about the objects that are present in the image.'),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Visual tracking"),": This is the task of tracking the movement of objects in images or videos. Visual detector models can be used to initialize visual trackers by identifying the objects that they need to track.")),(0,i.kt)("p",null,"You may choose the visual detector model type in cases where:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"You want to detect and localize objects within an image, and accuracy and the ability to carefully target solutions take priority over speed and ease of use."),(0,i.kt)("li",{parentName:"ul"},'You need a detection model to learn new features not recognized by the existing Clarifai models. In that case, you may need to "deep fine-tune" your custom model and integrate it directly within your ',(0,i.kt)("a",{parentName:"li",href:"https://docs.clarifai.com/portal-guide/workflows/"},"workflows"),"."),(0,i.kt)("li",{parentName:"ul"},"You have a custom-tailored dataset with bounding box annotations for objects, and the expertise and time to fine-tune models.")),(0,i.kt)("h2",{id:"example-use-case"},"Example use case"),(0,i.kt)("p",null,"A roofing company wants to provide insurance companies and customers with a consistent way of evaluating roof damage. This company captures images of roofs with a drone, and then feeds the images into a detection model. The detection model can then locate and classify specific areas of damage on the roofs."))}p.isMDXComponent=!0}}]);