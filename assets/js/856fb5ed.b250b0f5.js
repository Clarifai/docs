"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[5245],{58215:function(e,n,t){var a=t(67294);n.Z=function(e){var n=e.children,t=e.hidden,r=e.className;return a.createElement("div",{role:"tabpanel",hidden:t,className:r},n)}},26396:function(e,n,t){t.d(n,{Z:function(){return d}});var a=t(87462),r=t(67294),s=t(72389),i=t(79443);var o=function(){var e=(0,r.useContext)(i.Z);if(null==e)throw new Error('"useUserPreferencesContext" is used outside of "Layout" component.');return e},c=t(63616),u=t(86010),l="tabItem_vU9c";function p(e){var n,t,s,i=e.lazy,p=e.block,d=e.defaultValue,h=e.values,m=e.groupId,f=e.className,g=r.Children.map(e.children,(function(e){if((0,r.isValidElement)(e)&&void 0!==e.props.value)return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})),_=null!=h?h:g.map((function(e){var n=e.props;return{value:n.value,label:n.label,attributes:n.attributes}})),b=(0,c.lx)(_,(function(e,n){return e.value===n.value}));if(b.length>0)throw new Error('Docusaurus error: Duplicate values "'+b.map((function(e){return e.value})).join(", ")+'" found in <Tabs>. Every value needs to be unique.');var w=null===d?d:null!=(n=null!=d?d:null==(t=g.find((function(e){return e.props.default})))?void 0:t.props.value)?n:null==(s=g[0])?void 0:s.props.value;if(null!==w&&!_.some((function(e){return e.value===w})))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+w+'" but none of its children has the corresponding value. Available values are: '+_.map((function(e){return e.value})).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");var v=o(),E=v.tabGroupChoices,C=v.setTabGroupChoices,N=(0,r.useState)(w),T=N[0],y=N[1],S=[],A=(0,c.o5)().blockElementScrollPositionUntilNextRender;if(null!=m){var P=E[m];null!=P&&P!==T&&_.some((function(e){return e.value===P}))&&y(P)}var I=function(e){var n=e.currentTarget,t=S.indexOf(n),a=_[t].value;a!==T&&(A(n),y(a),null!=m&&C(m,a))},O=function(e){var n,t=null;switch(e.key){case"ArrowRight":var a=S.indexOf(e.currentTarget)+1;t=S[a]||S[0];break;case"ArrowLeft":var r=S.indexOf(e.currentTarget)-1;t=S[r]||S[S.length-1]}null==(n=t)||n.focus()};return r.createElement("div",{className:"tabs-container"},r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,u.Z)("tabs",{"tabs--block":p},f)},_.map((function(e){var n=e.value,t=e.label,s=e.attributes;return r.createElement("li",(0,a.Z)({role:"tab",tabIndex:T===n?0:-1,"aria-selected":T===n,key:n,ref:function(e){return S.push(e)},onKeyDown:O,onFocus:I,onClick:I},s,{className:(0,u.Z)("tabs__item",l,null==s?void 0:s.className,{"tabs__item--active":T===n})}),null!=t?t:n)}))),i?(0,r.cloneElement)(g.filter((function(e){return e.props.value===T}))[0],{className:"margin-vert--md"}):r.createElement("div",{className:"margin-vert--md"},g.map((function(e,n){return(0,r.cloneElement)(e,{key:n,hidden:e.props.value!==T})}))))}function d(e){var n=(0,s.Z)();return r.createElement(p,(0,a.Z)({key:String(n)},e))}},36297:function(e,n,t){t.r(n),t.d(n,{contentTitle:function(){return p},default:function(){return f},frontMatter:function(){return l},metadata:function(){return d},toc:function(){return h}});var a=t(87462),r=t(63366),s=(t(67294),t(3905)),i=t(26396),o=t(58215),c=t(19055),u=["components"],l={description:"Group or separate items in your dataset.",sidebar_position:1},p="Combine or Negate",d={unversionedId:"api-guide/search/legacy-search/combine-or-negate",id:"api-guide/search/legacy-search/combine-or-negate",title:"Combine or Negate",description:"Group or separate items in your dataset.",source:"@site/docs/api-guide/search/legacy-search/combine-or-negate.md",sourceDirName:"api-guide/search/legacy-search",slug:"/api-guide/search/legacy-search/combine-or-negate",permalink:"/api-guide/search/legacy-search/combine-or-negate",tags:[],version:"current",sidebarPosition:1,frontMatter:{description:"Group or separate items in your dataset.",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Legacy Search",permalink:"/api-guide/search/legacy-search/"},next:{title:"Filter",permalink:"/api-guide/search/legacy-search/filter"}},h=[],m={toc:h};function f(e){var n=e.components,t=(0,r.Z)(e,u);return(0,s.kt)("wrapper",(0,a.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"combine-or-negate"},"Combine or Negate"),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Group or separate items in your dataset")),(0,s.kt)("hr",null),(0,s.kt)("p",null,"You can also combine searches using AND."),(0,s.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,s.kt)("div",{parentName:"div",className:"admonition-heading"},(0,s.kt)("h5",{parentName:"div"},(0,s.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,s.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,s.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"info")),(0,s.kt)("div",{parentName:"div",className:"admonition-content"},(0,s.kt)("p",{parentName:"div"},"The initialization code used in the following example is outlined in detail on the ",(0,s.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/api-guide/api-overview/api-clients/#client-installation-instructions"},"client installation page.")))),(0,s.kt)(i.Z,{mdxType:"Tabs"},(0,s.kt)(o.Z,{value:"grpc_python",label:"gRPC Python",mdxType:"TabItem"},(0,s.kt)(c.Z,{className:"language-python",mdxType:"CodeBlock"},"################################################################################\n# In this section, we set the user authentication, app ID, and the concepts we  \n# we want to search by. Change these strings to run your own example.\n################################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to search by your own concepts\nCONCEPT_NAME_1 = 'cat'\nCONCEPT_NAME_2 = 'dog'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID) # The userDataObject is required when using a PAT\n\n# Here we search for images which we labeled with \"cat\" and for which the General prediction model does not find\n# a \"dog\" concept.\npost_searches_response = stub.PostSearches(\n    service_pb2.PostSearchesRequest(\n        user_app_id=userDataObject,\n        query=resources_pb2.Query(\n            ands=[\n                resources_pb2.And(\n                    input=resources_pb2.Input(  # Setting Input indicates we search for images that have the concept(s)\n                                                # which we added to the input manually.\n                        data=resources_pb2.Data(\n                            concepts=[\n                                resources_pb2.Concept(\n                                    name=CONCEPT_NAME_1,\n                                    value=1\n                                )\n                            ]\n                        )\n                    )\n                ),\n                resources_pb2.And(\n                    output=resources_pb2.Output(  # Setting Output indicates we search for images that have the concept(s)\n                                                  # which were predicted by the General model.\n                        data=resources_pb2.Data(\n                            concepts=[\n                                resources_pb2.Concept(\n                                    name=CONCEPT_NAME_2,\n                                    value=0\n                                )\n                            ]\n                        )\n                    )\n                )\n            ]\n        )\n    ),\n    metadata=metadata\n)\n\nif post_searches_response.status.code != status_code_pb2.SUCCESS:\n    print(post_searches_response.status)\n    raise Exception(\"Post searches failed, status: \" + post_searches_response.status.description)\n\nprint(\"Found inputs:\")\nfor hit in post_searches_response.hits:\n    print(\"\\tScore %.2f for %s\" % (hit.score, hit.input.id))")),(0,s.kt)(o.Z,{value:"grpc_nodejs",label:"gRPC NodeJS",mdxType:"TabItem"},(0,s.kt)(c.Z,{className:"language-javascript",mdxType:"CodeBlock"},'//index.js file\n\n///////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, and the concepts we  \n// we want to search by. Change these strings to run your own example.\n//////////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = \'YOUR_USER_ID_HERE\';\n// Your PAT (Personal Access Token) can be found in the portal under Authentification\nconst PAT = \'YOUR_PAT_HERE\';\nconst APP_ID = \'YOUR_APP_ID_HERE\';\n// Change these to search by your own concepts\nconst CONCEPT_NAME_1 = \'cat\';\nconst CONCEPT_NAME_2 = \'dog\';\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\n// Here we search for images which we labeled with "cat" and for which the General prediction model does not find\n// a "dog" concept\n\nstub.PostSearches(\n    {\n        user_app_id: {\n            user_id: USER_ID,\n            app_id: APP_ID\n        },\n        query: {\n            ands: [\n                {\n                    input: {  // Setting Input indicates we search for images that have the concept(s)\n                        // which we added to the input manually\n                        data: {\n                            concepts: [\n                                {\n                                    name: CONCEPT_NAME_1,\n                                    value: 1\n                                }\n                            ]\n                        }\n                    }\n                },\n                {\n                    output: {  // Setting Output indicates we search for images that have the concept(s)\n                        // which were predicted by the General model\n                        data: {\n                            concepts: [\n                                {\n                                    name: CONCEPT_NAME_2,\n                                    value: 0\n                                }\n                            ]\n                        }\n                    }\n                }\n            ]\n        }\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error("Post searches failed, status: " + response.status.description);\n        }\n\n        console.log("Found inputs:");\n        for (const hit of response.hits) {\n            console.log("\\tScore " + hit.score + " for " + hit.input.id);\n        }\n    }\n);')),(0,s.kt)(o.Z,{value:"grpc_java",label:"gRPC Java",mdxType:"TabItem"},(0,s.kt)(c.Z,{className:"language-java",mdxType:"CodeBlock"},'package com.clarifai.example;\n\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\n\npublic class ClarifaiExample {\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, and the concepts we  \n    // we want to search by. Change these strings to run your own example.\n    //////////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to search by your own concepts\n    static final String CONCEPT_NAME_1 = "cat";\n    static final String CONCEPT_NAME_2 = "dog";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n            .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        // Here we search for images which we labeled with "cat" and for which the General prediction model does not find\n        // a "dog" concept.\n        MultiSearchResponse postSearchesResponse = stub.postSearches(\n            PostSearchesRequest.newBuilder()\n            .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n            .setQuery(\n                Query.newBuilder()\n                .addAnds(\n                    And.newBuilder().setInput( // Setting Input indicates we search for images that have the concept(s)\n                        // which we added to the input manually.\n                        Input.newBuilder().setData(\n                            Data.newBuilder().addConcepts(\n                                Concept.newBuilder()\n                                .setName(CONCEPT_NAME_1)\n                                .setValue(1f)\n                            )\n                        )\n                    )\n                )\n                .addAnds(\n                    And.newBuilder().setOutput( // Setting Output indicates we search for images that have the concept(s)\n                        // which were predicted by the General model.\n                        Output.newBuilder().setData(\n                            Data.newBuilder().addConcepts(\n                                Concept.newBuilder()\n                                .setName(CONCEPT_NAME_2)\n                                .setValue(0f)\n                            )\n                        )\n                    )\n                )\n            )\n            .build()\n        );\n\n        if (postSearchesResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post searches failed, status: " + postSearchesResponse.getStatus());\n        }\n\n        System.out.println("Found inputs " + postSearchesResponse.getHitsCount() + ":");\n        for (Hit hit : postSearchesResponse.getHitsList()) {\n            System.out.printf("\\tScore %.2f for %s\\n", hit.getScore(), hit.getInput().getId());\n        }\n\n    }\n\n}')),(0,s.kt)(o.Z,{value:"curl",label:"cURL",mdxType:"TabItem"},(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-bash"},'# Here we search for images which we labeled with "cat" and for which the General prediction model does not find\n# a "dog" concept.\n\ncurl -X POST \\\n  -H "Authorization: Key {api-key}" \\\n  -H "Content-Type: application/json" \\\n-d \'\n{\n    "query": {\n        "ands": [\n            {\n                "input":{\n                    "data": {\n                        "concepts": [\n                            {\n                                "name": "cat",\n                                "value": 1\n                            }\n                        ]\n                    }\n                }\n            },\n            {\n                "output": {\n                    "data": {\n                        "concepts": [\n                            {\n                                "name": "dog",\n                                "value": 0\n                            }\n                        ]\n                    }\n                }\n            }\n        ]\n    }\n}\'\\\nhttps://api.clarifai.com/v2/searches\n')))))}f.isMDXComponent=!0}}]);