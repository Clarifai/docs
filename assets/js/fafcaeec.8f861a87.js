"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[8823],{11470:(e,n,t)=>{t.d(n,{A:()=>v});var a=t(96540),o=t(18215),i=t(17559),s=t(23104),l=t(56347),r=t(205),c=t(57485),p=t(31682),d=t(70679);function m(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:n,children:t}=e;return(0,a.useMemo)(()=>{const e=n??function(e){return m(e).map(({props:{value:e,label:n,attributes:t,default:a}})=>({value:e,label:n,attributes:t,default:a}))}(t);return function(e){const n=(0,p.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function u({value:e,tabValues:n}){return n.some(n=>n.value===e)}function g({queryString:e=!1,groupId:n}){const t=(0,l.W6)(),o=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,c.aZ)(o),(0,a.useCallback)(e=>{if(!o)return;const n=new URLSearchParams(t.location.search);n.set(o,e),t.replace({...t.location,search:n.toString()})},[o,t])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:o}=e,i=h(e),[s,l]=(0,a.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!u({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:i})),[c,p]=g({queryString:t,groupId:o}),[m,f]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,o]=(0,d.Dv)(n);return[t,(0,a.useCallback)(e=>{n&&o.set(e)},[n,o])]}({groupId:o}),x=(()=>{const e=c??m;return u({value:e,tabValues:i})?e:null})();(0,r.A)(()=>{x&&l(x)},[x]);return{selectedValue:s,selectValue:(0,a.useCallback)(e=>{if(!u({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);l(e),p(e),f(e)},[p,f,i]),tabValues:i}}var x=t(92303);const A={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var b=t(74848);function y({className:e,block:n,selectedValue:t,selectValue:a,tabValues:i}){const l=[],{blockElementScrollPositionUntilNextRender:r}=(0,s.a_)(),c=e=>{const n=e.currentTarget,o=l.indexOf(n),s=i[o].value;s!==t&&(r(n),a(s))},p=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":n},e),children:i.map(({value:e,label:n,attributes:a})=>(0,b.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{l.push(e)},onKeyDown:p,onClick:c,...a,className:(0,o.A)("tabs__item",A.tabItem,a?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function j({lazy:e,children:n,selectedValue:t}){const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=i.find(e=>e.props.value===t);return e?(0,a.cloneElement)(e,{className:(0,o.A)("margin-top--md",e.props.className)}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:i.map((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function I(e){const n=f(e);return(0,b.jsxs)("div",{className:(0,o.A)(i.G.tabs.container,"tabs-container",A.tabList),children:[(0,b.jsx)(y,{...n,...e}),(0,b.jsx)(j,{...n,...e})]})}function v(e){const n=(0,x.A)();return(0,b.jsx)(I,{...e,children:m(e.children)},String(n))}},19365:(e,n,t)=>{t.d(n,{A:()=>s});t(96540);var a=t(18215);const o={tabItem:"tabItem_Ymn6"};var i=t(74848);function s({children:e,hidden:n,className:t}){return(0,i.jsx)("div",{role:"tabpanel",className:(0,a.A)(o.tabItem,t),hidden:n,children:e})}},84039:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>C,contentTitle:()=>w,default:()=>O,frontMatter:()=>_,metadata:()=>a,toc:()=>P});const a=JSON.parse('{"id":"compute/inference/open-ai","title":"OpenAI","description":"Run inferences on Clarifai models using OpenAI","source":"@site/docs/compute/inference/open-ai.md","sourceDirName":"compute/inference","slug":"/compute/inference/open-ai","permalink":"/compute/inference/open-ai","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"description":"Run inferences on Clarifai models using OpenAI","sidebar_position":2,"toc_max_heading_level":4},"sidebar":"tutorialSidebar","previous":{"title":"Inference via UI","permalink":"/compute/inference/clarifai/ui"},"next":{"title":"LiteLLM","permalink":"/compute/inference/litellm"}}');var o=t(74848),i=t(28453),s=t(11470),l=t(19365),r=t(88149);const c='import os\nfrom openai import OpenAI\n\n# Initialize the OpenAI client, pointing to Clarifai\'s API\nclient = OpenAI(     \n    base_url="https://api.clarifai.com/v2/ext/openai/v1",  # Clarifai\'s OpenAI-compatible API endpoint\n    api_key=os.environ["CLARIFAI_PAT"]  # Ensure CLARIFAI_PAT is set as an environment variable\n)\n\n# Make a chat completion request to a Clarifai-hosted model\nresponse = client.chat.completions.create(    \n    model="https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",\n    #model="anthropic/completion/models/claude-sonnet-4", # Or, provide Clarifai model name\n    messages=[\n        {"role": "system", "content": "You are a helpful assistant."},\n        {"role": "user", "content": "Who are you?"}\n    ],\n    # You can also add other OpenAI-compatible parameters like max_tokens, etc.\n    max_completion_tokens=100,  # Limits the response length\n    temperature=0.7,  # Controls randomness of the output    \n)\n\n# Print the model\'s response\nprint(response.choices[0].message.content)',p='import OpenAI from "openai";\n\nconst client = new OpenAI({\n  baseURL: "https://api.clarifai.com/v2/ext/openai/v1",\n  apiKey: process.env.CLARIFAI_PAT,\n});\n\nconst response = await client.chat.completions.create({\n  model: "https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",\n  messages: [\n    { role: "system", content: "You are a helpful assistant." },\n    { role: "user", content: "Who are you?" },\n  ],\n});\n\nconsole.log(response.choices?.[0]?.message.content);',d='import os\nfrom openai import OpenAI\n\n# Initialize the OpenAI client, pointing to Clarifai\'s API\nclient = OpenAI(     \n    base_url="https://api.clarifai.com/v2/ext/openai/v1",  # Clarifai\'s OpenAI-compatible API endpoint\n    api_key=os.environ["CLARIFAI_PAT"]  # Ensure CLARIFAI_PAT is set as an environment variable\n)\n\n# Make a chat completion request to a Clarifai-hosted model\nresponse = client.chat.completions.create(    \n    model="https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",\n    #model="anthropic/completion/models/claude-sonnet-4", # Or, provide Clarifai model name\n    messages=[\n        {"role": "system", "content": "You are a helpful assistant."},\n        {"role": "user", "content": "Who are you?"}\n    ],\n    # You can also add other OpenAI-compatible parameters like max_tokens, etc.\n    max_completion_tokens=100,  # Limits the response length\n    temperature=0.7,  # Controls randomness of the output\n    stream=True  # Enables streaming the response token by token\n)\n\nprint("Assistant\'s Response:")\nfor chunk in response:\n    # Safely check if choices, delta, and content exist before accessing\n    if chunk.choices and \\\n       chunk.choices[0].delta and \\\n       chunk.choices[0].delta.content is not None:\n        print(chunk.choices[0].delta.content, end=\'\')\nprint("\\n")  ',m='import os\nfrom openai import OpenAI\n\n# Initialize the OpenAI-compatible client for Clarifai\nclient = OpenAI(    \n    base_url="https://api.clarifai.com/v2/ext/openai/v1",\n    api_key=os.environ["CLARIFAI_PAT"]  # Ensure CLARIFAI_PAT is set as an environment variable   \n)\n\n# Define the external tools (functions) that the LLM can call.\n# In this example, it\'s a \'get_weather\' function.\ntools = [\n    {\n        "type": "function",\n        "function": {\n            "name": "get_weather",\n            "description": "Returns the current temperature for a given location.",\n            "parameters": {\n                "type": "object",\n                "properties": {\n                    "location": {\n                        "type": "string",\n                        "description": "City and country, e.g., \'Bogot\xe1, Colombia\'"\n                    }\n                },\n                "required": ["location"],\n                "additionalProperties": False # Ensures no extra parameters are passed\n            }\n        }\n    }\n]\n\n# Create a chat completion request with tool-calling enabled\nresponse = client.chat.completions.create(\n    model="https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",\n    #model="anthropic/completion/models/claude-sonnet-4", # Or, provide Clarifai model name\n    messages=[\n        {"role": "user", "content": "What is the weather like in New York today?"}\n    ],\n    tools=tools,\n    tool_choice=\'auto\' # Let the LLM decide if it needs to use a tool\n)\n\n# Print the tool call proposed by the model, if any\ntool_calls = response.choices[0].message.tool_calls\nprint("Tool calls:", tool_calls)\n',h='import OpenAI from "openai";\nimport type { ChatCompletionTool } from "openai/resources";\n\nconst client = new OpenAI({\n  baseURL: "https://api.clarifai.com/v2/ext/openai/v1",\n  apiKey: process.env.CLARIFAI_PAT,\n});\n\nconst tools: ChatCompletionTool[] = [\n  {\n    type: "function",\n    function: {\n      name: "get_weather",\n      description: "Get current temperature for a given location.",\n      parameters: {\n        type: "object",\n        properties: {\n          location: {\n            type: "string",\n            description: "City and country e.g. Bogot\xe1, Colombia",\n          },\n        },\n        required: ["location"],\n        additionalProperties: false,\n      },\n      strict: true,\n    },\n  },\n];\n\nconst toolCompletion = await client.chat.completions.create({\n  model: "https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",\n  messages: [\n    { role: "system", content: "You are a helpful assistant." },\n    { role: "user", content: "What is the weather in New York?" },\n  ],\n  tools,\n});\n\nconsole.log(toolCompletion.choices?.[0]?.message.tool_calls);\n',u='import os\nimport json\nfrom openai import OpenAI\n\n# Initialize the OpenAI client, pointing to Clarifai\'s OpenAI-compatible API endpoint\nclient = OpenAI(\n    base_url="https://api.clarifai.com/v2/ext/openai/v1",\n    api_key=os.environ["CLARIFAI_PAT"]  # Ensure CLARIFAI_PAT is set as an environment variable  \n)\n\n# Define the external tools (functions) that the LLM can call.\n# In this example, it\'s a \'get_weather\' function.\ntools = [{\n    "type": "function",\n    "function": {\n        "name": "get_weather",\n        "description": "Get current temperature for a given location.",\n        "parameters": {\n            "type": "object",\n            "properties": {\n                "location": {\n                    "type": "string",\n                    "description": "City and country, e.g., \'Bogot\xe1, Colombia\'"\n                }\n            },\n            "required": ["location"],\n            "additionalProperties": False # Ensures no extra parameters are passed\n        },\n        "strict": True # Enforces strict adherence to parameter schema\n    }\n}]\n\n## Simulate Tool Execution (for demonstration)\n\n# This function simulates calling an external weather API.\n# In a real application, this would make an actual API request.\ndef get_weather(location: str):\n    """Simulates fetching weather for a given location."""\n    # Placeholder data for demonstration\n    if "New York" in location:\n        return {"location": "New York", "temperature": "20\xb0C", "conditions": "Partly cloudy"}\n    elif "London" in location:\n        return {"location": "London", "temperature": "15\xb0C", "conditions": "Rainy"}\n    else:\n        return {"location": location, "temperature": "N/A", "conditions": "Unknown"}\n\n## LLM Call with Tooling\n\n# First API call: The LLM decides if a tool needs to be called.\nprint("--- Initial LLM Call (Tool Recommendation) ---")\nfirst_response = client.chat.completions.create(\n    model="https://clarifai.com/openai/chat-completion/models/gpt-oss-120b", # Ensure this model supports tool calling on Clarifai\'s platform\n    messages=[\n        {"role": "user", "content": "What is the weather like in New York today?"}\n    ],\n    tools=tools, # Provide the list of available tools\n    tool_choice="auto", # Let the LLM decide if it needs to use a tool\n)\n\n\n## Process LLM\'s Response and Execute Tool (if recommended)\n\n# Check if the LLM decided to call a tool\nif first_response.choices[0].message.tool_calls:\n    tool_calls = first_response.choices[0].message.tool_calls\n    print(f"\\nLLM recommended tool calls: {tool_calls}")\n\n    # Execute each recommended tool call\n    available_functions = {\n        "get_weather": get_weather, # Map function name to actual Python function\n    }\n\n    messages = [\n        {"role": "user", "content": "What is the weather like in New York today?"}\n    ]\n    messages.append(first_response.choices[0].message) # Add LLM\'s tool call suggestion to messages\n\n    for tool_call in tool_calls:\n        function_name = tool_call.function.name\n        function_to_call = available_functions[function_name]\n        function_args = json.loads(tool_call.function.arguments)\n\n        # Call the actual Python function\n        function_response = function_to_call(**function_args)\n        print(f"\\nExecuting tool: {function_name}({function_args}) -> {function_response}")\n\n        # Add the tool\'s output to the conversation for the LLM to process\n        messages.append(\n            {\n                "tool_call_id": tool_call.id,\n                "role": "tool",\n                "name": function_name,\n                "content": json.dumps(function_response),\n            }\n        )\n\n    # ---\n    ## Second LLM Call (Summarize Tool Output)\n    \n\n    # Now, send the tool\'s output back to the LLM to get a natural language response\n    print("\\n--- Second LLM Call (Summarizing Tool Output) ---")\n    second_response = client.chat.completions.create(\n        model="https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",\n        #model="anthropic/completion/models/claude-sonnet-4", # Or, provide Clarifai model name\n        messages=messages, # Continue the conversation with tool output\n    )\n\n    print("\\nFinal Assistant\'s Response:")\n    print(second_response.choices[0].message.content)\n\nelse:\n    print("\\nLLM did not recommend any tool calls.")\n    print("Assistant\'s direct response:")\n    print(first_response.choices[0].message.content)',g="--- Initial LLM Call (Tool Recommendation) ---\n\nLLM recommended tool calls: [ChatCompletionMessageToolCall(id='toolu_01Mhqb1c7ne4GPKWY9eZtgxd', function=Function(arguments='{\"location\": \"New York, United States\"}', name='get_weather'), type='function')]\n\nExecuting tool: get_weather({'location': 'New York, United States'}) -> {'location': 'New York', 'temperature': '20\xb0C', 'conditions': 'Partly cloudy'}\n\n--- Second LLM Call (Summarizing Tool Output) ---\n\nFinal Assistant's Response:\nThe weather in New York today is:\n- **Temperature:** 20\xb0C (68\xb0F)\n- **Conditions:** Partly cloudy\n\nIt's a pleasant day with mild temperatures and partly cloudy skies!",f='import os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    base_url="https://api.clarifai.com/v2/ext/openai/v1",\n    api_key=os.environ[\'CLARIFAI_PAT\'],\n)\nresponse = client.images.generate(\n    model="https://clarifai.com/xai/image-generation/models/grok-2-image-1212",\n    prompt="A cat in a tree",\n)\nprint(response)',x='import os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    base_url="https://api.clarifai.com/v2/ext/openai/v1",\n    api_key=os.environ[\'CLARIFAI_PAT\'],\n)\n\nresponse = client.embeddings.create(\n   input="The food was delicious and the service was excellent.",\n   model="https://clarifai.com/openai/embed/models/text-embedding-ada-002"\n)\n\nprint(response.data[0].embedding)\n',A='import os\nfrom openai import OpenAI\n\n# Initialize the OpenAI client, pointing to Clarifai\'s API\nclient = OpenAI(\n    base_url="https://api.clarifai.com/v2/ext/openai/v1",  # Clarifai\'s OpenAI-compatible API endpoint\n    api_key=os.environ["CLARIFAI_PAT"]  # Ensure CLARIFAI_PAT is set as an environment variable\n)\n\n# Make a response request to a Clarifai-hosted model\nresponse = client.responses.create(\n    model="https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",\n    #model="openai/chat-completion/models/gpt-oss-120b", # Or, provide Clarifai model name\n    input="Tell me a three sentence bedtime story about a unicorn.",\n\n    # You can also add other OpenAI-compatible parameters like max tokens, etc.   \n    max_output_tokens=100,\n    temperature=0.7,\n)\n\n# Print the model\'s response\nprint(response.output_text)',b='import os\nimport requests\nimport base64\nfrom pathlib import Path\nfrom openai import OpenAI\n\n# Option 1: Use a local image file\n# path = "local/path/of/image.png"\n# image_base64 = base64.b64encode(Path(path).read_bytes()).decode()\n\n# Option 2: Download image from URL and convert to base64\ndef get_image_base64(image_url):\n    """Download image and convert it to a base64-encoded string."""\n    response = requests.get(image_url)\n    return base64.b64encode(response.content).decode("utf-8")\n\nimage_url = "https://samples.clarifai.com/cat1.jpeg"\nimage_base64 = get_image_base64(image_url)\n\n# Initialize OpenAI client using Clarifai\'s OpenAI-compatible endpoint\nclient = OpenAI(\n    base_url="https://api.clarifai.com/v2/ext/openai/v1",\n    api_key=os.environ["CLARIFAI_PAT"],\n)\n\nresponse = client.chat.completions.create(\n    model="https://clarifai.com/openai/chat-completion/models/gpt-4o",\n    messages=[\n        {\n            "role": "user",\n            "content": [\n                {"type": "text", "text": "Describe the image"},\n                {\n                    "type": "image_url",\n                    "image_url": {\n                        "url": f"data:image/jpeg;base64,{image_base64}"\n                    }\n                }\n            ]\n        }\n    ],\n    temperature=0.7,\n    max_tokens=1024    \n)\n\n# Output the result\nprint(f"Response: {response.choices[0].message.content}")',y="Tool calls: [ChatCompletionMessageFunctionToolCall(id='call_d81a514ab00346a78e65318e', function=Function(arguments='{\"location\": \"New York, USA\"}', name='get_weather'), type='function', index=0)]",j='curl -X POST "https://api.clarifai.com/v2/ext/openai/v1/chat/completions" \\\n  -H "Authorization: Key YOUR_PAT_HERE" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model": "https://clarifai.com/openai/chat-completion/models/gpt-oss-120b/versions/ba43503e5628487686d31f223e71b033",\n    "messages": [\n      {\n        "role": "system",\n        "content": "You are a helpful assistant."\n      },\n      {\n        "role": "user",\n        "content": "Who are you?"\n      }\n    ]\n  }\'\n',I='from openai import OpenAI\nfrom pydantic import BaseModel, Field\nimport os\n\nclient = OpenAI(\n    base_url="https://api.clarifai.com/v2/ext/openai/v1",\n    api_key=os.environ["CLARIFAI_PAT"] # Ensure CLARIFAI_PAT is set as an environment variable\n)\n\n# Define the output schema\nclass PersonInfo(BaseModel):\n    name: str = Field(..., description="Full name of the person")\n    age: int = Field(..., description="Age of the person in years")\n    email: str = Field(..., pattern=r"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$",\n                       description="Email address of the person")\n\n\n# JSON schema, Use the schema in a chat completion\nresponse = client.chat.completions.create(\n    model="https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",\n    messages=[\n        {\n            "role": "user",\n            "content": (\n                "John Miller is 29 years old and can be reached at john.miller@example.com. "\n                "He recently joined our company as a data analyst."\n            ),\n        },\n    ],\n    max_tokens=200,\n    response_format={\n        "type": "json_schema",\n        "json_schema": {\n            "name": "PersonInfo",\n            "schema": PersonInfo.model_json_schema(),\n        },\n    },\n)\n\nprint(response.choices[0].message.content)\n',v='from openai import OpenAI\nfrom pydantic import BaseModel, Field\nimport os\n\nclient = OpenAI(\n    base_url="https://api.clarifai.com/v2/ext/openai/v1",\n    api_key=os.environ["CLARIFAI_PAT"] # Ensure CLARIFAI_PAT is set as an environment variable\n)\n\n# Define the output schema\nclass PersonInfo(BaseModel):\n    name: str = Field(..., description="Full name of the person")\n    age: int = Field(..., description="Age of the person in years")\n    email: str = Field(..., pattern=r"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$",\n                       description="Email address of the person")\n\n\n# Pydantic \ncompletion = client.chat.completions.parse(\n    model="https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",\n    messages=[\n        {\n            "role": "user",\n            "content": (\n                "John Miller is 29 years old and can be reached at john.miller@example.com. "\n                "He recently joined our company as a data analyst."\n            ),\n        },\n    ],\n    max_tokens=200,\n    response_format=PersonInfo\n)\nprint(completion.choices[0].message.parsed)',_={description:"Run inferences on Clarifai models using OpenAI",sidebar_position:2,toc_max_heading_level:4},w="OpenAI",C={},P=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Install OpenAI Package",id:"install-openai-package",level:3},{value:"Get a PAT Key",id:"get-a-pat-key",level:3},{value:"Get a Clarifai Model",id:"get-a-clarifai-model",level:3},{value:"Responses API",id:"responses-api",level:2},{value:"Text Inputs",id:"text-inputs",level:3},{value:"Chat Completions API",id:"chat-completions-api",level:2},{value:"Text Inputs",id:"text-inputs-1",level:3},{value:"Multimodal Inputs",id:"multimodal-inputs",level:3},{value:"Streaming",id:"streaming",level:3},{value:"Tool Calling",id:"tool-calling",level:3},{value:"Structured Outputs",id:"structured-outputs",level:3},{value:"Standard JSON Schema Extraction",id:"standard-json-schema-extraction",level:4},{value:"Pydantic-Integrated Extraction",id:"pydantic-integrated-extraction",level:4},{value:"Images Generate API",id:"images-generate-api",level:2},{value:"Embeddings API",id:"embeddings-api",level:2}];function k(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"openai",children:"OpenAI"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Run inferences on Clarifai models using OpenAI"})}),"\n",(0,o.jsx)("hr",{}),"\n",(0,o.jsxs)(n.p,{children:["You can run inferences on Clarifai-hosted models using the OpenAI client library by leveraging the Clarifai\u2019s ",(0,o.jsx)(n.a,{href:"/compute/inference/#predict-with-openai-compatible-format",children:"OpenAI-compatible API endpoint"}),"."]}),"\n",(0,o.jsx)(n.p,{children:"This allows you to use the same code and tools you would with OpenAI, in either Python or JavaScript, by simply configuring the client to point to Clarifai and providing your PAT (Personal Access Token) key."}),"\n",(0,o.jsx)(n.admonition,{type:"tip",children:(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://github.com/Clarifai/examples/tree/main/models/model_predict",children:"Click here"})," for additional examples on how to perform model predictions using various SDKs \u2014 such as the Clarifai SDK, OpenAI client, and LiteLLM. The examples demonstrate various model types and include both streaming and non-streaming modes, as well as tool calling capabilities."]})}),"\n","\n","\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsx)(n.h3,{id:"install-openai-package",children:"Install OpenAI Package"}),"\n",(0,o.jsxs)(n.p,{children:["Install the ",(0,o.jsx)(n.code,{children:"openai"})," package."]}),"\n",(0,o.jsxs)(s.A,{groupId:"code",children:[(0,o.jsx)(l.A,{value:"bash",label:"Python",children:(0,o.jsx)(r.A,{className:"language-bash",children:" pip install openai "})}),(0,o.jsx)(l.A,{value:"node.js",label:"Node.js",children:(0,o.jsx)(r.A,{className:"language-bash",children:" npm install openai "})})]}),"\n",(0,o.jsx)(n.h3,{id:"get-a-pat-key",children:"Get a PAT Key"}),"\n",(0,o.jsxs)(n.p,{children:["You need a ",(0,o.jsx)(n.a,{href:"https://docs.clarifai.com/control/authentication/pat",children:"Personal Access Token (PAT)"})," key to authenticate your connection to the Clarifai platform. You can get one by navigating to ",(0,o.jsx)(n.strong,{children:"Settings"})," in the collapsible left sidebar, selecting ",(0,o.jsx)(n.strong,{children:"Secrets"}),", and creating or copying an existing token from there."]}),"\n",(0,o.jsxs)(n.p,{children:["You can then set the PAT as an environment variable using ",(0,o.jsx)(n.code,{children:"CLARIFAI_PAT"}),":"]}),"\n",(0,o.jsxs)(s.A,{groupId:"code",children:[(0,o.jsx)(l.A,{value:"bash",label:"Unix-Like Systems",children:(0,o.jsx)(r.A,{className:"language-bash",children:" export CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE "})}),(0,o.jsx)(l.A,{value:"bash2",label:"Windows",children:(0,o.jsx)(r.A,{className:"language-bash",children:" set CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE "})})]}),"\n",(0,o.jsx)(n.h3,{id:"get-a-clarifai-model",children:"Get a Clarifai Model"}),"\n",(0,o.jsxs)(n.p,{children:["Go to the Clarifai ",(0,o.jsx)(n.a,{href:"https://clarifai.com/explore",children:"Community"})," platform and select the model you want to use for making predictions."]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Some Clarifai models that support OpenAI"}),(0,o.jsxs)(r.A,{className:"language-python",children:[(0,o.jsx)(n.a,{href:"https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",children:"https://clarifai.com/openai/chat-completion/models/gpt-oss-120b"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/deepseek-ai/deepseek-chat/models/DeepSeek-R1-0528-Qwen3-8B",children:"https://clarifai.com/deepseek-ai/deepseek-chat/models/DeepSeek-R1-0528-Qwen3-8B"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/meta/Llama-3/models/Llama-3_2-3B-Instruct",children:"https://clarifai.com/meta/Llama-3/models/Llama-3_2-3B-Instruct"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/anthropic/completion/models/claude-sonnet-4",children:"https://clarifai.com/anthropic/completion/models/claude-sonnet-4"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/qwen/qwenLM/models/Qwen3-14B",children:"https://clarifai.com/qwen/qwenLM/models/Qwen3-14B"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/mistralai/completion/models/Devstral-Small-2505_gguf-4bit",children:"https://clarifai.com/mistralai/completion/models/Devstral-Small-2505_gguf-4bit"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/clarifai/main/models/general-image-recognition",children:"https://clarifai.com/clarifai/main/models/general-image-recognition"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/xai/chat-completion/models/grok-3",children:"https://clarifai.com/xai/chat-completion/models/grok-3"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/openai/chat-completion/models/gpt-4o",children:"https://clarifai.com/openai/chat-completion/models/gpt-4o"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/openai/chat-completion/models/gpt-4_1",children:"https://clarifai.com/openai/chat-completion/models/gpt-4_1"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/gcp/generate/models/gemini-2_5-flash",children:"https://clarifai.com/gcp/generate/models/gemini-2_5-flash"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/anthropic/completion/models/claude-3_5-haiku",children:"https://clarifai.com/anthropic/completion/models/claude-3_5-haiku"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/qwen/qwenLM/models/Qwen3-30B-A3B-GGUF",children:"https://clarifai.com/qwen/qwenLM/models/Qwen3-30B-A3B-GGUF"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/gcp/generate/models/gemini-2_0-flash",children:"https://clarifai.com/gcp/generate/models/gemini-2_0-flash"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/gcp/generate/models/gemma-3-12b-it",children:"https://clarifai.com/gcp/generate/models/gemma-3-12b-it"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/microsoft/text-generation/models/Phi-4-reasoning-plus",children:"https://clarifai.com/microsoft/text-generation/models/Phi-4-reasoning-plus"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/openbmb/miniCPM/models/MiniCPM3-4B",children:"https://clarifai.com/openbmb/miniCPM/models/MiniCPM3-4B"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/microsoft/text-generation/models/phi-4-mini-instruct",children:"https://clarifai.com/microsoft/text-generation/models/phi-4-mini-instruct"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/qwen/qwen-VL/models/Qwen2_5-VL-7B-Instruct",children:"https://clarifai.com/qwen/qwen-VL/models/Qwen2_5-VL-7B-Instruct"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/microsoft/text-generation/models/phi-4",children:"https://clarifai.com/microsoft/text-generation/models/phi-4"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/xai/chat-completion/models/grok-2-vision-1212",children:"https://clarifai.com/xai/chat-completion/models/grok-2-vision-1212"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/xai/image-generation/models/grok-2-image-1212",children:"https://clarifai.com/xai/image-generation/models/grok-2-image-1212"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/xai/chat-completion/models/grok-2-1212",children:"https://clarifai.com/xai/chat-completion/models/grok-2-1212"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/qwen/qwenLM/models/QwQ-32B-AWQ",children:"https://clarifai.com/qwen/qwenLM/models/QwQ-32B-AWQ"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/gcp/generate/models/gemini-2_0-flash-lite",children:"https://clarifai.com/gcp/generate/models/gemini-2_0-flash-lite"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/anthropic/completion/models/claude-opus-4",children:"https://clarifai.com/anthropic/completion/models/claude-opus-4"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/openai/chat-completion/models/o4-mini",children:"https://clarifai.com/openai/chat-completion/models/o4-mini"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/openai/chat-completion/models/o3",children:"https://clarifai.com/openai/chat-completion/models/o3"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/openbmb/miniCPM/models/MiniCPM-o-2_6-language",children:"https://clarifai.com/openbmb/miniCPM/models/MiniCPM-o-2_6-language"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/deepseek-ai/deepseek-chat/models/DeepSeek-R1-Distill-Qwen-7B",children:"https://clarifai.com/deepseek-ai/deepseek-chat/models/DeepSeek-R1-Distill-Qwen-7B"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/qwen/qwenCoder/models/Qwen2_5-Coder-7B-Instruct",children:"https://clarifai.com/qwen/qwenCoder/models/Qwen2_5-Coder-7B-Instruct"})]})]}),"\n",(0,o.jsx)(n.h2,{id:"responses-api",children:"Responses API"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.a,{href:"https://platform.openai.com/docs/api-reference/responses",children:"OpenAI Responses"})," API endpoint provides a powerful interface for generating model responses, allowing you to leverage OpenAI's most advanced capabilities."]}),"\n",(0,o.jsx)(n.p,{children:"It\u2019s highly versatile, supporting both text and image inputs and producing text outputs, as well as advanced features like streaming and tool calling."}),"\n",(0,o.jsx)(n.h3,{id:"text-inputs",children:"Text Inputs"}),"\n",(0,o.jsx)(s.A,{groupId:"code",children:(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:A})})}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Example Output"}),(0,o.jsx)(r.A,{className:"language-text",children:"Under a silver\u2011shimmering moon, a gentle unicorn named Lira tiptoed into the sleepy meadow, her horn casting soft, glittering lullabies over the swaying wildflowers. As the night wind whispered sweet dreams, she gathered a handful of moon\u2011kissed dew and sprinkled it over the slumbering forest creatures, coax"})]}),"\n",(0,o.jsx)(n.h2,{id:"chat-completions-api",children:"Chat Completions API"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.a,{href:"https://platform.openai.com/docs/api-reference/chat",children:"OpenAI Chat Completions"})," API endpoint enables you to generate a model response by providing a list of messages that constitute a conversation."]}),"\n",(0,o.jsx)(n.h3,{id:"text-inputs-1",children:"Text Inputs"}),"\n",(0,o.jsxs)(s.A,{groupId:"code",children:[(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:c})}),(0,o.jsx)(l.A,{value:"typescript",label:"TypeScript",children:(0,o.jsx)(r.A,{className:"language-typescript",children:p})}),(0,o.jsx)(l.A,{value:"curl",label:"cURL",children:(0,o.jsx)(r.A,{className:"language-bash",children:j})})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Example Output"}),(0,o.jsx)(r.A,{className:"language-text",children:"I\u2019m ChatGPT, an AI language model created by OpenAI. I\u2019ve been trained on a wide range of text so I can help answer questions, brainstorm ideas, explain concepts, and assist with many other tasks. Think of me as a virtual assistant you can chat with\u2014"})]}),"\n",(0,o.jsx)(n.h3,{id:"multimodal-inputs",children:"Multimodal Inputs"}),"\n",(0,o.jsx)(n.p,{children:"The OpenAI Chat Completions API supports multimodal inputs."}),"\n",(0,o.jsx)(s.A,{groupId:"code",children:(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:b})})}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Example Output"}),(0,o.jsx)(r.A,{className:"language-text",children:"Response: The image shows a ginger tabby cat lying down on a stone surface. The cat has a striped pattern on its fur and is looking directly at the camera with alert, bright eyes. The background features a textured wall, and the lighting highlights the cat's features, giving a warm and cozy atmosphere."})]}),"\n",(0,o.jsx)(n.h3,{id:"streaming",children:"Streaming"}),"\n",(0,o.jsx)(n.p,{children:"The OpenAI Chat Completions API supports streaming."}),"\n",(0,o.jsx)(s.A,{groupId:"code",children:(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:d})})}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Example Output"}),(0,o.jsx)(r.A,{className:"language-text",children:"Assistant's Response:\nI\u2019m ChatGPT, an AI language model created by OpenAI. I\u2019ve been trained on a wide range of text data so I can help answer questions, explain concepts, brainstorm ideas, draft writing, solve problems, and more. Think of me as a virtual assistant that can converse with you on many topics\u2014"})]}),"\n",(0,o.jsx)(n.h3,{id:"tool-calling",children:"Tool Calling"}),"\n",(0,o.jsx)(n.p,{children:"The OpenAI Chat Completions API supports tool calling (also known as function calling)."}),"\n",(0,o.jsx)(n.p,{children:'Here is an example code that sets up a basic tool-calling interaction. It simulates a weather API and shows how the LLM would "call" that tool when asked about the weather.'}),"\n",(0,o.jsxs)(s.A,{groupId:"code",children:[(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:m})}),(0,o.jsx)(l.A,{value:"typescript",label:"TypeScript",children:(0,o.jsx)(r.A,{className:"language-typescript",children:h})})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Example Output"}),(0,o.jsx)(r.A,{className:"language-text",children:y})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Tool Calling Implementation Example"}),(0,o.jsx)(r.A,{className:"language-python",children:u}),(0,o.jsx)(r.A,{className:"language-text",children:g})]}),"\n",(0,o.jsx)(n.h3,{id:"structured-outputs",children:"Structured Outputs"}),"\n",(0,o.jsxs)(n.p,{children:["The Chat Completions API supports generating structured JSON outputs from any ",(0,o.jsx)(n.a,{href:"#get-a-clarifai-model",children:"supported"})," OpenAI-compatible large language model."]}),"\n",(0,o.jsx)(n.p,{children:"This feature lets you go beyond plain text generation by enforcing that the model\u2019s output follows a strict, predictable data structure. Structured responses make it easier to integrate model outputs into downstream applications with greater safety, consistency, and reliability."}),"\n",(0,o.jsxs)(n.p,{children:["To define, validate, and serialize these structured responses, ",(0,o.jsx)(n.a,{href:"https://docs.pydantic.dev/latest/",children:"Pydantic"})," is used \u2014 a powerful data modeling library for Python."]}),"\n",(0,o.jsx)(n.p,{children:"You can install Pydantic with:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"pip install pydantic\n"})}),"\n",(0,o.jsx)(n.p,{children:"We support two main ways of generating the structured JSON responses:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Standard JSON schema extraction"}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Pydantic-integrated extraction."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h4,{id:"standard-json-schema-extraction",children:"Standard JSON Schema Extraction"}),"\n",(0,o.jsxs)(n.p,{children:["This technique calls the chat completion endpoint and explicitly requests the model to return its response in a ",(0,o.jsx)(n.a,{href:"https://json-schema.org/",children:"JSON"})," format that conforms to a specified Pydantic schema."]}),"\n",(0,o.jsx)(s.A,{groupId:"code",children:(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:I})})}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Example Output"}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:'{"age": 29, "email": "john.miller@example.com", "name": "John Miller"}\n'})})]}),"\n",(0,o.jsx)(n.h4,{id:"pydantic-integrated-extraction",children:"Pydantic-Integrated Extraction"}),"\n",(0,o.jsxs)(n.p,{children:["This technique uses a convenience method (",(0,o.jsx)(n.code,{children:"client.chat.completions.parse"}),") that handles the structured output request and attempts to automatically parse the JSON response into a Pydantic object, simplifying the extraction process."]}),"\n",(0,o.jsx)(s.A,{groupId:"code",children:(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:v})})}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Example Output"}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"name='John Miller' age=29 email='john.miller@example.com'\n"})})]}),"\n",(0,o.jsx)(n.h2,{id:"images-generate-api",children:"Images Generate API"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.a,{href:"https://platform.openai.com/docs/api-reference/images",children:"OpenAI Images Generate"})," API endpoint enables you to generate an image by providing a prompt."]}),"\n",(0,o.jsx)(n.p,{children:"Here is an example of how to generate an image using a model that supports Clarifai's OpenAI-compatible API endpoint."}),"\n",(0,o.jsx)(s.A,{groupId:"code",children:(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:f})})}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Example Output"}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"ImagesResponse(created=None, data=[Image(b64_json=None, revised_prompt='A high-resolution photograph of a cat perched on a branch in a lush, green tree during the daytime. The cat, possibly a tabby, is the central focus of the image, looking slightly to the side with its fur naturally positioned. The background features a soft, slightly blurred forest setting with sunlight filtering through the leaves, creating a serene and natural environment. The composition avoids any distracting elements, ensuring the cat remains the primary subject in a peaceful outdoor scene.', url='https://imgen.x.ai/xai-imgen/xai-tmp-imgen-41202340-c0e1-4669-bed5-e70f7b491176.jpeg')], usage=None)\n"})})]}),"\n",(0,o.jsx)(n.h2,{id:"embeddings-api",children:"Embeddings API"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.a,{href:"https://platform.openai.com/docs/guides/embeddings",children:"OpenAI Embeddings"})," API allows you to convert text into numerical vector representations (embeddings) that capture semantic meaning. These embeddings can then be used to measure the similarity or relatedness between different pieces of text."]}),"\n",(0,o.jsx)(n.p,{children:"Here\u2019s an example of how to generate embeddings using a model that supports Clarifai\u2019s OpenAI-compatible API endpoint."}),"\n",(0,o.jsx)(s.A,{groupId:"code",children:(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:x})})}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Example Output"}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"[0.007715723942965269, -0.005610561463981867, 0.0038386366795748472, -0.023672660812735558, -0.0028357207775115967, 0.0058668977580964565, 0.005136339459568262, -0.029632480815052986, 0.009997117333114147, -0.027863759547472, 0.016123555600643158, 0.010894294828176498, -0.0065814354456961155, -0.03468230739235878, -0.019545646384358406, 0.003260277910158038, 0.032759785652160645, -0.006728828884661198, 0.00939472671598196, -0.020865777507424355, -0.02409561537206173, 0.01959691382944584, 0.0123361861333251, -0.003186581190675497, -0.007440162356942892, 0.016213273629546165, 0.0012400270206853747, -0.017956361174583435, 0.009266559034585953, 0.017943544313311577, 0.0027379924431443214, -0.005963024217635393, -0.03734820336103439, 0.001370598329231143, -0.014213849790394306, -0.017328336834907532, -0.019648181274533272, 0.005863693542778492, 0.003191387513652444, 0.004690954927355051, 0.003135313745588064, -0.014265117235481739, 0.012977027334272861, 0.008625717833638191, -0.04129578545689583, 0.012047807686030865, 0.007613189052790403, 0.0061424593441188335, -0.01573905162513256, -0.019276492297649384, 0.011778654530644417, -0.01596975326538086, -0.011560768820345402, -0.013201321475207806, 0.0214809849858284, 0.017174534499645233, -0.007286360487341881, -0.009708738885819912, 0.02837643213570118, -0.015290462411940098, -0.009221700020134449, 0.02190393954515457, -0.021827038377523422, -0.018379315733909607, -0.019789164885878563, -0.01197731588035822, -0.012836041860282421, 0.00048784009413793683, 0.0025665676221251488, 0.0067160120233893394, 0.0037296938244253397, 0.011150631122291088, 0.012803999707102776, -0.01639270968735218, 0.018968889489769936, -0.012880900874733925, -0.008503957651555538, 0.00356307509355247, -0.004127014894038439, . . .]\n"})})]})]})}function O(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(k,{...e})}):k(e)}}}]);