"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[3364],{11470:(e,t,n)=>{n.d(t,{A:()=>v});var r=n(96540),i=n(18215),a=n(17559),o=n(23104),s=n(56347),c=n(205),u=n(57485),l=n(31682),d=n(70679);function p(e){return r.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:t,children:n}=e;return(0,r.useMemo)(()=>{const e=t??function(e){return p(e).map(({props:{value:e,label:t,attributes:n,default:r}})=>({value:e,label:t,attributes:n,default:r}))}(n);return function(e){const t=(0,l.XI)(e,(e,t)=>e.value===t.value);if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[t,n])}function f({value:e,tabValues:t}){return t.some(t=>t.value===e)}function g({queryString:e=!1,groupId:t}){const n=(0,s.W6)(),i=function({queryString:e=!1,groupId:t}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,u.aZ)(i),(0,r.useCallback)(e=>{if(!i)return;const t=new URLSearchParams(n.location.search);t.set(i,e),n.replace({...n.location,search:t.toString()})},[i,n])]}function m(e){const{defaultValue:t,queryString:n=!1,groupId:i}=e,a=h(e),[o,s]=(0,r.useState)(()=>function({defaultValue:e,tabValues:t}){if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!f({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=t.find(e=>e.default)??t[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:a})),[u,l]=g({queryString:n,groupId:i}),[p,m]=function({groupId:e}){const t=function(e){return e?`docusaurus.tab.${e}`:null}(e),[n,i]=(0,d.Dv)(t);return[n,(0,r.useCallback)(e=>{t&&i.set(e)},[t,i])]}({groupId:i}),_=(()=>{const e=u??p;return f({value:e,tabValues:a})?e:null})();(0,c.A)(()=>{_&&s(_)},[_]);return{selectedValue:o,selectValue:(0,r.useCallback)(e=>{if(!f({value:e,tabValues:a}))throw new Error(`Can't select invalid tab value=${e}`);s(e),l(e),m(e)},[l,m,a]),tabValues:a}}var _=n(92303);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var w=n(74848);function y({className:e,block:t,selectedValue:n,selectValue:r,tabValues:a}){const s=[],{blockElementScrollPositionUntilNextRender:c}=(0,o.a_)(),u=e=>{const t=e.currentTarget,i=s.indexOf(t),o=a[i].value;o!==n&&(c(t),r(o))},l=e=>{let t=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const n=s.indexOf(e.currentTarget)+1;t=s[n]??s[0];break}case"ArrowLeft":{const n=s.indexOf(e.currentTarget)-1;t=s[n]??s[s.length-1];break}}t?.focus()};return(0,w.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":t},e),children:a.map(({value:e,label:t,attributes:r})=>(0,w.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:e=>{s.push(e)},onKeyDown:l,onClick:u,...r,className:(0,i.A)("tabs__item",b.tabItem,r?.className,{"tabs__item--active":n===e}),children:t??e},e))})}function C({lazy:e,children:t,selectedValue:n}){const a=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const e=a.find(e=>e.props.value===n);return e?(0,r.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,w.jsx)("div",{className:"margin-top--md",children:a.map((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==n}))})}function x(e){const t=m(e);return(0,w.jsxs)("div",{className:(0,i.A)(a.G.tabs.container,"tabs-container",b.tabList),children:[(0,w.jsx)(y,{...t,...e}),(0,w.jsx)(C,{...t,...e})]})}function v(e){const t=(0,_.A)();return(0,w.jsx)(x,{...e,children:p(e.children)},String(t))}},19365:(e,t,n)=>{n.d(t,{A:()=>o});n(96540);var r=n(18215);const i={tabItem:"tabItem_Ymn6"};var a=n(74848);function o({children:e,hidden:t,className:n}){return(0,a.jsx)("div",{role:"tabpanel",className:(0,r.A)(i.tabItem,n),hidden:t,children:e})}},57985:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>_,contentTitle:()=>m,default:()=>y,frontMatter:()=>g,metadata:()=>r,toc:()=>b});const r=JSON.parse('{"id":"integrations/unstructured/s3-rag","title":"Use RAG With Unstructured.io","description":"Learn how to use RAG with Unstructured.io","source":"@site/docs/integrations/unstructured/s3-rag.md","sourceDirName":"integrations/unstructured","slug":"/integrations/unstructured/s3-rag","permalink":"/integrations/unstructured/s3-rag","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chat With Dropbox Using Unstructured.io","permalink":"/integrations/unstructured/dropbox"},"next":{"title":"Ingest Email Messages From Salesforce Using Unstructured.io","permalink":"/integrations/unstructured/salesforce"}}');var i=n(74848),a=n(28453),o=n(11470),s=n(19365),c=n(88149);const u="import os  # Importing the os module for operating system related functionalities.\nfrom unstructured.ingest.connector.fsspec.s3 import S3AccessConfig, SimpleS3Config  # Importing S3AccessConfig and SimpleS3Config classes from the fsspec.s3 module of the unstructured.ingest.connector package.\nfrom unstructured.ingest.interfaces import (  # Importing multiple classes from the interfaces module of the unstructured.ingest package.\n    PartitionConfig,\n    ProcessorConfig,\n    ChunkingConfig,\n    ReadConfig,\n)\nfrom unstructured.ingest.runner import S3Runner  # Importing the S3Runner class from the runner module of the unstructured.ingest package.\n\n# Importing classes related to Clarifai integration from the clarifai module of the unstructured.ingest.connector package.\nfrom unstructured.ingest.connector.clarifai import (\n    ClarifaiAccessConfig,\n    ClarifaiWriteConfig,\n    SimpleClarifaiConfig,\n)\n\n# Importing Writer class from the base_writer module of the unstructured.ingest.runner.writers package.\nfrom unstructured.ingest.runner.writers.base_writer import Writer\n\n# Importing ClarifaiWriter class from the clarifai module of the unstructured.ingest.runner.writers package.\nfrom unstructured.ingest.runner.writers.clarifai import (\n    ClarifaiWriter,\n)\n",l='def clarifai_writer() -> Writer:\n    # This function defines a writer for the Clarifai service.\n    # It returns an instance of ClarifaiWriter class.\n\n    return ClarifaiWriter(\n        connector_config=SimpleClarifaiConfig(\n            # Configuration for accessing the Clarifai API.\n            access_config=ClarifaiAccessConfig(\n                api_key="PAT"  # API key for accessing the Clarifai service.\n            ),\n            # Configuration specific to the Clarifai application.\n            app_id="app_id",  # The ID of the Clarifai application.\n            user_id="user_id"  # The ID of the Clarifai user.\n        ),\n        write_config=ClarifaiWriteConfig()  # Configuration for writing data to Clarifai.\n    )\n',d='if __name__ == "__main__":\n    writer = clarifai_writer()    \n    # Instantiating an S3Runner object with various configurations.\n    runner = S3Runner(\n        processor_config=ProcessorConfig(\n            verbose=True,  # Setting verbosity to True for detailed output.\n            output_dir="s3-output-local",  # Setting the output directory for processed data.\n            num_processes=2,  # Specifying the number of processes to be used.\n        ),\n        read_config=ReadConfig(),  # Instantiating a ReadConfig object with default configurations.\n        partition_config=PartitionConfig(),  # Instantiating a PartitionConfig object with default configurations.\n        connector_config=SimpleS3Config(  # Instantiating a SimpleS3Config object with S3 access configurations and remote URL.\n            access_config=S3AccessConfig(\n                key=access_key,  # Setting the access key for S3.\n                secret=secret_access,  # Setting the secret access key for S3.\n            ),\n            remote_url="your_s3_data_uri",  # Specifying the remote URL for S3 data.\n        ),\n        writer=writer,  # Passing the ClarifaiWriter object as the writer.\n        writer_kwargs={},  # Passing empty keyword arguments to the writer.\n    )\n    \n    # Running the S3Runner instance.\n    runner.run()\n',p='from clarifai.rag import RAG\n\nWORKFLOW_URL = \'rag_workflow_url\'\n# creating RAG object with prebuilt workflow\nrag_object_from_url = RAG(workflow_url = WORKFLOW_URL)\n\nresult=rag_object_from_url.chat(messages=[{"role":"human", "content":"What is Central Public Procurement Portal"}])\n\n# Extract the content of the response and split it by newline character (\'\\n\') into a list \'ans\'.\nanswer = result[0]["content"].split(\'\\n\')\nprint(answer)\n',h='2024-04-15 13:21:07,085 MainProcess DEBUG    updating download directory to: /root/.cache/unstructured/ingest/s3/5b2778ce2a\nDEBUG:unstructured.ingest:updating download directory to: /root/.cache/unstructured/ingest/s3/5b2778ce2a\n2024-04-15 13:21:07,091 MainProcess INFO     running pipeline: DocFactory -> Reader -> Partitioner -> Writer -> Copier with config: {"reprocess": false, "verbose": true, "work_dir": "/root/.cache/unstructured/ingest/pipeline", "output_dir": "s3-output-local", "num_processes": 2, "raise_on_error": false}\nINFO:unstructured.ingest:running pipeline: DocFactory -> Reader -> Partitioner -> Writer -> Copier with config: {"reprocess": false, "verbose": true, "work_dir": "/root/.cache/unstructured/ingest/pipeline", "output_dir": "s3-output-local", "num_processes": 2, "raise_on_error": false}\n2024-04-15 13:21:07,210 MainProcess INFO     Running doc factory to generate ingest docs. Source connector: {"processor_config": {"reprocess": false, "verbose": true, "work_dir": "/root/.cache/unstructured/ingest/pipeline", "output_dir": "s3-output-local", "num_processes": 2, "raise_on_error": false}, "read_config": {"download_dir": "/root/.cache/unstructured/ingest/s3/5b2778ce2a", "re_download": false, "preserve_downloads": false, "download_only": false, "max_docs": null}, "connector_config": {"remote_url": "s3://new-bucket-for-databricks-integration-23102023/procurement.txt", "uncompress": false, "recursive": false, "file_glob": null, "access_config": {"anonymous": false, "endpoint_url": null, "token": null}, "protocol": "s3", "path_without_protocol": "new-bucket-for-databricks-integration-23102023/procurement.txt", "dir_path": "new-bucket-for-databricks-integration-23102023", "file_path": "procurement.txt"}}\n2024-04-15 13:21:08,156 MainProcess INFO     processing 1 docs via 2 processes\nINFO:unstructured.ingest:processing 1 docs via 2 processes\n2024-04-15 13:21:08,161 MainProcess INFO     Calling Reader with 1 docs\nINFO:unstructured.ingest:Calling Reader with 1 docs\n2024-04-15 13:21:08,164 MainProcess INFO     Running source node to download data associated with ingest docs\nINFO:unstructured.ingest:Running source node to download data associated with ingest docs\n2024-04-15 13:21:11,016 MainProcess INFO     Calling Partitioner with 1 docs\nINFO:unstructured.ingest:Calling Partitioner with 1 docs\n2024-04-15 13:21:11,026 MainProcess INFO     Running partition node to extract content from json files. Config: {"pdf_infer_table_structure": true, "strategy": "auto", "ocr_languages": null, "encoding": null, "additional_partition_args": {}, "skip_infer_table_types": null, "fields_include": ["element_id", "text", "type", "metadata", "embeddings"], "flatten_metadata": false, "metadata_exclude": [], "metadata_include": [], "partition_endpoint": "https://api.unstructured.io/general/v0/general", "partition_by_api": false, "api_key": null, "hi_res_model_name": null}, partition kwargs: {}]\nINFO:unstructured.ingest:Running partition node to extract content from json files. Config: {"pdf_infer_table_structure": true, "strategy": "auto", "ocr_languages": null, "encoding": null, "additional_partition_args": {}, "skip_infer_table_types": null, "fields_include": ["element_id", "text", "type", "metadata", "embeddings"], "flatten_metadata": false, "metadata_exclude": [], "metadata_include": [], "partition_endpoint": "https://api.unstructured.io/general/v0/general", "partition_by_api": false, "api_key": null, "hi_res_model_name": null}, partition kwargs: {}]\n2024-04-15 13:21:11,033 MainProcess INFO     Creating /root/.cache/unstructured/ingest/pipeline/partitioned\nINFO:unstructured.ingest:Creating /root/.cache/unstructured/ingest/pipeline/partitioned\n2024-04-15 13:21:18,576 MainProcess INFO     Calling Copier with 1 docs\nINFO:unstructured.ingest:Calling Copier with 1 docs\n2024-04-15 13:21:18,581 MainProcess INFO     Running copy node to move content to desired output location\nINFO:unstructured.ingest:Running copy node to move content to desired output location\n2024-04-15 13:21:20,011 MainProcess INFO     uploading elements from 1 document(s) to the destination\nINFO:unstructured.ingest:uploading elements from 1 document(s) to the destination\n2024-04-15 13:21:20,015 MainProcess INFO     Calling Writer with 1 docs\nINFO:unstructured.ingest:Calling Writer with 1 docs\n2024-04-15 13:21:20,018 MainProcess INFO     Running write node to upload content. Destination connector: {"write_config": {"batch_size": 50}, "connector_config": {"access_config": {"api_key": "*******"}, "app_id": "unst-clf", "user_id": "8tzpjy1a841y", "dataset_id": null}, "_client": null}]\nINFO:unstructured.ingest:Running write node to upload content. Destination connector: {"write_config": {"batch_size": 50}, "connector_config": {"access_config": {"api_key": "***REDACTED***"}, "app_id": "unst-clf", "user_id": "8tzpjy1a841y", "dataset_id": null}, "_client": null}]\n2024-04-15 13:21:20,517 MainProcess INFO     Extending 204 json elements from content in s3-output-local/procurement.txt.json\nINFO:unstructured.ingest:Extending 204 json elements from content in s3-output-local/procurement.txt.json\n2024-04-15 13:21:20,532 MainProcess INFO     writing 204 objects to destination app unst-clf \nINFO:unstructured.ingest:writing 204 objects to destination app unst-clf \n2024-04-15 13:21:23 INFO     clarifai.client.input:                                                    input.py:687\n                             Inputs Uploaded                                                                       \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             details: "All inputs successfully added"                                              \n                             req_id: "5c9d83ec06888714335749a3aa572c0b" ',f='"The Central Public Procurement Portal (CPPP) is a platform designed, developed, and hosted by the National Informatics Centre in association with the Department of Expenditure. Its main goal is to ensure transparency in public procurement processes. The portal provides a single access point to information on procurements made across various Ministries and Departments. It contains features like e-publishing and e-procurement modules and it\'s mandatory for all Ministries/Departments of the Central Government and other entities to publish their tender enquiries and information about the resulting contracts on the CPPP. The portal provides access to documents related to pre-qualification, Bidders\u2019 enlistment, Bidding documents, and other procurement-related information. It also facilitates e-procurement for Ministries/Departments that do not have large procurement volumes or only require procurement for day-to-day operations."',g={},m="Use RAG With Unstructured.io",_={},b=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Initialization",id:"initialization",level:2},{value:"Data Ingestion",id:"data-ingestion",level:2},{value:"Chat",id:"chat",level:2}];function w(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components},{Details:n}=t;return n||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"use-rag-with-unstructuredio",children:"Use RAG With Unstructured.io"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.strong,{children:"Learn how to use RAG with Unstructured.io"})}),"\n",(0,i.jsx)("hr",{}),"\n",(0,i.jsx)(t.p,{children:"RAG systems are a powerful combination of two techniques: information retrieval and text generation. When you ask a question, the system searches for related details (context) and then leverages that context to generate a response using text generation methods. Using Unstructured.io we can transform the data into a format suitable for RAG. The Clarifai platform provides various LLMs that can be used for text generation inside RAG. Hence by integrating Clarifai with Unstructured.io, you can build RAG applications with ease."}),"\n",(0,i.jsx)(t.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["Setting up the Clarifai Python SDK along with PAT. Refer to the installation and configuration with the PAT token ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/python-sdk/sdk-overview/",children:"here"}),"."]}),"\n"]}),"\n",(0,i.jsx)(t.admonition,{type:"note",children:(0,i.jsxs)(t.p,{children:["Guide to get your ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/clarifai-basics/authentication/personal-access-tokens",children:"PAT"})]})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"import os\nos.environ['CLARIFAI_PAT'] =\"YOUR_PAT\"\n"})}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Install the required packages."}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:'! pip install "unstructured[clarifai]" #make sure the unstructured version is 0.13 or above\n! pip install "unstructured[s3]" #since our source is S3\n! pip install httpx\n'})}),"\n",(0,i.jsx)(t.h2,{id:"initialization",children:"Initialization"}),"\n",(0,i.jsx)(t.p,{children:"The first part of creating an app based on Unstructured.io is to set up the data we are going to ingest into the app. The data we are going to use will be stored in the s3 bucket. To access the data using Unstructured.io, we have to provide some AWS access keys."}),"\n",(0,i.jsx)(t.admonition,{type:"info",children:(0,i.jsxs)(t.p,{children:["Click ",(0,i.jsx)(t.a,{href:"https://medium.com/@shamnad.p.s/how-to-create-an-s3-bucket-and-aws-access-key-id-and-secret-access-key-for-accessing-it-5653b6e54337",children:"here"})," to learn how to get the s3 access keys."]})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"access_key='YOUR_S3_ACCESS_KEYS'\nsecret_access='YOUR_S3_SECRET_ACCESS_KEYS'\n"})}),"\n",(0,i.jsx)(t.p,{children:"After setting up the access keys for the s3 bucket, let\u2019s import some necessary libraries."}),"\n",(0,i.jsx)(o.A,{groupId:"code",children:(0,i.jsx)(s.A,{value:"python",label:"Python",children:(0,i.jsx)(c.A,{className:"language-python",children:u})})}),"\n",(0,i.jsx)(t.p,{children:"Next, we have to write a function that will configure the target Clarifai app where the ingested documents will be loaded,"}),"\n",(0,i.jsx)(o.A,{groupId:"code",children:(0,i.jsx)(s.A,{value:"python",label:"Python",children:(0,i.jsx)(c.A,{className:"language-python",children:l})})}),"\n",(0,i.jsx)(t.h2,{id:"data-ingestion",children:"Data Ingestion"}),"\n",(0,i.jsx)(t.p,{children:"In data ingestion, there are two important concepts Source Connector and Destination Connector. For our use case the Source Connector will fetch the data from the S3 bucket and the Destination Connector will send the transformed data to the Clarifai app."}),"\n",(0,i.jsxs)(t.p,{children:["Click ",(0,i.jsx)(t.a,{href:"https://unstructured-io.github.io/unstructured/ingest/index.html",children:"here"})," to learn more about Ingestion."]}),"\n",(0,i.jsx)(o.A,{groupId:"code",children:(0,i.jsx)(s.A,{value:"python",label:"Python",children:(0,i.jsx)(c.A,{className:"language-python",children:d})})}),"\n",(0,i.jsxs)(n,{children:[(0,i.jsx)("summary",{children:"Output"}),(0,i.jsx)(c.A,{className:"language-python",children:h})]}),"\n",(0,i.jsx)(t.h2,{id:"chat",children:"Chat"}),"\n",(0,i.jsx)(t.p,{children:"In the final step, we are going to perform information retrieval using RAG based on the data we ingested from S3 to the Clarifai app using Unstructured.io. You can use a workflow with a RAG prompter for initialising RAG. After successfully creating a workflow, you can get the URL from the Clarifai portal. After creating the rag object using workflow URL you can start retrieving text from the data we ingested using Unstructured.io."}),"\n",(0,i.jsx)(o.A,{groupId:"code",children:(0,i.jsx)(s.A,{value:"python",label:"Python",children:(0,i.jsx)(c.A,{className:"language-python",children:p})})}),"\n",(0,i.jsxs)(n,{children:[(0,i.jsx)("summary",{children:"Output"}),(0,i.jsx)(c.A,{className:"language-python",children:f})]})]})}function y(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(w,{...e})}):w(e)}}}]);