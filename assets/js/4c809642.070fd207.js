"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[9723],{11470:(e,n,i)=>{i.d(n,{A:()=>v});var o=i(96540),a=i(18215),l=i(17559),t=i(23104),r=i(56347),s=i(205),d=i(57485),c=i(31682),h=i(70679);function u(e){return o.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p(e){const{values:n,children:i}=e;return(0,o.useMemo)(()=>{const e=n??function(e){return u(e).map(({props:{value:e,label:n,attributes:i,default:o}})=>({value:e,label:n,attributes:i,default:o}))}(i);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,i])}function m({value:e,tabValues:n}){return n.some(n=>n.value===e)}function f({queryString:e=!1,groupId:n}){const i=(0,r.W6)(),a=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,d.aZ)(a),(0,o.useCallback)(e=>{if(!a)return;const n=new URLSearchParams(i.location.search);n.set(a,e),i.replace({...i.location,search:n.toString()})},[a,i])]}function g(e){const{defaultValue:n,queryString:i=!1,groupId:a}=e,l=p(e),[t,r]=(0,o.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const i=n.find(e=>e.default)??n[0];if(!i)throw new Error("Unexpected error: 0 tabValues");return i.value}({defaultValue:n,tabValues:l})),[d,c]=f({queryString:i,groupId:a}),[u,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[i,a]=(0,h.Dv)(n);return[i,(0,o.useCallback)(e=>{n&&a.set(e)},[n,a])]}({groupId:a}),x=(()=>{const e=d??u;return m({value:e,tabValues:l})?e:null})();(0,s.A)(()=>{x&&r(x)},[x]);return{selectedValue:t,selectValue:(0,o.useCallback)(e=>{if(!m({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);r(e),c(e),g(e)},[c,g,l]),tabValues:l}}var x=i(92303);const y={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var _=i(74848);function b({className:e,block:n,selectedValue:i,selectValue:o,tabValues:l}){const r=[],{blockElementScrollPositionUntilNextRender:s}=(0,t.a_)(),d=e=>{const n=e.currentTarget,a=r.indexOf(n),t=l[a].value;t!==i&&(s(n),o(t))},c=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const i=r.indexOf(e.currentTarget)+1;n=r[i]??r[0];break}case"ArrowLeft":{const i=r.indexOf(e.currentTarget)-1;n=r[i]??r[r.length-1];break}}n?.focus()};return(0,_.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":n},e),children:l.map(({value:e,label:n,attributes:o})=>(0,_.jsx)("li",{role:"tab",tabIndex:i===e?0:-1,"aria-selected":i===e,ref:e=>{r.push(e)},onKeyDown:c,onClick:d,...o,className:(0,a.A)("tabs__item",y.tabItem,o?.className,{"tabs__item--active":i===e}),children:n??e},e))})}function j({lazy:e,children:n,selectedValue:i}){const l=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=l.find(e=>e.props.value===i);return e?(0,o.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,_.jsx)("div",{className:"margin-top--md",children:l.map((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==i}))})}function w(e){const n=g(e);return(0,_.jsxs)("div",{className:(0,a.A)(l.G.tabs.container,"tabs-container",y.tabList),children:[(0,_.jsx)(b,{...n,...e}),(0,_.jsx)(j,{...n,...e})]})}function v(e){const n=(0,x.A)();return(0,_.jsx)(w,{...e,children:u(e.children)},String(n))}},19365:(e,n,i)=>{i.d(n,{A:()=>t});i(96540);var o=i(18215);const a={tabItem:"tabItem_Ymn6"};var l=i(74848);function t({children:e,hidden:n,className:i}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,o.A)(a.tabItem,i),hidden:n,children:e})}},72245:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>j,contentTitle:()=>b,default:()=>k,frontMatter:()=>_,metadata:()=>o,toc:()=>w});const o=JSON.parse('{"id":"compute/upload/README","title":"Build and Upload Models","description":"Build and import models, including from external sources like Hugging Face","source":"@site/docs/compute/upload/README.mdx","sourceDirName":"compute/upload","slug":"/compute/upload/","permalink":"/compute/upload/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"description":"Build and import models, including from external sources like Hugging Face","toc_min_heading_level":2,"toc_max_heading_level":5},"sidebar":"tutorialSidebar","previous":{"title":"Advanced Inference Options","permalink":"/compute/inference/advanced"},"next":{"title":"Test Models Locally","permalink":"/compute/upload/test-locally"}}');var a=i(74848),l=i(28453),t=i(11470),r=i(19365),s=i(88149);const d='from clarifai.runners.models.model_class import ModelClass\nfrom typing import Iterator\n\n\nclass MyModel(ModelClass):\n  """A custom runner that adds "Hello World" to the end of the text."""\n\n  def load_model(self):\n    """Load the model here."""\n\n  @ModelClass.method\n  def predict(self, text1: str = "") -> str:\n    """This is the method that will be called when the runner is run. It takes in an input and\n    returns an output.\n    """\n\n    output_text = text1 + " Hello World!"\n\n    return output_text\n\n  @ModelClass.method\n  def generate(self, text1: str = "") -> Iterator[str]:\n    """Example yielding a whole batch of streamed stuff back."""\n\n    for i in range(10):  # fake something iterating generating 10 times.\n      output_text = text1 + f"Generate Hello World {i}"\n      yield output_text\n\n  @ModelClass.method\n  def stream(self, input_iterator: Iterator[str]) -> Iterator[str]:\n    """Example yielding a whole batch of streamed stuff back."""\n\n    for i, input in enumerate(input_iterator):\n      output_text = input + f"Stream Hello World {i}"\n      yield output_text',c='model:\n  id: "my-uploaded-model"\n  user_id: "YOUR_USER_ID_HERE"\n  app_id: "YOUR_APP_ID_HERE"\n  model_type_id: "text-to-text"\n\nbuild_info:\n  python_version: "3.11"\n  # platform: "linux/amd64,linux/arm64"  # Optional: Specify target platform(s) for Docker image build\n\ninference_compute_info:\n  cpu_limit: "1"\n  cpu_requests: "1"\n  cpu_memory: "13Gi"\n  cpu_memory_requests: "2Gi"\n  num_accelerators: 1\n  accelerator_type: ["NVIDIA-*"]\n  accelerator_memory: "15Gi"\n',h='checkpoints:\n  type: "huggingface"\n  repo_id: "meta-llama/Meta-Llama-3-8B-Instruct"\n  when: "runtime"\n  hf_token: "your_hf_token" # Required for private models',u="concepts:\n  - id: '0'\n    name: bus\n  - id: '1'\n    name: person\n  - id: '2'\n    name: bicycle\n  - id: '3'\n    name: car",p='clarifai model init\n[INFO] 13:58:37.002093 Initializing model with default templates... |  thread=8349786304 \nPress Enter to continue...\n[INFO] 13:58:39.866019 Created /Users/macbookpro/Desktop/code3/two/1/model.py |  thread=8349786304 \n[INFO] 13:58:39.866409 Created /Users/macbookpro/Desktop/code3/two/requirements.txt |  thread=8349786304 \n[INFO] 13:58:39.866669 Created /Users/macbookpro/Desktop/code3/two/config.yaml |  thread=8349786304 \n[INFO] 13:58:39.866717 Model initialization complete in /Users/macbookpro/Desktop/code3/two |  thread=8349786304 \n[INFO] 13:58:39.866755 Next steps: |  thread=8349786304 \n[INFO] 13:58:39.866789 1. Search for \'# TODO: please fill in\' comments in the generated files |  thread=8349786304 \n[INFO] 13:58:39.866822 2. Update the model configuration in config.yaml |  thread=8349786304 \n[INFO] 13:58:39.866853 3. Add your model dependencies to requirements.txt |  thread=8349786304 \n[INFO] 13:58:39.866883 4. Implement your model logic in 1/model.py |  thread=8349786304 \nclarifai model upload \n[INFO] 14:05:28.366437 No checkpoints specified in the config file |  thread=8349786304 \n[INFO] 14:05:28.367158 Setup: Using Python version 3.11 from the config file to build the Dockerfile |  thread=8349786304 \n[INFO] 14:05:28.367434 Setup: Validating requirements.txt file at /Users/macbookpro/Desktop/code3/two/requirements.txt using uv pip compile |  thread=8349786304 \n[INFO] 14:08:20.832060 Setup: Requirements.txt file validated successfully |  thread=8349786304 \n[INFO] 14:08:20.832914 Setup: Linting Python files: [\'/Users/macbookpro/Desktop/code3/two/1/model.py\'] |  thread=8349786304 \n[INFO] 14:08:20.893378 Setup: Python code linted successfully, no errors found. |  thread=8349786304 \n[INFO] 14:08:20.893821 Setup: Using NVIDIA base image to build the Docker image and upload the model |  thread=8349786304 \n[INFO] 14:08:21.153133 New model will be created at https://clarifai.com/alfrick/my-models/models/friday20th-two with it\'s first version. |  thread=8349786304 \nPress Enter to continue...\n[INFO] 14:08:30.795209 Uploading file... |  thread=6171717632 \n[INFO] 14:08:30.796342 Upload complete! |  thread=6171717632 \nStatus: Upload done, Progress: 0% - Completed upload of files, initiating model version image build..  request_id: sdk-python-11.10.2-6a2Status: Model image is currently being built., Progress: 0% - Model version image is being built.  request_id: sdk-python-11.10.2-6a242da[INFO] 14:08:31.584822 Created Model Version ID: ffb9c659ead240b69a5f829b503e725d |  thread=8349786304 \n[INFO] 14:08:31.585337 Full url to that version is: https://clarifai.com/alfrick/my-models/models/friday20th-two |  thread=8349786304 \n[INFO] 14:08:38.535619 2025-11-20 11:08:33.133911 INFO: Downloading uploaded buildable from storage...\n2025-11-20 11:08:33.966481 INFO: Done downloading buildable from storage\n2025-11-20 11:08:33.969976 INFO: Extracting upload...\n2025-11-20 11:08:33.975026 INFO: Done extracting upload\n2025-11-20 11:08:33.977716 INFO: Parsing requirements file for buildable version ID ****829b503e725d\n2025-11-20 11:08:34.004653 INFO: Dockerfile found at /shared/context/Dockerfile\ncat: /shared/context/downloader/hf_token: No such file or directory\n2025-11-20 11:08:34.748208 INFO: Setting up credentials\namazon-ecr-credential-helper\nVersion:    0.8.0\nGit commit: ********\n2025-11-20 11:08:34.753465 INFO: Building image...\n#1 \\[internal] load build definition from Dockerfile\n#1 DONE 0.0s\n\n#1 \\[internal] load build definition from Dockerfile\n#1 transferring dockerfile: 3.40kB done\n#1 WARN: FromAsCasing: \'as\' and \'FROM\' keywords\' casing do not match (line 7)\n#1 DONE 0.0s\n\n#2 resolve image config for docker-image://docker.io/docker/dockerfile:1.13-labs\n#2 DONE 0.1s\n\n#3 docker-image://docker.io/docker/dockerfile:1.13-labs@sha256:************18b8\n#3 resolve docker.io/docker/dockerfile:1.13-labs@sha256:************18b8 done\n#3 CACHED\n\n#4 \\[linux/arm64 internal] load metadata for public.ecr.aws/clarifai-models/python-base:3.11-********\n#4 DONE 0.2s\n\n#5 \\[linux/amd64 internal] load metadata for public.ecr.aws/clarifai-models/python-base:3.11-********\n#5 DONE 0.2s\n\n#6 \\[internal] load .dockerignore\n#6 transferring context: 2B done\n#6 DONE 0.0s\n\n#7 \\[internal] load build context\n#7 transferring context: 2.73kB done\n#7 DONE 0.0s\n\n#8 \\[linux/amd64 model-assets 1/8] FROM public.ecr.aws/clarifai-models/python-base:3.11-********@sha256:************48e5\n#8 resolve public.ecr.aws/clarifai-models/python-base:3.11-********@sha256:************48e5 done\n#8 CACHED\n\n#9 \\[linux/arm64 final 1/5] FROM public.ecr.aws/clarifai-models/python-base:3.11-********@sha256:************48e5\n#9 resolve public.ecr.aws/clarifai-models/python-base:3.11-********@sha256:************48e5 done\n#9 CACHED\n\n#10 \\[linux/arm64 final 2/5] COPY --link --chown=65532:65532 requirements.txt /home/nonroot/requirements.txt\n#10 merging done\n#10 DONE 0.0s\n\n#11 \\[linux/amd64 final 2/5] COPY --link --chown=65532:65532 requirements.txt /home/nonroot/requirements.txt\n#11 merging done\n#11 DONE 0.0s\n\n#12 \\[linux/amd64 final 3/5] RUN ["uv", "pip", "install", "--no-cache-dir", "-r", "/home/nonroot/requirements.txt"]\n#12 0.071 Using Python 3.11.14 environment at: /venv\n#12 0.518 Resolved 35 packages in 445ms\n#12 0.525 Downloading grpcio (6.3MiB)\n#12 0.529 Downloading pygments (1.2MiB)\n#12 0.529 Downloading pydantic-core (1.9MiB)\n#12 0.529 Downloading pillow (6.7MiB)\n#12 0.530 Downloading aiohttp (1.7MiB)\n#12 0.530 Downloading ruff (10.8MiB)\n#12 0.530 Downloading numpy (16.1MiB)\n#12 0.567 Downloading uv (17.0MiB)\n#12 0.701  Downloading pydantic-core\n#12 0.827  Downloading aiohttp\n#12 1.010  Downloading ruff\n#12 1.060  Downloading uv\n#12 1.061  Downloading grpcio\n#12 1.063  Downloading pillow\n#12 1.096  Downloading pygments\n#12 1.275  Downloading numpy\n#12 1.275 Prepared 27 packages in 756ms\n#12 1.276 Uninstalled 1 package in 0.91ms\n#12 1.297 Installed 27 packages in 20ms\n#12 1.297  + aiohappyeyeballs==2.6.1\n#12 1.297  + aiohttp==3.13.2\n#12 1.297  + aiosignal==1.4.0\n#12 1.297  + attrs==25.4.0\n#12 1.297  + charset-normalizer==3.4.4\n#12 1.297  + clarifai==11.10.2\n#12 1.297  + clarifai-grpc==11.10.5\n#12 1.297  + clarifai-protocol==0.0.34\n#12 1.297  + contextlib2==21.6.0\n#12 1.297  + frozenlist==1.8.0\n#12 1.297  + googleapis-common-protos==1.72.0\n#12 1.297  + grpcio==1.76.0\n#12 1.297  + multidict==6.7.0\n#12 1.297  + numpy==2.3.5\n#12 1.297  + pillow==12.0.0\n#12 1.297  + propcache==0.4.1\n#12 1.297  + protobuf==6.33.1\n#12 1.297  + psutil==7.0.0\n#12 1.297  + pydantic-core==2.33.2\n#12 1.297  + pygments==2.19.2\n#12 1.297  + requests==2.32.5\n#12 1.297  + ruff==0.11.4\n#12 1.297  + schema==0.7.5\n#12 1.297  + tabulate==0.9.0\n#12 1.297  + urllib3==2.5.0\n#12 1.297  - uv==0.9.9\n#12 1.297  + uv==0.7.12\n#12 1.297  + yarl==1.22.0\n#12 DONE 1.4s\n\n#13 \\[linux/amd64 final 4/5] RUN ["uv", "pip", "show", "--no-cache-dir", "clarifai"]\n#13 0.081 Using Python 3.11.14 environment at: /venv\n#13 0.084 Name: clarifai\n#13 0.084 Version: 11.10.2\n#13 0.084 Location: /venv/lib/python3.11/site-packages\n#13 0.084 Requires: aiohttp, clarifai-grpc, clarifai-protocol, click, fsspec, numpy, packaging, pillow, psutil, pydantic-core, pygments, pyyaml, requests, ruff, schema, tabulate, tqdm, uv\n#13 0.084 Required-by: clarifai-protocol\n#13 DONE 0.1s\n\n#14 \\[linux/amd64 model-assets 2/8] RUN pip install --no-cache-dir clarifai==11.10.2 huggingface_hub\n#14 0.837 Collecting clarifai==11.10.2\n#14 0.902   Downloading clarifai-11.10.2-py3-none-any.whl.metadata (23 kB)\n#14 0.911 Requirement already satisfied: huggingface_hub in /venv/lib/python3.11/site-packages (1.1.4)\n#14 0.944 Collecting clarifai-grpc>=11.10.3 (from clarifai==11.10.2)\n#14 0.948   Downloading clarifai_grpc-11.10.5-py3-none-any.whl.metadata (4.4 kB)\n#14 0.989 Collecting clarifai-protocol>=0.0.33 (from clarifai==11.10.2)\n#14 0.994   Downloading clarifai_protocol-0.0.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n#14 1.129 Collecting numpy>=1.22.0 (from clarifai==11.10.2)\n#14 1.133   Downloading numpy-2.3.5-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n#14 1.150 Requirement already satisfied: tqdm>=4.65.0 in /venv/lib/python3.11/site-packages (from clarifai==11.10.2) (4.67.1)\n#14 1.150 Requirement already satisfied: PyYAML>=6.0.1 in /venv/lib/python3.11/site-packages (from clarifai==11.10.2) (6.0.3)\n#14 1.158 Collecting schema==0.7.5 (from clarifai==11.10.2)\n#14 1.161   Downloading schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)\n#14 1.282 Collecting Pillow>=9.5.0 (from clarifai==11.10.2)\n#14 1.285   Downloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n#14 1.315 Collecting tabulate>=0.9.0 (from clarifai==11.10.2)\n#14 1.318   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n#14 1.322 Requirement already satisfied: fsspec>=2024.6.1 in /venv/lib/python3.11/site-packages (from clarifai==11.10.2) (2025.10.0)\n#14 1.323 Requirement already satisfied: click>=8.1.7 in /venv/lib/python3.11/site-packages (from clarifai==11.10.2) (8.3.0)\n#14 1.338 Collecting requests>=2.32.3 (from clarifai==11.10.2)\n#14 1.341   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n#14 1.718 Collecting aiohttp>=3.10.0 (from clarifai==11.10.2)\n#14 1.722   Downloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n#14 1.869 Collecting uv==0.7.12 (from clarifai==11.10.2)\n#14 1.875   Downloading uv-0.7.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n#14 2.137 Collecting ruff==0.11.4 (from clarifai==11.10.2) |  thread=8349786304 \n[INFO] 14:08:47.340894 #14 1.722   Downloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n#14 1.869 Collecting uv==0.7.12 (from clarifai==11.10.2)\n#14 1.875   Downloading uv-0.7.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n#14 2.137 Collecting ruff==0.11.4 (from clarifai==11.10.2)\n#14 2.142   Downloading ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n#14 2.188 Collecting psutil==7.0.0 (from clarifai==11.10.2)\n#14 2.192   Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n#14 2.206 Collecting pygments>=2.19.2 (from clarifai==11.10.2)\n#14 2.209   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n#14 2.739 Collecting pydantic_core==2.33.2 (from clarifai==11.10.2)\n#14 2.743   Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n#14 2.744 Requirement already satisfied: packaging==25.0 in /venv/lib/python3.11/site-packages (from clarifai==11.10.2) (25.0)\n#14 2.746 Requirement already satisfied: typing-extensions!=4.7.0,>=4.6.0 in /venv/lib/python3.11/site-packages (from pydantic_core==2.33.2->clarifai==11.10.2) (4.15.0)\n#14 2.753 Collecting contextlib2>=0.5.5 (from schema==0.7.5->clarifai==11.10.2)\n#14 2.757   Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n#14 2.759 Requirement already satisfied: filelock in /venv/lib/python3.11/site-packages (from huggingface_hub) (3.20.0)\n#14 2.760 Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /venv/lib/python3.11/site-packages (from huggingface_hub) (1.2.0)\n#14 2.760 Requirement already satisfied: httpx<1,>=0.23.0 in /venv/lib/python3.11/site-packages (from huggingface_hub) (0.28.1)\n#14 2.761 Requirement already satisfied: shellingham in /venv/lib/python3.11/site-packages (from huggingface_hub) (1.5.4)\n#14 2.762 Requirement already satisfied: typer-slim in /venv/lib/python3.11/site-packages (from huggingface_hub) (0.20.0)\n#14 2.768 Requirement already satisfied: anyio in /venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.11.0)\n#14 2.768 Requirement already satisfied: certifi in /venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (2025.11.12)\n#14 2.768 Requirement already satisfied: httpcore==1.* in /venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n#14 2.769 Requirement already satisfied: idna in /venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (3.11)\n#14 2.770 Requirement already satisfied: h11>=0.16 in /venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\n#14 2.781 Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.10.0->clarifai==11.10.2)\n#14 2.784   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n#14 2.791 Collecting aiosignal>=1.4.0 (from aiohttp>=3.10.0->clarifai==11.10.2)\n#14 2.794   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n#14 2.805 Collecting attrs>=17.3.0 (from aiohttp>=3.10.0->clarifai==11.10.2)\n#14 2.809   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n#14 2.855 Collecting frozenlist>=1.1.1 (from aiohttp>=3.10.0->clarifai==11.10.2)\n#14 2.859   Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n#14 3.011 Collecting multidict<7.0,>=4.5 (from aiohttp>=3.10.0->clarifai==11.10.2)\n#14 3.015   Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n#14 3.054 Collecting propcache>=0.2.0 (from aiohttp>=3.10.0->clarifai==11.10.2)\n#14 3.058   Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n#14 3.289 Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.10.0->clarifai==11.10.2)\n#14 3.293   Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n#14 3.643 Collecting grpcio>=1.53.2 (from clarifai-grpc>=11.10.3->clarifai==11.10.2)\n#14 3.647   Downloading grpcio-1.76.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n#14 3.819 Collecting protobuf>=5.29.5 (from clarifai-grpc>=11.10.3->clarifai==11.10.2)\n#14 3.824   Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n#14 3.836 Collecting googleapis-common-protos>=1.57.0 (from clarifai-grpc>=11.10.3->clarifai==11.10.2)\n#14 3.840   Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n#14 3.952 Collecting charset_normalizer<4,>=2 (from requests>=2.32.3->clarifai==11.10.2)\n#14 3.956   Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n#14 3.975 Collecting urllib3<3,>=1.21.1 (from requests>=2.32.3->clarifai==11.10.2)\n#14 3.979   Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n#14 3.987 Requirement already satisfied: sniffio>=1.1 in /venv/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub) (1.3.1)\n#14 3.996 Downloading clarifai-11.10.2-py3-none-any.whl (306 kB)\n#14 4.005 Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n#14 4.014 Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n#14 4.043    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 73.4 MB/s  0:00:00\n#14 4.050 Downloading ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n#14 4.111    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 11.3/11.3 MB 194.3 MB/s  0:00:00\n#14 4.114 Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n#14 4.121 Downloading uv-0.7.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.8 MB)\n#14 4.182    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 17.8/17.8 MB 292.6 MB/s  0:00:00\n#14 4.186 Downloading aiohttp-3.13.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n#14 4.195    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.7/1.7 MB 229.5 MB/s  0:00:00\n#14 4.199 Downloading multidict-6.7.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n#14 4.204 Downloading yarl-1.22.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (365 kB)\n#14 4.210 Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n#14 4.214 Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n#14 4.218 Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n#14 4.223 Downloading clarifai_grpc-11.10.5-py3-none-any.whl (305 kB)\n#14 4.229 Downloading clarifai_protocol-0.0.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (409 kB)\n#14 4.233 Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n#14 4.237 Downloading frozenlist-1.8.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (231 kB)\n#14 4.241 Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n#14 4.245 Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n#14 4.249 Downloading grpcio-1.76.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n#14 4.263    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 491.7 MB/s  0:00:00\n#14 4.267 Downloading numpy-2.3.5-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n#14 4.298    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 16.9/16.9 MB 559.0 MB/s  0:00:00\n#14 4.302 Downloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n#14 4.331    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.0/7.0 MB 253.1 MB/s  0:00:00\n#14 4.335 Downloading propcache-0.4.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (210 kB)\n#14 4.339 Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n#14 4.342    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.2/1.2 MB 713.1 MB/s  0:00:00\n#14 4.345 Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n#14 4.349 Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n#14 4.352 Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n#14 4.356 Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n#14 4.489 Installing collected packages: uv, urllib3, tabulate, ruff, pygments, pydantic_core, psutil, protobuf, propcache, Pillow, numpy, multidict, grpcio, frozenlist, contextlib2, charset_normalizer, attrs, aiohappyeyeballs, yarl, schema, requests, googleapis-common-protos, aiosignal, clarifai-grpc, aiohttp, clarifai-protocol, clarifai\n#14 4.489   Attempting uninstall: uv\n#14 4.490     Found existing installation: uv 0.9.9\n#14 4.492     Uninstalling uv-0.9.9:\n#14 4.495       Successfully uninstalled uv-0.9.9 |  thread=8349786304 \n[INFO] 14:08:50.414074 #14 7.989 8s)\n#14 7.991 Successfully installed Pillow-12.0.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 attrs-25.4.0 charset_normalizer-3.4.4 clarifai-11.10.2 clarifai-grpc-11.10.5 clarifai-protocol-0.0.34 contextlib2-21.6.0 frozenlist-1.8.0 googleapis-common-protos-1.72.0 grpcio-1.76.0 multidict-6.7.0 numpy-2.3.5 propcache-0.4.1 protobuf-6.33.1 psutil-7.0.0 pydantic_core-2.33.2 pygments-2.19.2 requests-2.32.5 ruff-0.11.4 schema-0.7.5 tabulate-0.9.0 urllib3-2.5.0 uv-0.7.12 yarl-1.22.0\n#14 ...\n\n#15 \\[linux/arm64 final 3/5] RUN ["uv", "pip", "install", "--no-cache-dir", "-r", "/home/nonroot/requirements.txt"]\n#15 1.183 Using Python 3.11.14 environment at: /venv\n#15 3.871 Resolved 35 packages in 2.59s\n#15 3.954 Downloading aiohttp (1.7MiB)\n#15 3.975 Downloading pygments (1.2MiB)\n#15 3.981 Downloading uv (15.8MiB)\n#15 3.983 Downloading ruff (9.9MiB)\n#15 3.984 Downloading pydantic-core (1.8MiB)\n#15 3.987 Downloading grpcio (6.1MiB)\n#15 3.990 Downloading pillow (6.1MiB)\n#15 3.991 Downloading numpy (13.9MiB)\n#15 5.116  Downloading pydantic-core\n#15 5.649  Downloading aiohttp\n#15 6.918  Downloading ruff\n#15 7.099  Downloading uv\n#15 7.131  Downloading pillow\n#15 7.143  Downloading grpcio\n#15 7.277  Downloading pygments\n#15 8.094  Downloading numpy\n#15 8.096 Prepared 27 packages in 4.21s\n#15 8.108 Uninstalled 1 package in 10ms\n#15 8.232 Installed 27 packages in 124ms\n#15 8.236  + aiohappyeyeballs==2.6.1\n#15 8.236  + aiohttp==3.13.2\n#15 8.236  + aiosignal==1.4.0\n#15 8.236  + attrs==25.4.0\n#15 8.236  + charset-normalizer==3.4.4\n#15 8.236  + clarifai==11.10.2\n#15 8.236  + clarifai-grpc==11.10.5\n#15 8.237  + clarifai-protocol==0.0.34\n#15 8.237  + contextlib2==21.6.0\n#15 8.237  + frozenlist==1.8.0\n#15 8.237  + googleapis-common-protos==1.72.0\n#15 8.237  + grpcio==1.76.0\n#15 8.237  + multidict==6.7.0\n#15 8.237  + numpy==2.3.5\n#15 8.237  + pillow==12.0.0\n#15 8.237  + propcache==0.4.1\n#15 8.238  + protobuf==6.33.1\n#15 8.238  + psutil==7.0.0\n#15 8.238  + pydantic-core==2.33.2\n#15 8.238  + pygments==2.19.2\n#15 8.238  + requests==2.32.5\n#15 8.238  + ruff==0.11.4\n#15 8.238  + schema==0.7.5\n#15 8.238  + tabulate==0.9.0\n#15 8.238  + urllib3==2.5.0\n#15 8.239  - uv==0.9.9\n#15 8.239  + uv==0.7.12\n#15 8.239  + yarl==1.22.0\n#15 DONE 8.4s\n\n#14 \\[linux/amd64 model-assets 2/8] RUN pip install --no-cache-dir clarifai==11.10.2 huggingface_hub\n#14 DONE 8.5s\n\n#16 \\[linux/arm64 final 4/5] RUN ["uv", "pip", "show", "--no-cache-dir", "clarifai"]\n#16 ...\n\n#17 \\[linux/amd64 model-assets 3/8] WORKDIR /home/nonroot/main\n#17 DONE 0.0s\n\n#18 \\[linux/amd64 model-assets 4/8] COPY --link downloader/unused.yaml /home/nonroot/main/1/checkpoints/.cache/unused.yaml\n#18 DONE 0.0s\n\n#19 \\[linux/amd64 model-assets 5/8] COPY --link config.yaml /home/nonroot/main/\n#19 merging done\n#19 DONE 0.0s\n\n#20 \\[linux/amd64 model-assets 6/8] RUN  ["python", "-m", "clarifai.cli", "model", "download-checkpoints", "/home/nonroot/main", "--out_path", "/home/nonroot/main/1/checkpoints", "--stage", "build"]\n#20 0.216 [WARNING] 11:08:43.952582 Could not write configuration to disk. Could be a read only file system. |  thread=140436804668992 \n#20 0.546 [WARNING] 11:08:44.282684 Config file /home/nonroot/.config/clarifai/config not found, using default config. Run \'clarifai config\' on the command line to create a config file. |  thread=140436804668992 \n#20 0.546 [WARNING] 11:08:44.282803 Config file /home/nonroot/.config/clarifai/config not found, using default config. Run \'clarifai config\' on the command line to create a config file. |  thread=140436804668992 \n#20 0.546 [INFO] 11:08:44.282943 No checkpoints specified in the config file |  thread=140436804668992 \n#20 DONE 0.6s\n\n#21 \\[linux/amd64 model-assets 7/8] COPY --link 1 /home/nonroot/main/1\n#21 DONE 0.0s\n\n#22 \\[linux/amd64 model-assets 8/8] COPY --link requirements.txt /home/nonroot/main/\n#22 merging 0.0s done\n#22 DONE 0.0s\n\n#16 \\[linux/arm64 final 4/5] RUN ["uv", "pip", "show", "--no-cache-dir", "clarifai"]\n#16 ...\n\n#23 \\[linux/amd64 final 5/5] COPY --link --chown=65532:65532 --from=model-assets /home/nonroot/main /home/nonroot/main\n#23 DONE 0.0s\n\n#16 \\[linux/arm64 final 4/5] RUN ["uv", "pip", "show", "--no-cache-dir", "clarifai"]\n#16 1.031 Using Python 3.11.14 environment at: /venv\n#16 1.079 Name: clarifai\n#16 1.079 Version: 11.10.2\n#16 1.079 Location: /venv/lib/python3.11/site-packages\n#16 1.079 Requires: aiohttp, clarifai-grpc, clarifai-protocol, click, fsspec, numpy, packaging, pillow, psutil, pydantic-core, pygments, pyyaml, requests, ruff, schema, tabulate, tqdm, uv\n#16 1.080 Required-by: clarifai-protocol\n#16 DONE 1.1s\n\n#24 \\[linux/arm64 final 5/5] COPY --link --chown=65532:65532 --from=model-assets /home/nonroot/main /home/nonroot/main\n#24 DONE 0.0s\n\n#25 exporting to image\n#25 exporting layers |  thread=8349786304 \n[INFO] 14:08:54.513161 #25 exporting layers 6.6s done\n#25 exporting manifest sha256:************7702 done\n#25 exporting config sha256:************62fc done\n#25 exporting manifest sha256:************1f5e done\n#25 exporting config sha256:************4138 done\n#25 exporting manifest list sha256:************f85a done\n#25 pushing layers\n#25 ...\n\n#26 \\[auth] sharing credentials for 891377382885.dkr.ecr.us-east-1.amazonaws.com\n#26 DONE 0.0s\n\n#25 exporting to image |  thread=8349786304 \n[INFO] 14:08:58.587380 #25 pushing layers 2.7s done\n#25 pushing manifest for ****/prod/pytorch:****829b503e725d@sha256:************f85a\n#25 pushing manifest for ****/prod/pytorch:****829b503e725d@sha256:************f85a 1.0s done\n#25 DONE 10.3s\n2025-11-20 11:08:55.012710 INFO: Done building image!!! |  thread=8349786304 \n[INFO] 14:08:58.588026 Model build complete! |  thread=8349786304 \n[INFO] 14:08:58.588121 Build time elapsed 27.0s) |  thread=8349786304 \n[INFO] 14:08:58.588216 Check out the model at https://clarifai.com/alfrick/my-models/models/friday20th-two version: ffb9c659ead240b69a5f829b503e725d |  thread=8349786304 \n[INFO] 14:08:58.640505 \n\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n# Here is a code snippet to use this model:\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n                 |  thread=8349786304 \n[INFO] 14:08:58.640586 # Clarifai Model Client Script\n# Set the environment variables `CLARIFAI_DEPLOYMENT_ID` and `CLARIFAI_PAT` to run this script.\n# Example usage:\nimport os\n\nfrom clarifai.client import Model\nfrom clarifai.runners.utils import data_types\n\nmodel = Model(\n    "https://clarifai.com/alfrick/my-models/models/friday20th-two",\n    deployment_id=os.environ.get("CLARIFAI_DEPLOYMENT_ID", None),  # Only needed for dedicated deployed models\n    deployment_user_id=os.environ.get("CLARIFAI_DEPLOYMENT_USER_ID", None),  # Organization or user ID for deployment/nodepool\n)\n\n# Example model prediction from different model methods:\n\nresponse = model.predict(\n    text1="What is the future of AI?",\n)\nprint(response)\n\nresponse = model.generate(\n    text1="What is the future of AI?",\n)\nfor res in response:\n    print(res)\n\nresponse = model.stream(\n    input_iterator=iter([\'What is the future of AI?\']),\n)\n |  thread=8349786304 \n[INFO] 14:08:58.640757 \n\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n                 |  thread=8349786304 \n\n\ud83d\udd36 Do you want to deploy the model? [Y/n]: y\n\n\ud83d\ude80 Model Deployment\n\n\ud83d\udda5\ufe0f  Available Compute Clusters:\n1. advanced-cluster-au64  \u2013  No description\nSelect compute cluster (number): 1\n\n\ud83d\udce6  Available Nodepools:\n1. advanced-nodepool-ncz5  \u2013  No description\nSelect nodepool (number): 1\n\n\u2328\ufe0f  Enter Deployment Configuration:\nEnter deployment ID [deploy-friday20th-two-b74f6d]: \nEnter minimum replicas [1]: 1\nEnter maximum replicas [5]: 5\n\n\u23f3 Deploying model...\n[INFO] 14:15:25.845466 Deployment with ID \'deploy-friday20th-two-b74f6d\' is created:\ncode: SUCCESS\ndescription: "Ok"\nreq_id: "sdk-python-11.10.2-26228389300b4ecb822cd801d35ef19b"\n |  thread=8349786304 \n\u2705 Deployment \'deploy-friday20th-two-b74f6d\' successfully created for model \'friday20th-two\' with version \'ffb9c659ead240b69a5f829b503e725d\'.\nModel deployed successfully! You can test it now.\n\n\ud83d\uddd1\ufe0f Do you want to backtrack and clean up? [Y/n]: y\n\n\ud83d\udd04 Starting backtrack process...\nDo you want to delete the deployment? [Y/n]: n\nDo you want to delete the model version? [y/N]: n',m='from clarifai.client import Model\nimport os\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n# Also set CLARIFAI_DEPLOYMENT_ID as an environment variable\n\n# Initialize with your model URL\nmodel = Model(\n    url="https://clarifai.com/user-id/app-id/models/model-id",\n    deployment_id=os.environ.get("CLARIFAI_DEPLOYMENT_ID", None),\n    )\n\nfor response in model.predict("Yes, I uploaded it! "):\n    print(response)',f='from clarifai.client import Model\nimport os\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n# Also set CLARIFAI_DEPLOYMENT_ID as an environment variable\n\n# Initialize with your model URL\nmodel = Model(\n    url="https://clarifai.com/user-id/app-id/models/model-id",\n    deployment_id=os.environ.get("CLARIFAI_DEPLOYMENT_ID", None),\n    )\n\nfor response in model.generate("Yes, I uploaded it! "):\n    print(response)',g="Y\ne\ns\n,\n \nI\n \nu\np\nl\no\na\nd\ne\nd\n \ni\nt\n!\n \n \nH\ne\nl\nl\no\n \nW\no\nr\nl\nd\n!",x="Yes, I uploaded it! Generate Hello World 0\nYes, I uploaded it! Generate Hello World 1\nYes, I uploaded it! Generate Hello World 2\nYes, I uploaded it! Generate Hello World 3\nYes, I uploaded it! Generate Hello World 4\nYes, I uploaded it! Generate Hello World 5\nYes, I uploaded it! Generate Hello World 6\nYes, I uploaded it! Generate Hello World 7\nYes, I uploaded it! Generate Hello World 8\nYes, I uploaded it! Generate Hello World 9",y='# syntax=docker/dockerfile:1.13-labs\nFROM --platform=$TARGETPLATFORM public.ecr.aws/clarifai-models/python-base:3.11-42938da8e33b0f37ee7db16b83631da94c2348b9 as final\n\nCOPY --link requirements.txt /home/nonroot/requirements.txt\n\nENV VIRTUAL_ENV=/venv\nENV PATH="/home/nonroot/.local/bin:$VIRTUAL_ENV/bin:$PATH"\n\n\n# Update clarifai package so we always have latest protocol to the API. Everything should land in /venv\nRUN ["uv", "pip", "install", "--no-cache-dir", "-r", "/home/nonroot/requirements.txt"]\nRUN ["uv", "pip", "show", "--no-cache-dir", "clarifai"]\n\n# Set the NUMBA cache dir to /tmp\n# Set the TORCHINDUCTOR cache dir to /tmp\n# The CLARIFAI* will be set by the templaing system.\nENV NUMBA_CACHE_DIR=/tmp/numba_cache \\\n    TORCHINDUCTOR_CACHE_DIR=/tmp/torchinductor_cache \\\n    HOME=/tmp \\\n    DEBIAN_FRONTEND=noninteractive\n\n#####\n# Copy the files needed to download\n#####\n# This creates the directory that HF downloader will populate and with nonroot:nonroot permissions up.\nCOPY --chown=nonroot:nonroot downloader/unused.yaml /home/nonroot/main/1/checkpoints/.cache/unused.yaml\n\n#####\n# Download checkpoints if config.yaml has checkpoints.when = "build"\nCOPY --link=true config.yaml /home/nonroot/main/\nRUN ["python", "-m", "clarifai.cli", "model", "download-checkpoints", "/home/nonroot/main", "--out_path", "/home/nonroot/main/1/checkpoints", "--stage", "build"]\n#####\n\n# Copy in the actual files like config.yaml, requirements.txt, and most importantly 1/model.py\n# for the actual model.\n# If checkpoints aren\'t downloaded since a checkpoints: block is not provided, then they will\n# be in the build context and copied here as well.\nCOPY --link=true 1 /home/nonroot/main/1\n# At this point we only need these for validation in the SDK.\nCOPY --link=true requirements.txt config.yaml /home/nonroot/main/\n\n# Add the model directory to the python path.\nENV PYTHONPATH=${PYTHONPATH}:/home/nonroot/main \\\n    CLARIFAI_PAT=${CLARIFAI_PAT} \\\n    CLARIFAI_USER_ID=${CLARIFAI_USER_ID} \\\n    CLARIFAI_RUNNER_ID=${CLARIFAI_RUNNER_ID} \\\n    CLARIFAI_NODEPOOL_ID=${CLARIFAI_NODEPOOL_ID} \\\n    CLARIFAI_COMPUTE_CLUSTER_ID=${CLARIFAI_COMPUTE_CLUSTER_ID} \\\n    CLARIFAI_API_BASE=${CLARIFAI_API_BASE:-https://api.clarifai.com}\n\n# Finally run the clarifai entrypoint to start the runner loop and local runner server.\n# Note(zeiler): we may want to make this a clarifai CLI call.\nENTRYPOINT ["python", "-m", "clarifai.runners.server"]\nCMD ["--model_path", "/home/nonroot/main"]\n#############################\n',_={description:"Build and import models, including from external sources like Hugging Face",toc_min_heading_level:2,toc_max_heading_level:5},b="Build and Upload Models",j={},w=[{value:"Step 1: Perform Prerequisites",id:"step-1-perform-prerequisites",level:2},{value:"Sign Up or Log In",id:"sign-up-or-log-in",level:3},{value:"Install Clarifai Package",id:"install-clarifai-package",level:3},{value:"Set Up Cluster and Nodepool",id:"set-up-cluster-and-nodepool",level:3},{value:"Set Up Docker or a Virtual Environment",id:"set-up-docker-or-a-virtual-environment",level:3},{value:"Create Project Directory",id:"create-project-directory",level:3},{value:"Step 2: Build a Model",id:"step-2-build-a-model",level:2},{value:"Prepare <code>model.py</code>",id:"prepare-modelpy",level:3},{value:"a. <code>load_model</code> Method",id:"a-load_model-method",level:4},{value:"b. Prediction Methods",id:"b-prediction-methods",level:4},{value:"Prepare <code>config.yaml</code>",id:"prepare-configyaml",level:3},{value:"Model Info",id:"model-info",level:4},{value:"Build Info",id:"build-info",level:4},{value:"Compute Resources",id:"compute-resources",level:4},{value:"Hugging Face Model Checkpoints",id:"hugging-face-model-checkpoints",level:4},{value:"Model Concepts or Labels",id:"model-concepts-or-labels",level:4},{value:"Prepare <code>requirements.txt</code>",id:"prepare-requirementstxt",level:3},{value:"Step 3: Test the Model Locally",id:"step-3-test-the-model-locally",level:2},{value:"Step 4: Upload the Model to Clarifai",id:"step-4-upload-the-model-to-clarifai",level:2},{value:"Step 5: Deploy the Model",id:"step-5-deploy-the-model",level:2},{value:"Step 6: Predict With Model",id:"step-6-predict-with-model",level:2},{value:"Unary-Unary Predict Call",id:"unary-unary-predict-call",level:3},{value:"Unary-Stream Predict Call",id:"unary-stream-predict-call",level:3},{value:"Additional Examples",id:"additional-examples",level:2}];function v(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components},{Details:i}=n;return i||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"build-and-upload-models",children:"Build and Upload Models"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Build and import models, including from sources like Hugging Face"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsx)("div",{style:{position:"relative",width:"100%",overflow:"hidden","padding-top":"56.25%"},children:(0,a.jsx)("iframe",{width:"900",height:"500",style:{position:"absolute",top:"0",left:"0",bottom:"0",right:"0",width:"100%",height:"100%"},src:"https://www.youtube.com/embed/SpIDmDtf7UE",title:"Upload Custom Models to Clarifai Platform Using Python SDK",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowfullscreen:!0})}),"\n",(0,a.jsx)("br",{}),"\n",(0,a.jsx)("br",{}),"\n",(0,a.jsx)(n.p,{children:"The Clarifai Python SDK allows you to upload custom models easily. Whether you're working with a pre-trained model from an external source like Hugging Face, or one you've built from scratch, Clarifai allows seamless integration of your models, enabling you to take advantage of the platform\u2019s powerful capabilities."}),"\n",(0,a.jsx)(n.p,{children:"Once imported to our platform, your model can be utilized alongside Clarifai's vast suite of AI tools. It will be automatically deployed and ready to be evaluated, combined with other models and agent operators in a workflow, or used to serve inference requests as it is."}),"\n",(0,a.jsxs)(n.p,{children:["Let\u2019s walk through how to build and upload a custom model to the Clarifai platform. This example model appends the phrase ",(0,a.jsx)(n.code,{children:"Hello World"})," to any input text and also supports streaming responses."]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Explore ",(0,a.jsx)(n.a,{href:"https://github.com/Clarifai/runners-examples",children:"this repository"})," for examples on uploading different model types."]}),"\n",(0,a.jsxs)(n.li,{children:["Uploading models to the Clarifai platform requires a ",(0,a.jsx)(n.a,{href:"https://www.clarifai.com/pricing",children:"paid plan"}),"."]}),"\n"]})}),"\n","\n","\n","\n","\n","\n",(0,a.jsx)(n.h2,{id:"step-1-perform-prerequisites",children:"Step 1: Perform Prerequisites"}),"\n",(0,a.jsx)(n.h3,{id:"sign-up-or-log-in",children:"Sign Up or Log In"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://clarifai.com/login",children:"Log in to"})," your existing Clarifai account, or ",(0,a.jsx)(n.a,{href:"https://clarifai.com/signup",children:"sign up"})," for a new one. If you're creating a new account, a default application will be provided for you."]}),"\n",(0,a.jsx)(n.p,{children:"Next, retrieve the following credentials:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"App ID"})," \u2013 Go to your application\u2019s page and select the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/create/applications/manage#app-overview",children:(0,a.jsx)(n.strong,{children:"Overview"})})," option in the collapsible left sidebar. Get the app ID from there."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"User ID"})," \u2013 In the collapsible left sidebar, select ",(0,a.jsx)(n.strong,{children:"Settings"})," and choose ",(0,a.jsx)(n.strong,{children:"Account"})," from the dropdown list. Then, locate your user ID."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Personal Access Token (PAT)"})," \u2013 From the same ",(0,a.jsx)(n.strong,{children:"Settings"})," option, choose ",(0,a.jsx)(n.strong,{children:"Secrets"})," to generate or copy your ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/control/authentication/pat",children:"PAT"}),". This token is used to authenticate your connection with the Clarifai platform."]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["You need to set the ",(0,a.jsx)(n.code,{children:"CLARIFAI_PAT"})," you've retrieved as an environment variable to enhance its security."]}),"\n",(0,a.jsxs)(t.A,{groupId:"code",children:[(0,a.jsx)(r.A,{value:"bash",label:"Unix-Like Systems",children:(0,a.jsx)(s.A,{className:"language-bash",children:" export CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE "})}),(0,a.jsx)(r.A,{value:"bash2",label:"Windows",children:(0,a.jsx)(s.A,{className:"language-bash",children:" set CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE "})})]}),"\n",(0,a.jsx)(n.h3,{id:"install-clarifai-package",children:"Install Clarifai Package"}),"\n",(0,a.jsxs)(n.p,{children:["Install the latest version of the ",(0,a.jsx)(n.code,{children:"clarifai"})," Python package. This will also install the Clarifai ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/cli/",children:"Command Line Interface"})," (CLI), which we'll use for testing and uploading the model."]}),"\n",(0,a.jsx)(t.A,{groupId:"code",children:(0,a.jsx)(r.A,{value:"bash",label:"Bash",children:(0,a.jsx)(s.A,{className:"language-bash",children:" pip install --upgrade clarifai "})})}),"\n",(0,a.jsx)(n.h3,{id:"set-up-cluster-and-nodepool",children:"Set Up Cluster and Nodepool"}),"\n",(0,a.jsxs)(n.p,{children:["To run reliably and efficiently, your model requires a dedicated compute environment consisting of a ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/deployments/clusters-nodepools/",children:"cluster and a nodepool"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"Once your model is uploaded to the Clarifai platform, you need to deploy it to an existing compute environment."}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," A cluster is the foundation of your compute environment, while a nodepool is a single compute node or a group of nodes within a cluster that provides the resources your model requires."]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["You can follow ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/getting-started/set-up-compute",children:"this guide"})," to set up your compute environment fast."]}),"\n",(0,a.jsx)(n.h3,{id:"set-up-docker-or-a-virtual-environment",children:"Set Up Docker or a Virtual Environment"}),"\n",(0,a.jsx)(n.p,{children:"To test, run, and upload your model, you need to set up either a Docker container or a Python virtual environment. This ensures proper dependency management and prevents conflicts in your project."}),"\n",(0,a.jsxs)(n.p,{children:["Both options allow you to work with different Python versions. For example, you can use Python 3.11 for uploading one model and Python 3.12 for another \u2014 configured via the ",(0,a.jsx)(n.a,{href:"#build-info",children:(0,a.jsx)(n.code,{children:"config.yaml"})})," file."]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsx)(n.p,{children:"If Docker is installed on your system, it is highly recommended to use it for running the model. Docker provides better isolation and a fully portable environment, including for Python and system libraries."}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["You should ensure your local environment has sufficient memory and compute resources to handle model loading and execution, especially during ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/sdk/compute-orchestration/test-models-locally",children:"testing"}),"."]}),"\n",(0,a.jsx)(n.h3,{id:"create-project-directory",children:"Create Project Directory"}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:["You can automatically generate the required files by running the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/resources/api-overview/cli#clarifai-model-init",children:(0,a.jsx)(n.code,{children:"clarifai model init"})})," command in the terminal from your current directory. After the files are created, you can modify them as needed."]})}),"\n",(0,a.jsx)(n.p,{children:"Create a project directory and organize your files as indicated below to fit the requirements of uploading models to the Clarifai platform."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"your_model_directory/\n\u251c\u2500\u2500 1/\n\u2502   \u2514\u2500\u2500 model.py\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 config.yaml\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"your_model_directory/"})," \u2013 The root directory containing all files related to your custom model.","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"1/"})," \u2013 A subdirectory that holds the model file (",(0,a.jsxs)(n.em,{children:["Note that the folder is named as ",(0,a.jsx)(n.strong,{children:"1"})]}),").","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"model.py"})," \u2013 Contains the code that defines your model, including loading the model and running inference."]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"requirements.txt"})," \u2013 Lists the Python dependencies required to run your model."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"config.yaml"})," \u2013 Contains model metadata and configuration details necessary for building the model, defining compute resources, and more."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"step-2-build-a-model",children:"Step 2: Build a Model"}),"\n",(0,a.jsx)(n.p,{children:"Let's talk about the general steps you'd follow to upload any type of model to the Clarifai platform."}),"\n",(0,a.jsxs)(n.h3,{id:"prepare-modelpy",children:["Prepare ",(0,a.jsx)(n.code,{children:"model.py"})]}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"model.py"})," file contains the core logic for your model, including how the model is loaded and how predictions are made. This file must define a custom class that inherits from ",(0,a.jsx)(n.code,{children:"ModelClass"})," and implements the required methods."]}),"\n",(0,a.jsxs)(n.p,{children:["This is the ",(0,a.jsx)(n.code,{children:"model.py"})," file for the custom model we want to upload:"]}),"\n",(0,a.jsx)(t.A,{groupId:"code",children:(0,a.jsx)(r.A,{value:"python",label:"Python",children:(0,a.jsx)(s.A,{className:"language-python",children:d})})}),"\n",(0,a.jsx)(n.p,{children:"Let\u2019s break down what each part of the file does."}),"\n",(0,a.jsxs)(n.h4,{id:"a-load_model-method",children:["a. ",(0,a.jsx)(n.code,{children:"load_model"})," Method"]}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"load_model"})," method is optional but recommended, as it prepares the model for inference by handling resource-heavy initializations. It is particularly useful for:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"One-time setup of heavy resources, such as loading trained models or initializing data transformations."}),"\n",(0,a.jsx)(n.li,{children:"Executing tasks during model container startup to reduce runtime latency."}),"\n",(0,a.jsx)(n.li,{children:"Loading essential components like tokenizers, pipelines, and other model-related assets."}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Here is an example:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'def load_model(self):\n  self.tokenizer = AutoTokenizer.from_pretrained("model/")\n  self.pipeline = transformers.pipeline(...)\n'})}),"\n",(0,a.jsx)(n.h4,{id:"b-prediction-methods",children:"b. Prediction Methods"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"model.py"})," file must include at least one method decorated with ",(0,a.jsx)(n.code,{children:"@ModelClass.method"})," to define the prediction endpoints."]}),"\n",(0,a.jsxs)(n.p,{children:["In the example model we want to upload, we defined a method that appends the phrase ",(0,a.jsx)(n.code,{children:"Hello World"})," to any input text and added support for different types of ",(0,a.jsx)(n.a,{href:"#step-6-predict-with-model",children:"streaming responses"}),"."]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," The structure of prediction methods on the client side directly mirrors the method signatures defined in your ",(0,a.jsx)(n.code,{children:"model.py"})," file. This one-to-one mapping provides flexibility in defining prediction methods with varying names and arguments."]}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsx)(n.p,{children:"Here are some examples of method mapping:"}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsxs)(n.th,{children:[(0,a.jsx)(n.code,{children:"model.py"})," Model Implementation"]}),(0,a.jsx)(n.th,{children:"Client-Side Usage Pattern"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"@ModelClass.method def predict(...)"})}),(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"model.predict(...)"})})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"@ModelClass.method def generate(...)"})}),(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"model.generate(...)"})})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"@ModelClass.method def stream(...)"})}),(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:"model.stream(...)"})})]})]})]}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:["You can learn more about the structure of prediction methods ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/models/inference/#structure-of-prediction-methods",children:"here"}),"."]}),"\n"]}),"\n",(0,a.jsxs)(n.admonition,{type:"warning",children:[(0,a.jsx)(n.mdxAdmonitionTitle,{children:(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/models/model-upload/data-types/",children:"Supported Input and Output Data Types"})}),(0,a.jsxs)(n.p,{children:["Each parameter in the class methods must be annotated with a type, and the return type must also be specified. Clarifai's model framework supports rich data typing for both inputs and outputs. Supported types include ",(0,a.jsx)(n.code,{children:"Text"}),", ",(0,a.jsx)(n.code,{children:"Image"}),", ",(0,a.jsx)(n.code,{children:"Audio"}),", ",(0,a.jsx)(n.code,{children:"Video"}),", and more."]})]}),"\n",(0,a.jsxs)(n.h3,{id:"prepare-configyaml",children:["Prepare ",(0,a.jsx)(n.code,{children:"config.yaml"})]}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"config.yaml"})," file is essential for specifying the model\u2019s metadata, compute resource requirements, and model checkpoints."]}),"\n",(0,a.jsxs)(n.p,{children:["This is the ",(0,a.jsx)(n.code,{children:"config.yaml"})," file for the custom model we want to upload:"]}),"\n",(0,a.jsx)(t.A,{groupId:"code",children:(0,a.jsx)(r.A,{value:"yaml",label:"YAML",children:(0,a.jsx)(s.A,{className:"language-yaml",children:c})})}),"\n",(0,a.jsx)(n.p,{children:"Let\u2019s break down what each part of the file does."}),"\n",(0,a.jsx)(n.h4,{id:"model-info",children:"Model Info"}),"\n",(0,a.jsxs)(n.p,{children:["This section defines your unique model ID (any arbitrary name you choose), along with the Clarifai user ID and app ID you retrieved ",(0,a.jsx)(n.a,{href:"#sign-up-or-log-in",children:"earlier"}),". These values will determine where the model is uploaded on the Clarifai platform."]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," If you reference an app that doesn\u2019t exist, the CLI will prompt you to create it during the ",(0,a.jsx)(n.a,{href:"#step-4-upload-the-model-to-clarifai",children:"model upload"})," process."]}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"build-info",children:"Build Info"}),"\n",(0,a.jsxs)(n.p,{children:["This section specifies details about the environment used to build or run the model. You can include the ",(0,a.jsx)(n.code,{children:"python_version"}),", which is useful for ensuring compatibility between the model and its runtime environment, as different Python versions may have varying dependencies, library support, and performance characteristics."]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," We currently support Python 3.11 and Python 3.12 (default)."]}),"\n"]}),"\n",(0,a.jsxs)(n.admonition,{title:"multi-architecture support",type:"info",children:[(0,a.jsxs)(n.p,{children:["By default, model images are built for the ",(0,a.jsx)(n.strong,{children:"linux/amd64"})," architecture. If needed, you can provide a comma-separated list of additional target platforms to build a multi-architecture image."]}),(0,a.jsxs)(n.p,{children:["Enabling multi-architecture builds allows the system to route requests to model-serving ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/deployments/clusters-nodepools",children:"nodepools"})," running on different hardware architectures (such as x86 or Arm)."]}),(0,a.jsx)(n.p,{children:"During deployment configuration and request routing, the system automatically validates which node instance types are compatible with the model\u2019s supported platforms."}),(0,a.jsx)(n.p,{children:"This unified build process enhances cost efficiency and hardware flexibility. For example, you can build a single model version that works across multiple architectures, eliminating the need to maintain and manage separate model versions for each hardware type."})]}),"\n",(0,a.jsx)(n.h4,{id:"compute-resources",children:"Compute Resources"}),"\n",(0,a.jsx)(n.p,{children:"To deploy your model on Clarifai\u2019s dedicated compute, you must define the minimum compute resources required for running it, including CPU, memory, and optional GPU specifications."}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," For ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/local-runners/",children:"local execution"}),", the ",(0,a.jsx)(n.code,{children:"inference_compute_info"})," section is optional \u2014 the model runs entirely on your machine using local CPU/GPU resources."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"These are some parameters you can define:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"cpu_limit"})})," \u2013 Number of CPUs allocated for the model (follows ",(0,a.jsx)(n.a,{href:"https://kubernetes.io/docs/reference/kubernetes-api/common-definitions/quantity/",children:"Kubernetes notation"}),', e.g., "1", "2").']}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"cpu_requests"})})," (default: ",(0,a.jsx)(n.code,{children:"500m"}),' (500 millicores)) \u2013 Specifies the minimum amount of CPU resources to request. Follows Kubernetes notation (e.g., "100m", "1", "4.5"), where 1 equals one full CPU core.']}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"cpu_memory"})}),' \u2013 Minimum memory required for the CPU (uses Kubernetes notation, e.g., "1Gi", "1500Mi", "3Gi").']}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"cpu_memory_requests"})})," (default: ",(0,a.jsx)(n.code,{children:"500Mi"})," (500 mebibytes)) \u2013 Specifies the minimum amount of memory to request for the CPU. Also follows Kubernetes notation, such as 1Ki (1 kibibyte), 1500Mi (1500 mebibytes), 3Gi(3 gibibytes), and 4Ti (4 tebibytes)."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"num_accelerators"})})," \u2013 Number of GPUs or TPUs to use for inference."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"accelerator_type"})})," \u2013 Specifies the type of hardware ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/deployments/cloud-instances/",children:"accelerators"}),' (e.g., GPU or TPU) supported by the model (e.g., "NVIDIA-A10G"). ',(0,a.jsxs)(n.em,{children:["Note that instead of specifying an exact accelerator type, you can use a wildcard ",(0,a.jsx)(n.code,{children:"(*)"})," to automatically match all available accelerators that fit your use case. For example, using ",(0,a.jsx)(n.code,{children:'["NVIDIA-*"]'})," will enable the system to choose from all NVIDIA options compatible with your model."]})]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"accelerator_memory"})})," \u2013 Minimum memory required for the GPU or TPU."]}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"hugging-face-model-checkpoints",children:"Hugging Face Model Checkpoints"}),"\n",(0,a.jsx)(n.p,{children:"If you're using a model from Hugging Face, you can automatically download its checkpoints by specifying the appropriate configuration in this section."}),"\n",(0,a.jsxs)(n.p,{children:["For private or restricted Hugging Face repositories, make sure to include an access token. Learn how to generate one ",(0,a.jsx)(n.a,{href:"https://huggingface.co/docs/hub/en/security-tokens",children:"here"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["See the ",(0,a.jsx)(n.a,{href:"#additional-examples",children:"additional examples"})," below for how to define Hugging Face checkpoints."]}),"\n",(0,a.jsx)(t.A,{groupId:"code",children:(0,a.jsx)(r.A,{value:"yaml",label:"YAML",children:(0,a.jsx)(s.A,{className:"language-yaml",children:h})})}),"\n",(0,a.jsxs)(n.admonition,{type:"note",children:[(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"when"})," parameter in the ",(0,a.jsx)(n.code,{children:"checkpoints"})," section determines when model checkpoints should be downloaded and stored. It must be set to one of the following options:"]}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"runtime"})," (",(0,a.jsx)(n.em,{children:"default"}),") \u2013 Downloads checkpoints when loading the model in the ",(0,a.jsx)(n.code,{children:"load_model"})," method."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"build"})," \u2013 Downloads checkpoints during the image build process."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"upload"})," \u2013 Downloads checkpoints before uploading the model."]}),"\n"]}),(0,a.jsxs)(n.p,{children:["For larger models, we highly recommend downloading checkpoints at ",(0,a.jsx)(n.code,{children:"runtime"}),". Doing so prevents unnecessary increases in Docker image size, which has some advantages:"]}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Smaller image sizes"}),"\n",(0,a.jsx)(n.li,{children:"Faster build times"}),"\n",(0,a.jsx)(n.li,{children:"Quicker uploads and inference on the Clarifai platform"}),"\n"]}),(0,a.jsxs)(n.p,{children:["Downloading checkpoints at ",(0,a.jsx)(n.code,{children:"build"})," or ",(0,a.jsx)(n.code,{children:"upload"})," time can significantly increase image size, resulting in longer upload times and increased cold start latency."]})]}),"\n",(0,a.jsx)(n.h4,{id:"model-concepts-or-labels",children:"Model Concepts or Labels"}),"\n",(0,a.jsxs)(n.p,{children:["This section is required if your model outputs concepts or labels and is not being directly loaded from Hugging Face. So, you must define a ",(0,a.jsx)(n.code,{children:"concepts"})," section in the ",(0,a.jsx)(n.code,{children:"config.yaml"})," file."]}),"\n",(0,a.jsx)(n.p,{children:"The following model types output concepts or labels:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"visual-classifier"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"visual-detector"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"visual-segmenter"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"text-classifier"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.code,{children:"visual-keypointer"})}),"\n"]}),"\n",(0,a.jsx)(t.A,{groupId:"code",children:(0,a.jsx)(r.A,{value:"yaml",label:"YAML",children:(0,a.jsx)(s.A,{className:"language-yaml",children:u})})}),"\n",(0,a.jsxs)(n.admonition,{type:"note",children:[(0,a.jsx)(n.mdxAdmonitionTitle,{}),(0,a.jsxs)(n.p,{children:["If you're using a model from Hugging Face and the ",(0,a.jsx)(n.code,{children:"checkpoints"})," section is defined, the Clarifai platform will automatically infer concepts. In this case, you don\u2019t need to manually specify them."]})]}),"\n",(0,a.jsxs)(n.h3,{id:"prepare-requirementstxt",children:["Prepare ",(0,a.jsx)(n.code,{children:"requirements.txt"})]}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"requirements.txt"})," file lists all the Python dependencies your model needs."]}),"\n",(0,a.jsxs)(n.p,{children:["This is the ",(0,a.jsx)(n.code,{children:"requirements.txt"})," file for the custom model we want to upload:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"clarifai>=11.8.2\n"})}),"\n",(0,a.jsx)(n.p,{children:"If your model requires Torch, we provide optimized pre-built Torch images as the base for machine learning and inference tasks."}),"\n",(0,a.jsx)(n.p,{children:"These images include all necessary dependencies, ensuring efficient execution. The available pre-built Torch images are:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"2.4.1-py3.11-cuda124"})," \u2014 Based on PyTorch 2.4.1, Python 3.11, and CUDA 12.4."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"2.5.1-py3.11-cuda124"})," \u2014 Based on PyTorch 2.5.1, Python 3.11, and CUDA 12.4."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"2.4.1-py3.12-cuda124"})," \u2014 Based on PyTorch 2.4.1, Python 3.12, and CUDA 12.4."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"2.5.1-py3.12-cuda124"})," \u2014 Based on PyTorch 2.5.1, Python 3.12, and CUDA 12.4."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"To use a specific Torch version, define it in your requirements.txt file like this:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"torch==2.5.1\n"})}),"\n",(0,a.jsx)(n.p,{children:"This ensures the correct pre-built image is pulled from Clarifai's container registry, ensuring the correct environment is used. This minimizes cold start times and speeds up model uploads and runtime execution \u2014 avoiding the overhead of building images from scratch or pulling and configuring them from external sources."}),"\n",(0,a.jsxs)(n.p,{children:["We recommend using either ",(0,a.jsx)(n.code,{children:"torch==2.5.1"})," or ",(0,a.jsx)(n.code,{children:"torch==2.4.1"}),". If your model requires a different Torch version, you can specify it in requirements.txt, but this may slightly increase the model upload time."]}),"\n",(0,a.jsx)(n.h2,{id:"step-3-test-the-model-locally",children:"Step 3: Test the Model Locally"}),"\n",(0,a.jsx)(n.p,{children:"Before uploading your model to the Clarifai platform, it's important to test it locally to catch any typos or misconfigurations in the code."}),"\n",(0,a.jsxs)(n.p,{children:["Learn how to  run and test your models locally ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/upload/test-locally",children:"here"}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"step-4-upload-the-model-to-clarifai",children:"Step 4: Upload the Model to Clarifai"}),"\n",(0,a.jsx)(n.p,{children:"Once your model is ready, you can upload it to the platform using Clarifai CLI."}),"\n",(0,a.jsx)(n.p,{children:"To upload your model, run the following command in your terminal:"}),"\n",(0,a.jsx)(t.A,{groupId:"code",children:(0,a.jsx)(r.A,{value:"bash",label:"Bash",children:(0,a.jsx)(s.A,{className:"language-bash",children:" clarifai model upload ./your/model/path/here "})})}),"\n",(0,a.jsx)(n.p,{children:"Alternatively, navigate to the directory containing your custom model and run the command without specifying the directory path:"}),"\n",(0,a.jsx)(t.A,{groupId:"code",children:(0,a.jsx)(r.A,{value:"bash",label:"Bash",children:(0,a.jsx)(s.A,{className:"language-bash",children:" clarifai model upload "})})}),"\n",(0,a.jsx)(n.p,{children:"This command builds the model\u2019s Docker image using the defined compute resources and uploads it to Clarifai, where it can be served in production.\nThe build logs will be displayed in your terminal, which helps you troubleshoot any upload issues."}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note"}),": If you make any changes to your model and upload it again to the Clarifai platform, a new version of the model will be created automatically."]}),"\n"]}),"\n",(0,a.jsx)("a",{id:"skip-dockerfile"}),"\n",(0,a.jsxs)(n.admonition,{title:"Skip Dockerfile",type:"note",children:[(0,a.jsxs)(n.p,{children:["By default, when you upload a model, the CLI automatically generates a ",(0,a.jsx)(n.code,{children:"Dockerfile"})," in the root of your model directory. This ensures your model can be built and deployed with the correct environment."]}),(0,a.jsxs)(n.p,{children:["In some cases, though, you may prefer to provide your own custom ",(0,a.jsx)(n.a,{href:"https://docs.docker.com/reference/dockerfile/",children:"Dockerfile"}),", such as when a specific base image is required for model inference."]}),(0,a.jsxs)(n.p,{children:["To do this, use the ",(0,a.jsx)(n.code,{children:"--skip_dockerfile"})," flag. This tells the CLI to skip automatic Dockerfile generation and instead rely on the one you\u2019ve created."]}),(0,a.jsx)(t.A,{groupId:"code",children:(0,a.jsx)(r.A,{value:"bash",label:"Bash",children:(0,a.jsx)(s.A,{className:"language-bash",children:"clarifai model upload --skip_dockerfile"})})}),(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Automatically Generated Dockerfile Example"}),(0,a.jsx)(s.A,{className:"language-dockerfile",children:y})]})]}),"\n",(0,a.jsx)(n.h2,{id:"step-5-deploy-the-model",children:"Step 5: Deploy the Model"}),"\n",(0,a.jsx)(n.p,{children:"After your model is successfully uploaded to the Clarifai platform, the terminal will walk you through the deployment process to prepare it for inference."}),"\n",(0,a.jsx)(n.p,{children:"Follow the on-screen prompts to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"Choose an existing cluster and nodepool where your model will run."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Specify the deployment configuration, including defining the minimum and maximum number of ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/deployments/deploy-model#model-replica",children:"replicas"})," to control scalability. Take note of the generated ",(0,a.jsx)(n.code,{children:"deployment_id"}),"."]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," After completing the setup, you can backtrack to adjust these settings or clean up resources later if needed."]}),"\n"]}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Build Logs Example"}),(0,a.jsx)(s.A,{className:"language-text",children:p})]}),"\n",(0,a.jsx)(n.h2,{id:"step-6-predict-with-model",children:"Step 6: Predict With Model"}),"\n",(0,a.jsxs)(n.p,{children:["Once the model is successfully deployed, you can generate predictions either programmatically or through the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/getting-started/quickstart-playground",children:"UI Playground"}),"."]}),"\n",(0,a.jsx)(n.h3,{id:"unary-unary-predict-call",children:"Unary-Unary Predict Call"}),"\n",(0,a.jsxs)(n.p,{children:["You can make a ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/models/inference/api/#unary-unary-predict-call",children:"unary-unary"})," predict call using the model."]}),"\n",(0,a.jsx)(t.A,{groupId:"code",children:(0,a.jsx)(r.A,{value:"python",label:"Python",children:(0,a.jsx)(s.A,{className:"language-python",children:m})})}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Example Output"}),(0,a.jsx)(s.A,{className:"language-text",children:g})]}),"\n",(0,a.jsx)(n.h3,{id:"unary-stream-predict-call",children:"Unary-Stream Predict Call"}),"\n",(0,a.jsxs)(n.p,{children:["You can make a ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/models/inference/api/#unary-stream-predict-call",children:"unary-stream"})," predict call using the model."]}),"\n",(0,a.jsx)(t.A,{groupId:"code",children:(0,a.jsx)(r.A,{value:"python",label:"Python",children:(0,a.jsx)(s.A,{className:"language-python",children:f})})}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Example Output"}),(0,a.jsx)(s.A,{className:"language-text",children:x})]}),"\n",(0,a.jsx)(n.h2,{id:"additional-examples",children:"Additional Examples"}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:["You can find various up-to-date model upload examples ",(0,a.jsx)(n.a,{href:"https://github.com/Clarifai/runners-examples",children:"here"}),", which demonstrate different use cases and optimizations.\nHere is an example of how to ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/resources/api-overview/cli#initialize-with-github-template",children:"download"})," a model: ",(0,a.jsx)(n.code,{children:"clarifai model init --github-url https://github.com/Clarifai/runners-examples/tree/main/local-runners/ollama-model-upload"}),"."]})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"https://github.com/Clarifai/runners-examples/tree/main/llm/vllm-gemma-3-1b-it",children:"An OpenAI-compatible model"})," built with Clarifai\u2019s ",(0,a.jsx)(n.code,{children:"OpenAIModelClass"})]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"https://github.com/Clarifai/runners-examples/tree/main/llm/hf-llama-3_2-1b-instruct",children:"A Llama-3.2-1B-Instruct model"})," built with Clarifai\u2019s ",(0,a.jsx)(n.code,{children:"ModelClass"})]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"https://github.com/Clarifai/runners-examples/tree/main/image-classifier/nsfw-image-classifier",children:"An NSFW Image Classifier model"})," built with Clarifai\u2019s ",(0,a.jsx)(n.code,{children:"VisualClassifierClass"})]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"https://github.com/Clarifai/runners-examples/tree/main/image-detector/detr-resnet-image-detection",children:"A DETR ResNet Image Detector model"})," built with Clarifai\u2019s ",(0,a.jsx)(n.code,{children:"VisualDetectorClass"})]}),"\n",(0,a.jsxs)(n.li,{children:["Sandboxed execution with ",(0,a.jsx)(n.a,{href:"https://www.daytona.io/",children:"Daytona"})," and Clarifai","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"https://www.youtube.com/watch?v=S9pMcLzqbgo",children:"A YouTube video"})," on how to upload and run a custom model on Clarifai, start a local runner, and execute the model within a Daytona Sandbox. The model\u2019s repository is ",(0,a.jsx)(n.a,{href:"https://github.com/Clarifai/runners-examples/tree/daytona-code-generator-model/code-generation/daytona-code-generator",children:"here"}),"."]}),"\n"]}),"\n"]}),"\n"]})]})}function k(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(v,{...e})}):v(e)}}}]);