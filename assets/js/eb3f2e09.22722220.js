"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[4783],{82926:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>P,contentTitle:()=>D,default:()=>M,frontMatter:()=>w,metadata:()=>T,toc:()=>j});var i=t(74848),o=t(28453),a=t(11470),s=t(19365),r=t(21432);const l='from clarifai.client.model import Model\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\n# Specify the correct user_id/app_id pairings\n# Since you\'re making inferences outside your app\'s scope\n#USER_ID = "nlptownres"\n#APP_ID = "text-classification"\n\n# Text sentiment analysis with 3 classes positive, negative, neutral.\n# You can set the model using model URL or model ID.\n# Change these to whatever model you want to use\n# eg : MODEL_ID = \'sentiment-analysis-twitter-roberta-base\'\n# You can also set a particular model version by specifying the  version ID\n# eg: MODEL_VERSION_ID = \'aa7f35c01e0642fda5cf400f543e7c40\'\n#  Model class objects can be inititalised by providing its URL or also by defining respective user_id, app_id and model_id\n\n\n# eg : model = Model(user_id="clarifai", app_id="main", model_id=MODEL_ID)\n\nmodel_url = "https://clarifai.com/erfan/text-classification/models/sentiment-analysis-twitter-roberta-base"\n\n# The predict API gives flexibility to generate predictions for data provided through URL,Filepath and bytes format.\n\n\n# Example for prediction through Bytes:\n# model_prediction = model.predict_by_bytes(input_bytes, input_type="text")\n\n\n# Example for prediction through URL:\n# model_prediction = Model(model_url).predict_by_url(URL, input_type="text")\n\n\nfile_path = "datasets/upload/data/text_files/positive/0_9.txt"\nmodel_prediction = Model(url=model_url, pat="YOUR_PAT").predict_by_filepath(\n    file_path, input_type="text"\n)\n\n# Get the output\nfor concept in model_prediction.outputs[0].data.concepts:\n    print(f"concept: {concept.name:<20} confidence: {round(concept.value, 3)}")\n',d='import { Model } from "clarifai-nodejs";\nimport path from "path";\n\n/**\n    Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    Specify the correct userId/appId pairings\n    Since you\'re making inferences outside your app\'s scope\n    USER_ID = "nlptownres"\n    APP_ID = "text-classification"\n\n    You can set the model using model URL or model ID.\n    Change these to whatever model you want to use\n    eg : MODEL_ID = "sentiment-analysis-twitter-roberta-base"\n    You can also set a particular model version by specifying the  version ID\n    eg: MODEL_VERSION_ID = "aa7f35c01e0642fda5cf400f543e7c40"\n    Model class objects can be initialised by providing its URL or also by defining respective userId, appId and modelId\n\n    eg : \n    const model = new Model({\n        authConfig: {\n            userId: "clarifai",\n            appId: "main",\n            pat: process.env.CLARIFAI_PAT,\n        },\n        modelId: MODEL_ID,\n    });\n\n*/\n\nconst modelUrl =\n  "https://clarifai.com/erfan/text-classification/models/sentiment-analysis-twitter-roberta-base";\n\n/**\n        The predict API gives flexibility to generate predictions for data provided through URL, Filepath and bytes format.\n\n\n        Example for prediction through Bytes:\n        const modelPrediction = await model.predictByBytes({\n                                    inputBytes,\n                                    inputType\n                                });\n\n\n        Example for prediction through Filepath:\n        const modelPrediction = await model.predictByFilepath({\n                                    filepath, \n                                    inputType\n                                });\n    */\n\nconst filepath = path.resolve(__dirname, "../../../assets/sample.txt");\n\nconst model = new Model({\n  url: modelUrl,\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n  },\n});\nconst modelPrediction = await model.predictByFilepath({\n  filepath,\n  inputType: "text",\n});\n\n// Get the output\nconsole.log(\n  modelPrediction?.[modelPrediction.length - 1]?.data?.conceptsList,\n);',c='from clarifai.client.model import Model\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nprompt = "What\u2019s the future of AI?"\n# You can set the model using model URL or model ID.\nmodel_url="https://clarifai.com/openai/chat-completion/models/GPT-4"\n\n\n# Model Predict\nmodel_prediction = Model(url=model_url,pat="YOUR_PAT").predict_by_bytes(prompt.encode(), input_type="text")\n\nprint(model_prediction.outputs[0].data.text.raw)',p='import { Model } from "clarifai-nodejs";\n\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\nconst prompt = "What\u2019s the future of AI?";\n// You can set the model using model URL or model ID.\nconst modelUrl = "https://clarifai.com/openai/chat-completion/models/GPT-4";\n\n// Model Predict\nconst model = new Model({\n  url: modelUrl,\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n  },\n});\n\n\nconst modelPrediction = await model.predictByBytes({\n  inputBytes: Buffer.from(prompt),\n  inputType: "text",\n});\n\nconsole.log(modelPrediction?.[0]?.data?.text?.raw);\n',u='from clarifai.client.model import Model\n\nprompt = """Classes: [`positive`, `negative`, `neutral`]\nText: Sunny weather makes me happy.\n\nClassify the text into one of the above classes."""\n\n\n\n# Model Predict\nmodel_prediction = Model("https://clarifai.com/openai/chat-completion/models/GPT-4").predict_by_bytes(prompt.encode(), input_type="text")\n\nprint(model_prediction.outputs[0].data.text.raw)',m="import { Model } from \"clarifai-nodejs\";\n\nconst prompt = `Classes: ['positive', 'negative', 'neutral']\nText: Sunny weather makes me happy.\n\nClassify the text into one of the above classes.`;\n\n// Model Predict\nconst model = new Model({\n  url: \"https://clarifai.com/openai/chat-completion/models/GPT-4\",\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n  },\n});\n\n\nconst modelPrediction = await model.predictByBytes({\n  inputBytes: Buffer.from(prompt),\n  inputType: \"text\",\n});\n\nconsole.log(modelPrediction?.[0]?.data?.text?.raw);\n",h='from clarifai.client.model import Model\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\n# Specify the correct user_id/app_id pairings\n# Since you\'re making inferences outside your app\'s scope\n#USER_ID = "stability-ai"\n#APP_ID = "stable-diffusion-2"\n\n# You can set the model using model URL or model ID.\n# Change these to whatever model you want to use\n# eg : MODEL_ID = \'stable-diffusion-xl\'\n# You can also set a particular model version by specifying the  version ID\n# eg: MODEL_VERSION_ID = \'0c919cc1edfc455dbc96207753f178d7\'\n#  Model class objects can be inititalised by providing its URL or also by defining respective user_id, app_id and model_id\n\n# eg : model = Model(user_id="clarifai", app_id="main", model_id=MODEL_ID)\n\ninput_text = b"floor plan for 2 bedroom kitchen house"\n\n# The predict API gives flexibility to generate predictions for data provided through URL,Filepath and Bytes format.\n\n\n# Example for prediction through URL:\n# model_prediction = model.predict_by_url(url, input_type="text")\n\n\n# Example for prediction through Filepath:\n# model_prediction = Model(model_url).predict_by_filepath(filepath, input_type="text")\n\n# Image Generation using Stable Diffusion XL\nmodel_url = "https://clarifai.com/stability-ai/stable-diffusion-2/models/stable-diffusion-xl"\n\nmodel_prediction = Model(url=model_url, pat="YOUR_PAT").predict_by_bytes(\n    input_text, input_type="text"\n)\n\n\n# Base64 image to numpy array\nim_b = model_prediction.outputs[0].data.image.base64\nimage_np = np.frombuffer(im_b, np.uint8)\nimg_np = cv2.imdecode(image_np, cv2.IMREAD_COLOR)\n# Display the image\nplt.axis("off")\nplt.imshow(img_np[..., ::-1])\n',f='import { Model } from "clarifai-nodejs";\nimport fs from "fs";\n\n/**\n    Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    Specify the correct userId/appId pairings\n    Since you\'re making inferences outside your app\'s scope\n    USER_ID = "stability-ai"\n    APP_ID = "stable-diffusion-2"\n\n    You can set the model using model URL or model ID.\n    Change these to whatever model you want to use\n    eg : MODEL_ID = "stable-diffusion-xl"\n    You can also set a particular model version by specifying the  version ID\n    eg: MODEL_VERSION_ID = "0c919cc1edfc455dbc96207753f178d7"\n    Model class objects can be initialised by providing its URL or also by defining respective userId, appId and modelId\n\n    eg : \n    const model = new Model({\n        authConfig: {\n            userId: "clarifai",\n            appId: "main",\n            pat: process.env.CLARIFAI_PAT,\n        },\n        modelId: MODEL_ID,\n    });\n\n*/\n\nconst inputText: Buffer = Buffer.from("floor plan for 2 bedroom kitchen house");\n\n/**\n        The predict API gives flexibility to generate predictions for data provided through URL, Filepath and bytes format.\n\n\n        Example for prediction through Bytes:\n        const modelPrediction = await model.predictByBytes({\n                                    inputBytes,\n                                    inputType\n                                });\n\n\n        Example for prediction through Filepath:\n        const modelPrediction = await model.predictByFilepath({\n                                    filepath, \n                                    inputType\n                                });\n    */\n\n// Image Generation using Stable Diffusion XL\nconst modelUrl =\n  "https://clarifai.com/stability-ai/stable-diffusion-2/models/stable-diffusion-xl";\n\n\nconst model = new Model({\n  url: modelUrl,\n  authConfig: { pat: process.env.CLARIFAI_PAT },\n});\n\nconst modelPrediction = await model.predictByBytes({\n  inputBytes: inputText,\n  inputType: "text",\n});\n\n// Base64 image to numpy array\nconst outputBase64 = modelPrediction?.[0]?.data?.image?.base64 ?? "";\n\nfs.writeFileSync("image.png", outputBase64, "base64");\n',g='from clarifai.client.model import Model\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\n# Specify the correct user_id/app_id pairings\n# Since you\'re making inferences outside your app\'s scope\n#USER_ID = "eleven-labs"\n#APP_ID = "audio-generation"\n\n# You can set the model using model URL or model ID.\n# Change these to whatever model you want to use\n# eg : MODEL_ID = \'speech-synthesis\'\n# You can also set a particular model version by specifying the  version ID\n# eg: MODEL_VERSION_ID = \'f588d92c044d4487a38c8f3d7a3b0eb2\'\n#  Model class objects can be inititalised by providing its URL or also by defining respective user_id, app_id and model_id\n\n# eg : model = Model(user_id="clarifai", app_id="main", model_id=MODEL_ID)\n\n\ninput_text = "Hello, How are you doing today!"\n\n# The predict API gives flexibility to generate predictions for data provided through URL,Filepath and bytes format.\n\n\n# Example for prediction through URL:\n# model_prediction = model.predict_by_url(url, input_type="text")\n\n\n# Example for prediction through Filepath:\n# model_prediction = Model(model_url).predict_by_filepath(filepath, input_type="text")\n\nmodel_url = "https://clarifai.com/eleven-labs/audio-generation/models/speech-synthesis"\n\nmodel_prediction = Model(url=model_url, pat="YOUR_PAT").predict_by_bytes(\n    input_text, "text"\n)\n\n# Save the audio file\nwith open("output_audio.wav", mode="bx") as f:\n    f.write(model_prediction.outputs[0].data.audio.base64)\n',y='import { Model } from "clarifai-nodejs";\nimport fs from "fs";\n\n/**\n    Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    Specify the correct userId/appId pairings\n    Since you\'re making inferences outside your app\'s scope\n    USER_ID = "eleven-labs"\n    APP_ID = "audio-generation"\n\n    You can set the model using model URL or model ID.\n    Change these to whatever model you want to use\n    eg : MODEL_ID = \'speech-synthesis\'\n    You can also set a particular model version by specifying the  version ID\n    eg: MODEL_VERSION_ID = "f588d92c044d4487a38c8f3d7a3b0eb2"\n    Model class objects can be initialised by providing its URL or also by defining respective userId, appId and modelId\n\n    eg : \n    const model = new Model({\n        authConfig: {\n            userId: "clarifai",\n            appId: "main",\n            pat: process.env.CLARIFAI_PAT,\n        },\n        modelId: MODEL_ID,\n    });\n\n*/\n\nconst inputText = Buffer.from("Hello, How are you doing today!");\n\n/**\n        The predict API gives flexibility to generate predictions for data provided through URL, Filepath and bytes format.\n\n\n        Example for prediction through Bytes:\n        const modelPrediction = await model.predictByBytes({\n                                    inputBytes,\n                                    inputType\n                                });\n\n\n        Example for prediction through Filepath:\n        const modelPrediction = await model.predictByFilepath({\n                                    filepath, \n                                    inputType\n                                });\n    */\n\nconst modelUrl =\n  "https://clarifai.com/eleven-labs/audio-generation/models/speech-synthesis";\n\n\nconst model = new Model({\n  url: modelUrl,\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n  },\n});\nconst modelPrediction = await model.predictByBytes({\n  inputType: "text",\n  inputBytes: inputText,\n});\n\n// Save the audio file\n// Note: The following code assumes you have the necessary logic to write the audio data to a file in TypeScript.\n// You may need to modify this part based on your specific requirements.\nconst outputBase64 = modelPrediction?.[0]?.data?.audio?.base64 ?? "";\n\nfs.writeFileSync("audio.wav", outputBase64, "base64");\n',b='from clarifai.client.model import Model\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\n# Specify the correct user_id/app_id pairings\n# Since you\'re making inferences outside your app\'s scope\n#USER_ID = "cohere"\n#APP_ID = "embed"\n\n# You can set the model using model URL or model ID.\n# Change these to whatever model you want to use\n# eg : MODEL_ID = \'cohere-embed-english-v3_0\'\n# You can also set a particular model version by specifying the  version ID\n# eg: MODEL_VERSION_ID = \'model_version\'\n#  Model class objects can be inititalised by providing its URL or also by defining respective user_id, app_id and model_id\n\n# eg : model = Model(user_id="clarifai", app_id="main", model_id=MODEL_ID)\n\ninput_text = """In India Green Revolution commenced in the early 1960s that led to an increase in food grain production, especially in Punjab, Haryana, and Uttar Pradesh. Major milestones in this undertaking were the development of high-yielding varieties of wheat. The Green revolution is revolutionary in character due to the introduction of new technology, new ideas, the new application of inputs like HYV seeds, fertilizers, irrigation water, pesticides, etc. As all these were brought suddenly and spread quickly to attain dramatic results thus it is termed as a revolution in green agriculture.\n"""\n# The predict API gives the flexibility to generate predictions for data provided through URL, Filepath and bytes format.\n\n# Example for prediction through URL:\n# model_prediction = model.predict_by_url(URL ,input_type="text")\n\n\n# Example for prediction through Filepath:\n# model_prediction = Model(model_url).predict_by_filepath(image_filepath, input_type="text")\n\n\nmodel_url = "https://clarifai.com/cohere/embed/models/cohere-embed-english-v3_0"\n\nmodel_prediction = Model(url=model_url, pat="YOUR_PAT").predict_by_bytes(\n    input_text, "text"\n)\n\nembeddings = model_prediction.outputs[0].data.embeddings[0].vector\n\nnum_dimensions = model_prediction.outputs[0].data.embeddings[0].num_dimensions\n\nprint(embeddings[:10])\n',x='import { Model } from "clarifai-nodejs";\n\n/**\n    Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    Specify the correct userId/appId pairings\n    Since you\'re making inferences outside your app\'s scope\n    USER_ID = "cohere"\n    APP_ID = "embed"\n\n    You can set the model using model URL or model ID.\n    Change these to whatever model you want to use\n    eg : MODEL_ID = \'cohere-embed-english-v3_0\'\n    You can also set a particular model version by specifying the  version ID\n    eg: MODEL_VERSION_ID = "model_version"\n    Model class objects can be initialised by providing its URL or also by defining respective userId, appId and modelId\n\n    eg : \n    const model = new Model({\n        authConfig: {\n            userId: "clarifai",\n            appId: "main",\n            pat: process.env.CLARIFAI_PAT,\n        },\n        modelId: MODEL_ID,\n    });\n\n*/\n\nconst inputText = Buffer.from(\n  `In India Green Revolution commenced in the early 1960s that led to an increase in food grain production, especially in Punjab, Haryana, and Uttar Pradesh. Major milestones in this undertaking were the development of high-yielding varieties of wheat. The Green revolution is revolutionary in character due to the introduction of new technology, new ideas, the new application of inputs like HYV seeds, fertilizers, irrigation water, pesticides, etc. As all these were brought suddenly and spread quickly to attain dramatic results thus it is termed as a revolution in green agriculture.`,\n);\n\n/**\n        The predict API gives flexibility to generate predictions for data provided through URL, Filepath and bytes format.\n\n\n        Example for prediction through Bytes:\n        const modelPrediction = await model.predictByBytes({\n                                    inputBytes,\n                                    inputType\n                                });\n\n\n        Example for prediction through Filepath:\n        const modelPrediction = await model.predictByFilepath({\n                                    filepath, \n                                    inputType\n                                });\n    */\nconst modelUrl =\n  "https://clarifai.com/cohere/embed/models/cohere-embed-english-v3_0";\n\n\nconst model = new Model({\n  url: modelUrl,\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n  },\n});\n\nconst modelPrediction = await model.predictByBytes({\n  inputBytes: inputText,\n  inputType: "text",\n});\n\nconst embeddings =\n  modelPrediction?.[0]?.data?.embeddingsList?.[0]?.vectorList ?? [];\n\n// const numDimensions =\n//   modelPrediction?.[0]?.data?.embeddingsList?.[0]?.numDimensions;\n\nconsole.log(embeddings.slice(0, 10));\n',v="concept: LABEL_0              confidence: 0.605\nconcept: LABEL_1              confidence: 0.306\nconcept: LABEL_2              confidence: 0.089",_="The future of AI is vast and holds immense potential. Here are a few possibilities:\n\n1. Enhanced Personalization: AI will be able to understand and predict user preferences with increasing accuracy. This will allow for highly personalized experiences, from product recommendations to personalized healthcare.\n\n2. Automation: AI will continue to automate routine tasks, freeing up time for individuals to focus on more complex problems. This could be in any field, from manufacturing to customer service.\n\n3. Advanced Data Analysis: AI will be able to analyze and interpret large amounts of data more efficiently. This could lead to significant breakthroughs in fields like climate science, medicine, and economics.\n\n4. AI in Healthcare: AI is expected to revolutionize healthcare, from predicting diseases before symptoms appear, to assisting in surgeries, to personalized treatment plans.\n\n5. Improved AI Ethics: As AI becomes more integral to our lives, there will be an increased focus on ensuring it is used ethically and responsibly. This could lead to advancements in AI that are more transparent, fair, and accountable.\n\n6. General AI: Perhaps the most exciting (and daunting) prospect is the development of Artificial General Intelligence (AGI) - AI systems that possess the ability to understand, learn, adapt, and implement knowledge across a wide array of tasks, much like a human brain.\n\nRemember, while AI holds great promise, it's also important to consider the challenges and implications it brings, such as job displacement due to automation, privacy concerns, and ethical considerations.",I="`positive`";var A=t(9588);const w={sidebar_position:2},D="Text as Input",T={id:"sdk/Inference-from-AI-Models/Text-as-Input",title:"Text as Input",description:"Learn how to perform inference with text as input using Clarifai SDKs",source:"@site/docs/sdk/Inference-from-AI-Models/Text-as-Input.md",sourceDirName:"sdk/Inference-from-AI-Models",slug:"/sdk/Inference-from-AI-Models/Text-as-Input",permalink:"/sdk/Inference-from-AI-Models/Text-as-Input",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/sdk/Inference-from-AI-Models/Text-as-Input.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Image as Input",permalink:"/sdk/Inference-from-AI-Models/Image-as-Input"},next:{title:"Audio as Input",permalink:"/sdk/Inference-from-AI-Models/Audio-as-Input"}},P={},j=[{value:"Text Classifier",id:"text-classifier",level:2},{value:"Text Generation Using LLM",id:"text-generation-using-llm",level:2},{value:"Text Classifier Using LLM",id:"text-classifier-using-llm",level:2},{value:"Text  to image",id:"text--to-image",level:2},{value:"Text to Audio",id:"text-to-audio",level:2},{value:"Text Embedder",id:"text-embedder",level:2}];function L(e){const n={a:"a",admonition:"admonition",h1:"h1",h2:"h2",p:"p",strong:"strong",...(0,o.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"text-as-input",children:"Text as Input"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Learn how to perform inference with text as input using Clarifai SDKs"})}),"\n",(0,i.jsx)("hr",{}),"\n",(0,i.jsx)(n.p,{children:"Unlock the potential of Clarifai's state-of-the-art text-based AI features, allowing you to elevate your applications with unparalleled accuracy and efficiency. Dive into a comprehensive suite of tools designed to simplify the integration of Clarifai's AI capabilities, empowering developers to unleash the potential of text-driven applications across various domains. Discover a robust and developer-friendly SDKs that streamlines the incorporation of advanced text-based AI models, making it easier than ever to implement powerful natural language processing solutions."}),"\n",(0,i.jsx)(n.h2,{id:"text-classifier",children:"Text Classifier"}),"\n",(0,i.jsxs)(n.p,{children:["Empower your applications with text classification ",(0,i.jsx)(n.a,{href:"https://clarifai.com/explore/models?page=1&perPage=24&filterData=%5B%7B%22field%22%3A%22model_type_id%22%2C%22value%22%3A%5B%22text-classifier%22%5D%7D%5D",children:"models"})," using Clarifai's Predict API for Text. By providing input text to your preferred classification model, you can gain valuable insights into the content's nature. This API offers flexibility, allowing you to provide data through URLs or files for seamless text classification."]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsx)(n.p,{children:"The file size of each text input should be less than 20MB."})}),"\n",(0,i.jsxs)(a.A,{children:[(0,i.jsxs)(s.A,{value:"python",label:"Python",children:[(0,i.jsx)(r.A,{className:"language-python",children:l}),(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:"Output"}),(0,i.jsx)(r.A,{className:"language-text",children:v})]})]}),(0,i.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,i.jsx)(r.A,{className:"language-typescript",children:d})})]}),"\n",(0,i.jsx)(n.h2,{id:"text-generation-using-llm",children:"Text Generation Using LLM"}),"\n",(0,i.jsxs)(n.p,{children:["Empower your applications with dynamic text creation using the robust capabilities of the Clarifai Predict API. This API leverages cutting-edge text generation ",(0,i.jsx)(n.a,{href:"https://clarifai.com/explore/models?page=1&perPage=24&filterData=%5B%7B%22field%22%3A%22model_type_id%22%2C%22value%22%3A%5B%22text-to-text%22%5D%7D%5D",children:"models"})," to generate textual content dynamically based on user-defined prompts, providing a versatile and powerful tool for various applications."]}),"\n",(0,i.jsxs)(a.A,{children:[(0,i.jsxs)(s.A,{value:"python",label:"Python",children:[(0,i.jsx)(r.A,{className:"language-python",children:c}),(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:"Output"}),(0,i.jsx)(r.A,{className:"language-text",children:_})]})]}),(0,i.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,i.jsx)(r.A,{className:"language-typescript",children:p})})]}),"\n",(0,i.jsx)(n.h2,{id:"text-classifier-using-llm",children:"Text Classifier Using LLM"}),"\n",(0,i.jsxs)(n.p,{children:["Dive into the realm of text classification with Clarifai's Predict API, where you can leverage Language ",(0,i.jsx)(n.a,{href:"https://clarifai.com/explore/models?page=1&perPage=24&filterData=%5B%7B%22field%22%3A%22model_type_id%22%2C%22value%22%3A%5B%22text-to-text%22%5D%7D%5D",children:"Models"})," (LLM) to categorize text based on carefully constructed prompts."]}),"\n",(0,i.jsxs)(a.A,{children:[(0,i.jsxs)(s.A,{value:"python",label:"Python",children:[(0,i.jsx)(r.A,{className:"language-python",children:u}),(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:"Output"}),(0,i.jsx)(r.A,{className:"language-text",children:I})]})]}),(0,i.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,i.jsx)(r.A,{className:"language-typescript",children:m})})]}),"\n",(0,i.jsx)(n.h2,{id:"text--to-image",children:"Text  to image"}),"\n",(0,i.jsxs)(n.p,{children:["Leverage the power of the Predict API to seamlessly transform textual input into vibrant and expressive images. With the Text to Image ",(0,i.jsx)(n.a,{href:"https://clarifai.com/explore/models?page=1&perPage=24&filterData=%5B%7B%22field%22%3A%22model_type_id%22%2C%22value%22%3A%5B%22text-to-image%22%5D%7D%5D",children:"models"}),", you can effortlessly generate visually compelling content by providing text as input."]}),"\n",(0,i.jsxs)(a.A,{children:[(0,i.jsxs)(s.A,{value:"python",label:"Python",children:[(0,i.jsx)(r.A,{className:"language-python",children:h}),(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:"Output"}),(0,i.jsx)("img",{src:"/img/python-sdk/text_to_image.png"})]})]}),(0,i.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,i.jsx)(r.A,{className:"language-typescript",children:f})})]}),"\n",(0,i.jsx)(n.h2,{id:"text-to-audio",children:"Text to Audio"}),"\n",(0,i.jsxs)(n.p,{children:["The Text to Audio ",(0,i.jsx)(n.a,{href:"https://clarifai.com/explore/models?page=1&perPage=24&filterData=%5B%7B%22field%22%3A%22input_fields%22%2C%22value%22%3A%5B%22text%22%5D%7D%2C%7B%22field%22%3A%22use_cases%22%2C%22value%22%3A%5B%22speech-synthesis%22%2C%22text-to-speech%22%5D%7D%5D",children:"models"}),", powered by our Predict API, seamlessly transforms provided textual content into an audio file using advanced speech synthesis models. This capability allows users to effortlessly convert written text into a natural and expressive audio experience."]}),"\n",(0,i.jsxs)(a.A,{children:[(0,i.jsx)(s.A,{value:"python",label:"Python",children:(0,i.jsx)(r.A,{className:"language-python",children:g})}),(0,i.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,i.jsx)(r.A,{className:"language-typescript",children:y})})]}),"\n",(0,i.jsx)(n.h2,{id:"text-embedder",children:"Text Embedder"}),"\n",(0,i.jsxs)(n.p,{children:["The Predict API offers a versatile set of capabilities, including the conversion of text into embedding vectors through the Text Embedder ",(0,i.jsx)(n.a,{href:"https://clarifai.com/explore/models?page=1&perPage=24&filterData=%5B%7B%22field%22%3A%22model_type_id%22%2C%22value%22%3A%5B%22text-embedder%22%5D%7D%5D",children:"model"}),". This powerful functionality serves various purposes, making it an invaluable tool for applications such as Semantic Similarity Analysis, Content Recommendation Systems, Anomaly Detection, and Document Clustering."]}),"\n",(0,i.jsxs)(a.A,{children:[(0,i.jsxs)(s.A,{value:"python",label:"Python",children:[(0,i.jsx)(r.A,{className:"language-python",children:b}),(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:"Output"}),(0,i.jsx)(r.A,{className:"language-text",children:A.A})]})]}),(0,i.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,i.jsx)(r.A,{className:"language-typescript",children:x})})]})]})}function M(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(L,{...e})}):L(e)}},19365:(e,n,t)=>{t.d(n,{A:()=>s});t(96540);var i=t(18215);const o={tabItem:"tabItem_Ymn6"};var a=t(74848);function s(e){let{children:n,hidden:t,className:s}=e;return(0,a.jsx)("div",{role:"tabpanel",className:(0,i.A)(o.tabItem,s),hidden:t,children:n})}},11470:(e,n,t)=>{t.d(n,{A:()=>I});var i=t(96540),o=t(18215),a=t(23104),s=t(56347),r=t(205),l=t(57485),d=t(31682),c=t(70679);function p(e){return i.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function u(e){const{values:n,children:t}=e;return(0,i.useMemo)((()=>{const e=n??function(e){return p(e).map((e=>{let{props:{value:n,label:t,attributes:i,default:o}}=e;return{value:n,label:t,attributes:i,default:o}}))}(t);return function(e){const n=(0,d.X)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function m(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function h(e){let{queryString:n=!1,groupId:t}=e;const o=(0,s.W6)(),a=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,l.aZ)(a),(0,i.useCallback)((e=>{if(!a)return;const n=new URLSearchParams(o.location.search);n.set(a,e),o.replace({...o.location,search:n.toString()})}),[a,o])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:o}=e,a=u(e),[s,l]=(0,i.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!m({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const i=t.find((e=>e.default))??t[0];if(!i)throw new Error("Unexpected error: 0 tabValues");return i.value}({defaultValue:n,tabValues:a}))),[d,p]=h({queryString:t,groupId:o}),[f,g]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[o,a]=(0,c.Dv)(t);return[o,(0,i.useCallback)((e=>{t&&a.set(e)}),[t,a])]}({groupId:o}),y=(()=>{const e=d??f;return m({value:e,tabValues:a})?e:null})();(0,r.A)((()=>{y&&l(y)}),[y]);return{selectedValue:s,selectValue:(0,i.useCallback)((e=>{if(!m({value:e,tabValues:a}))throw new Error(`Can't select invalid tab value=${e}`);l(e),p(e),g(e)}),[p,g,a]),tabValues:a}}var g=t(92303);const y={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var b=t(74848);function x(e){let{className:n,block:t,selectedValue:i,selectValue:s,tabValues:r}=e;const l=[],{blockElementScrollPositionUntilNextRender:d}=(0,a.a_)(),c=e=>{const n=e.currentTarget,t=l.indexOf(n),o=r[t].value;o!==i&&(d(n),s(o))},p=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":t},n),children:r.map((e=>{let{value:n,label:t,attributes:a}=e;return(0,b.jsx)("li",{role:"tab",tabIndex:i===n?0:-1,"aria-selected":i===n,ref:e=>l.push(e),onKeyDown:p,onClick:c,...a,className:(0,o.A)("tabs__item",y.tabItem,a?.className,{"tabs__item--active":i===n}),children:t??n},n)}))})}function v(e){let{lazy:n,children:t,selectedValue:o}=e;const a=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=a.find((e=>e.props.value===o));return e?(0,i.cloneElement)(e,{className:"margin-top--md"}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:a.map(((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==o})))})}function _(e){const n=f(e);return(0,b.jsxs)("div",{className:(0,o.A)("tabs-container",y.tabList),children:[(0,b.jsx)(x,{...n,...e}),(0,b.jsx)(v,{...n,...e})]})}function I(e){const n=(0,g.A)();return(0,b.jsx)(_,{...e,children:p(e.children)},String(n))}},9588:(e,n,t)=>{t.d(n,{A:()=>i});const i="[-0.02596100978553295,\n\n 0.023946398869156837,\n\n -0.07173235714435577,\n\n 0.032294824719429016,\n\n 0.020313993096351624,\n\n -0.026998838409781456,\n\n 0.008684193715453148,\n\n -0.016651064157485962,\n\n -0.012316598556935787,\n\n 0.00042328768176957965]"}}]);