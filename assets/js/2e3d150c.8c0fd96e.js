"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[92],{18213:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/ui_inference_4-e39145e262e4014b70f613e52ed7d563.png"},28453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>a});var i=n(96540);const o={},s=i.createContext(o);function r(e){const t=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(s.Provider,{value:t},e.children)}},40721:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/model_predictions-2-c2b13ba1d393872b9c5d638a9eb69a0d.png"},47786:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/ui_inference_3-8b01f6cdff5008a9b97c9939f1c6b067.png"},63347:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/ui_inference_2-403f201592795bd44264e606da52f92d.png"},65297:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/compute-28-750c7a48d27a32df02aead32d9f5c749.png"},65948:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/ui_inference_5-8abe30404686df2ff2c0c010e2fdf752.png"},67736:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/ui_inference_1-4b9639b9536c82ddad85da27ea140201.png"},70956:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/compute-27-1-e93bde345656c702f45489cd245dc7a4.png"},71223:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"compute/inference/clarifai/ui","title":"Inference via UI","description":"Generate model or workflow predictions on the UI","source":"@site/docs/compute/inference/clarifai/ui.md","sourceDirName":"compute/inference/clarifai","slug":"/compute/inference/clarifai/ui","permalink":"/compute/inference/clarifai/ui","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"description":"Generate model or workflow predictions on the UI","sidebar_position":4,"toc_max_heading_level":4},"sidebar":"tutorialSidebar","previous":{"title":"Legacy Inference via API","permalink":"/compute/inference/clarifai/api-legacy"},"next":{"title":"OpenAI","permalink":"/compute/inference/open-ai"}}');var o=n(74848),s=n(28453);const r={description:"Generate model or workflow predictions on the UI",sidebar_position:4,toc_max_heading_level:4},a="Inference via UI",l={},d=[{value:"Generate Chat Predictions",id:"generate-chat-predictions",level:2},{value:"Step 1: Get a Model",id:"step-1-get-a-model",level:3},{value:"Step 2: Run Your Inference",id:"step-2-run-your-inference",level:3},{value:"Generate Multimodal Predictions",id:"generate-multimodal-predictions",level:2},{value:"Step 1: Get a Model",id:"step-1-get-a-model-1",level:3},{value:"Step 2: Run Your Inference",id:"step-2-run-your-inference-1",level:3},{value:"Generate Visual Predictions",id:"generate-visual-predictions",level:2},{value:"Step 1: Get a Model",id:"step-1-get-a-model-2",level:3},{value:"Step 2: Run Your Inference",id:"step-2-run-your-inference-2",level:3},{value:"Try Your Own Images or Videos",id:"try-your-own-images-or-videos",level:4},{value:"Batch Predict on App Inputs",id:"batch-predict-on-app-inputs",level:4},{value:"Generate Predictions Within Input-Viewer",id:"generate-predictions-within-input-viewer",level:2},{value:"Step 1: Get a Model",id:"step-1-get-a-model-3",level:3},{value:"Step 2: Run Your Inference",id:"step-2-run-your-inference-3",level:3}];function c(e){const t={a:"a",admonition:"admonition",blockquote:"blockquote",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"inference-via-ui",children:"Inference via UI"})}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.strong,{children:"Generate model or workflow predictions on the UI"})}),"\n",(0,o.jsx)("hr",{}),"\n",(0,o.jsx)(t.p,{children:"You can perform predictions using a model directly through the Clarifai's User Interface (UI) \u2014 no code required. This method is ideal for quick testing, demos, and visual validation of your model's performance."}),"\n",(0,o.jsx)(t.p,{children:"You can simply upload an input (such as text, image, or video) and view the output predictions in real-time within an intuitive user experience."}),"\n",(0,o.jsxs)(t.p,{children:["The Clarifai ",(0,o.jsx)(t.a,{href:"https://clarifai.com/explore",children:"Community"})," platform offers a wide selection of the latest AI models that you can use to run inferences. You can also ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/compute/upload/",children:"build and upload"})," your own custom models and use them for predictions."]}),"\n",(0,o.jsx)(t.admonition,{title:"Predict With Compute Orchestration",type:"info",children:(0,o.jsxs)(t.p,{children:["If you want to make predictions using Clarifai\u2019s Compute Orchestration capabilities, you\u2019ll need to set up a cluster, create a nodepool, and ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/compute/deployments/deploy-model",children:"deploy"})," your model to it. Once deployed, you can select this deployment for running inferences. If you don\u2019t configure a custom deployment, the platform will use the default Clarifai Shared deployment where applicable, ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/compute/inference/#predict-with-compute-orchestration",children:"as explained here"}),"."]})}),"\n",(0,o.jsx)(t.h2,{id:"generate-chat-predictions",children:"Generate Chat Predictions"}),"\n",(0,o.jsx)(t.p,{children:"The Clarifai platform lets you generate human-like text in a conversational format using large language models (LLMs). You simply provide text as input, known as a prompt, and these models generate coherent, context-aware text-based responses."}),"\n",(0,o.jsx)(t.p,{children:"These models are ideal for tasks such as answering questions, summarizing content, generating code, or engaging in dialogue."}),"\n",(0,o.jsx)(t.h3,{id:"step-1-get-a-model",children:"Step 1: Get a Model"}),"\n",(0,o.jsxs)(t.p,{children:["After finding a language model you want to use, go to its individual page and click the ",(0,o.jsx)(t.strong,{children:"Open in Playground"})," button located in the upper-right corner."]}),"\n",(0,o.jsxs)(t.p,{children:["For this example, we'll use the ",(0,o.jsx)(t.a,{href:"https://clarifai.com/meta/Llama-3/models/Llama-3_2-3B-Instruct",children:"Llama-3.2-3B-Instruct"})," model."]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:n(67736).A+"",width:"1889",height:"888"})}),"\n",(0,o.jsx)(t.h3,{id:"step-2-run-your-inference",children:"Step 2: Run Your Inference"}),"\n",(0,o.jsx)(t.p,{children:"You\u2019ll be taken to Clarifai\u2019s AI Playground \u2014 an intuitive interface that lets you quickly run inferences with models and explore the platform\u2019s full capabilities without any additional setup."}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:n(63347).A+"",width:"1897",height:"871"})}),"\n",(0,o.jsxs)(t.blockquote,{children:["\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.em,{children:"Alternatively, you can access the Playground directly from the top navigation bar. Once inside, use the model selector in the upper-left corner to search and choose the model you want to use for inference."})}),"\n"]}),"\n",(0,o.jsxs)(t.blockquote,{children:["\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.strong,{children:"Note:"})," If you click the ",(0,o.jsx)(t.strong,{children:"View Model Page"})," icon (the file symbol) next to the model selector, you\u2019ll be taken to the model\u2019s individual page, where you can view detailed information about it. Next to it, you\u2019ll find the ",(0,o.jsx)(t.strong,{children:"Copy Model URL"})," icon, which allows you to quickly copy the model\u2019s URL for easy sharing or reference."]}),"\n"]}),"\n",(0,o.jsx)(t.p,{children:"In the message box at the bottom of the Playground, enter your desired prompt to generate text using the selected model. You can also choose from the predefined prompt examples provided."}),"\n",(0,o.jsxs)(t.p,{children:["Once your input is ready, click the ",(0,o.jsx)(t.strong,{children:"arrow icon"})," in the message box to submit your request."]}),"\n",(0,o.jsx)(t.p,{children:"The model\u2019s response will stream in real time, allowing you to see the output as it\u2019s being generated \u2014 just like a live chat experience. Clarifai\u2019s streaming capabilities allow language models to return responses token by token, enabling natural and interactive conversations."}),"\n",(0,o.jsx)(t.admonition,{type:"note",children:(0,o.jsxs)(t.p,{children:["For these examples, we\u2019re using the default deployment settings (",(0,o.jsx)(t.strong,{children:"Clarifai Shared"}),") and default ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/compute/inference/advanced",children:"inference parameters"}),". You can customize these settings as needed to suit more advanced use cases."]})}),"\n",(0,o.jsxs)(t.blockquote,{children:["\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.em,{children:"You can also toggle the button in the upper-left section of the Playground to view ready-to-use API code snippets in multiple programming languages \u2014 just copy and paste them into your project."})}),"\n"]}),"\n",(0,o.jsxs)(t.blockquote,{children:["\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:n(47786).A+"",width:"1895",height:"896"})}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"generate-multimodal-predictions",children:"Generate Multimodal Predictions"}),"\n",(0,o.jsx)(t.p,{children:"Clarifai supports multimodal models \u2014 models that can process and understand more than one type of input at a time, such as images combined with text. These models are designed to handle complex scenarios where context from multiple input types improves prediction quality."}),"\n",(0,o.jsx)(t.p,{children:"Their common use cases include tasks like image captioning, visual question answering (VQA), and multimodal classification."}),"\n",(0,o.jsx)(t.h3,{id:"step-1-get-a-model-1",children:"Step 1: Get a Model"}),"\n",(0,o.jsxs)(t.p,{children:["After finding a multimodal model you want to use, go to its individual page and click the ",(0,o.jsx)(t.strong,{children:"Open in Playground"})," button located in the upper-right corner, as illustrated earlier."]}),"\n",(0,o.jsxs)(t.p,{children:["For this example, we\u2019ll use the ",(0,o.jsx)(t.a,{href:"https://clarifai.com/openai/chat-completion/models/gpt-4o",children:"GPT-4o"})," model, which can process both an image and a text prompt simultaneously."]}),"\n",(0,o.jsx)(t.h3,{id:"step-2-run-your-inference-1",children:"Step 2: Run Your Inference"}),"\n",(0,o.jsxs)(t.p,{children:["While on the AI Playground, navigate to the message box at the bottom and click the plus (",(0,o.jsx)(t.strong,{children:"+"}),") button. A pop-up window will appear, allowing you to select and upload an image."]}),"\n",(0,o.jsx)(t.p,{children:"Once the image is uploaded, enter your accompanying text prompt in the message box. Then, click the arrow icon to submit your request."}),"\n",(0,o.jsx)(t.p,{children:"The model\u2019s response will be streamed in real time, allowing you to see the output as it\u2019s being generated."}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:n(18213).A+"",width:"1910",height:"891"})}),"\n",(0,o.jsx)(t.h2,{id:"generate-visual-predictions",children:"Generate Visual Predictions"}),"\n",(0,o.jsx)(t.p,{children:"The Clarifai platform allows you to leverage powerful AI models to analyze and understand visual data such as images and videos. By providing visual input, you can prompt a model to analyze the content and generate an output based on its learned visual understanding."}),"\n",(0,o.jsxs)(t.p,{children:["Depending on the model type, the output may include ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/create/models/deep-fine-tuning/visual-classifier",children:"image classifications"}),", ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/create/models/deep-fine-tuning/visual-detector",children:"object detections"}),", ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/create/models/deep-fine-tuning/visual-segmenter",children:"segmentation masks"}),", or even AI-generated visuals."]}),"\n",(0,o.jsx)(t.admonition,{type:"note",children:(0,o.jsxs)(t.p,{children:["The Playground automatically detects the appropriate mode based on the selected model \u2014 intelligently switching between ",(0,o.jsx)(t.strong,{children:"Chat"})," and ",(0,o.jsx)(t.strong,{children:"Vision"})," modes to match the model's capabilities."]})}),"\n",(0,o.jsx)(t.h3,{id:"step-1-get-a-model-2",children:"Step 1: Get a Model"}),"\n",(0,o.jsxs)(t.p,{children:["After finding a visual model you want to use, go to its individual page and click the ",(0,o.jsx)(t.strong,{children:"Open in Playground"})," button located in the upper-right corner, as illustrated earlier."]}),"\n",(0,o.jsxs)(t.p,{children:["For this example, we'll use the ",(0,o.jsx)(t.a,{href:"https://clarifai.com/clarifai/main/models/general-image-recognition",children:"general-image-recognition"})," model to identify and classify a variety of concepts in images."]}),"\n",(0,o.jsx)(t.h3,{id:"step-2-run-your-inference-2",children:"Step 2: Run Your Inference"}),"\n",(0,o.jsxs)(t.p,{children:["While on the AI Playground, click the plus (",(0,o.jsx)(t.strong,{children:"+"}),") blue button on the left side. A pop-up will appear, offering the following options for making predictions:"]}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"Try your own image or video"}),"\n",(0,o.jsx)(t.li,{children:"Batch predict on app inputs"}),"\n"]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:n(65948).A+"",width:"1914",height:"891"})}),"\n",(0,o.jsx)(t.h4,{id:"try-your-own-images-or-videos",children:"Try Your Own Images or Videos"}),"\n",(0,o.jsx)(t.p,{children:"This option lets you add an input and see its predictions without leaving the Playground screen. If you click the button, a small window will pop up, allowing you to upload your input."}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:n(40721).A+"",width:"1912",height:"825"})}),"\n",(0,o.jsx)(t.p,{children:"After uploading the image, the model will analyze it and return a list of concepts identified on the right side of the page."}),"\n",(0,o.jsx)(t.h4,{id:"batch-predict-on-app-inputs",children:"Batch Predict on App Inputs"}),"\n",(0,o.jsxs)(t.p,{children:["This option lets you select an app and a ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/create/datasets/",children:"dataset"}),". If you click the button, a small window will pop up, allowing you to choose an app and a dataset with the inputs you want to view their predictions."]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:n(92328).A+"",width:"1904",height:"826"})}),"\n",(0,o.jsxs)(t.p,{children:["After selecting an app and a dataset, click the ",(0,o.jsx)(t.strong,{children:"Try Inputs"})," button."]}),"\n",(0,o.jsxs)(t.p,{children:["You\u2019ll be redirected to the ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/create/labeling/ui/#single-input-viewer",children:"single Input-Viewer"})," screen with the default mode set to ",(0,o.jsx)(t.strong,{children:"Predict"}),", allowing you to see the predictions on an input based on your selections."]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:n(71943).A+"",width:"1914",height:"830"})}),"\n",(0,o.jsx)(t.h2,{id:"generate-predictions-within-input-viewer",children:"Generate Predictions Within Input-Viewer"}),"\n",(0,o.jsxs)(t.blockquote,{children:["\n",(0,o.jsxs)(t.p,{children:["The single Input-Viewer is the main page that showcases the details of a single input available in your app. If you click an input listed on the ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/inputs-manager/",children:"Inputs-Manager"})," page, you'll be redirected to the viewer page for that input, where you can view and interact with it."]}),"\n"]}),"\n",(0,o.jsx)(t.h3,{id:"step-1-get-a-model-3",children:"Step 1: Get a Model"}),"\n",(0,o.jsxs)(t.p,{children:["To make predictions on an input within the single Input-Viewer, start by switching to predict mode by toggling the ",(0,o.jsx)(t.strong,{children:"Predict"})," button located in the upper-left corner of the page."]}),"\n",(0,o.jsxs)(t.p,{children:["Next, click the ",(0,o.jsx)(t.strong,{children:"Choose a model or workflow"})," button in the right sidebar to select the model you want to use."]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:" ",src:n(87990).A+"",width:"1910",height:"901"})}),"\n",(0,o.jsx)(t.p,{children:"In the window that appears, choose your desired model. You can choose your own customized model or workflow, or look for a public one from the Community platform. You can also create your own model or workflow from there."}),"\n",(0,o.jsxs)(t.blockquote,{children:["\n",(0,o.jsxs)(t.p,{children:["To select a public model or workflow from the Community, click the ",(0,o.jsx)(t.strong,{children:"Explore Community Models / Workflows"})," button. In the pop-up window, use the search bar to find the desired model or workflow."]}),"\n"]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:" ",src:n(70956).A+"",width:"1906",height:"891"})}),"\n",(0,o.jsxs)(t.p,{children:["For this example, let\u2019s choose the Community\u2019s ",(0,o.jsx)(t.a,{href:"https://clarifai.com/qwen/qwen-VL/models/Qwen2_5-VL-7B-Instruct",children:"Qwen2_5-VL-7B-Instruct"})," model, which is a vision-language model that excels in visual recognition tasks."]}),"\n",(0,o.jsx)(t.h3,{id:"step-2-run-your-inference-3",children:"Step 2: Run Your Inference"}),"\n",(0,o.jsxs)(t.p,{children:["Next, select a deployment from the ",(0,o.jsx)(t.strong,{children:"Deployment"})," dropdown. For this example, we\u2019re using the default deployment settings (",(0,o.jsx)(t.strong,{children:"Clarifai Shared"}),")."]}),"\n",(0,o.jsxs)(t.p,{children:["If needed, you can also ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/compute/deployments/deploy-model#via-the-ui",children:"create a new deployment"})," from this window."]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:" ",src:n(65297).A+"",width:"1908",height:"907"})}),"\n",(0,o.jsxs)(t.p,{children:["Lastly, click the ",(0,o.jsx)(t.strong,{children:"Predict"})," button at the bottom of the sidebar to start making the predictions."]}),"\n",(0,o.jsx)(t.p,{children:"The model will process the input and return predictions in real time, allowing you to immediately view the results within the Input-Viewer screen."}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:" ",src:n(71432).A+"",width:"1909",height:"898"})}),"\n",(0,o.jsx)(t.admonition,{type:"note",children:(0,o.jsxs)(t.p,{children:["For models that output concepts, the ",(0,o.jsx)(t.strong,{children:"Prediction Threshold"})," slider allows you to control which predictions are displayed by setting a minimum confidence level. Only predictions with probabilities that meet or exceed this threshold will be shown. You can also use the ",(0,o.jsx)(t.strong,{children:"Filter by concept"})," search field to quickly locate specific concepts and view their associated predictions on the page."]})})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},71432:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/compute-29-dcf88d3a22da123e13c5cd69cbfa9470.png"},71943:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/model_predictions-4-a165e305aad61c888f0e06b8fe19d362.png"},87990:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/compute-27-37ad3581250d1b0d2b245389e66c58f0.png"},92328:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/model_predictions-3-633cb23591c5ac316727335979c37261.png"}}]);