"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[7685],{12840:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>s,metadata:()=>a,toc:()=>d});var o=n(74848),r=n(28453);const s={description:"Learn about our aggregate operators",sidebar_position:5},i="Aggregate",a={id:"portal-guide/agent-system-operators/aggregate",title:"Aggregate",description:"Learn about our aggregate operators",source:"@site/docs/portal-guide/agent-system-operators/aggregate.md",sourceDirName:"portal-guide/agent-system-operators",slug:"/portal-guide/agent-system-operators/aggregate",permalink:"/portal-guide/agent-system-operators/aggregate",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/portal-guide/agent-system-operators/aggregate.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{description:"Learn about our aggregate operators",sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"Push",permalink:"/portal-guide/agent-system-operators/push"},next:{title:"Algorithmic Predict",permalink:"/portal-guide/agent-system-operators/algorithmic-predict"}},c={},d=[{value:"<strong>Features</strong>",id:"features",level:3},{value:"Text Aggregation Operator",id:"text-aggregation-operator",level:2},{value:"<strong>Example Scenario:</strong>",id:"example-scenario",level:3},{value:"<strong>Workflow Integration and Setup</strong>",id:"workflow-integration-and-setup",level:3},{value:"Object Counter",id:"object-counter",level:2},{value:"<strong>Example Scenario:</strong>",id:"example-scenario-1",level:3},{value:"<strong>Object Counter Setup</strong>",id:"object-counter-setup",level:3}];function l(e){const t={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h1,{id:"aggregate",children:"Aggregate"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.strong,{children:"Learn about our aggregate operators"})}),"\n",(0,o.jsx)("hr",{}),"\n",(0,o.jsx)(t.p,{children:"Aggregate operators are designed to process and synthesize data across multiple regions of an image or multiple frames in a video sequence. These operators are crucial for applications requiring consolidated information from dispersed data points, such as object counting or text aggregation within images."}),"\n",(0,o.jsx)(t.h3,{id:"features",children:(0,o.jsx)(t.strong,{children:"Features"})}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Enhanced Data Synthesis"}),": Aggregate operators combine data from multiple inputs to produce a coherent output, simplifying further analysis."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Customizable Workflows"}),": Easily integrated into custom workflows, these operators allow flexible configurations to suit varied use cases."]}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"text-aggregation-operator",children:"Text Aggregation Operator"}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.strong,{children:"Input"}),": ",(0,o.jsx)(t.code,{children:"regions[\u2026].data.text"})]}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.strong,{children:"Output"}),": ",(0,o.jsx)(t.code,{children:"text"})]}),"\n",(0,o.jsx)(t.p,{children:"The Text Aggregation Operator consolidates detected text elements within an image, organizing them into a coherent body of text. This operator is especially beneficial in workflows that process documents or extract readable information from various visual media formats."}),"\n",(0,o.jsx)(t.p,{children:"This model arranges text detections spatially from left to right and then from top to bottom, mimicking the natural reading order. This functionality ensures the output text follows a logical sequence, increasing its usability for subsequent processing or analysis. The operator adjusts to the positional dynamics of text within the image, making it versatile across different types of textual content."}),"\n",(0,o.jsx)(t.h3,{id:"example-scenario",children:(0,o.jsx)(t.strong,{children:"Example Scenario:"})}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.strong,{children:"Text"})," ",(0,o.jsx)(t.strong,{children:"Blocks"}),": Multiple addresses on a package"]}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.strong,{children:"Sorting"})," ",(0,o.jsx)(t.strong,{children:"Order"}),": Left to right, top to bottom"]}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.strong,{children:"Operation"}),": The operator organizes the detected addresses into a sequence replicating the text's layout as it appears on the package."]}),"\n",(0,o.jsx)(t.h3,{id:"workflow-integration-and-setup",children:(0,o.jsx)(t.strong,{children:"Workflow Integration and Setup"})}),"\n",(0,o.jsx)(t.p,{children:"Let's demonstrate how you can use the Text Aggregator alongside an OCR operator. This is because the OCR operator identifies regions with text and provides the text read with a score. The text aggregator then uses that output as input."}),"\n",(0,o.jsxs)(t.ol,{children:["\n",(0,o.jsx)(t.li,{children:"Go to the workflow builder page. Search for the OCR operator in the left-hand sidebar and drag it onto the empty workspace. Then, select a model from the pop-up on the right-hand sidebar."}),"\n",(0,o.jsx)(t.li,{children:"Search for the Text Aggregation operator in the left-hand sidebar, drag it onto the workspace, and set up its output configuration based on the requirements."}),"\n",(0,o.jsx)(t.li,{children:"Connect the OCR  with the Text Aggregator and save the workflow."}),"\n"]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"alt text",src:n(14343).A+"",width:"3024",height:"1426"})}),"\n",(0,o.jsx)(t.p,{children:"To see it in action, upload the inputs from your local device or use the inputs in the app. When you upload inputs, the workflow will give the output based on the configurations done."}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"alt text",src:n(45868).A+"",width:"3008",height:"1562"})}),"\n",(0,o.jsxs)(t.p,{children:["You can try this workflow ",(0,o.jsx)(t.a,{href:"https://clarifai.com/clarifai/Sample-Workflows-for-Docs/workflows/Text-Aggregation?version=d5a9822e504e4bd68c57c51177d031f1",children:"here"})]}),"\n",(0,o.jsx)(t.h2,{id:"object-counter",children:"Object Counter"}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.strong,{children:"Input"}),": ",(0,o.jsx)(t.code,{children:"regions[\u2026].data.concepts"})]}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.strong,{children:"Output"}),": ",(0,o.jsx)(t.code,{children:"metadata"})]}),"\n",(0,o.jsx)(t.p,{children:"The Object Counter operator is tailored to quantify objects within images or video frames based on specific concepts. This operator is instrumental in environments where accurate object tracking and counting are required across successive frames, such as in surveillance, traffic monitoring, and automated inventory systems."}),"\n",(0,o.jsx)(t.p,{children:"This model excels in recognizing and counting occurrences of predefined concepts within the designated regions of interest, frame by frame. By leveraging advanced detection algorithms, the Object Counter ensures precise counts, enhancing data analysis and decision-making processes in real-time applications."}),"\n",(0,o.jsx)(t.h3,{id:"example-scenario-1",children:(0,o.jsx)(t.strong,{children:"Example Scenario:"})}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.strong,{children:"Object of Interest"}),': "Vehicle"']}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.strong,{children:"Operation"}),": The operator counts the number of vehicles across video frames, providing real-time data essential for traffic flow analysis."]}),"\n",(0,o.jsx)(t.h3,{id:"object-counter-setup",children:(0,o.jsx)(t.strong,{children:"Object Counter Setup"})}),"\n",(0,o.jsxs)(t.p,{children:["Let's demonstrate how you can use the Object Counter alongside a ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/model/model-types/visual-detector",children:"Visual Detector"}),". The reason behind this is that the Visual Detector identifies regions and provides the confidence scores that the Object Counter uses to count the regions effectively. Without the Visual Detector, the Object Counter would lack the necessary data to perform its counting function."]}),"\n",(0,o.jsxs)(t.ol,{children:["\n",(0,o.jsxs)(t.li,{children:["Go to the workflow builder page. Search for the visual-detector option in the left-hand sidebar and drag it onto the empty workspace. Then, use the pop-up that appears on the right-hand sidebar to search for a detection model, such as ",(0,o.jsx)(t.a,{href:"https://clarifai.com/clarifai/main/models/general-image-detection",children:"general-image-detection"}),"."]}),"\n",(0,o.jsx)(t.li,{children:"Search for the Object Counter option in the left-hand sidebar and drag it onto the workspace."}),"\n",(0,o.jsx)(t.li,{children:"Connect the Visual Detector with the Object Counter operator and save your workflow."}),"\n"]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"alt text",src:n(41300).A+"",width:"3024",height:"1400"})}),"\n",(0,o.jsxs)(t.ol,{children:["\n",(0,o.jsxs)(t.li,{children:["To see it in action, upload the inputs from your local device or use the inputs in the app. When you upload inputs, the workflow will give the output based on the configurations done. For this example, ",(0,o.jsx)(t.a,{href:"https://samples.clarifai.com/05/26/e0/d96cab4e0cb85c430f2ef763b3.jpg",children:"this"})," image is used."]}),"\n"]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"alt text",src:n(63759).A+"",width:"3024",height:"1542"})}),"\n",(0,o.jsxs)(t.p,{children:["To ensure accurate counting, the Visual Detector identifies the regions of interest and assigns confidence scores to them, which the Object Counter then uses to perform the counting function. However, due to the complex nature of this operation, the workflow's output is not supported directly in the web viewer. Users must access the detailed results in a JSON format to review the count and other metadata effectively. This approach guarantees precise data interpretation and enhances decision-making processes. ",(0,o.jsx)(t.br,{}),"\n",(0,o.jsx)(t.br,{}),"\n",'JSON for the above output is given below, and at the end, the "',(0,o.jsx)(t.strong,{children:'object_count": 8'})," is given."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-json",children:'{\n  "json": {\n    "id": "6ef88a0a76c94da6a02c8ea58feb13d5",\n    "status": {\n      "code": 10000,\n      "description": "Ok"\n    },\n    "created_at": "2024-09-04T00:28:29.404495670Z",\n    "model": {\n      "id": "workflow-model-61fd-d06227acd7d1",\n      "name": "workflow-model-61fd-d06227acd7d1",\n      "created_at": "2024-09-04T00:28:26.852951Z",\n      "modified_at": "2024-09-04T00:28:26.852951Z",\n      "app_id": "Text-Generator",\n      "model_version": {\n        "id": "fd2bdda515164775bbbd1b24a2d620a6",\n        "created_at": "2024-09-04T00:28:27.141447Z",\n        "status": {\n          "code": 21100,\n          "description": "Model is trained and ready for deployment"\n        },\n        "visibility": {\n          "gettable": 10\n        },\n        "app_id": "Text-Generator",\n        "user_id": "mohit01",\n        "metadata": {},\n        "inference_compute_info": {}\n      },\n      "user_id": "mohit01",\n      "model_type_id": "object-counter",\n      "visibility": {\n        "gettable": 10\n      },\n      "toolkits": [],\n      "use_cases": [],\n      "languages": [],\n      "languages_full": [],\n      "check_consents": [],\n      "workflow_recommended": false\n    },\n    "data": {\n      "metadata": {\n        "object_count": 8\n      }\n    }\n  }\n}\n'})}),"\n",(0,o.jsxs)(t.p,{children:["You can try this workflow ",(0,o.jsx)(t.a,{href:"https://clarifai.com/clarifai/Sample-Workflows-for-Docs/workflows/Object-Counter?version=97dbdbae2b78452cafbefc6ddc63d69b",children:"here"})]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},41300:(e,t,n)=>{n.d(t,{A:()=>o});const o=n.p+"assets/images/OC 1-0b995f2c1efb25dd4b67d3c88df88fe0.png"},63759:(e,t,n)=>{n.d(t,{A:()=>o});const o=n.p+"assets/images/OC 2-24c9f0f838fb66294507a5c589bc5df1.png"},14343:(e,t,n)=>{n.d(t,{A:()=>o});const o=n.p+"assets/images/TA 1-11e049e5d10bb4efe6aae583cdfa8632.png"},45868:(e,t,n)=>{n.d(t,{A:()=>o});const o=n.p+"assets/images/TA 2-846cd30d55901c53bb7f3b30c39f9a23.png"},28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>a});var o=n(96540);const r={},s=o.createContext(r);function i(e){const t=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(s.Provider,{value:t},e.children)}}}]);