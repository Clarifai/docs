"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[2164],{11470:(e,t,n)=>{n.d(t,{A:()=>v});var s=n(96540),a=n(18215),r=n(17559),o=n(23104),i=n(56347),d=n(205),u=n(57485),c=n(31682),l=n(70679);function p(e){return s.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,s.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:t,children:n}=e;return(0,s.useMemo)(()=>{const e=t??function(e){return p(e).map(({props:{value:e,label:t,attributes:n,default:s}})=>({value:e,label:t,attributes:n,default:s}))}(n);return function(e){const t=(0,c.XI)(e,(e,t)=>e.value===t.value);if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[t,n])}function m({value:e,tabValues:t}){return t.some(t=>t.value===e)}function g({queryString:e=!1,groupId:t}){const n=(0,i.W6)(),a=function({queryString:e=!1,groupId:t}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,u.aZ)(a),(0,s.useCallback)(e=>{if(!a)return;const t=new URLSearchParams(n.location.search);t.set(a,e),n.replace({...n.location,search:t.toString()})},[a,n])]}function f(e){const{defaultValue:t,queryString:n=!1,groupId:a}=e,r=h(e),[o,i]=(0,s.useState)(()=>function({defaultValue:e,tabValues:t}){if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=t.find(e=>e.default)??t[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:r})),[u,c]=g({queryString:n,groupId:a}),[p,f]=function({groupId:e}){const t=function(e){return e?`docusaurus.tab.${e}`:null}(e),[n,a]=(0,l.Dv)(t);return[n,(0,s.useCallback)(e=>{t&&a.set(e)},[t,a])]}({groupId:a}),b=(()=>{const e=u??p;return m({value:e,tabValues:r})?e:null})();(0,d.A)(()=>{b&&i(b)},[b]);return{selectedValue:o,selectValue:(0,s.useCallback)(e=>{if(!m({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);i(e),c(e),f(e)},[c,f,r]),tabValues:r}}var b=n(92303);const y={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var O=n(74848);function x({className:e,block:t,selectedValue:n,selectValue:s,tabValues:r}){const i=[],{blockElementScrollPositionUntilNextRender:d}=(0,o.a_)(),u=e=>{const t=e.currentTarget,a=i.indexOf(t),o=r[a].value;o!==n&&(d(t),s(o))},c=e=>{let t=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const n=i.indexOf(e.currentTarget)+1;t=i[n]??i[0];break}case"ArrowLeft":{const n=i.indexOf(e.currentTarget)-1;t=i[n]??i[i.length-1];break}}t?.focus()};return(0,O.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":t},e),children:r.map(({value:e,label:t,attributes:s})=>(0,O.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:e=>{i.push(e)},onKeyDown:c,onClick:u,...s,className:(0,a.A)("tabs__item",y.tabItem,s?.className,{"tabs__item--active":n===e}),children:t??e},e))})}function _({lazy:e,children:t,selectedValue:n}){const r=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const e=r.find(e=>e.props.value===n);return e?(0,s.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,O.jsx)("div",{className:"margin-top--md",children:r.map((e,t)=>(0,s.cloneElement)(e,{key:t,hidden:e.props.value!==n}))})}function k(e){const t=f(e);return(0,O.jsxs)("div",{className:(0,a.A)(r.G.tabs.container,"tabs-container",y.tabList),children:[(0,O.jsx)(x,{...t,...e}),(0,O.jsx)(_,{...t,...e})]})}function v(e){const t=(0,b.A)();return(0,O.jsx)(k,{...e,children:p(e.children)},String(t))}},19365:(e,t,n)=>{n.d(t,{A:()=>o});n(96540);var s=n(18215);const a={tabItem:"tabItem_Ymn6"};var r=n(74848);function o({children:e,hidden:t,className:n}){return(0,r.jsx)("div",{role:"tabpanel",className:(0,s.A)(a.tabItem,n),hidden:t,children:e})}},33962:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>K,contentTitle:()=>z,default:()=>J,frontMatter:()=>W,metadata:()=>s,toc:()=>V});const s=JSON.parse('{"id":"compute/inference/clarifai/api","title":"Inference via API","description":"Generate predictions with models","source":"@site/docs/compute/inference/clarifai/api.md","sourceDirName":"compute/inference/clarifai","slug":"/compute/inference/clarifai/api","permalink":"/compute/inference/clarifai/api","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"description":"Generate predictions with models","sidebar_position":2,"toc_max_heading_level":4},"sidebar":"tutorialSidebar","previous":{"title":"Model Inference","permalink":"/compute/inference/clarifai/"},"next":{"title":"Legacy Inference via API","permalink":"/compute/inference/clarifai/api-legacy"}}');var a=n(74848),r=n(28453),o=n(11470),i=n(19365),d=n(88149);const u='from clarifai.client import Model\nfrom clarifai.runners.utils.data_types import Image\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize with model URL\nmodel = Model(\n    url="https://clarifai.com/openai/chat-completion/models/o4-mini",\n    # deployment_id="DEPLOYMENT_ID_HERE"\n)\n\nresponse = model.predict(\n    prompt="Describe the image",\n    image=Image(url="https://samples.clarifai.com/cat1.jpeg") \n)\n\nprint(response)\n\n"""\n# --- Predict using an image uploaded from a local machine ---\n\n# 1. Specify the path to your local image file\nlocal_image_path = "path/to/your/image.jpg"  # Replace with the actual path to your image\n\n# 2. Read the image file into bytes\nwith open(local_image_path, "rb") as f:\n    image_bytes = f.read()\n\nresponse = model.predict(\n    prompt="Describe the image",\n    # Provide Image as bytes\n    image=Image(bytes=image_bytes)\n)\n\nprint(response)\n\n# You can also convert a Pillow (PIL) Image object into a Clarifai Image data type \n# image=Image.from_pil(pil_image)\n\n"""',c='from clarifai.client import Model\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize with model URL\nmodel = Model(\n    url="https://clarifai.com/openai/chat-completion/models/o4-mini",\n    # deployment_id="DEPLOYMENT_ID_HERE"\n)\n\nresponse = model.predict("What is photosynthesis?")\n# Or\n# response = model.predict(prompt="What is photosynthesis?")\n\nprint(response)\n',l='from clarifai.client import Model\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize with model URL\nmodel = Model(\n    url="https://clarifai.com/openai/chat-completion/models/o4-mini",\n    # deployment_id="DEPLOYMENT_ID_HERE"\n)\n\nresponse_stream = model.generate(\n    prompt="Explain quantum computing in simple terms"  \n)\n\nfor text_chunk in response_stream:\n    print(text_chunk, end="", flush=True)\n\n"""\n# --- Load prompt text from URL ---\n\nprompt_from_url = requests.get("https://samples.clarifai.com/featured-models/redpajama-economic.txt") # Remember to import requests\nprompt_text = prompt_from_url.text.strip()\n\nresponse_stream = model.generate(\n    prompt=prompt_text\n)\n\nfor text_chunk in response_stream:\n    print(text_chunk, end="", flush=True)\n\n"""',p='from clarifai.client import Model\nfrom clarifai.runners.utils.data_types import Audio\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize with model URL\nmodel = Model(\n    url="MODEL_URL_HERE",\n    # deployment_id="DEPLOYMENT_ID_HERE"\n)\n\n# client-side streaming\nresponse_stream = model.transcribe_audio(\n    audio=iter(Audio(bytes=b\'\'))\n    # Or, provide audio as URL\n    # audio=Audio(url="https://example.com/audio.mp3")\n)\n\nfor text_chunk in response_stream:\n    print(text_chunk.text, end="", flush=True)',h='from clarifai.client import Model\nfrom clarifai.runners.utils.data_types import Text\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize with model URL\nmodel = Model(\n    url="MODEL_URL_HERE", \n    # deployment_id="YOUR_DEPLOYMENT_ID_HERE"\n)\n\n# Create a list of input Texts to simulate a stream\ninput_texts = iter([\n    Text(text="First input."),\n    Text(text="Second input."),\n    Text(text="Third input.")\n])\n\n# Call the stream method and process outputs\nresponse_iterator = model.stream(input_texts)\n\n# Print streamed results\nprint("Streaming output:\\n")\nfor response in response_iterator:\n    print(response.text)\n',m='from clarifai.client import Model\nfrom clarifai.runners.utils.data_types import Image\n\n# Set PAT as an environment variable before running:\n#   export CLARIFAI_PAT=YOUR_PAT_HERE   # macOS / Linux\n#   set CLARIFAI_PAT=YOUR_PAT_HERE      # Windows\n\n# Initialize with model URL\nmodel = Model(\n    url="https://clarifai.com/openai/chat-completion/models/o4-mini"\n)\n\n# Prepare batch inputs\ninputs = [\n    {\n        "prompt": "Describe the image",\n        "image": Image(url="https://samples.clarifai.com/cat1.jpeg")\n    },\n    {\n        "prompt": "Describe the image",\n        "image": Image(url="https://samples.clarifai.com/cat2.jpeg")\n    },\n    {\n        "prompt": "Describe the image",\n        "image": Image(url="https://samples.clarifai.com/cat3.jpeg")\n    },\n]\n\n# Run batch prediction\nbatch_results = model.predict(inputs)\n\n# Print output results\nprint("Batch Prediction Results:\\n")\nfor i, result in enumerate(batch_results):\n    print(f"Input {i+1}:")\n    print(result)\n    print("-" * 40)\n\n"""\n# --- Predict using an image uploaded from a local machine ---\n# Replace with the actual path to your image files\nimage_1 = "path/to/your/image_1.jpg"\nimage_2 = "path/to/your/image_2.jpg"\nimage_3 = "path/to/your/image_3.jpg"\n\ndef load_image_bytes(path: str) -> bytes:\n    # Read a local image file into raw bytes.\n    with open(path, "rb") as f:\n        return f.read()\n\ninputs_from_local = [\n    {\n        "prompt": "Describe the image",\n        "image": Image(bytes=load_image_bytes(image_1)),\n    },\n    {\n        "prompt": "Describe the image",\n        "image": Image(bytes=load_image_bytes(image_2)),\n    },\n    {\n        "prompt": "Describe the image",\n        "image": Image(bytes=load_image_bytes(image_3)),\n    },\n]\n\n# Run prediction\nresults_local = model.predict(inputs_from_local)\n\n# Print results\nprint("\\nResults from LOCAL IMAGES:\\n")\nfor i, result in enumerate(results_local):\n    print(f"Image {i+1}:")\n    print(result)\n    print("-" * 40)\n"""',g='from clarifai.client import Model\nfrom clarifai.runners.utils.data_types import Text\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize with model URL\nmodel = Model(\n    url="https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",\n    # deployment_id="DEPLOYMENT_ID_HERE"\n)\n\n# Prepare batch inputs using standard Python STRINGS for the prompt value\ninputs = [\n    {"prompt": "Write a short positive review about a new sci-fi movie."},\n    {"prompt": "Write a short negative review about a new sci-fi movie."},\n    {"prompt": "Write a short neutral review about a new sci-fi movie."},\n]\n\n# Run batch prediction\nbatch_results = model.predict(inputs)\n\n# Print output results in a readable format\nprint("Batch Prediction Results:\\n")\nfor i, result in enumerate(batch_results):\n    print(f"Input {i+1}:")\n    print(result)       \n    print("-" * 40)',f='from clarifai.client import Model\nfrom clarifai.runners.utils.data_types import Image\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize model\nmodel = Model(\n    url="https://clarifai.com/openai/chat-completion/models/o4-mini",\n    # deployment_id="DEPLOYMENT_ID_HERE"\n)\n\n# Perform prediction with prompt and image\nresult = model.predict(\n    prompt="Describe this image",\n    image=Image(url="https://samples.clarifai.com/metro-north.jpg"),\n    max_tokens=1024    \n)\n\n# Print the prediction result\nprint(result)',b="Batch Prediction Results:\n\nInput 1:\n**Review: \u201cStarlight Frontier\u201d \u2013 A Thrilling Leap Into the Cosmos**\n\n\u201cStarlight Frontier\u201d bursts onto the screen with the kind of bold imagination that reminds us why sci\u2011fi is the genre of limitless possibility. Director Maya Chen crafts a sleek, high\u2011octane adventure that balances jaw\u2011dropping visual spectacle with a surprisingly heartfelt story.\n\nThe film\u2019s world\u2011building is nothing short of spectacular. From the neon\u2011lit megacities of the orbital colonies to the hauntingly beautiful alien wastelands of the Andromeda fringe, every frame feels meticulously designed, and the cutting\u2011edge VFX make the cosmos feel both vast and intimately lived\u2011in. The use of practical effects\u2014especially the tactile, retro\u2011futuristic ship interiors\u2014adds a warm, tactile layer that grounds the high\u2011tech spectacle.\n\nAt the heart of the narrative is a diverse crew of misfits led by the charismatic and deeply human Captain Aria (played with fierce conviction by Zoe Patel). Their chemistry is electric, and the script gives each character a genuine arc, turning what could have been a standard \u201csave the galaxy\u201d plot into a resonant tale about trust, sacrifice, and the search for belonging.\n\nThe pacing is spot\u2011on: the opening act hooks you with a pulse\u2011pounding chase through an asteroid field, the middle delves into a thought\u2011provoking mystery about an ancient alien signal, and the climax delivers a breathtaking showdown that feels earned rather than gratuitous. The score, a soaring blend of synth\u2011wave and orchestral motifs by composer Luis Ortega, perfectly amplifies the emotional stakes without ever overwhelming the story.\n\nWhat truly sets \u201cStarlight Frontier\u201d apart is its optimism. In a time when many sci\u2011fi films lean heavily into dystopia, this movie dares to imagine a future where curiosity, cooperation, and wonder still drive humanity forward. It\u2019s a refreshing reminder that the stars are not just a backdrop for conflict, but a canvas for hope.\n\nIn short, \u201cStarlight Frontier\u201d is a dazzling, emotionally resonant ride that will satisfy both die\u2011hard genre fans and newcomers alike. It\u2019s a must\u2011see that proves the future of sci\u2011fi cinema is bright, bold, and brimming with heart. \ud83d\ude80\u2728\n----------------------------------------\nInput 2:\n**Title: \u201cStellar Drift\u201d \u2013 A Missed Opportunity**\n\nI went into *Stellar Drift* with high hopes, but the film quickly proved to be a disappointing slog. The plot feels like a patchwork of overused tropes\u2014galactic wars, a reluctant hero, and a \u201cmysterious artifact\u201d that never lives up to its hype. The world\u2011building is shallow; the supposedly intricate alien cultures are reduced to generic costume designs and vague exposition, leaving the setting feeling more like a backdrop than a living universe.\n\nThe pacing is another major flaw. The first half drags with endless exposition and lackluster dialogue, while the climax rushes through what could have been an epic showdown, leaving key character arcs unresolved. Speaking of characters, the leads are bland and underdeveloped, making it hard to care about their fates. Even the visual effects, which should be the film\u2019s saving grace, are uneven\u2014some scenes sparkle with vivid detail, but many look cheap and CGI\u2011heavy, pulling you out of the immersion.\n\nIn short, *Stellar Drift* promises a grand sci\u2011fi adventure but delivers a forgettable, formulaic mess. If you\u2019re looking for something fresh and thought\u2011provoking, you\u2019ll have to look elsewhere.\n----------------------------------------\nInput 3:\n**Review: \u201cStellar Frontier\u201d (2025)**  \n\n\u201cStellar Frontier\u201d arrives as a competent addition to the contemporary sci\u2011fi catalog, delivering a blend of familiar tropes and modest ambition. The film\u2019s premise\u2014a crew of explorers racing against a rogue AI to secure a habitable exoplanet\u2014offers a clear narrative hook, though the plot unfolds in a fairly predictable rhythm. The screenplay leans on standard genre beats, delivering enough twists to keep the story moving without venturing into particularly daring territory.\n\nVisually, the movie shines. Production design and VFX teams craft convincing space vistas and sleek ship interiors that feel grounded yet imaginative. The color palette, dominated by cool blues and stark whites, reinforces the cold expanse of deep space while occasional warm tones hint at the human element.\n\nPerformances are solid across the board. The lead, Maya Patel, brings a measured intensity to her role as commander, and the supporting cast provides reliable, if not standout, contributions. Direction by Lena Ortiz maintains a steady pace, balancing action sequences with quieter character moments, though at times the pacing feels uneven, lingering on exposition before accelerating into the climax.\n\nOverall, \u201cStellar Frontier\u201d is a well\u2011executed, if unremarkable, sci\u2011fi entry. It offers enough visual spectacle and competent storytelling to satisfy genre fans, even if it doesn\u2019t push the boundaries of the field.\n----------------------------------------",y="Results from LOCAL IMAGES:\n\nImage 1:\nThe image shows a young orange tabby cat lying on its side against the base of a wall. Its body is stretched out on what looks like a smooth concrete or tiled ledge, and its front paw is gently curled under its chest. The cat\u2019s coat is a warm, golden-orange hue marked with slightly darker, classic tabby stripes. Its amber eyes are open and gazing softly toward the viewer, and its pink nose and long white whiskers stand out against the rich color of its fur. Behind the cat you can see two different wall surfaces\u2014one a darker, earthy brown texture and the other a lighter, off-white plaster\u2014adding a subtle contrast to the scene. The overall lighting is soft and warm, giving the photo a cozy, relaxed atmosphere.\n----------------------------------------\nImage 2:\nThe photo shows a close-up of a tortoiseshell (calico-patterned) cat looking straight up at the camera. Its coat is mottled with patches of black, orange and cream, and it has striking pale green eyes. You can also see a scattering of long white whiskers framing its face. The background is softly out of focus, with earthy tones suggesting leaf-litter or soil underfoot.\n----------------------------------------\nImage 3:\nThe image shows a close-up of a long-haired orange-and-white cat lying outdoors on the ground. Its coat is predominantly a warm ginger color, with white fur around the muzzle, chest, and whiskers. The cat\u2019s amber eyes look directly at the camera, and its tufted ears and fluffy fur give it a soft, well-groomed appearance. In the background you can see out-of-focus green grass, suggesting the cat is resting in a garden or grassy area.\n----------------------------------------\n",O='from clarifai.client import Model\n\n# Set PAT as an environment variable:\n#   export CLARIFAI_PAT=YOUR_PAT_HERE   # macOS / Linux\n#   set CLARIFAI_PAT=YOUR_PAT_HERE      # Windows\n\n# Initialize the model\nmodel = Model(\n    url="https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",\n)\n\n# Get both the processed response and raw protobuf response\nresponse, proto_response = model.predict(\n    prompt="What is photosynthesis?",\n    reasoning_effort="medium",\n    with_proto=True\n)\n\n# The protobuf response contains rich metadata\nprint(f"Request ID for debugging: {proto_response.status.req_id}")\nprint(f"Success or error status code: {proto_response.status.code}") \nprint(f"Human-readable status description: {proto_response.status.description}")\nprint(f"Additional status details: {proto_response.status.details}")\nprint(f"Percent progress completed: {proto_response.status.percent_completed}")\n\n# Outputs\nprint(f"Number of Outputs: {len(proto_response.outputs)}")\n\nif proto_response.outputs:\n    output = proto_response.outputs[0]\n    print(f"Output status code: {output.status.code}")\n    print(f"Output status description: {output.status.description}")\n    print(f"Raw output data: {output.data}")\nelse:\n    print("No outputs returned.")\n\n# And much more depending on the model and operation...\n\n# Example debugging usage \nprint("\\nDebugging example:")\ntry:\n    result, proto_response = model.predict(prompt="Hello", with_proto=True)\n    print(f"Success! request ID: {proto_response.status.req_id}")\nexcept Exception as e:\n    print(f"Error occurred: {e}")\n    print(f"Status description: {proto_response.status.description}")\n    print(f"Debug using request ID: {proto_response.status.req_id}")\n',x='Request ID for debugging: sdk-python-11.10.2-df9e4c855cbb4b249c135078bdeece45\nSuccess or error status code: 10000\nHuman-readable status description: Success\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "**Photosynthesis** is the natural process by which green plants, algae, and many bacteria convert light energy from the sun into chemical energy stored in sugars (carbohydrates). In doing so, they also produce the oxygen we breathe.  \\n\\n---\\n\\n## The Basic Idea\\n\\n| Input (reactants) | Energy source | Output (products) |\\n|-------------------|---------------|-------------------|\\n| **CO\u2082** (carbon dioxide) | **Sunlight** (photons) | **C\u2086H\u2081\u2082O\u2086** (glucose) |\\n| **H\u2082O** (water) |  | **O\u2082** (oxygen) |\\n\\nThe overall balanced chemical equation is:\\n\\n\\\\[\\n6\\\\; \\\\text{CO}_2 \\\\;+\\\\; 6\\\\; \\\\text{H}_2\\\\text{O} \\\\;+\\\\; \\\\text{light energy} \\\\;\\\\longrightarrow\\\\; \\\\text{C}_6\\\\text{H}_{12}\\\\text{O}_6 \\\\;+\\\\; 6\\\\; \\\\text{O}_2\\n\\\\]\\n\\n---\\n\\n## Where It Happens\\n\\n- **Chloroplasts** \u2013 organelles in plant cells (and in algae) that contain the pigment **chlorophyll**.\\n- **Thylakoid membranes** \u2013 stacked discs inside chloroplasts where the light\u2011dependent reactions occur.\\n- **Stroma** \u2013 the fluid surrounding the thylakoids where the Calvin (light\u2011independent) cycle takes place.\\n\\n---\\n\\n## Two Main Stages\\n\\n### 1. Light\u2011Dependent Reactions (the \u201cphoto\u201d part)\\n\\n| Step | What happens | Key molecules |\\n|------|--------------|----------------|\\n| **Photon absorption** | Chlorophyll captures light photons. | Excited electrons |\\n| **Water splitting (photolysis)** | H\u2082O \u2192 O\u2082 + H\u207a + e\u207b | Releases O\u2082 to the atmosphere. |\\n| **Electron transport chain** | Excited electrons move through proteins, pumping protons to create a gradient. | Generates ATP (via chemiosmosis) and NADPH (via ferredoxin\u2011NADP\u207a reductase). |\\n\\n**Outputs:** ATP (energy currency) and NADPH (reducing power), plus O\u2082 as a by\u2011product.\\n\\n### 2. Light\u2011Independent Reactions \u2013 The Calvin Cycle (also called the \u201cdark\u201d reactions)\\n\\n| Phase | What happens | Key molecules |\\n|-------|--------------|----------------|\\n| **Carbon fixation** | CO\u2082 is attached to a 5\u2011carbon sugar (ribulose\u20111,5\u2011bisphosphate, RuBP) by the enzyme **Rubisco**, forming a 6\u2011carbon intermediate that splits into two 3\u2011carbon molecules (3\u2011phosphoglycerate, 3\u2011PGA). | 3\u2011PGA |\\n| **Reduction** | ATP and NADPH from the light reactions convert 3\u2011PGA into glyceraldehyde\u20113\u2011phosphate (G3P). | G3P (a sugar\u2011phosphate) |\\n| **Regeneration** | Some G3P molecules are used to regenerate RuBP, allowing the cycle to continue. | RuBP |\\n| **Carbohydrate synthesis** | For every 6 CO\u2082 fixed, 2 G3P exit the cycle; two G3P can be linked to form one glucose (C\u2086H\u2081\u2082O\u2086). | Glucose (or other carbohydrates) |\\n\\n**Outputs:** Glucose (or other sugars) that can be stored as starch, used for growth, or broken down for energy; the cycle also consumes the ATP and NADPH produced earlier.\\n\\n---\\n\\n## Why It Matters\\n\\n1. **Primary production** \u2013 Photosynthesis is the base of most food webs. All heterotrophic organisms (animals, fungi, most bacteria) ultimately rely on the organic carbon fixed by photosynthesizers.\\n2. **Oxygen supply** \u2013 The O\u2082 released is essential for aerobic respiration in most living things.\\n3. **Carbon cycle** \u2013 It removes CO\u2082 from the atmosphere, helping regulate Earth\u2019s climate.\\n4. **Human uses** \u2013 Crops (wheat, rice, corn, etc.) are cultivated for their photosynthetic products; biofuels, bioplastics, and even synthetic photosynthesis research aim to harness this process for sustainable energy.\\n\\n---\\n\\n## Quick Summary (in a nutshell)\\n\\n- **Photosynthesis** = **light energy** + **CO\u2082** + **H\u2082O** \u2192 **glucose** + **O\u2082**.  \\n- Takes place in chloroplasts, using chlorophyll to capture sunlight.  \\n- Consists of **light\u2011dependent reactions** (make ATP & NADPH, release O\u2082) and the **Calvin cycle** (use ATP/NADPH to turn CO\u2082 into sugars).  \\n- It fuels the planet\u2019s ecosystems and maintains atmospheric oxygen.\\n\\nFeel free to ask if you\u2019d like more detail on any part\u2014e.g., the role of specific pigments, variations in algae and cyanobacteria, or how scientists are trying to improve photosynthetic efficiency for agriculture!"\n  }\n  id: "return"\n}\n\n\nDebugging example:\nSuccess! request ID: sdk-python-11.10.2-97cfaaa6f39c4639ab46c8f53df3baa1',_='from clarifai.client import Model\n\n# Set PAT as an environment variable:\n#   export CLARIFAI_PAT=YOUR_PAT_HERE   # macOS / Linux\n#   set CLARIFAI_PAT=YOUR_PAT_HERE      # Windows\n\n# Initialize the model\nmodel = Model(\n    url="https://clarifai.com/openai/chat-completion/models/gpt-oss-120b",\n)\n\n# Stream both processed responses and raw protobuf metadata\nfor response, proto_response in model.generate(\n    prompt="What is photosynthesis?",\n    reasoning_effort="medium",\n    with_proto=True\n):\n    # Processed chunk of streamed text\n    print(f"Generated chunk: {response}")\n\n    # Protobuf metadata for this streamed chunk\n    print(f"Request ID for debugging: {proto_response.status.req_id}")\n    print(f"Success or error status code: {proto_response.status.code}")\n    print(f"Human-readable status description: {proto_response.status.description}")\n    print(f"Additional status details: {proto_response.status.details}")\n    print(f"Percent progress completed: {proto_response.status.percent_completed}")\n\n    # Outputs (each streamed chunk may contain output data)\n    print(f"Number of Outputs: {len(proto_response.outputs)}")\n\n    if proto_response.outputs:\n        output = proto_response.outputs[0]\n        print(f"Output status code: {output.status.code}")\n        print(f"Output status description: {output.status.description}")\n        print(f"Raw output data: {output.data}")\n    else:\n        print("No outputs returned in this streamed chunk.")\n\n    print("---")  # Separator for each streamed chunk\n',k='Generated chunk: \nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: The user asks: "What is photos\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "The user asks: \\"What is photos"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: ynthesis?" Provide a clear explanation. Could include process\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "ynthesis?\\" Provide a clear explanation. Could include process"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: , equation, importance, steps (light-dependent,\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: ", equation, importance, steps (light-dependent,"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  Calvin cycle), organisms, etc. Should be concise\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " Calvin cycle), organisms, etc. Should be concise"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  but thorough. Use simple\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " but thorough. Use simple"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  language. Possibly ask follow\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " language. Possibly ask follow"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: -up. Provide answer.\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "-up. Provide answer."\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: **Photosynthesis** is the process by which green plants, algae, and some bacteria capture light\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "**Photosynthesis** is the process by which green plants, algae, and some bacteria capture light"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  energy from the sun and\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " energy from the sun and"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  turn it into chemical energy stored in sugars (carbohydrates). In doing so, they also produce oxygen as a by\u2011product.  \n\n---\n\n## The Basic Chemical Equation\n\n\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " turn it into chemical energy stored in sugars (carbohydrates). In doing so, they also produce oxygen as a by\u2011product.  \\n\\n---\\n\\n## The Basic Chemical Equation\\n\\n"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: \\[\n\\text{6\u202fCO\u2082\u202f\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "\\\\[\\n\\\\text{6\u202fCO\u2082\u202f"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: +\u202f6\u202fH\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "+\u202f6\u202fH"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: \u2082O\u202f+\u202flight energy} \\;\\\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "\u2082O\u202f+\u202flight energy} \\\\;\\\\"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: xrightarrow{\\text{chlorophyll}}\\; \\text{C\u2086H\u2081\u2082O\u2086\u202f+\u202f\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "xrightarrow{\\\\text{chlorophyll}}\\\\; \\\\text{C\u2086H\u2081\u2082O\u2086\u202f+\u202f"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: 6\u202fO\u2082}\n\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "6\u202fO\u2082}\\n"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: \\]\n\n- **CO\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "\\\\]\\n\\n- **CO"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: \u2082** \u2013 carbon dioxide\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "\u2082** \u2013 carbon dioxide"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  from the air  \n- **H\u2082O** \u2013 water taken up by\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " from the air  \\n- **H\u2082O** \u2013 water taken up by"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  roots  \n- **C\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " roots  \\n- **C"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: \u2086H\u2081\u2082O\u2086** \u2013 glucose (a simple\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "\u2086H\u2081\u2082O\u2086** \u2013 glucose (a simple"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  sugar) that fuels the\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " sugar) that fuels the"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  plant\u2019s growth  \n- **O\u2082** \u2013\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " plant\u2019s growth  \\n- **O\u2082** \u2013"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  oxygen released into the atmosphere\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " oxygen released into the atmosphere"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:   \n\n---\n\n## Where It Happens\n\n- **Chloroplasts** \u2013 organelles in plant cells that contain the pigment **\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "  \\n\\n---\\n\\n## Where It Happens\\n\\n- **Chloroplasts** \u2013 organelles in plant cells that contain the pigment **"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: chlorophyll**, which absorbs\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "chlorophyll**, which absorbs"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  light (mainly blue\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " light (mainly blue"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  and red wavelengths).  \n\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " and red wavelengths).  \\n"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: - **Thylakoid membranes** \u2013 stacked discs inside chloroplasts\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "- **Thylakoid membranes** \u2013 stacked discs inside chloroplasts"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  where the light\u2011dependent reactions occur.  \n- **Stroma** \u2013 the fluid surrounding the thylakoids where the Calvin (light\u2011independent) cycle takes place.\n\n---\n\n## Two Main Stages\n\n| Stage\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " where the light\u2011dependent reactions occur.  \\n- **Stroma** \u2013 the fluid surrounding the thylakoids where the Calvin (light\u2011independent) cycle takes place.\\n\\n---\\n\\n## Two Main Stages\\n\\n| Stage"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  | What Happens | Key\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " | What Happens | Key"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  Products |\n|-------|--------------|--------------|\n| **1. Light\u2011dependent reactions** (in\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " Products |\\n|-------|--------------|--------------|\\n| **1. Light\u2011dependent reactions** (in"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  thylakoids)\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " thylakoids)"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  | \u2022 Light energy exc\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " | \u2022 Light energy exc"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: ites electrons in chlorophyll\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "ites electrons in chlorophyll"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: .<br>\u2022 Water\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: ".<br>\u2022 Water"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  is split (photol\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " is split (photol"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: ysis) \u2192 O\u2082 + H\u207a + electrons.<br>\u2022 Excited electrons travel through\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "ysis) \u2192 O\u2082 + H\u207a + electrons.<br>\u2022 Excited electrons travel through"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  an electron transport chain,\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " an electron transport chain,"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  creating a proton gradient that\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " creating a proton gradient that"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  drives **ATP** synthesis\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " drives **ATP** synthesis"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: .<br>\u2022 NAD\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: ".<br>\u2022 NAD"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: P\u207a is reduced\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "P\u207a is reduced"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  to **NADPH**. | ATP,\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " to **NADPH**. | ATP,"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  NADPH, O\u2082\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " NADPH, O\u2082"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  (released) |\n| **2. Calvin Cycle\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " (released) |\\n| **2. Calvin Cycle"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  (light\u2011independent reactions)** (in st\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " (light\u2011independent reactions)** (in st"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: roma) | \u2022 ATP\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "roma) | \u2022 ATP"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  and NADPH power the\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " and NADPH power the"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  fixation of CO\u2082.\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " fixation of CO\u2082."\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: <br>\u2022 CO\u2082 is attached to a five\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "<br>\u2022 CO\u2082 is attached to a five"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: \u2011carbon sugar (Ru\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "\u2011carbon sugar (Ru"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: BP) by the enzyme **Rubisco**, forming a six\u2011carbon intermediate\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "BP) by the enzyme **Rubisco**, forming a six\u2011carbon intermediate"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  that splits into two three\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " that splits into two three"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: \u2011carbon molecules (3\u2011PGA).\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "\u2011carbon molecules (3\u2011PGA)."\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: <br>\u2022 Through a\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "<br>\u2022 Through a"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  series of steps, \nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " series of steps, "\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: 3\u2011PGA is\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "3\u2011PGA is"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  converted into **G3\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " converted into **G3"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: P** (glycer\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "P** (glycer"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: aldehyde\u20113\u2011phosphate).<br>\u2022 Some G3P leaves the cycle to become glucose and other carbohydrates\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "aldehyde\u20113\u2011phosphate).<br>\u2022 Some G3P leaves the cycle to become glucose and other carbohydrates"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: ; the rest regenerates\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "; the rest regenerates"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  RuBP. | Gl\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " RuBP. | Gl"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: ucose (or other carbohydrates), regeneration of RuBP |\n\n---\n\n## Why It Matters\n\n1. **Energy Source for Life**\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "ucose (or other carbohydrates), regeneration of RuBP |\\n\\n---\\n\\n## Why It Matters\\n\\n1. **Energy Source for Life**"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:   \n   - All heter\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "  \\n   - All heter"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: otrophic organisms (animals, fungi, most bacteria) ultimately rely on the organic carbon produced by photos\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "otrophic organisms (animals, fungi, most bacteria) ultimately rely on the organic carbon produced by photos"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: ynthesis.\n\n2. **\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "ynthesis.\\n\\n2. **"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: Oxygen Production**  \n\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "Oxygen Production**  \\n"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:    - The O\u2082 released is essential for aerobic respiration, which powers most\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "   - The O\u2082 released is essential for aerobic respiration, which powers most"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  complex life.\n\n3. **Carbon Dioxide Regulation\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " complex life.\\n\\n3. **Carbon Dioxide Regulation"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: **  \n   - Photos\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "**  \\n   - Photos"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: ynthesis removes CO\u2082 from the atmosphere, helping to\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "ynthesis removes CO\u2082 from the atmosphere, helping to"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  moderate Earth\u2019s climate.\n\n\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " moderate Earth\u2019s climate.\\n\\n"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: 4. **Economic Importance\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "4. **Economic Importance"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: **  \n   - Cro\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "**  \\n   - Cro"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: ps (wheat, rice, corn, etc.) are cultivated for food\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "ps (wheat, rice, corn, etc.) are cultivated for food"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: , fiber, and bio\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: ", fiber, and bio"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: fuels\u2014all products of\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "fuels\u2014all products of"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  photosynthetic biomass.\n\n5\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " photosynthetic biomass.\\n\\n5"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: . **Ecological Foundations\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: ". **Ecological Foundations"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: **  \n   - Primary\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "**  \\n   - Primary"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  producers (photosynthesizers) form the base\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " producers (photosynthesizers) form the base"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  of most food webs,\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " of most food webs,"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  supporting herbivores,\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " supporting herbivores,"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  predators, and decompos\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " predators, and decompos"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: ers.\n\n---\n\n## Quick\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "ers.\\n\\n---\\n\\n## Quick"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  Summary (in a nutshell\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " Summary (in a nutshell"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: )\n\n- **Photosynthesis** = **light energy\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: ")\\n\\n- **Photosynthesis** = **light energy"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  \u2192 chemical energy** (\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " \u2192 chemical energy** ("\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: sugar) + **\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "sugar) + **"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: oxygen**.  \n- Takes place in **chlor\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "oxygen**.  \\n- Takes place in **chlor"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: oplasts** using **\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "oplasts** using **"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: chlorophyll**.  \n\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "chlorophyll**.  \\n"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: - Consists of **light\u2011dependent reactions** (make ATP & NADPH, split water)\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "- Consists of **light\u2011dependent reactions** (make ATP & NADPH, split water)"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  and the **Calvin cycle** (fix CO\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " and the **Calvin cycle** (fix CO"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: \u2082 into sugar).  \n\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "\u2082 into sugar).  \\n"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: - It fuels almost all\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "- It fuels almost all"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  life on Earth and keeps\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " life on Earth and keeps"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  our atmosphere breathable.\n\n---\n\n\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " our atmosphere breathable.\\n\\n---\\n\\n"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: ### Want to dive deeper\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "### Want to dive deeper"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: ?\n\n- **Variations\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "?\\n\\n- **Variations"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: **: C\u2084\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "**: C\u2084"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  and CAM photosynthesis (\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " and CAM photosynthesis ("\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: adaptations for hot/d\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "adaptations for hot/d"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: ry environments).  \n- **Molecular details**\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: "ry environments).  \\n- **Molecular details**"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: : Structure of photosystems\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: ": Structure of photosystems"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  I & II, the\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " I & II, the"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  role of the electron carrier\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " role of the electron carrier"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  plastoquinone,\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " plastoquinone,"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  etc.  \n- **Biotechnological angles**\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " etc.  \\n- **Biotechnological angles**"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: : Engineering crops for higher\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: ": Engineering crops for higher"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  photosynthetic efficiency, artificial\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " photosynthetic efficiency, artificial"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  photosynthesis for clean energy\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " photosynthesis for clean energy"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: .\n\nFeel free to ask\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: ".\\n\\nFeel free to ask"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  if any part intrigues\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " if any part intrigues"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk:  you!\nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n    string_value: " you!"\n  }\n  id: "return"\n}\n\n---\nGenerated chunk: \nRequest ID for debugging: sdk-python-11.10.2-da226933309d40f58a35d585b3c188ce\nSuccess or error status code: 10000\nHuman-readable status description: Ok\nAdditional status details: \nPercent progress completed: 0\nNumber of Outputs: 1\nOutput status code: 10000\nOutput status description: \nRaw output data: parts {\n  data {\n  }\n  id: "return"\n}\n',v='import { Model } from "clarifai-nodejs";\n\nconst model = new Model({\n  url: "https://clarifai.com/openai/chat-completion/models/o4-mini",\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n  },\n});\n\nconst response = await model.predict({\n  // see available methodNames using model.availableMethods()\n  methodName: "predict",\n  prompt: "What is photosynthesis?",\n});\n\nconsole.log(JSON.stringify(response));\n\n// get response data from the response object\nModel.getOutputDataFromModelResponse(response);',A='import { Model } from "clarifai-nodejs";\n\nconst model = new Model({\n  url: "https://clarifai.com/openai/chat-completion/models/o4-mini",\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n  },\n});\n\nconst response = await model.predict({\n  // see available methodNames using model.availableMethods()\n  methodName: "predict",\n  prompt: "Describe the image",\n  image: {\n    url: "https://samples.clarifai.com/cat1.jpeg",\n  },\n});\n\nconsole.log(JSON.stringify(response));\n\n// get response data from the response object\nModel.getOutputDataFromModelResponse(response);',R='import { Model } from "clarifai-nodejs";\n\nconst model = new Model({\n  url: "https://clarifai.com/openai/chat-completion/models/o4-mini",\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n  },\n});\n\nconst responseStream = model.generate({\n  // see available methodNames using model.availableMethods()\n  methodName: "generate",\n  prompt: "what is photosynthesis?",\n});\n\nfor await (const response of responseStream) {\n  console.log(JSON.stringify(response));\n\n  // get response data from the response object\n  Model.getOutputDataFromModelResponse(response);\n}',I="Photosynthesis is the process by which certain organisms\u2014primarily plants, algae, and some bacteria\u2014convert light energy (usually from the sun) into chemical energy stored in sugars. In essence, these organisms capture carbon dioxide (CO\u2082) from the air and water (H\u2082O) from the soil, then use sunlight to drive a series of reactions that produce oxygen (O\u2082) as a by-product and synthesize glucose (C\u2086H\u2081\u2082O\u2086) or related carbohydrates.\n\nKey points:\n\n1. Light absorption\n   \u2022 Chlorophyll and other pigments in chloroplasts (in plants and algae) absorb photons, elevating electrons to higher energy states.\n\n2. Light-dependent reactions (in thylakoid membranes)\n   \u2022 Convert light energy into chemical energy in the form of ATP and NADPH.\n   \u2022 Split water molecules, releasing O\u2082.\n\n3. Calvin cycle (light-independent reactions, in the stroma)\n   \u2022 Use ATP and NADPH to fix CO\u2082 into organic molecules.\n   \u2022 Produce glyceraldehyde-3-phosphate (G3P), which can be converted into glucose and other carbs.\n\nOverall simplified equation:\n6 CO\u2082 + 6 H\u2082O + light energy \u2192 C\u2086H\u2081\u2082O\u2086 + 6 O\u2082\n\nImportance:\n\u2022 Generates the oxygen we breathe.\n\u2022 Forms the base of most food chains by producing organic matter.\n\u2022 Plays a critical role in the global carbon cycle and helps mitigate CO\u2082 in the atmosphere.",P="The image shows a young ginger tabby cat lying on its side against what looks like a rough, earth-toned wall. Its coat is a warm orange with classic darker orange stripe markings. The cat\u2019s front paw is tucked in, and its head rests on the surface below, with its large amber eyes gazing directly toward the viewer. The lighting is soft, highlighting the cat\u2019s whiskers, ear fur, and the texture of its velvety coat. Overall, the scene feels calm and slightly curious, as if the cat has paused mid-nap to watch something interesting.",w='from clarifai.client import Model\nfrom clarifai.runners.utils.data_types import Image\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize with model URL\nmodel = Model(\n    url="https://clarifai.com/openai/chat-completion/models/o4-mini",\n    # deployment_id="DEPLOYMENT_ID_HERE"\n)\n\nresponse_stream = model.generate(\n    prompt="Describe the image",\n    image=Image(url="https://samples.clarifai.com/cat1.jpeg") \n)\n\nfor text_chunk in response_stream:\n    print(text_chunk, end="", flush=True)\n\n\n"""\n# --- Predict using an image uploaded from a local machine ---\n\n# 1. Specify the path to your local image file\nlocal_image_path = "path/to/your/image.jpg"  # Replace with the actual path to your image\n\n# 2. Read the image file into bytes\nwith open(local_image_path, "rb") as f:\n    image_bytes = f.read()\n\nresponse_stream = model.generate(\n    prompt="Describe the image",\n    # Provide Image as bytes\n    image=Image(bytes=image_bytes)\n)\n\nfor text_chunk in response_stream:\n    print(text_chunk, end="", flush=True)\n\n# You can also convert a Pillow (PIL) Image object into a Clarifai Image data type \n# image=Image.from_pil(pil_image)\n\n"""',j='import { Model } from "clarifai-nodejs";\n\nconst model = new Model({\n  url: "https://clarifai.com/openai/chat-completion/models/o4-mini",\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n  },\n});\n\nconst responseStream = await model.generate({\n  // see available methodNames using model.availableMethods()\n  methodName: "generate",\n  prompt: "Describe the image",\n  image: {\n    url: "https://samples.clarifai.com/cat1.jpeg",\n  },\n});\n\nfor await (const response of responseStream) {\n    console.log(JSON.stringify(response));\n  \n    // get response data from the response object\n    Model.getOutputDataFromModelResponse(response);\n  }',S='from clarifai.client import Model\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize with model URL\nmodel = Model(url="https://clarifai.com/anthropic/completion/models/claude-sonnet-4")\n\n# Define tools \ntools = [\n    {\n        "type": "function",\n        "function": {\n            "name": "get_weather",\n            "description": "Get current temperature for a given location.",\n            "parameters": {\n                "type": "object",\n                "properties": {\n                    "location": {\n                        "type": "string",\n                        "description": "City and country e.g. Bogot\xe1, Colombia"\n                    },\n                    "units": {\n                        "type": "string",\n                        "description": "Temperature units, e.g. Celsius or Fahrenheit",\n                        "enum": ["Celsius", "Fahrenheit"]\n                    }\n                },\n                "required": ["location"],\n                "additionalProperties": False\n            },\n            "strict": True\n        }\n    }\n]\n\nresponse = model.generate(\n    prompt="What is the temperature in Tokyo in Celsius?",\n    tools=tools,\n    tool_choice=\'auto\',\n    max_tokens=1024,\n    temperature=0.5,\n)\n\n# Print response summary\nprint("Iterate or print response as needed:\\n", response)\n',T='# This example uses Matplotlib, Pillow, and NumPy. You can install them by running: pip install matplotlib Pillow numpy\n\nimport matplotlib.pyplot as plt\nfrom clarifai.runners.utils.data_types import Image\nfrom clarifai.client import Model\nfrom PIL import Image as PILImage\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize the model \nmodel = Model(\n    url="https://clarifai.com/meta/segment-anything/models/sam2_1-hiera-base-plus",\n    #deployment_id="DEPLOYMENT_ID_HERE"\n)\n\n# Load input image from URL\ninput_image = Image(url="https://samples.clarifai.com/cat1.jpeg")\n#Or, load from local file: input_image = Image.from_pil(PILImage.open("path/to/image.png"))\n\n# Run segmentation: returns a list of Region objects\nregions = model.segment_anything(image=input_image)\n\n# Loop through each Region, extract its mask, and display it\nfor idx, region in enumerate(regions):\n    mask = region.mask\n    #mask = Image.from_proto(region.mask.proto)  # Alternative low-level access\n    # region.mask is a Clarifai Image object; convert it to a NumPy array for visualization\n    mask_array = mask.to_numpy()\n\n    # Plot the mask with matplotlib\n    plt.figure(figsize=(5, 5))\n    plt.imshow(mask_array, cmap=\'gray\')\n    plt.title(f"Mask {idx + 1}")\n    plt.axis(\'off\')\n    plt.show()\n\n    # Print progress\n    print(f"Processed mask {idx + 1} out of {len(regions)}")\n\n    # Optional: do anything else with mask_array here\n    # (e.g., save to disk, overlay on the original image, etc.)\n',D='# This example uses Matplotlib, Pillow, and NumPy. You can install them by running: pip install matplotlib Pillow numpy\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image as PILImage\nfrom clarifai.client import Model\nfrom clarifai.runners.utils.data_types import Image, Region, Concept\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize the model \nmodel = Model(\n    url="https://clarifai.com/meta/segment-anything/models/sam2_1-hiera-base-plus",\n     #deployment_id="DEPLOYMENT_ID_HERE"\n)\n\ninput_image = Image(url="https://samples.clarifai.com/cat1.jpeg")\n# Load input image from local file\n#input_image = Image.from_pil(PILImage.open("path/to/image.png"))\n\n# Point-based input (Region form)\npoint_prompt_regions = [\n    Region(point=[0.1, 0.2, 0.0], concepts=[Concept(name="1", value=1.0)]),\n    Region(point=[0.2, 0.3, 0.0], concepts=[Concept(name="0", value=0.0)])\n]\n\nregions = model.predict(image=input_image, regions=point_prompt_regions, return_type="all")\n\n# # Optional: use dict format instead\n# point_prompt_dict = dict(points=[[0.1, 0.2], [0.2, 0.3]], labels=[1, 0])\n# regions = model.predict(image=input_image, dict_inputs=point_prompt_dict, return_type="all")\n\n# Box-based input (Region form)\n# box_prompt_regions = [Region(box=[0.1, 0.2, 0.3, 0.4])]\n# regions = model.predict(image=input_image, regions=box_prompt_regions, return_type="all")\n\n# # Optional: use dict format instead\n# box_prompt_dict = dict(box=[0.1, 0.2, 0.3, 0.4])\n# regions = model.predict(image=input_image, dict_inputs=box_prompt_dict, return_type="all")\n\n# Visualize each predicted mask\nfor idx, region in enumerate(regions):\n    mask = region.mask\n    #mask = Image.from_proto(region.mask.proto)  # Alternative low-level access\n    # region.mask is a Clarifai Image object; convert it to a NumPy array for visualization\n    mask_array = mask.to_numpy()\n\n    # Plot the mask with matplotlib\n    plt.figure(figsize=(5, 5))\n    plt.imshow(mask_array, cmap=\'gray\')\n    plt.title(f"Mask {idx + 1}")\n    plt.axis(\'off\')\n    plt.show()\n\n     # Print progress\n    print(f"Processed mask {idx + 1} out of {len(regions)}")\n\n    # Optional: do anything else with mask_array here\n    # (e.g., save to disk, overlay on the original image, etc.)\n',N='# This example uses Matplotlib, Pillow, and NumPy. You can install them by running: pip install matplotlib Pillow numpy\n\nimport matplotlib.pyplot as plt\nfrom clarifai.client import Model\nfrom clarifai.runners.utils.data_types import Video, Region, Concept, Frame\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Initialize the model \nmodel = Model(\n    url="https://clarifai.com/meta/segment-anything/models/sam2_1-hiera-base-plus",\n    #deployment_id="DEPLOYMENT_ID_HERE"\n)\n\n# Load video from a URL\nvideo = Video(url="https://samples.clarifai.com/beer.mp4")\n\n# Or: load from local file \n# video_path = "path/to/video.mp4"\n# with open(video_path, "rb") as f:\n#     video = Video(bytes=f.read())\n\n# Define frame-level prompts using Regions with track IDs\nframe0 = Frame(\n    regions=[\n        Region(point=[0.1, 0.2, 0.0], concepts=[Concept(name="1", value=1.0)], track_id="1"),\n        Region(point=[0.2, 0.3, 0.0], concepts=[Concept(name="0", value=0.0)], track_id="1"),\n    ]\n)\nframe0.proto.frame_info.index = 0\n\nframe1 = Frame(\n    regions=[\n        Region(point=[0.11, 0.22, 0.0], concepts=[Concept(name="1", value=1.0)], track_id="2"),\n        Region(point=[0.22, 0.33, 0.0], concepts=[Concept(name="0", value=0.0)], track_id="2"),\n    ]\n)\nframe1.proto.frame_info.index = 1\n\n# Generate masks using the frame-based approach\noutput_frames = model.generate(video=video, frames=[frame0, frame1], return_type="all")\n\n# Alternatively,  use `list_dict_inputs` instead\n# frame_objs = [\n#     dict(\n#         points=[[0.1, 0.2], [0.2, 0.3]],\n#         box=None,\n#         obj_id=0,\n#         labels=[1, 0],\n#         frame_idx=0\n#     ),\n#     dict(\n#         points=[[0.11, 0.22], [0.22, 0.33]],\n#         box=None,\n#         obj_id=1,\n#         labels=[1, 0],\n#         frame_idx=1\n#     ),\n# ]\n# output_frames = model.generate(video=video, list_dict_inputs=frame_objs, return_type="all")\n\n# Visualize the output masks\nfor frame_idx, frame in enumerate(output_frames):\n    for region_idx, region in enumerate(frame.regions):\n        mask = region.mask  # Clarifai Image object\n        track_id = region.track_id\n\n        # Convert mask to NumPy array\n        mask_array = mask.to_numpy()\n\n        # Show the mask\n        plt.figure(figsize=(5, 5))\n        plt.imshow(mask_array, cmap=\'gray\')\n        plt.title(f"Frame {frame_idx}, Region {region_idx}, Track ID: {track_id}")\n        plt.axis(\'off\')\n        plt.show()\n\n        print(f"Displayed mask for Frame {frame_idx}, Track ID: {track_id}")\n',H='from clarifai.client import Model\n\n# Initialize with explicit IDs\nmodel = Model(user_id="model_user_id", app_id="model_app_id", model_id="model_id")\n\n# Or initialize with model URL\nmodel = Model(url="https://clarifai.com/model_user_id/model_app_id/models/model_id")\n\n# Specify a model version\nmodel = Model(url="https://clarifai.com/model_user_id/model_app_id/models/model_id/model_version/model_version_id")\n\n# Or specify using the model_version parameter\nmodel = Model(url="https://clarifai.com/model_user_id/model_app_id/models/model_id", model_version = {"id": "model_version_id"})\n',E='import { Model } from "clarifai-nodejs";\n\nconst model = new Model({\n    modelId: "model_id",\n    modelUserAppId: {\n      userId: "model_user_id",\n      appId: "model_app_id",\n    },\n    authConfig: {\n      pat: "pat",\n    },\n  });',C='import asyncio\nfrom clarifai.client.model import Model\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Async main function\nasync def main():\n    # Initialize the model with the appropriate URL\n    model = Model(url="https://clarifai.com/openai/chat-completion/models/o4-mini")\n    \n    # Perform async prediction\n    model_prediction = await model.async_predict(\n        prompt="What is the value of pi?",\n        max_tokens=500\n    )\n\n    return await model_prediction\n\n# Entry point\nif __name__ == "__main__":\n    # Run the async main function and print the result\n    print(asyncio.run(main()))\n',q='import asyncio\nfrom clarifai.client.model import Model\n\n# Set PAT as an environment variable\n#   export CLARIFAI_PAT=YOUR_PAT_HERE # Unix-Like Systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE  # Windows\n\n# Async main function\nasync def main():\n    # Initialize the model with the appropriate URL\n    model = Model(url="https://clarifai.com/qwen/qwenLM/models/QwQ-32B-AWQ")\n\n    # Generate response asynchronously\n    generate_response = await model.async_generate(\n        prompt="What is the value of pi?",\n        max_tokens=100\n    )\n\n    # Iterate over the async generator to receive streamed results\n    async for response in await generate_response:\n        print(response)\n\n# Entry point\nif __name__ == "__main__":\n    # Run the main async function\n    asyncio.run(main())\n',G='response = model.predict(\n    prompt="What is photosynthesis?",\n    max_tokens=1024\n)\n',L='clarifai model predict --model_url https://clarifai.com/openai/chat-completion/models/o4-mini --inputs \'{"prompt": "What is photosynthesis?"}\'',M='clarifai model predict --model_url https://clarifai.com/openai/chat-completion/models/o4-mini --method generate --inputs \'{"prompt": "What is photosynthesis?"}\'',U='clarifai model predict --model_url https://clarifai.com/openai/chat-completion/models/gpt-oss-120b --inputs \'{"prompt": "What is photosynthesis?", "max_tokens": 100}\'',F='clarifai model predict --model_url https://clarifai.com/openai/chat-completion/models/o4-mini --inputs \'{"prompt": "Describe the image", "image": "https://samples.clarifai.com/cat1.jpeg"}\'',Y='clarifai model predict --model_url https://clarifai.com/openai/chat-completion/models/o4-mini --method generate --inputs \'{"prompt": "Describe the image", "image": "https://samples.clarifai.com/cat1.jpeg"}\'',W={description:"Generate predictions with models",sidebar_position:2,toc_max_heading_level:4},z="Inference via API",K={},V=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Install Clarifai Packages",id:"install-clarifai-packages",level:3},{value:"Get a PAT Key",id:"get-a-pat-key",level:3},{value:"Prediction Tips",id:"prediction-tips",level:2},{value:"Set Up Dedicated Deployment",id:"set-up-dedicated-deployment",level:4},{value:"Initialize the Model Client",id:"initialize-the-model-client",level:4},{value:"Set Up Inference Parameters",id:"set-up-inference-parameters",level:4},{value:"Unary-Unary Predict Call",id:"unary-unary-predict-call",level:2},{value:"Text Inputs",id:"text-inputs",level:3},{value:"Image Inputs",id:"image-inputs",level:3},{value:"Image-to-Text",id:"image-to-text",level:4},{value:"Visual Segmentation",id:"visual-segmentation",level:4},{value:"Example 1",id:"example-1",level:5},{value:"Arguments",id:"arguments",level:5},{value:"Returns",id:"returns",level:5},{value:"Example 2",id:"example-2",level:5},{value:"Arguments",id:"arguments-1",level:5},{value:"Returns",id:"returns-1",level:5},{value:"Unary-Stream Predict Call",id:"unary-stream-predict-call",level:2},{value:"Text Inputs",id:"text-inputs-1",level:3},{value:"Image Inputs",id:"image-inputs-1",level:3},{value:"Video Inputs",id:"video-inputs",level:3},{value:"Arguments",id:"arguments-2",level:5},{value:"Returns",id:"returns-2",level:5},{value:"Stream-Stream Predict Call",id:"stream-stream-predict-call",level:2},{value:"Text Inputs",id:"text-inputs-2",level:3},{value:"Audio Inputs",id:"audio-inputs",level:3},{value:"Multimodal Predictions",id:"multimodal-predictions",level:2},{value:"Batch Prediction Handling",id:"batch-prediction-handling",level:2},{value:"Text Inputs",id:"text-inputs-3",level:3},{value:"Image Inputs",id:"image-inputs-2",level:3},{value:"Tool Calling",id:"tool-calling",level:2},{value:"Asynchronous Inference",id:"asynchronous-inference",level:2},{value:"Async Prediction",id:"async-prediction",level:3},{value:"Async Generation",id:"async-generation",level:3},{value:"Raw Protobuf Response Information",id:"raw-protobuf-response-information",level:2},{value:"Predict With Protobuf",id:"predict-with-protobuf",level:3},{value:"Stream With Protobuf",id:"stream-with-protobuf",level:3}];function B(e){const t={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{Details:n}=t;return n||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"inference-via-api",children:"Inference via API"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.strong,{children:"Generate predictions with models"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsx)(t.admonition,{type:"tip",children:(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://github.com/Clarifai/examples/tree/main/models/model_predict",children:"Click here"})," for additional examples on how to perform model predictions using various SDKs \u2014 such as the Clarifai SDK, OpenAI client, and LiteLLM. The examples demonstrate various model types and include both streaming and non-streaming modes, as well as tool calling capabilities."]})}),"\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n",(0,a.jsx)(t.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsx)(t.h3,{id:"install-clarifai-packages",children:"Install Clarifai Packages"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["Install the latest version of the Clarifai ",(0,a.jsx)(t.a,{href:"https://github.com/Clarifai/clarifai-python/",children:"Python"})," SDK package. This also installs the ",(0,a.jsx)(t.a,{href:"https://docs.clarifai.com/resources/api-overview/cli",children:"Command Line Interface (CLI)"}),"."]}),"\n"]}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"bash",label:"Bash",children:(0,a.jsx)(d.A,{className:"language-bash",children:" pip install --upgrade clarifai "})})}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["Install the latest version of the Clarifai ",(0,a.jsx)(t.a,{href:"https://github.com/Clarifai/clarifai-nodejs",children:"Node.js"})," SDK package."]}),"\n"]}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"bash",label:"Bash",children:(0,a.jsx)(d.A,{className:"language-bash",children:" npm install clarifai-nodejs "})})}),"\n",(0,a.jsx)(t.h3,{id:"get-a-pat-key",children:"Get a PAT Key"}),"\n",(0,a.jsxs)(t.p,{children:["You need a ",(0,a.jsx)(t.a,{href:"https://docs.clarifai.com/control/authentication/pat/#how-to-create-a-pat-on-the-platform",children:"PAT"})," (Personal Access Token) key to authenticate your connection to the Clarifai platform. You can get one by navigating to ",(0,a.jsx)(t.strong,{children:"Settings"})," in the collapsible left sidebar, selecting ",(0,a.jsx)(t.strong,{children:"Secrets"}),", and creating or copying an existing token from there."]}),"\n",(0,a.jsxs)(t.p,{children:["You can then set the PAT as an environment variable using ",(0,a.jsx)(t.code,{children:"CLARIFAI_PAT"}),". This also authenticates your session when using the Clarifai\u2019s CLI."]}),"\n",(0,a.jsxs)(t.blockquote,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Note:"})," Storing your PAT in an environment variable is more secure than hardcoding it directly in your code."]}),"\n"]}),"\n",(0,a.jsxs)(o.A,{groupId:"code",children:[(0,a.jsx)(i.A,{value:"bash",label:"Unix-Like Systems",children:(0,a.jsx)(d.A,{className:"language-bash",children:" export CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE "})}),(0,a.jsx)(i.A,{value:"bash2",label:"Windows",children:(0,a.jsx)(d.A,{className:"language-bash",children:" set CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE "})})]}),"\n",(0,a.jsx)(t.h2,{id:"prediction-tips",children:"Prediction Tips"}),"\n",(0,a.jsx)(t.h4,{id:"set-up-dedicated-deployment",children:"Set Up Dedicated Deployment"}),"\n",(0,a.jsxs)(t.p,{children:["To use our dedicated Compute Orchestration capabilities, ensure your model is ",(0,a.jsx)(t.a,{href:"https://docs.clarifai.com/compute/deployments/deploy-model",children:"deployed"}),". Then, specify the ",(0,a.jsx)(t.code,{children:"deployment_id"})," parameter \u2014 alternatively, you can specify both ",(0,a.jsx)(t.code,{children:"compute_cluster_id"})," and ",(0,a.jsx)(t.code,{children:"nodepool_id"}),", as explained ",(0,a.jsx)(t.a,{href:"https://docs.clarifai.com/compute/inference/#predict-with-compute-orchestration",children:"here"}),"."]}),"\n",(0,a.jsx)(t.admonition,{type:"info",children:(0,a.jsxs)(t.p,{children:["For dedicated deployments that belong to a different user or organization, alongside the ",(0,a.jsx)(t.code,{children:"deployment_id"}),", also provide the user ID or the organization ID as the ",(0,a.jsx)(t.code,{children:"Model"}),"'s ",(0,a.jsx)(t.code,{children:"deployment_user_id"}),"."]})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-text",children:'model = Model(\n    url="MODEL_URL_HERE",  \n    deployment_id="DEPLOYMENT_ID_HERE",\n    # For a deployment owned by a different user or organization:\n    # deployment_user_id="USER_ID or ORGANIZATION_ID_HERE", \n    # Or, set cluster and nodepool \n    # compute_cluster_id = "COMPUTE_CLUSTER_ID_HERE",\n    # nodepool_id = "NODEPOOL_ID_HERE"\n)\n'})}),"\n",(0,a.jsx)(t.admonition,{title:"note",type:"caution",children:(0,a.jsxs)(t.p,{children:["Only a curated set of featured models can be run using the default Clarifai ",(0,a.jsx)(t.a,{href:"https://docs.clarifai.com/compute/overview#deployment-options",children:"Shared SaaS (Serverless)"})," deployment option. To run inferences with any other models, you must deploy them to your own cluster and nodepool and specify the ",(0,a.jsx)(t.code,{children:"deployment_id"})," parameter."]})}),"\n",(0,a.jsx)(t.h4,{id:"initialize-the-model-client",children:"Initialize the Model Client"}),"\n",(0,a.jsx)(t.p,{children:"You can initialize the model client using either explicit IDs or the full model URL."}),"\n",(0,a.jsxs)(t.blockquote,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Note:"})," By default, the latest version of the model is used for inference. However, you can specify a different version when initializing the model."]}),"\n"]}),"\n",(0,a.jsxs)(o.A,{groupId:"code",children:[(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:H})}),(0,a.jsx)(i.A,{value:"node.js",label:"Node.js SDK",children:(0,a.jsx)(d.A,{className:"language-javascript",children:E})})]}),"\n",(0,a.jsx)(t.h4,{id:"set-up-inference-parameters",children:"Set Up Inference Parameters"}),"\n",(0,a.jsxs)(t.p,{children:["You can configure various ",(0,a.jsx)(t.a,{href:"https://docs.clarifai.com/compute/inference/advanced/#types-of-inference-parameters",children:"inference parameters"})," to customize your prediction requests to better suit your use case."]}),"\n",(0,a.jsxs)(t.p,{children:["Here is an example using the ",(0,a.jsx)(t.code,{children:"max_tokens"})," parameter:"]}),"\n",(0,a.jsxs)(o.A,{groupId:"code",children:[(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:G})}),(0,a.jsx)(i.A,{value:"cli",label:"CLI",children:(0,a.jsx)(d.A,{className:"language-bash",children:U})})]}),"\n",(0,a.jsx)(t.admonition,{type:"note",children:(0,a.jsxs)(t.p,{children:["Before making a prediction with a model, it\u2019s important to understand how its prediction methods are structured. Learn more ",(0,a.jsx)(t.a,{href:"https://docs.clarifai.com/compute/inference/clarifai/#structure-of-prediction-methods",children:"here"}),"."]})}),"\n",(0,a.jsx)(t.h2,{id:"unary-unary-predict-call",children:"Unary-Unary Predict Call"}),"\n",(0,a.jsx)(t.p,{children:"This is the simplest form of prediction: a single input is sent to the model, and a single response is returned. It\u2019s ideal for quick, non-streaming tasks, such as classifying an image or analyzing a short piece of text."}),"\n",(0,a.jsxs)(t.blockquote,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"NOTE"}),": Streaming means that the response is streamed back token by token, rather than waiting for the entire completion to be generated before returning. This is useful for building interactive applications where you want to display the response as it's being generated."]}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"text-inputs",children:"Text Inputs"}),"\n",(0,a.jsxs)(o.A,{groupId:"code",children:[(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:c})}),(0,a.jsx)(i.A,{value:"cli",label:"CLI",children:(0,a.jsx)(d.A,{className:"language-bash",children:L})}),(0,a.jsx)(i.A,{value:"node.js",label:"Node.js SDK",children:(0,a.jsx)(d.A,{className:"language-javascript",children:v})})]}),"\n",(0,a.jsxs)(n,{children:[(0,a.jsx)("summary",{children:"Example Output"}),(0,a.jsx)(d.A,{className:"language-text",children:I})]}),"\n",(0,a.jsx)(t.h3,{id:"image-inputs",children:"Image Inputs"}),"\n",(0,a.jsx)(t.h4,{id:"image-to-text",children:"Image-to-Text"}),"\n",(0,a.jsxs)(o.A,{groupId:"code",children:[(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:u})}),(0,a.jsx)(i.A,{value:"cli",label:"CLI",children:(0,a.jsx)(d.A,{className:"language-bash",children:F})}),(0,a.jsx)(i.A,{value:"node.js",label:"Node.js SDK",children:(0,a.jsx)(d.A,{className:"language-javascript",children:A})})]}),"\n",(0,a.jsxs)(n,{children:[(0,a.jsx)("summary",{children:"Example Output"}),(0,a.jsx)(d.A,{className:"language-text",children:P})]}),"\n",(0,a.jsx)(t.h4,{id:"visual-segmentation",children:"Visual Segmentation"}),"\n",(0,a.jsx)(t.h5,{id:"example-1",children:"Example 1"}),"\n",(0,a.jsxs)(t.p,{children:["Here\u2019s an example that uses the ",(0,a.jsx)(t.a,{href:"https://clarifai.com/meta/segment-anything/models/sam2_1-hiera-base-plus",children:"sam2_1-hiera-base-plus"})," model to automatically generate masks for all objects in a given image."]}),"\n",(0,a.jsxs)(n,{children:[(0,a.jsx)("summary",{children:"Arguments and Returns"}),(0,a.jsx)(t.p,{children:"These are the model\u2019s arguments and return values:"}),(0,a.jsx)(t.h5,{id:"arguments",children:"Arguments"}),(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"image (Image)"}),": The input image"]}),"\n"]}),(0,a.jsx)(t.h5,{id:"returns",children:"Returns"}),(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"List[Region]"}),": List of generated masks, which can be accessed via ",(0,a.jsx)(t.code,{children:"region.mask"})," or ",(0,a.jsx)(t.code,{children:"region.proto.region_info.mask"}),"."]}),"\n"]})]}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:T})})}),"\n",(0,a.jsx)(t.h5,{id:"example-2",children:"Example 2"}),"\n",(0,a.jsx)(t.p,{children:"Here\u2019s an example that uses the sam2_1-hiera-base-plus model to generate masks using points or boxes prompt."}),"\n",(0,a.jsxs)(n,{children:[(0,a.jsx)("summary",{children:"Arguments and Returns"}),(0,a.jsx)(t.p,{children:"These are the model\u2019s arguments and return values:"}),(0,a.jsx)(t.h5,{id:"arguments-1",children:"Arguments"}),(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"image (Image)"}),": The input image."]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"regions (List[Region])"}),": A list of region prompts, where each region can specify either points or a bounding box."]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["To indicate a positive (object) point, set:\n",(0,a.jsx)(t.code,{children:'region.concepts = [Concepts(name="1", value=1)]'})]}),"\n",(0,a.jsxs)(t.li,{children:["To indicate a negative (background) point, set:\n",(0,a.jsx)(t.code,{children:'region.concepts = [Concepts(name="0", value=0)]'})]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"dict_inputs (Dict)"}),": Keyword arguments passed directly to the ",(0,a.jsx)(t.code,{children:"SAM2ImagePredictor.predict(...)"})," method. Refer to ",(0,a.jsx)(t.a,{href:"https://github.com/facebookresearch/sam2/blob/main/notebooks/image_predictor_example.ipynb",children:"this example"})," for details."]}),"\n"]}),"\n"]}),(0,a.jsxs)(t.blockquote,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Note:"})," You may provide either ",(0,a.jsx)(t.code,{children:"regions"})," or ",(0,a.jsx)(t.code,{children:"dict_inputs"}),", but not both."]}),"\n"]}),(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"multimask_output (bool)"}),": Whether to return multiple masks for each prompt. Defaults to ",(0,a.jsx)(t.code,{children:"False"}),"."]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"return_type (str)"}),": Specifies the type of output to return. Must be one of:"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"box"})," \u2014 return bounding boxes only"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"mask"})," \u2014 return masks only"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"all"})," \u2014 return both bounding boxes and masks"]}),"\n"]}),"\n"]}),"\n"]}),(0,a.jsx)(t.h5,{id:"returns-1",children:"Returns"}),(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"List[Region]"}),": A list of generated regions. Masks can be accessed via ",(0,a.jsx)(t.code,{children:"region.mask"})," or ",(0,a.jsx)(t.code,{children:"region.proto.region_info.mask"}),"."]}),"\n"]})]}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:D})})}),"\n",(0,a.jsx)(t.admonition,{type:"tip",children:(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://docs.clarifai.com/compute/models/model-upload/data-types/",children:"Click here"})," to explore how to make predictions with other data types."]})}),"\n",(0,a.jsx)(t.h2,{id:"unary-stream-predict-call",children:"Unary-Stream Predict Call"}),"\n",(0,a.jsx)(t.p,{children:"This call sends a single input to the model but returns a stream of responses. This is especially useful for tasks that produce multiple outputs from one input, such as generating text completions or progressive predictions from a prompt."}),"\n",(0,a.jsx)(t.h3,{id:"text-inputs-1",children:"Text Inputs"}),"\n",(0,a.jsxs)(o.A,{groupId:"code",children:[(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:l})}),(0,a.jsx)(i.A,{value:"cli",label:"CLI",children:(0,a.jsx)(d.A,{className:"language-bash",children:M})}),(0,a.jsx)(i.A,{value:"node.js",label:"Node.js SDK",children:(0,a.jsx)(d.A,{className:"language-javascript",children:R})})]}),"\n",(0,a.jsx)(t.h3,{id:"image-inputs-1",children:"Image Inputs"}),"\n",(0,a.jsxs)(o.A,{groupId:"code",children:[(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:w})}),(0,a.jsx)(i.A,{value:"cli",label:"CLI",children:(0,a.jsx)(d.A,{className:"language-bash",children:Y})}),(0,a.jsx)(i.A,{value:"node.js",label:"Node.js SDK",children:(0,a.jsx)(d.A,{className:"language-javascript",children:j})})]}),"\n",(0,a.jsx)(t.h3,{id:"video-inputs",children:"Video Inputs"}),"\n",(0,a.jsxs)(t.p,{children:["Here\u2019s an example that uses the ",(0,a.jsx)(t.a,{href:"https://clarifai.com/meta/segment-anything/models/sam2_1-hiera-base-plus",children:"sam2_1-hiera-base-plus"})," model to automatically track objects in a video."]}),"\n",(0,a.jsxs)(n,{children:[(0,a.jsx)("summary",{children:"Arguments and Returns"}),(0,a.jsx)(t.p,{children:"These are the model\u2019s arguments and return values:"}),(0,a.jsx)(t.h5,{id:"arguments-2",children:"Arguments"}),(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"video (Video):"})," The input video."]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"frames (List[Frame]):"}),"\nA list of frames containing tracking prompts. For each frame:"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"frame.data.regions"})," specifies object locations using points or bounding boxes, as described in the ",(0,a.jsx)(t.code,{children:"predict"})," method."]}),"\n",(0,a.jsxs)(t.li,{children:["The frame index is identified by ",(0,a.jsx)(t.code,{children:"frame.frame_info.index"}),"."]}),"\n",(0,a.jsxs)(t.li,{children:["The object identity is specified using ",(0,a.jsx)(t.code,{children:"frame.data.regions[...].track_id"}),"."]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"list_dict_inputs (List[Dict]):"}),"\nA list of dictionaries following the ",(0,a.jsx)(t.code,{children:"SAM2VideoPredictor.add_new_points_or_box()"})," method signature. Each dictionary may include ",(0,a.jsx)(t.code,{children:"points"}),", ",(0,a.jsx)(t.code,{children:"box"}),", ",(0,a.jsx)(t.code,{children:"obj_id"}),", ",(0,a.jsx)(t.code,{children:"labels"}),", and ",(0,a.jsx)(t.code,{children:"frame_idx"}),". Refer to ",(0,a.jsx)(t.a,{href:"https://github.com/facebookresearch/sam2/blob/main/notebooks/video_predictor_example.ipynb",children:"this example"})," for details."]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"return_type (str):"})," Specifies the type of output to return. Must be one of:"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"box"})," \u2014 return bounding boxes only"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"mask"})," \u2014 return masks only"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"all"})," \u2014 return both bounding boxes and masks"]}),"\n"]}),"\n"]}),"\n"]}),(0,a.jsxs)(t.blockquote,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Note:"})," You may provide either ",(0,a.jsx)(t.code,{children:"frames"})," or ",(0,a.jsx)(t.code,{children:"list_dict_inputs"}),", but not both at the same time."]}),"\n"]}),(0,a.jsx)(t.h5,{id:"returns-2",children:"Returns"}),(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Iterator[Frame]:"})," An iterator over frames containing the generated masks and tracked object results for each frame."]}),"\n"]})]}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:N})})}),"\n",(0,a.jsx)(t.h2,{id:"stream-stream-predict-call",children:"Stream-Stream Predict Call"}),"\n",(0,a.jsx)(t.p,{children:"This call enables bidirectional streaming of both inputs and outputs, making it ideal for real-time applications and processing large datasets."}),"\n",(0,a.jsx)(t.p,{children:"In this setup, multiple inputs can be continuously streamed to the model, while predictions are returned in real time. It\u2019s especially useful for use cases like live video analysis or streaming sensor data."}),"\n",(0,a.jsx)(t.h3,{id:"text-inputs-2",children:"Text Inputs"}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:h})})}),"\n",(0,a.jsx)(t.h3,{id:"audio-inputs",children:"Audio Inputs"}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:p})})}),"\n",(0,a.jsx)(t.h2,{id:"multimodal-predictions",children:"Multimodal Predictions"}),"\n",(0,a.jsx)(t.p,{children:"You can make predictions using models that support multimodal inputs, such as a combination of images and text."}),"\n",(0,a.jsx)(t.p,{children:"Here is an example:"}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:f})})}),"\n",(0,a.jsx)(t.h2,{id:"batch-prediction-handling",children:"Batch Prediction Handling"}),"\n",(0,a.jsx)(t.p,{children:"Clarifai\u2019s model framework seamlessly supports both single and batch predictions through a unified interface. It can adapt to the input format, so no code changes are needed."}),"\n",(0,a.jsx)(t.p,{children:"The system automatically detects the type of input provided:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"If you pass a single input, it\u2019s treated as a singleton batch;"}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"If you pass multiple inputs as a list, they are handled as a parallel batch."}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"This means you can pass either a single input or a list of inputs, and the system will automatically process them appropriately \u2014 making your code cleaner and more flexible."}),"\n",(0,a.jsx)(t.h3,{id:"text-inputs-3",children:"Text Inputs"}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:g})})}),"\n",(0,a.jsxs)(n,{children:[(0,a.jsx)("summary",{children:"Example Output"}),(0,a.jsx)(d.A,{className:"language-text",children:b})]}),"\n",(0,a.jsx)(t.h3,{id:"image-inputs-2",children:"Image Inputs"}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:m})})}),"\n",(0,a.jsxs)(n,{children:[(0,a.jsx)("summary",{children:"Example Output"}),(0,a.jsx)(d.A,{className:"language-text",children:y})]}),"\n",(0,a.jsx)(t.h2,{id:"tool-calling",children:"Tool Calling"}),"\n",(0,a.jsx)(t.p,{children:"Tool calling in LLMs is a capability that allows models to autonomously decide when and how to call external tools, functions, or APIs during a conversation \u2014 based on the user\u2019s input and the context."}),"\n",(0,a.jsxs)(t.p,{children:["You can learn more about it ",(0,a.jsx)(t.a,{href:"https://docs.clarifai.com/compute/models/inference/open-ai#tool-calling",children:"here"}),"."]}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:S})})}),"\n",(0,a.jsx)(t.h2,{id:"asynchronous-inference",children:"Asynchronous Inference"}),"\n",(0,a.jsxs)(t.p,{children:["Asynchronous inference enables non-blocking execution of model prediction tasks. Instead of waiting for each prediction to complete before proceeding, you can use the ",(0,a.jsx)(t.code,{children:"async_predict"})," and ",(0,a.jsx)(t.code,{children:"async_generate"})," methods to submit multiple requests concurrently and retrieve the results once they're ready."]}),"\n",(0,a.jsx)(t.h3,{id:"async-prediction",children:"Async Prediction"}),"\n",(0,a.jsx)(t.p,{children:"You can use this for standard prediction tasks that return a complete result in a single response. The output is typically a structured object, like a dictionary or JSON."}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:C})})}),"\n",(0,a.jsx)(t.h3,{id:"async-generation",children:"Async Generation"}),"\n",(0,a.jsx)(t.p,{children:"You can use this for generative models that produce output incrementally \u2014 such as large language models that stream tokens one by one. The response is an asynchronous stream, which you iterate over."}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:q})})}),"\n",(0,a.jsx)(t.h2,{id:"raw-protobuf-response-information",children:"Raw Protobuf Response Information"}),"\n",(0,a.jsxs)(t.p,{children:["By default, prediction methods in the ",(0,a.jsx)(t.a,{href:"https://docs.clarifai.com/resources/api-references/python#model",children:(0,a.jsx)(t.code,{children:"Model"})})," class \u2014 such as ",(0,a.jsx)(t.code,{children:"predict()"}),", ",(0,a.jsx)(t.code,{children:"generate()"}),", and others \u2014 return only the processed, user-friendly response."]}),"\n",(0,a.jsxs)(t.p,{children:["If you need deeper insight, you can pass ",(0,a.jsx)(t.code,{children:"with_proto=True"}),", which makes the method return a tuple containing both the processed result and the underlying raw Protobuf response."]}),"\n",(0,a.jsxs)(t.p,{children:["Note that ",(0,a.jsx)(t.code,{children:"with_proto=False"})," is the default behavior, meaning only the processed result is returned without the raw protobuf data."]}),"\n",(0,a.jsxs)(t.blockquote,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Note:"}),"  This parameter is supported in both ",(0,a.jsx)(t.a,{href:"#asynchronous-inference",children:"synchronous and asynchronous"})," model operations."]}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"predict-with-protobuf",children:"Predict With Protobuf"}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:O})})}),"\n",(0,a.jsxs)(n,{children:[(0,a.jsx)("summary",{children:"Example Output"}),(0,a.jsx)(d.A,{className:"language-text",children:x})]}),"\n",(0,a.jsx)(t.h3,{id:"stream-with-protobuf",children:"Stream With Protobuf"}),"\n",(0,a.jsx)(o.A,{groupId:"code",children:(0,a.jsx)(i.A,{value:"python",label:"Python SDK",children:(0,a.jsx)(d.A,{className:"language-python",children:_})})}),"\n",(0,a.jsxs)(n,{children:[(0,a.jsx)("summary",{children:"Example Output"}),(0,a.jsx)(d.A,{className:"language-text",children:k})]}),"\n",(0,a.jsxs)(t.admonition,{type:"tip",children:[(0,a.jsxs)(t.p,{children:["Retrieving raw Protobuf response information works with any custom method defined in the ",(0,a.jsx)(t.code,{children:"ModelClient"})," class. For example:"]}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'result, proto = model.my_custom_method(\n    input_data="some data",\n    temperature=0.7,\n    with_proto=True\n)\n'})})]})]})}function J(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(B,{...e})}):B(e)}}}]);