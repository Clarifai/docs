"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[1519],{9740:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/custom_model_create_model-5b14bd9190511a632e1c15ecf7ea9f70.png"},18987:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/custom_models_upload_inputs_window-fdeee91b1f0caba8d132de52c85e90ae.png"},26412:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/custom_model_create_model_page-d3a3262a7b48330cbd3fd6486d82f663.png"},49256:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/illustration-training-22112a4ec017ebaf5f8c40832742148d.png"},50069:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/custom_model_upload_inputs-6a57515612d503ecd87f98770cab6c24.png"},54316:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/custom_models_upload_inputs_window_2-3e3246946db05ec574ed1e5b555569a0.png"},65537:(e,n,t)=>{t.d(n,{A:()=>w});var s=t(96540),a=t(18215),i=t(65627),o=t(56347),r=t(50372),l=t(30604),c=t(11861),d=t(78749);function p(e){return s.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,s.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function u(e){const{values:n,children:t}=e;return(0,s.useMemo)((()=>{const e=n??function(e){return p(e).map((e=>{let{props:{value:n,label:t,attributes:s,default:a}}=e;return{value:n,label:t,attributes:s,default:a}}))}(t);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function h(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function _(e){let{queryString:n=!1,groupId:t}=e;const a=(0,o.W6)(),i=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,l.aZ)(i),(0,s.useCallback)((e=>{if(!i)return;const n=new URLSearchParams(a.location.search);n.set(i,e),a.replace({...a.location,search:n.toString()})}),[i,a])]}function m(e){const{defaultValue:n,queryString:t=!1,groupId:a}=e,i=u(e),[o,l]=(0,s.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!h({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const s=t.find((e=>e.default))??t[0];if(!s)throw new Error("Unexpected error: 0 tabValues");return s.value}({defaultValue:n,tabValues:i}))),[c,p]=_({queryString:t,groupId:a}),[m,g]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[a,i]=(0,d.Dv)(t);return[a,(0,s.useCallback)((e=>{t&&i.set(e)}),[t,i])]}({groupId:a}),f=(()=>{const e=c??m;return h({value:e,tabValues:i})?e:null})();(0,r.A)((()=>{f&&l(f)}),[f]);return{selectedValue:o,selectValue:(0,s.useCallback)((e=>{if(!h({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);l(e),p(e),g(e)}),[p,g,i]),tabValues:i}}var g=t(9136);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var I=t(74848);function E(e){let{className:n,block:t,selectedValue:s,selectValue:o,tabValues:r}=e;const l=[],{blockElementScrollPositionUntilNextRender:c}=(0,i.a_)(),d=e=>{const n=e.currentTarget,t=l.indexOf(n),a=r[t].value;a!==s&&(c(n),o(a))},p=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return(0,I.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":t},n),children:r.map((e=>{let{value:n,label:t,attributes:i}=e;return(0,I.jsx)("li",{role:"tab",tabIndex:s===n?0:-1,"aria-selected":s===n,ref:e=>{l.push(e)},onKeyDown:p,onClick:d,...i,className:(0,a.A)("tabs__item",f.tabItem,i?.className,{"tabs__item--active":s===n}),children:t??n},n)}))})}function C(e){let{lazy:n,children:t,selectedValue:i}=e;const o=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=o.find((e=>e.props.value===i));return e?(0,s.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,I.jsx)("div",{className:"margin-top--md",children:o.map(((e,n)=>(0,s.cloneElement)(e,{key:n,hidden:e.props.value!==i})))})}function A(e){const n=m(e);return(0,I.jsxs)("div",{className:(0,a.A)("tabs-container",f.tabList),children:[(0,I.jsx)(E,{...n,...e}),(0,I.jsx)(C,{...n,...e})]})}function w(e){const n=(0,g.A)();return(0,I.jsx)(A,{...e,children:p(e.children)},String(n))}},72942:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/custom_model_create_new_model-2-b4c52569b6dd51b928abaab35b5cda9b.png"},75945:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/custom_model_create_model_page-2-2914b307a275a224ae34887347285bc4.png"},79329:(e,n,t)=>{t.d(n,{A:()=>o});t(96540);var s=t(18215);const a={tabItem:"tabItem_Ymn6"};var i=t(74848);function o(e){let{children:n,hidden:t,className:o}=e;return(0,i.jsx)("div",{role:"tabpanel",className:(0,s.A)(a.tabItem,o),hidden:t,children:n})}},81763:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/custom_model_create_new_model-ccd9b68babc717393174fe83eba5e36e.png"},89365:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/custom_model_dataset_version-511303e31a43922a3df1f837f0da6237.png"},93825:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>k,contentTitle:()=>Y,default:()=>G,frontMatter:()=>H,metadata:()=>s,toc:()=>$});const s=JSON.parse('{"id":"create/models/transfer-learning/visual-classifier","title":"Visual Classifier","description":"Learn how to use transfer learning to create custom visual classifier model","source":"@site/docs/create/models/transfer-learning/visual-classifier.md","sourceDirName":"create/models/transfer-learning","slug":"/create/models/transfer-learning/visual-classifier","permalink":"/create/models/transfer-learning/visual-classifier","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"description":"Learn how to use transfer learning to create custom visual classifier model","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Text Classifier","permalink":"/create/models/transfer-learning/text-classifier"},"next":{"title":"Deep Fine-Tuning","permalink":"/create/models/deep-fine-tuning/"}}');var a=t(74848),i=t(28453),o=t(65537),r=t(79329),l=t(58069);const c="##############################################################################\n# In this section, we set the user authentication, app ID, and the images and \n# concepts we want to add. Change these strings to run your own example.\n##############################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the Account's Security section\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to add your own images with concepts\nIMAGE_URL_1 = 'https://samples.clarifai.com/puppy.jpeg'\nIMAGE_URL_2 = 'https://samples.clarifai.com/wedding.jpg'\nCONCEPT_ID_1 = 'charlie'\nCONCEPT_ID_2 = 'our_wedding'\nCONCEPT_ID_3 = 'our_wedding'\nCONCEPT_ID_4 = 'charlie'\nCONCEPT_ID_5 = 'cat'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\npost_inputs_response = stub.PostInputs(\n    service_pb2.PostInputsRequest(\n        user_app_id=userDataObject,\n        inputs=[\n            resources_pb2.Input(\n                data=resources_pb2.Data(\n                    image=resources_pb2.Image(\n                        url=IMAGE_URL_1,\n                        allow_duplicate_url=True\n                    ),\n                    concepts=[\n                        resources_pb2.Concept(id=CONCEPT_ID_1, value=1),\n                        resources_pb2.Concept(id=CONCEPT_ID_2, value=0),\n                    ]\n                )\n            ),\n            resources_pb2.Input(\n                data=resources_pb2.Data(\n                    image=resources_pb2.Image(\n                        url=IMAGE_URL_2,\n                        allow_duplicate_url=True\n                    ),\n                    concepts=[\n                        resources_pb2.Concept(id=CONCEPT_ID_3, value=1),\n                        resources_pb2.Concept(id=CONCEPT_ID_4, value=0),\n                        resources_pb2.Concept(id=CONCEPT_ID_5, value=0),\n                    ]\n                )\n            ),\n        ]\n    ),\n    metadata=metadata\n)\n\nif post_inputs_response.status.code != status_code_pb2.SUCCESS:\n    print(\"There was an error with your request!\")\n    for input_object in post_inputs_response.inputs:\n        print(\"Input \" + input_object.id + \" status:\")\n        print(input_object.status)\n   \n    print(post_inputs_response.status)\n    raise Exception(\"Post inputs failed, status: \" + post_inputs_response.status.description)\n\nprint(post_inputs_response)\n",d="##############################################################################\n# In this section, we set the user authentication, app ID, and model ID.\n# Change these strings to run your own example.\n##############################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the Account's Security section\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change this to create your own model\nMODEL_ID = 'my-pets'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\npost_models_response = stub.PostModels(\n    service_pb2.PostModelsRequest(\n        user_app_id=userDataObject,\n        models=[\n            resources_pb2.Model(\n                id=MODEL_ID                            \n            )\n        ]\n    ),\n    metadata=metadata\n)\n\nif post_models_response.status.code != status_code_pb2.SUCCESS:\n    print(post_models_response.status)\n    raise Exception(\"Post models failed, status: \" + post_models_response.status.description)\n\n",p="########################################################################################\n# In this section, we set the user authentication, app ID, model ID, and concept IDs.\n# Change these strings to run your own example.\n########################################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the Account's Security section\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to train your own model\nMODEL_ID = 'my-pets'\nCONCEPT_ID_1 = 'charlie'\nCONCEPT_ID_2 = 'our_wedding'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\npost_model_versions = stub.PostModelVersions(\n    service_pb2.PostModelVersionsRequest(\n        user_app_id=userDataObject,\n        model_id=MODEL_ID,\n        model_versions=[\n            resources_pb2.ModelVersion(\n                output_info=resources_pb2.OutputInfo(\n                    data=resources_pb2.Data(\n                        concepts=[\n                            resources_pb2.Concept(id=CONCEPT_ID_1, value=1), # 1 means true, this concept is present\n                            resources_pb2.Concept(id=CONCEPT_ID_2, value=1)\n                            ] \n                        ),\n                )\n            )]\n    ),\n    metadata=metadata\n)\n\nif post_model_versions.status.code != status_code_pb2.SUCCESS:\n    print(post_model_versions.status)\n    raise Exception(\"Post models versions failed, status: \" + post_model_versions.status.description)\n",u="####################################################################################\n# In this section, we set the user authentication, app ID, model ID, model version, \n# and image URL. Change these strings to run your own example.\n####################################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the Account's Security section\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to make your own predictions\nMODEL_ID = 'my-pets'\nMODEL_VERSION = '8eb21f63ba9d40c7b84ecfd664ac603d'\nIMAGE_URL = 'https://samples.clarifai.com/puppy.jpeg'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\npost_model_outputs_response = stub.PostModelOutputs(\n    service_pb2.PostModelOutputsRequest(\n        user_app_id=userDataObject,\n        model_id=MODEL_ID,\n        version_id=MODEL_VERSION,  # This is optional. Defaults to the latest model version.\n        inputs=[\n            resources_pb2.Input(\n                data=resources_pb2.Data(\n                    image=resources_pb2.Image(\n                        url=IMAGE_URL\n                    )\n                )\n            )\n        ]\n    ),\n    metadata=metadata\n)\n\nif post_model_outputs_response.status.code != status_code_pb2.SUCCESS:\n    print(post_model_outputs_response.status)\n    raise Exception(\"Post model outputs failed, status: \" + post_model_outputs_response.status.description)\n\n# Since we have one input, one output will exist here.\noutput = post_model_outputs_response.outputs[0]\n\nprint(\"Predicted concepts:\")\nfor concept in output.data.concepts:\n    print(\"%s %.2f\" % (concept.name, concept.value))\n\n# Uncomment this line to print the raw output\n#print(post_model_outputs_response)",h='\x3c!--index.html file--\x3e\n\n<script>\n    //////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, and the images and \n    // concepts we want to add. Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////////\n\n    const USER_ID = \'YOUR_USER_ID_HERE\';\n    // Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    const PAT = \'YOUR_PAT_HERE\';\n    const APP_ID = \'YOUR_APP_ID_HERE\';\n    // Change these to add your own images with concepts\n    const IMAGE_URL_1 = \'https://samples.clarifai.com/puppy.jpeg\';\n    const IMAGE_URL_2 = \'https://samples.clarifai.com/wedding.jpg\';\n    const CONCEPT_ID_1 = \'charlie\';\n    const CONCEPT_ID_2 = \'our_wedding\';\n    const CONCEPT_ID_3 = \'our_wedding\';\n    const CONCEPT_ID_4 = \'charlie\';\n    const CONCEPT_ID_5 = \'cat\';\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    const raw = JSON.stringify({\n        "user_app_id": {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        "inputs": [\n            {\n                "data": {\n                    "image": {\n                        "url": IMAGE_URL_1,\n                        "allow_duplicate_url": true\n                    },\n                    "concepts": [\n                        {\n                            "id": CONCEPT_ID_1,\n                            "value": 1\n                        },\n                        {\n                            "id": CONCEPT_ID_2,\n                            "value": 0\n                        }\n                    ]\n                }\n            },\n            {\n                "data": {\n                    "image": {\n                        "url": IMAGE_URL_2,\n                        "allow_duplicate_url": true\n                    },\n                    "concepts": [\n                        {\n                            "id": CONCEPT_ID_3,\n                            "value": 1\n                        },\n                        {\n                            "id": CONCEPT_ID_4,\n                            "value": 0\n                        },\n                        {\n                            "id": CONCEPT_ID_5,\n                            "value": 0\n                        }\n                    ]\n                }\n            }\n        ]\n    });\n\n    const requestOptions = {\n        method: \'POST\',\n        headers: {\n            \'Accept\': \'application/json\',\n            \'Authorization\': \'Key \' + PAT\n        },\n        body: raw\n    };\n\n    fetch("https://api.clarifai.com/v2/inputs", requestOptions)\n        .then(response => response.text())\n        .then(result => console.log(result))\n        .catch(error => console.log(\'error\', error));\n\n<\/script>',_="\x3c!--index.html file--\x3e\n\n<script>\n    //////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, and model ID.\n    // Change these strings to run your own example.\n    //////////////////////////////////////////////////////////////////////////////\n\n    const USER_ID = 'YOUR_USER_ID_HERE';\n    // Your PAT (Personal Access Token) can be found in the Account's Security section\n    const PAT = 'YOUR_PAT_HERE';\n    const APP_ID = 'YOUR_APP_ID_HERE';\n    // Change this to create your own model\n    const MODEL_ID = 'my-pets';\n        \n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    const raw = JSON.stringify({\n        \"user_app_id\": {\n            \"user_id\": USER_ID,\n            \"app_id\": APP_ID\n        },\n        \"model\": {\n            \"id\": MODEL_ID       \n        }\n    });\n\n    const requestOptions = {\n        method: 'POST',\n        headers: {\n            'Accept': 'application/json',\n            'Authorization': 'Key ' + PAT\n        },\n        body: raw\n    };\n\n    fetch(\"https://api.clarifai.com/v2/models\", requestOptions)\n        .then(response => response.text())\n        .then(result => console.log(result))\n        .catch(error => console.log('error', error));\n\n<\/script>",m="\x3c!--index.html file--\x3e\n\n<script>\n  ////////////////////////////////////////////////////////////////////////////////////////\n  // In this section, we set the user authentication, app ID, model ID, and concept IDs. \n  // Change these strings to run your own example.\n  ///////////////////////////////////////////////////////////////////////////////////////\n\n  const USER_ID = 'YOUR_USER_ID_HERE';\n  // Your PAT (Personal Access Token) can be found in the Account's Security section\n  const PAT = 'YOUR_PAT_HERE';\n  const APP_ID = 'YOUR_APP_ID_HERE';\n  // Change these to train your own model\n  const MODEL_ID = 'my-pets';  \n  const CONCEPT_ID_1 = 'charlie';\n  const CONCEPT_ID_2 = 'our_wedding';\n\n  ///////////////////////////////////////////////////////////////////////////////////\n  // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n  ///////////////////////////////////////////////////////////////////////////////////\n\n  const raw = JSON.stringify({\n      \"user_app_id\": {\n          \"user_id\": USER_ID,\n          \"app_id\": APP_ID\n      },         \n      \"model_versions\":[{\n          \"output_info\": {\n              \"data\":{\n                  \"concepts\":[\n                          {\n                              \"id\": CONCEPT_ID_1,\n                              \"value\": 1\n                          },\n                          {\n                              \"id\": CONCEPT_ID_2,\n                              \"value\": 1\n                          },\n                      ]\n                  }\n              }\n          }]              \n \n  });\n\n  const requestOptions = {\n      method: 'POST',\n      headers: {\n          'Content-Type': 'application/json',\n          'Authorization': 'Key ' + PAT\n      },\n      body: raw\n  };\n\n  fetch(`https://api.clarifai.com/v2/models/${MODEL_ID}/versions`, requestOptions)\n      .then(response => response.text())\n      .then(result => console.log(result))\n      .catch(error => console.log('error', error));\n\n<\/script>",g="\x3c!--index.html file--\x3e\n\n<script>\n    //////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, model version, \n    // and image URL. Change these strings to run your own example.\n    //////////////////////////////////////////////////////////////////////////////////////\n\n    const USER_ID = 'YOUR_USER_ID_HERE';\n    // Your PAT (Personal Access Token) can be found in the Account's Security section\n    const PAT = 'YOUR_PAT_HERE';\n    const APP_ID = 'YOUR_APP_ID_HERE';\n    // Change these to make your own predictions\n    const MODEL_ID = 'my-pets';\n    const MODEL_VERSION = '6f2c3e043b3e49bdafd38851fb5675d5';\n    const IMAGE_URL = 'https://samples.clarifai.com/metro-north.jpg';\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    const raw = JSON.stringify({\n        \"user_app_id\": {\n            \"user_id\": USER_ID,\n            \"app_id\": APP_ID\n        },\n        \"inputs\": [\n            {\n                \"data\": {\n                    \"image\": {\n                        \"url\": IMAGE_URL\n                    }\n                }\n            }\n        ]\n    });\n\n    const requestOptions = {\n        method: 'POST',\n        headers: {\n            'Accept': 'application/json',\n            'Authorization': 'Key ' + PAT\n        },\n        body: raw\n    };\n\n    // NOTE: MODEL_VERSION_ID is optional, you can also call prediction with the MODEL_ID only\n    // https://api.clarifai.com/v2/models/{YOUR_MODEL_ID}/outputs\n    // this will default to the latest version_id\n\n    fetch(`https://api.clarifai.com/v2/models/${MODEL_ID}/versions/${MODEL_VERSION}/outputs`, requestOptions)\n        .then(response => response.text())\n        .then(result => console.log(result))\n        .catch(error => console.log('error', error));\n\n<\/script>",f="//index.js file\n\n//////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, and the images and \n// concepts we want to add. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = 'YOUR_USER_ID_HERE';\n// Your PAT (Personal Access Token) can be found in the Account's Security section\nconst PAT = 'YOUR_PAT_HERE';\nconst APP_ID = 'YOUR_APP_ID_HERE';\n// Change these to add your own images with concepts\nconst IMAGE_URL_1 = 'https://samples.clarifai.com/puppy.jpeg';\nconst IMAGE_URL_2 = 'https://samples.clarifai.com/wedding.jpg';\nconst CONCEPT_ID_1 = 'charlie';\nconst CONCEPT_ID_2 = 'our_wedding';\nconst CONCEPT_ID_3 = 'our_wedding';\nconst CONCEPT_ID_4 = 'charlie';\nconst CONCEPT_ID_5 = 'cat';\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require(\"clarifai-nodejs-grpc\");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set(\"authorization\", \"Key \" + PAT);\n\nstub.PostInputs(\n    {\n        user_app_id: {\n            \"user_id\": USER_ID,\n            \"app_id\": APP_ID\n        },\n        inputs: [\n            {\n                data: {\n                    image: { url: IMAGE_URL_1, allow_duplicate_url: true },\n                    concepts: [{ id: CONCEPT_ID_1, value: 1 }, { id: CONCEPT_ID_2, value: 0 }]\n                }\n            },\n            {\n                data: {\n                    image: { url: IMAGE_URL_2, allow_duplicate_url: true },\n                    concepts: [{ id: CONCEPT_ID_3, value: 1 }, { id: CONCEPT_ID_4, value: 0 }, { id: CONCEPT_ID_5, value: 0 }]\n                }\n            },\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            for (const input of response.inputs) {\n                console.log(\"Input \" + input.id + \" status: \");\n                console.log(JSON.stringify(input.status, null, 2) + \"\\n\");\n            }\n\n            throw new Error(\"Post inputs failed, status: \" + response.status.description);\n        }\n    }\n);",I='//index.js file\n\n///////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, and model ID.\n// Change these strings to run your own example.\n///////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = \'YOUR_USER_ID_HERE\';\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\nconst PAT = \'YOUR_PAT_HERE\';\nconst APP_ID = \'YOUR_APP_ID_HERE\';\n// Change this to create your own model\nconst MODEL_ID = \'my-pets\';\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\nstub.PostModels(\n    {\n        user_app_id: {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        models: [\n            {\n                id: MODEL_ID                              \n            }\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error("Post models failed, status: " + response.status.description);\n        }\n    }\n);',E="//index.js file\n\n////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, model ID, and concept IDs.\n// Change these strings to run your own example.\n//////////////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = 'YOUR_USER_ID_HERE';\n// Your PAT (Personal Access Token) can be found in the Account's Security section\nconst PAT = 'YOUR_PAT_HERE';\nconst APP_ID = 'YOUR_APP_ID_HERE';\n// Change these to train your own model\nconst MODEL_ID = 'my-pets';\nconst CONCEPT_ID_1 = 'charlie';\nconst CONCEPT_ID_2 = 'our_wedding';\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require(\"clarifai-nodejs-grpc\");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set(\"authorization\", \"Key \" + PAT);\n\nstub.PostModelVersions(\n    {\n        user_app_id: {\n            \"user_id\": USER_ID,\n            \"app_id\": APP_ID\n        },\n        model_id: MODEL_ID,\n        model_versions: [{\n            output_info: {\n                data: { concepts: [{ id: CONCEPT_ID_1, value: 1 }, { id: CONCEPT_ID_2, value: 1 }] },\n            }\n        }\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error(\"Post models failed, status: \" + response.status.description);\n        }\n    }\n);",C='//index.js file\n\n//////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, model ID, model version, \n// and image URL. Change these strings to run your own example.\n//////////////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = \'YOUR_USER_ID_HERE\';\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\nconst PAT = \'YOUR_PAT_HERE\';\nconst APP_ID = \'YOUR_APP_ID_HERE\';\n// Change these to make your own predictions\nconst MODEL_ID = \'my-pets\';\nconst MODEL_VERSION = \'6f2c3e043b3e49bdafd38851fb5675d5\';\nconst IMAGE_URL = \'https://samples.clarifai.com/metro-north.jpg\';\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\nstub.PostModelOutputs(\n    {\n        user_app_id: {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        model_id: MODEL_ID,\n        version_id: MODEL_VERSION,  // This is optional. Defaults to the latest model version\n        inputs: [\n            { data: { image: { url: IMAGE_URL } } }\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error("Post model outputs failed, status: " + response.status.description);\n        }\n\n        // Since we have one input, one output will exist here.\n        const output = response.outputs[0];\n\n        console.log("Predicted concepts:");\n        for (const concept of output.data.concepts) {\n            console.log(concept.name + " " + concept.value);\n        }\n    }\n);',A='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.status.StatusCode;\n\npublic class ClarifaiExample {\n\n    //////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, and the images and \n    // concepts we want to add. Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to add your own images with concepts\n    static final String IMAGE_URL_1 = "https://samples.clarifai.com/puppy.jpeg";\n    static final String IMAGE_URL_2 = "https://samples.clarifai.com/wedding.jpg";\n    static final String CONCEPT_ID_1 = "charlie";\n    static final String CONCEPT_ID_2 = "our_wedding";\n    static final String CONCEPT_ID_3 = "our_wedding";\n    static final String CONCEPT_ID_4 = "charlie";\n    static final String CONCEPT_ID_5 = "cat";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\t\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n            .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        MultiInputResponse postInputsResponse = stub.postInputs(\n            PostInputsRequest.newBuilder()\n            .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n            .addInputs(\n                Input.newBuilder()\n                .setData(\n                    Data.newBuilder()\n                    .setImage(\n                        Image.newBuilder()\n                        .setUrl(IMAGE_URL_1)\n                        .setAllowDuplicateUrl(true)\n                    )\n                    .addConcepts(Concept.newBuilder().setId(CONCEPT_ID_1).setValue(1))\n                    .addConcepts(Concept.newBuilder().setId(CONCEPT_ID_2).setValue(0))\n                )\n            )\n            .addInputs(\n                Input.newBuilder()\n                .setData(\n                    Data.newBuilder()\n                    .setImage(\n                        Image.newBuilder()\n                        .setUrl(IMAGE_URL_2)\n                        .setAllowDuplicateUrl(true)\n                    )\n                    .addConcepts(Concept.newBuilder().setId(CONCEPT_ID_3).setValue(1))\n                    .addConcepts(Concept.newBuilder().setId(CONCEPT_ID_4).setValue(0))\n                    .addConcepts(Concept.newBuilder().setId(CONCEPT_ID_5).setValue(0))\n                )\n            )\n            .build()\n        );\n\n        if (postInputsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            for (Input input: postInputsResponse.getInputsList()) {\n                System.out.println("Input " + input.getId() + " status: ");\n                System.out.println(input.getStatus() + "\\n");\n            }\n\n            throw new RuntimeException("Post inputs failed, status: " + postInputsResponse.getStatus());\n        }\n\n    }\n\n}',w='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.status.StatusCode;\n\npublic class ClarifaiExample {\n\n    ////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and model type ID.\n    // Change these strings to run your own example.\n    ///////////////////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change this to create your own model    \n    static final String MODEL_ID = "my-pets";\n       \n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\t\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n            .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        SingleModelResponse postModelsResponse = stub.postModels(\n            PostModelsRequest.newBuilder()\n            .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n            .addModels(\n                Model.newBuilder()\n                .setId(MODEL_ID)                            \n            ).build()\n        );\n\n        if (postModelsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post models failed, status: " + postModelsResponse.getStatus());\n        }\n\n    }\n\n}',D='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.status.StatusCode;\n\npublic class ClarifaiExample {\n\n    /////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and concept IDs.\n    // Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////////////////////\n    \n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    // Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to train your own model\n    static final String MODEL_ID = "my-pets";\n    static final String CONCEPT_ID_1 = "charlie";\n    static final String CONCEPT_ID_2 = "our_wedding";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\t\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n                .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        SingleModelResponse postModelVersionsResponse = stub.postModelVersions(\n                PostModelVersionsRequest.newBuilder()\n                        .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n                        .setModelId(MODEL_ID)\n                        .addModelVersions(ModelVersion.newBuilder()\n                                .setOutputInfo(OutputInfo.newBuilder()\n                                        .setData(Data.newBuilder()\n                                                .addConcepts(Concept.newBuilder()\n                                                        .setId(CONCEPT_ID_1)\n                                                        .setValue(1)\n                                                )\n                                                .addConcepts(Concept.newBuilder()\n                                                        .setId(CONCEPT_ID_2)\n                                                        .setValue(1)\n                                                )\n                                        )\n                                )\n                        )\n                        .build()\n        );\n\n        if (postModelVersionsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post model outputs failed, status: " + postModelVersionsResponse.getStatus());\n        }\n\n    }\n}\n',P='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.status.StatusCode;\n\npublic class ClarifaiExample {\n\n    //////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, model version, \n    // and image URL. Change these strings to run your own example\n    /////////////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\t\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to make your own predictions\n    static final String MODEL_ID = "my-pets";\n    static final String MODEL_VERSION = "6f2c3e043b3e49bdafd38851fb5675d5";\n    static final String IMAGE_URL = "https://samples.clarifai.com/metro-north.jpg";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\t\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n            .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        MultiOutputResponse postModelOutputsResponse = stub.postModelOutputs(\n            PostModelOutputsRequest.newBuilder()\n            .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n            .setModelId(MODEL_ID)\n            .setVersionId(MODEL_VERSION) // This is optional. Defaults to the latest model version \n            .addInputs(\n                Input.newBuilder().setData(\n                    Data.newBuilder().setImage(\n                        Image.newBuilder().setUrl(IMAGE_URL)\n                    )\n                )\n            )\n            .build()\n        );\n\n        if (postModelOutputsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post model outputs failed, status: " + postModelOutputsResponse.getStatus());\n        }\n\n        // Since we have one input, one output will exist here.\n        Output output = postModelOutputsResponse.getOutputs(0);\n\n        System.out.println("Predicted concepts:");\n        for (Concept concept: output.getData().getConceptsList()) {\n            System.out.printf("%s %.2f%n", concept.getName(), concept.getValue());\n        }\n\n    }\n\n}',b='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/inputs" \\\n  -H "Authorization: Key YOUR_PAT_HERE" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "inputs": [\n      {\n        "data": {\n          "image": {\n            "url": "https://samples.clarifai.com/puppy.jpeg",\n            "allow_duplicate_url": true\n          },\n          "concepts":[\n            {\n              "id": "charlie",\n              "value": 1\n            },\n            {\n              "id": "our_wedding",\n              "value": 0\n            }\n          ]\n        }\n      },\n      {\n        "data": {\n          "image": {\n            "url": "https://samples.clarifai.com/wedding.jpg",\n            "allow_duplicate_url": true\n          },\n          "concepts":[\n            {\n              "id": "our_wedding",\n              "value": 1\n            },\n            {\n              "id": "charlie",\n              "value": 0\n            },\n            {\n              "id": "cat",\n              "value": 0\n            }\n          ]\n        }\n      }\n    ]\n  }\'',O='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models" \\\n  -H "Authorization: Key YOUR_PAT_HERE" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model": {\n      "id": "my-pets"      \n    }\n  }\'',T='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models/YOUR_MODEL_ID_HERE/versions" \\\n  -H "Authorization: Key YOUR_PAT_HERE" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model_versions":[{\n        "output_info": {\n            "data":{\n                "concepts":[\n                        {\n                          "id": "charlie",\n                          "value": 1\n                        },\n                        {\n                          "id": "our_wedding",\n                          "value": 1\n                        }\n                    ]\n                }\n            }\n        }]  \n  }\'',R='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models/YOUR_MODEL_ID_HERE/versions/YOUR_MODEL_VERSION_ID_HERE/outputs" \\\n  -H "Authorization: Key YOUR_PAT_HERE" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "inputs": [\n      {\n        "data": {\n          "image": {\n            "url": "https://samples.clarifai.com/metro-north.jpg"\n          }\n        }\n      }\n    ]\n  }\'\n  ',S='<?php\n\nrequire __DIR__ . "/vendor/autoload.php";\n\n////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, and the images and \n// concepts we want to add. Change these strings to run your own example.\n////////////////////////////////////////////////////////////////////////////////////\n\n$USER_ID = "YOUR_USER_ID_HERE";\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\n$PAT = "YOUR_PAT_HERE";\n$APP_ID = "YOUR_APP_ID_HERE";\n// Change these to add your own images with concepts\n$IMAGE_URL_1 = "https://samples.clarifai.com/puppy.jpeg";\n$IMAGE_URL_2 = "https://samples.clarifai.com/wedding.jpg";\n$CONCEPT_ID_1 = "charlie";\n$CONCEPT_ID_2 = "our_wedding";\n$CONCEPT_ID_3 = "our_wedding";\n$CONCEPT_ID_4 = "charlie";\n$CONCEPT_ID_5 = "cat";\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nuse Clarifai\\Api\\Concept;\nuse Clarifai\\ClarifaiClient;\nuse Clarifai\\Api\\Data;\nuse Clarifai\\Api\\Image;\nuse Clarifai\\Api\\Input;\nuse Clarifai\\Api\\PostInputsRequest;\nuse Clarifai\\Api\\Status\\StatusCode;\nuse Clarifai\\Api\\UserAppIDSet;\n\n$client = ClarifaiClient::grpc();\n\n$metadata = ["Authorization" => ["Key " . $PAT]];\n\n$userDataObject = new UserAppIDSet([\n    "user_id" => $USER_ID,\n    "app_id" => $APP_ID\n]);\n\n// Let\'s make a RPC call to the Clarifai platform. It uses the opened gRPC client channel to communicate a\n// request and then wait for the response\n[$response, $status] = $client->PostInputs(\n    // The request object carries the request along with the request status and other metadata related to the request itself\n    new PostInputsRequest([\n        "user_app_id" => $userDataObject,\n        "inputs" => [\n            new Input([\n                // The Input object wraps the Data object in order to meet the API specification                    \n                "data" => new Data([\n                    // The Data object is constructed around the Image object. It offers a container that has additional image independent\n                    // metadata. In this particular use case, no other metadata is needed to be specified\n                    "image" => new Image([\n                        // In the Clarifai platform, an image is defined by a special Image object\n                        "url" => $IMAGE_URL_1,\n                        "allow_duplicate_url" => true\n                    ]),\n                    "concepts" => [\n                        new Concept([\n                            "id" => $CONCEPT_ID_1,\n                            "value" => 1\n                        ]),\n                        new Concept([\n                            "id" => $CONCEPT_ID_2,\n                            "value" => 0\n                        ])\n                    ]\n                ])\n            ]),\n            new Input([\n                "data" => new Data([\n                    "image" => new Image([\n                        "url" => $IMAGE_URL_2,\n                        "allow_duplicate_url" => true\n                    ]),\n                    "concepts" => [\n                        new Concept([\n                            "id" => $CONCEPT_ID_3,\n                            "value" => 1\n                        ]),\n                        new Concept([\n                            "id" => $CONCEPT_ID_4,\n                            "value" => 0\n                        ]),\n                        new Concept([\n                            "id" => $CONCEPT_ID_5,\n                            "value" => 0\n                        ])\n                    ]\n                ])\n            ])\n        ]\n    ]),\n    $metadata\n)->wait();\n\n// A response is returned and the first thing we do is check the status of it\n// A successful response will have a status code of 0; otherwise, there is some error\nif ($status->code !== 0) {\n    throw new Exception("Error: {$status->details}");\n}\n// In addition to the RPC response status, there is a Clarifai API status that reports if the operation was a success or failure \n// (not just that the communication was successful)\nif ($response->getStatus()->getCode() != StatusCode::SUCCESS) {\n    print $response->getStatus()->getDetails();\n    throw new Exception("Failure response: " . $response->getStatus()->getDescription());\n}\n\necho $response->serializeToJsonString();\n',j='<?php\n\nrequire __DIR__ . "/vendor/autoload.php";\n\n/////////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, and model ID.\n// Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////////////\n\n$USER_ID = "YOUR_USER_ID_HERE";\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\n$PAT = "YOUR_PAT_HERE";\n$APP_ID = "YOUR_APP_ID_HERE";\n// Change these to create your own model\n$MODEL_ID = "my-pets";\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nuse Clarifai\\ClarifaiClient;\nuse Clarifai\\Api\\Model;\nuse Clarifai\\Api\\PostModelsRequest;\nuse Clarifai\\Api\\Status\\StatusCode;\nuse Clarifai\\Api\\UserAppIDSet;\n\n$client = ClarifaiClient::grpc();\n\n$metadata = ["Authorization" => ["Key " . $PAT]];\n\n$userDataObject = new UserAppIDSet([\n    "user_id" => $USER_ID,\n    "app_id" => $APP_ID,\n]);\n\n// Let\'s make a RPC call to the Clarifai platform. It uses the opened gRPC client channel to communicate a\n// request and then wait for the response\n[$response, $status] = $client->PostModels(\n        // The request object carries the request along with the request status and other metadata related to the request itself\n        new PostModelsRequest([\n            "user_app_id" => $userDataObject,\n            "models" => [\n                new Model([                    \n                    "id" => $MODEL_ID                    \n                ]),\n            ],\n        ]),\n        $metadata\n    )->wait();\n\n// A response is returned and the first thing we do is check the status of it\n// A successful response will have a status code of 0; otherwise, there is some error\nif ($status->code !== 0) {\n    throw new Exception("Error: {$status->details}");\n}\n// In addition to the RPC response status, there is a Clarifai API status that reports if the operation was a success or failure\n// (not just that the communication was successful)\nif ($response->getStatus()->getCode() != StatusCode::SUCCESS) {\n    throw new Exception("Failure response: " . $response->getStatus()->getDescription() . " " . $response->getStatus()->getDetails());\n}\n\n?>\n',x='<?php\n\nrequire __DIR__ . "/vendor/autoload.php";\n\n/////////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, model ID, and concept ID. \n// Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////////////\n\n$USER_ID = "YOUR_USER_ID_HERE";\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\n$PAT = "YOUR_PAT_HERE";\n$APP_ID = "YOUR_APP_ID_HERE";\n// Change these to create your own model\n$MODEL_ID = "my-pets";\n$CONCEPT_ID_1 = "charlie";\n$CONCEPT_ID_2 = "our_wedding";\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nuse Clarifai\\ClarifaiClient;\nuse Clarifai\\Api\\PostModelVersionsRequest;\nuse Clarifai\\Api\\Status\\StatusCode;\nuse Clarifai\\Api\\UserAppIDSet;\nuse Clarifai\\Api\\ModelVersion;\nuse Clarifai\\Api\\OutputInfo;\nuse Clarifai\\Api\\Data;\nuse Clarifai\\Api\\Concept;\n\n$client = ClarifaiClient::grpc();\n\n$metadata = ["Authorization" => ["Key " . $PAT]];\n\n$userDataObject = new UserAppIDSet([\n    "user_id" => $USER_ID,\n    "app_id" => $APP_ID,\n]);\n\n// Let\'s make a RPC call to the Clarifai platform. It uses the opened gRPC client channel to communicate a\n// request and then wait for the response\n[$response, $status] = $client->PostModelVersions(\n    // The request object carries the request along with the request status and other metadata related to the request itself\n    new PostModelVersionsRequest([\n        "user_app_id" => $userDataObject,\n        "model_id" => $MODEL_ID,\n        "model_versions" => [\n            new ModelVersion([\n                "output_info" => new OutputInfo([\n                    "data" => new Data([\n                        "concepts" => [\n                            new Concept([\n                                "id" => $CONCEPT_ID_1,\n                                "value" => 1,\n                            ]),\n                            new Concept([\n                                "id" => $CONCEPT_ID_2,\n                                "value" => 1,\n                            ]),\n                        ],\n                    ]),\n                ]),\n            ]),\n        ],\n    ]),\n    $metadata\n)->wait();\n\n// A response is returned and the first thing we do is check the status of it\n// A successful response will have a status code of 0; otherwise, there is some error\nif ($status->code !== 0) {\n    throw new Exception("Error: {$status->details}");\n}\n// In addition to the RPC response status, there is a Clarifai API status that reports if the operation was a success or failure\n// (not just that the communication was successful)\nif ($response->getStatus()->getCode() != StatusCode::SUCCESS) {\n    throw new Exception("Failure response: " . $response->getStatus()->getDescription() . " " . $response->getStatus()->getDetails());\n}\n',v='<?php\n\nrequire __DIR__ . "/vendor/autoload.php";\n\n//////////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, model ID, model version,\n// and image URL. Change these strings to run your own example.\n//////////////////////////////////////////////////////////////////////////////////////////////////\n\n$USER_ID = "YOUR_USER_ID_HERE";\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\n$PAT = "YOUR_PAT_HERE";\n$APP_ID = "YOUR_APP_ID_HERE";\n// Change these to whatever model and image URL you want to use\n$MODEL_ID = "my-pets";\n$MODEL_VERSION_ID = "8eb21f63ba9d40c7b84ecfd664ac603d";\n$IMAGE_URL = "https://samples.clarifai.com/puppy.jpeg";\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nuse Clarifai\\ClarifaiClient;\nuse Clarifai\\Api\\Data;\nuse Clarifai\\Api\\Image;\nuse Clarifai\\Api\\Input;\nuse Clarifai\\Api\\PostModelOutputsRequest;\nuse Clarifai\\Api\\Status\\StatusCode;\nuse Clarifai\\Api\\UserAppIDSet;\n\n$client = ClarifaiClient::grpc();\n\n$metadata = ["Authorization" => ["Key " . $PAT]];\n\n$userDataObject = new UserAppIDSet([\n    "user_id" => $USER_ID,\n    "app_id" => $APP_ID,\n]);\n\n// Let\'s make a RPC call to the Clarifai platform. It uses the opened gRPC client channel to communicate a\n// request and then wait for the response\n[$response, $status] = $client->PostModelOutputs(\n        // The request object carries the request along with the request status and other metadata related to the request itself\n        new PostModelOutputsRequest([\n            "user_app_id" => $userDataObject,\n            "model_id" => $MODEL_ID,\n            "version_id" => $MODEL_VERSION_ID, // This is optional. Defaults to the latest model version\n            "inputs" => [\n                new Input([\n                    // The Input object wraps the Data object in order to meet the API specification\n                    "data" => new Data([\n                        // The Data object is constructed around the Image object. It offers a container that has additional image independent\n                        // metadata. In this particular use case, no other metadata is needed to be specified\n                        "image" => new Image([\n                            // In the Clarifai platform, an image is defined by a special Image object\n                            "url" => $IMAGE_URL,\n                        ]),\n                    ]),\n                ]),\n            ],\n        ]),\n        $metadata\n    )\n    ->wait();\n\n// A response is returned and the first thing we do is check the status of it\n// A successful response will have a status code of 0; otherwise, there is some error\nif ($status->code !== 0) {\n    throw new Exception("Error: {$status->details}");\n}\n// In addition to the RPC response status, there is a Clarifai API status that reports if the operation was a success or failure\n// (not just that the communication was successful)\nif ($response->getStatus()->getCode() != StatusCode::SUCCESS) {\n    throw new Exception("Failure response: " . $response->getStatus()->getDescription() . " " . $response->getStatus()->getDetails());\n}\n\n// The output of a successful call can be used in many ways. In this example, we loop through all of the predicted concepts\n// and print them out along with their numerical prediction value (confidence)\necho "Predicted concepts: </br>";\nforeach ($response->getOutputs()[0]->getData()->getConcepts() as $concept) {\n    echo $concept->getName() . ": " . number_format($concept->getValue(), 2) . "</br>";\n}\n\n?>\n',y='status {\n  code: SUCCESS\n  description: "Ok"\n  req_id: "7ff42b88ef477bb9b9ecab0b61d051ca"\n}\ninputs {\n  id: "7b708ee204284ed0a914dc37a7def8be"\n  data {\n    image {\n      url: "https://samples.clarifai.com/puppy.jpeg"\n      image_info {\n        format: "UnknownImageFormat"\n        color_mode: "UnknownColorMode"\n      }\n    }\n    concepts {\n      id: "charlie"\n      name: "charlie"\n      value: 1.0\n      app_id: "test-app"\n    }\n    concepts {\n      id: "our_wedding"\n      name: "our_wedding"\n      app_id: "test-app"\n    }\n  }\n  created_at {\n    seconds: 1646288847\n    nanos: 89138802\n  }\n  modified_at {\n    seconds: 1646288847\n    nanos: 89138802\n  }\n  status {\n    code: INPUT_DOWNLOAD_PENDING\n    description: "Download pending"\n  }\n}\ninputs {\n  id: "5571376e9d42447dafb76711669f6731"\n  data {\n    image {\n      url: "https://samples.clarifai.com/wedding.jpg"\n      image_info {\n        format: "UnknownImageFormat"\n        color_mode: "UnknownColorMode"\n      }\n    }\n    concepts {\n      id: "our_wedding"\n      name: "our_wedding"\n      value: 1.0\n      app_id: "test-app"\n    }\n    concepts {\n      id: "charlie"\n      name: "charlie"\n      app_id: "test-app"\n    }\n    concepts {\n      id: "cat"\n      name: "cat"\n      app_id: "test-app"\n    }\n  }\n  created_at {\n    seconds: 1646288847\n    nanos: 89138802\n  }\n  modified_at {\n    seconds: 1646288847\n    nanos: 89138802\n  }\n  status {\n    code: INPUT_DOWNLOAD_PENDING\n    description: "Download pending"\n  }\n}\n',N='status {\n  code: SUCCESS\n  description: "Ok"\n  req_id: "c179a31bea659b27214213ee137215f8"\n}\nmodel {\n  id: "my-pets"\n  name: "my-pets"\n  created_at {\n    seconds: 1693506608\n    nanos: 652910264\n  }\n  app_id: "items-app"\n  user_id: "my-user-id"\n  model_type_id: "embedding-classifier"\n  visibility {\n    gettable: PRIVATE\n  }\n  metadata {\n  }\n  modified_at {\n    seconds: 1693506608\n    nanos: 652910264\n  }\n  presets {\n  }\n  workflow_recommended {\n  }\n}\n',U='status {\n  code: SUCCESS\n  description: "Ok"\n  req_id: "c2b73a383ff73d57ce10eb92d4ceeca3"\n}\nmodel {\n  id: "my-pets"\n  name: "my-pets"\n  created_at {\n    seconds: 1693501169\n    nanos: 811818000\n  }\n  app_id: "items-app"\n  model_version {\n    id: "adbd648acc8146f788520dad0376411e"\n    created_at {\n      seconds: 1693558909\n      nanos: 61554817\n    }\n    status {\n      code: MODEL_QUEUED_FOR_TRAINING\n      description: "Model is currently in queue for training."\n    }\n    active_concept_count: 2\n    visibility {\n      gettable: PRIVATE\n    }\n    app_id: "items-app"\n    user_id: "alfrick"\n    metadata {\n    }\n    output_info {\n      output_config {\n      }\n      message: "Show output_info with: GET /models/{model_id}/output_info"\n      params {\n        fields {\n          key: "max_concepts"\n          value {\n            number_value: 20.0\n          }\n        }\n        fields {\n          key: "min_value"\n          value {\n            number_value: 0.0\n          }\n        }\n        fields {\n          key: "select_concepts"\n          value {\n            list_value {\n            }\n          }\n        }\n      }\n    }\n    input_info {\n      params {\n      }\n      base_embed_model {\n        id: "general-image-embedding"\n        app_id: "main"\n        model_version {\n          id: "bb186755eda04f9cbb6fe32e816be104"\n        }\n        user_id: "clarifai"\n        model_type_id: "visual-embedder"\n      }\n    }\n    train_info {\n      params {\n        fields {\n          key: "dataset_id"\n          value {\n            string_value: ""\n          }\n        }\n        fields {\n          key: "dataset_version_id"\n          value {\n            string_value: ""\n          }\n        }\n        fields {\n          key: "enrich_dataset"\n          value {\n            string_value: "Automatic"\n          }\n        }\n      }\n    }\n    import_info {\n    }\n  }\n  user_id: "alfrick"\n  model_type_id: "embedding-classifier"\n  visibility {\n    gettable: PRIVATE\n  }\n  metadata {\n  }\n  modified_at {\n    seconds: 1693501169\n    nanos: 811818000\n  }\n  presets {\n  }\n  workflow_recommended {\n  }\n}',M='status {\n    code: SUCCESS\n    description: "Ok"\n    req_id: "db4cf89c13303aa9889a89f2ae0a91f4"\n  }\n  outputs {\n    id: "20ed3f59dc5b4b1e9082a7e91ff29f48"\n    status {\n      code: SUCCESS\n      description: "Ok"\n    }\n    created_at {\n      seconds: 1646333543\n      nanos: 352417324\n    }\n    model {\n      id: "my-pets"\n      name: "my-pets"\n      created_at {\n        seconds: 1646291711\n        nanos: 640607000\n      }\n      app_id: "test-app"\n      output_info {\n        output_config {\n        }\n        message: "Show output_info with: GET /models/{model_id}/output_info"\n        params {\n          fields {\n            key: "max_concepts"\n            value {\n              number_value: 20.0\n            }\n          }\n          fields {\n            key: "min_value"\n            value {\n              number_value: 0.0\n            }\n          }\n          fields {\n            key: "select_concepts"\n            value {\n              list_value {\n              }\n            }\n          }\n        }\n      }\n      model_version {\n        id: "8eb21f63ba9d40c7b84ecfd664ac603d"\n        created_at {\n          seconds: 1646330065\n          nanos: 537080000\n        }\n        status {\n          code: MODEL_TRAINED\n          description: "Model is trained and ready"\n        }\n        total_input_count: 14\n        completed_at {\n          seconds: 1646330068\n          nanos: 100250000\n        }\n        visibility {\n          gettable: PRIVATE\n        }\n        app_id: "test-app"\n        user_id: "ei2leoz3s3iy"\n        metadata {\n        }\n      }\n      user_id: "ei2leoz3s3iy"\n      input_info {\n      }\n      train_info {\n      }\n      model_type_id: "embedding-classifier"\n      visibility {\n        gettable: PRIVATE\n      }\n      modified_at {\n        seconds: 1646291711\n        nanos: 640607000\n      }\n      import_info {\n      }\n    }\n    input {\n      id: "f1ce5584c5e54653b722ac3ef163a077"\n      data {\n        image {\n          url: "https://samples.clarifai.com/puppy.jpeg"\n        }\n      }\n    }\n    data {\n      concepts {\n        id: "charlie"\n        name: "charlie"\n        value: 0.9998574256896973\n        app_id: "test-app"\n      }\n    }\n  }\n  ',L="Predicted concepts:\ncharlie 1.00",H={description:"Learn how to use transfer learning to create custom visual classifier model",sidebar_position:2},Y="Visual Classifier",k={},$=[{value:"<strong>Via the UI</strong>",id:"via-the-ui",level:2},{value:"Step 1: Create an App",id:"step-1-create-an-app",level:3},{value:"Step 2: Create a Dataset",id:"step-2-create-a-dataset",level:3},{value:"Step 3: Add and Annotate Inputs",id:"step-3-add-and-annotate-inputs",level:3},{value:"Step 4: Update Dataset",id:"step-4-update-dataset",level:3},{value:"Step 5: Choose a Model Type",id:"step-5-choose-a-model-type",level:3},{value:"Step 6: Create a Model",id:"step-6-create-a-model",level:3},{value:"Step 7: Set Up the Model",id:"step-7-set-up-the-model",level:3},{value:"Step 8: Use Your Custom Model",id:"step-8-use-your-custom-model",level:3},{value:"<strong>Via the API</strong>",id:"via-the-api",level:2},{value:"Step 1: Create an App",id:"step-1-create-an-app-1",level:3},{value:"Step 2: Add Images With Concepts",id:"step-2-add-images-with-concepts",level:3},{value:"Step 3: Create a Model",id:"step-3-create-a-model",level:3},{value:"Step 4: Train the Model",id:"step-4-train-the-model",level:3},{value:"Step 5: Predict With the Model",id:"step-5-predict-with-the-model",level:3}];function V(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"visual-classifier",children:"Visual Classifier"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Learn how to use transfer learning to create custom visual classifier models"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsx)(n.p,{children:'A visual classifier model is a type of machine learning model that is trained to recognize and categorize images or visual inputs into predefined classes or labels. It "classifies" visual data based on patterns it has learned from training examples.'}),"\n",(0,a.jsxs)(n.p,{children:["Let's demonstrate how you can create a custom visual classifier model using the ",(0,a.jsx)(n.a,{href:"/create/models/transfer-learning/",children:"transfer learning"})," technique."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(49256).A+"",width:"700",height:"440"})}),"\n",(0,a.jsx)(n.h2,{id:"via-the-ui",children:(0,a.jsx)(n.strong,{children:"Via the UI"})}),"\n",(0,a.jsx)(n.p,{children:"Let\u2019s walk through how to create a model using the UI that can distinguish between pants and shorts."}),"\n",(0,a.jsx)(n.h3,{id:"step-1-create-an-app",children:"Step 1: Create an App"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/clarifai-basics/applications/create-an-application/#create-an-application-on-the-portal",children:"Click here"})," to learn how to create an application on the Clarifai platform."]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:"When creating the application, go with the default Image/Video option as the primary input type."})}),"\n",(0,a.jsx)(n.h3,{id:"step-2-create-a-dataset",children:"Step 2: Create a Dataset"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete/#create-a-new-dataset",children:"Click here"})," to learn how to create a dataset that will store the inputs."]}),"\n",(0,a.jsx)(n.h3,{id:"step-3-add-and-annotate-inputs",children:"Step 3: Add and Annotate Inputs"}),"\n",(0,a.jsx)(n.p,{children:"Next, you need to upload data to the app you've created. The input data, labeled with concepts, is what will be used for training your model. Training helps your model to \u201clearn\u201d from the annotated concepts on your inputs so that it can be able to recognize them."}),"\n",(0,a.jsx)(n.p,{children:"To get started with transfer learning, you don't need a large number of images. We recommend beginning with just 10 and adding more as needed."}),"\n",(0,a.jsxs)(n.p,{children:["In this example, we'll use 5 images of pants and 5 images of shorts sourced from ",(0,a.jsx)(n.a,{href:"https://github.com/alexeygrigorev/clothing-dataset-small",children:"this clothing dataset"}),". You can clone the repository and follow along with this documentation."]}),"\n",(0,a.jsxs)(n.p,{children:["To upload inputs, select the ",(0,a.jsx)(n.strong,{children:"Inputs"})," option in the collapsible left sidebar. Next, click the ",(0,a.jsx)(n.strong,{children:"Upload inputs"})," button."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"upload inputs",src:t(50069).A+"",width:"1888",height:"830"})}),"\n",(0,a.jsx)(n.p,{children:"The small window that pops up allows you to upload your inputs \u2014 either by providing publicly accessible URLs or by uploading them directly from your local device. For this illustration, we'll upload the images of pants and shorts from a local device."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"upload inputs window",src:t(18987).A+"",width:"1891",height:"893"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Use the ",(0,a.jsx)(n.strong,{children:"Select or add datasets"})," search box to select the dataset you previously created for storing the uploaded inputs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["To label the inputs with the ",(0,a.jsx)(n.code,{children:"pants"})," concept, click the plus (",(0,a.jsx)(n.strong,{children:"+"}),") icon next to the ",(0,a.jsx)(n.strong,{children:"Select or add concepts"})," search box. Then, type the new concept name in the search box. The new name you've typed will appear underneath the search box. Click the ",(0,a.jsx)(n.strong,{children:"Add new concept"})," button to create the concept. Once created, the concept will be listed underneath the search box."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Click the ",(0,a.jsx)(n.strong,{children:"Upload inputs"})," button at the bottom of the pop-up window to finalize uploading your annotated inputs to the dataset."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Similarly, upload the images of shorts to the dataset you previously created, and label them with the ",(0,a.jsx)(n.code,{children:"shorts"})," concept."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(54316).A+"",width:"1900",height:"821"})}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/annotate/create-get-update-delete",children:"Click here"})," to learn more about labeling inputs."]})}),"\n",(0,a.jsx)(n.h3,{id:"step-4-update-dataset",children:"Step 4: Update Dataset"}),"\n",(0,a.jsxs)(n.p,{children:["Next, go to the individual page of your dataset and create a version for it by clicking the ",(0,a.jsx)(n.strong,{children:"New version"})," button. This bookmarks the state of your data so that you can apply a specific version for training your custom model."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(89365).A+"",width:"1879",height:"828"})}),"\n",(0,a.jsx)(n.h3,{id:"step-5-choose-a-model-type",children:"Step 5: Choose a Model Type"}),"\n",(0,a.jsx)(n.p,{children:"Once you've added images that contain the concepts you want to train for, you can now proceed to create your custom model."}),"\n",(0,a.jsxs)(n.p,{children:["To begin, select the ",(0,a.jsx)(n.strong,{children:"Models"})," option in the collapsible left sidebar. On the ensuing page, click the ",(0,a.jsx)(n.strong,{children:"Add Model"})," button in the upper-right corner."]}),"\n",(0,a.jsxs)(n.p,{children:["In the pop-up window, choose the ",(0,a.jsx)(n.strong,{children:"Build a Custom Model"})," option, then click ",(0,a.jsx)(n.strong,{children:"Continue"})," to proceed."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(9740).A+"",width:"1887",height:"833"})}),"\n",(0,a.jsx)(n.p,{children:"You\u2019ll be redirected to a page where you can choose the type of model you want to create"}),"\n",(0,a.jsxs)(n.p,{children:["Let\u2019s choose the ",(0,a.jsx)(n.strong,{children:"Transfer Learn"})," model type."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(81763).A+"",width:"1883",height:"828"})}),"\n",(0,a.jsx)(n.h3,{id:"step-6-create-a-model",children:"Step 6: Create a Model"}),"\n",(0,a.jsxs)(n.p,{children:["On the ensuing page, provide a unique ID and click the ",(0,a.jsx)(n.strong,{children:"Continue to Configure Model"})," button to create your model."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(72942).A+"",width:"1823",height:"716"})}),"\n",(0,a.jsx)(n.h3,{id:"step-7-set-up-the-model",children:"Step 7: Set Up the Model"}),"\n",(0,a.jsx)(n.p,{children:"Next, you need to set up the model for training by providing the required details."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Create model page",src:t(26412).A+"",width:"1423",height:"1281"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Dataset"})," \u2014 Select a dataset to use to train the model. For this example, let's select the dataset we previously created \u2014 alongside its version."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Base Embed Model"})," \u2014 You can select the base model version to use for embeddings, which has to be one of the embed models in the app workflow. This allows you to specify the specific model in case the default workflow of your app has multiple embedding models present in it. For this example, let's go with the default option."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Concepts"})," \u2014 Select the concepts that you want the model to predict. For this example, let's choose the ",(0,a.jsx)(n.code,{children:"pants"})," and ",(0,a.jsx)(n.code,{children:"shorts"})," concepts."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Concepts Mutually Exclusive"})," \u2014 Let's turn the button on to indicate no overlap between any of the model concepts."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Enrich Dataset"})," \u2014 If enabled and set to ",(0,a.jsx)(n.code,{children:"Automatic"}),", this option enhances your model by incorporating supplemental data from pre-built datasets of negative embeddings, helping to improve accuracy. Alternatively, setting it to ",(0,a.jsx)(n.code,{children:"Disabled"})," will exclude the use of negative embeddings, regardless of their availability.\nFor this example, we'll proceed with the default ",(0,a.jsx)(n.code,{children:"Automatic"})," option."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Inference Settings (optional)"})," \u2014 Optionally, you can configure the provided inference settings for your model."]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["After configuring the settings, click the ",(0,a.jsx)(n.strong,{children:"Train Model"})," button to begin training your custom model."]}),"\n",(0,a.jsx)(n.h3,{id:"step-8-use-your-custom-model",children:"Step 8: Use Your Custom Model"}),"\n",(0,a.jsx)(n.p,{children:"You'll be redirected to the created model's page. Once the visual classifier model is trained, which normally takes a few seconds, you can put it to work."}),"\n",(0,a.jsxs)(n.p,{children:["For example, to use it for making a ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/ppredict/",children:"prediction"}),", click the blue (",(0,a.jsx)(n.strong,{children:"+"}),") ",(0,a.jsx)(n.strong,{children:"Try your own images or videos"})," button. A small window will pop up that allows you to upload an input and see its prediction probabilities on the right side of the page."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Predict with custom model",src:t(75945).A+"",width:"1778",height:"867"})}),"\n",(0,a.jsx)(n.p,{children:"That's it!"}),"\n",(0,a.jsx)(n.h2,{id:"via-the-api",children:(0,a.jsx)(n.strong,{children:"Via the API"})}),"\n",(0,a.jsx)(n.p,{children:"Let\u2019s walk through how to create a visual classifier model using the API."}),"\n",(0,a.jsx)(n.admonition,{type:"info",children:(0,a.jsxs)(n.p,{children:["Before using the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/python-sdk",children:"Python SDK"}),", ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/nodejs-sdk",children:"Node.js SDK"}),", or any of our ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/grpc-clients",children:"gRPC clients"}),", ensure they are properly installed on your machine. Refer to their respective installation guides for instructions on how to install and initialize them."]})}),"\n","\n","\n","\n","\n","\n","\n","\n","\n",(0,a.jsx)(n.h3,{id:"step-1-create-an-app-1",children:"Step 1: Create an App"}),"\n",(0,a.jsxs)(n.p,{children:["Before you create and train your first model, you need to ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/create-manage/applications/create",children:"create an application"})," and select ",(0,a.jsx)(n.strong,{children:"Image/Video"})," as the primary input type."]}),"\n",(0,a.jsx)(n.h3,{id:"step-2-add-images-with-concepts",children:"Step 2: Add Images With Concepts"}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:["This walkthrough example assumes that you've selected a Classification Base Workflow. If you choose a Detection Base Workflow, then this ",(0,a.jsx)(n.strong,{children:"Add Images With Concepts"})," example could throw an error message, such as ",(0,a.jsx)(n.code,{children:"Adding/patching inputs with pre-tagged concepts is not allowed for apps with a detection model in their base workflow. Please use Post or Patch Annotations instead."})," If you get such an error, you should first upload the inputs without any concepts attached and then use the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/api-guide/annotate/annotations/#add-annotations",children:"Annotations endpoint"})," to label the inputs."]})}),"\n",(0,a.jsx)(n.p,{children:"To get started training your own model, you need to first add images that already contain the concepts you want your model to see."}),"\n",(0,a.jsxs)(o.A,{groupId:"code",children:[(0,a.jsx)(r.A,{value:"grpc_python",label:"Python (gRPC)",children:(0,a.jsx)(l.A,{className:"language-python",children:c})}),(0,a.jsx)(r.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,a.jsx)(l.A,{className:"language-javascript",children:h})}),(0,a.jsx)(r.A,{value:"grpc_nodejs",label:"Node.js (gRPC)",children:(0,a.jsx)(l.A,{className:"language-javascript",children:f})}),(0,a.jsx)(r.A,{value:"grpc_java",label:"Java (gRPC)",children:(0,a.jsx)(l.A,{className:"language-java",children:A})}),(0,a.jsx)(r.A,{value:"php",label:"PHP (gRPC)",children:(0,a.jsx)(l.A,{className:"language-php",children:S})}),(0,a.jsx)(r.A,{value:"curl",label:"cURL",children:(0,a.jsx)(l.A,{className:"language-bash",children:b})})]}),"\n",(0,a.jsxs)(s,{children:[(0,a.jsx)("summary",{children:"Raw Output Example"}),(0,a.jsx)(l.A,{className:"language-js",children:y})]}),"\n",(0,a.jsx)(n.h3,{id:"step-3-create-a-model",children:"Step 3: Create a Model"}),"\n",(0,a.jsx)(n.p,{children:'After adding images with concepts, you are now ready to create a custom transfer learning model (also called an "embedding-classifier"). You need to provide an ID for the model.'}),"\n",(0,a.jsxs)(n.p,{children:["If you want to ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/api-guide/model/create-get-update-and-delete#create-a-model",children:"create another type of model"})," you could use the ",(0,a.jsx)(n.code,{children:"model_type_id"}),' parameter to specify it. Otherwise, the "embedding-classifier" model type will be created by default.']}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"PostModels"})," will create new models but not create new model versions. This means trainable models that have not yet been trained will require the additional step of calling the ",(0,a.jsx)(n.a,{href:"#step-4-train-the-model",children:(0,a.jsx)(n.strong,{children:"PostModelVersions"})})," endpoint, while providing the ",(0,a.jsx)(n.code,{children:"*_info"})," fields in the model version\u2014to affect training."]})}),"\n",(0,a.jsxs)(n.p,{children:["Take note of the ",(0,a.jsx)(n.code,{children:"model id"}),", as we'll need that for the next steps."]}),"\n",(0,a.jsxs)(o.A,{groupId:"code",children:[(0,a.jsx)(r.A,{value:"grpc_python",label:"Python (gRPC)",children:(0,a.jsx)(l.A,{className:"language-python",children:d})}),(0,a.jsx)(r.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,a.jsx)(l.A,{className:"language-javascript",children:_})}),(0,a.jsx)(r.A,{value:"grpc_nodejs",label:"Node.js (gRPC)",children:(0,a.jsx)(l.A,{className:"language-javascript",children:I})}),(0,a.jsx)(r.A,{value:"grpc_java",label:"Java (gRPC)",children:(0,a.jsx)(l.A,{className:"language-java",children:w})}),(0,a.jsx)(r.A,{value:"php",label:"PHP (gRPC)",children:(0,a.jsx)(l.A,{className:"language-php",children:j})}),(0,a.jsx)(r.A,{value:"curl",label:"cURL",children:(0,a.jsx)(l.A,{className:"language-bash",children:O})})]}),"\n",(0,a.jsxs)(s,{children:[(0,a.jsx)("summary",{children:"Raw Output Example"}),(0,a.jsx)(l.A,{className:"language-js",children:N})]}),"\n",(0,a.jsx)(n.h3,{id:"step-4-train-the-model",children:"Step 4: Train the Model"}),"\n",(0,a.jsx)(n.p,{children:"Now that you've added images with concepts, then created a model, the next step is to train the model. When you train a model, you are telling the system to look at all the images with concepts you've provided and learn from them."}),"\n",(0,a.jsx)(n.p,{children:"This train operation is asynchronous. It may take a few seconds for your model to be fully trained and ready."}),"\n",(0,a.jsxs)(n.p,{children:["Take note of the ",(0,a.jsx)(n.code,{children:"model_version id"})," in the response. We'll need that for the next section when we predict with the model."]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.strong,{children:"PostModelVersions"})," endpoint kicks off training and creates a new model version. You can also add concepts to a model when creating the model version\u2014and only if the model type supports it as defined in the model type parameters."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["You can use the ",(0,a.jsx)(n.strong,{children:"PostModelVersions"})," endpoint to give information specific to a model version. All the ",(0,a.jsx)(n.code,{children:"*_info"})," fields\u2014such as ",(0,a.jsx)(n.code,{children:"output_info"}),", ",(0,a.jsx)(n.code,{children:"input_info"}),", ",(0,a.jsx)(n.code,{children:"train_info"}),", and ",(0,a.jsx)(n.code,{children:"import_info"}),"\u2014are available on this endpoint."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["You cannot remove the training concepts from a model version. However, you can edit the additional ",(0,a.jsx)(n.code,{children:"OutputInfo.Params"})," concept options if they are defined in the model type."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["When training an embedding-classifier, you could specify the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/product-updates/upcoming-api-changes/closed-environment",children:(0,a.jsx)(n.code,{children:"enrich_dataset"})})," variable inside ",(0,a.jsx)(n.code,{children:"modelVersion.TrainInfo.Params"})," of the ",(0,a.jsx)(n.strong,{children:"PostModelVersions"})," endpoint. It lets you enrich the model with supplemental data from pre-built datasets of negative embeddings, which improves the model's accuracy. It has two options:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"Automatic"})," (default) means that if there are negative embeddings for a base model, we will use them\u2014and we won\u2019t use them if they\u2019re not available."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"Disabled"})," means that we should not use the negative embeddings whether they are available or not."]}),"\n"]}),"\n"]}),"\n"]})}),"\n",(0,a.jsxs)(o.A,{groupId:"code",children:[(0,a.jsx)(r.A,{value:"grpc_python",label:"Python (gRPC)",children:(0,a.jsx)(l.A,{className:"language-python",children:p})}),(0,a.jsx)(r.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,a.jsx)(l.A,{className:"language-javascript",children:m})}),(0,a.jsx)(r.A,{value:"grpc_nodejs",label:"Node.js (gRPC)",children:(0,a.jsx)(l.A,{className:"language-javascript",children:E})}),(0,a.jsx)(r.A,{value:"grpc_java",label:"Java (gRPC)",children:(0,a.jsx)(l.A,{className:"language-java",children:D})}),(0,a.jsx)(r.A,{value:"php",label:"PHP (gRPC)",children:(0,a.jsx)(l.A,{className:"language-php",children:x})}),(0,a.jsx)(r.A,{value:"curl",label:"cURL",children:(0,a.jsx)(l.A,{className:"language-bash",children:T})})]}),"\n",(0,a.jsxs)(s,{children:[(0,a.jsx)("summary",{children:"Raw Output Example"}),(0,a.jsx)(l.A,{className:"language-js",children:U})]}),"\n",(0,a.jsx)(n.h3,{id:"step-5-predict-with-the-model",children:"Step 5: Predict With the Model"}),"\n",(0,a.jsxs)(n.p,{children:["Now that we have trained the model, we can start making predictions with it. In our predict call, we specify three items: the ",(0,a.jsx)(n.code,{children:"model id"}),", ",(0,a.jsx)(n.code,{children:"model version id"})," (optional, defaults to the latest trained version if omitted), and the ",(0,a.jsx)(n.code,{children:"input"})," we want a prediction for."]}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsx)(n.p,{children:"You can repeat the above steps as often as you like. By adding more images with concepts and training, you can get the model to predict exactly how you want it to."})}),"\n",(0,a.jsxs)(o.A,{groupId:"code",children:[(0,a.jsx)(r.A,{value:"grpc_python",label:"Python (gRPC)",children:(0,a.jsx)(l.A,{className:"language-python",children:u})}),(0,a.jsx)(r.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,a.jsx)(l.A,{className:"language-javascript",children:g})}),(0,a.jsx)(r.A,{value:"grpc_nodejs",label:"Node.js (gRPC)",children:(0,a.jsx)(l.A,{className:"language-javascript",children:C})}),(0,a.jsx)(r.A,{value:"grpc_java",label:"Java (gRPC)",children:(0,a.jsx)(l.A,{className:"language-java",children:P})}),(0,a.jsx)(r.A,{value:"php",label:"PHP (gRPC)",children:(0,a.jsx)(l.A,{className:"language-php",children:v})}),(0,a.jsx)(r.A,{value:"curl",label:"cURL",children:(0,a.jsx)(l.A,{className:"language-bash",children:R})})]}),"\n",(0,a.jsxs)(s,{children:[(0,a.jsx)("summary",{children:"Text Output Example"}),(0,a.jsx)(l.A,{className:"language-js",children:L})]}),"\n",(0,a.jsxs)(s,{children:[(0,a.jsx)("summary",{children:"Raw Output Example"}),(0,a.jsx)(l.A,{className:"language-js",children:M})]})]})}function G(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(V,{...e})}):V(e)}}}]);