"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[5038],{484:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>l});var i=n(74848),a=n(28453);const s={description:"Learn about our text-to-text model type and understand its fine-tuning process",sidebar_position:9,pagination_next:null,keywords:["text-to-text models","text generation models","natural language processing","NLP text generation","machine learning text generation","AI text generation","text synthesis","text-to-text conversion","deep learning text generation","custom text-to-text models","pre-trained text-to-text models","text transformation AI"]},o="Text Generation",r={id:"portal-guide/model/model-types/text-to-text",title:"Text Generation",description:"Learn about our text-to-text model type and understand its fine-tuning process",source:"@site/docs/portal-guide/model/model-types/text-to-text.md",sourceDirName:"portal-guide/model/model-types",slug:"/portal-guide/model/model-types/text-to-text",permalink:"/portal-guide/model/model-types/text-to-text",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/portal-guide/model/model-types/text-to-text.md",tags:[],version:"current",sidebarPosition:9,frontMatter:{description:"Learn about our text-to-text model type and understand its fine-tuning process",sidebar_position:9,pagination_next:null,keywords:["text-to-text models","text generation models","natural language processing","NLP text generation","machine learning text generation","AI text generation","text synthesis","text-to-text conversion","deep learning text generation","custom text-to-text models","pre-trained text-to-text models","text transformation AI"]},sidebar:"tutorialSidebar",previous:{title:"Text Classifier",permalink:"/portal-guide/model/model-types/text-classifier"}},d={},l=[{value:"How to Fine-Tune Text Generation Models",id:"how-to-fine-tune-text-generation-models",level:2},{value:"1. Prepare Your Training Data",id:"1-prepare-your-training-data",level:3},{value:"2. Create an App",id:"2-create-an-app",level:3},{value:"3. Create a Dataset",id:"3-create-a-dataset",level:3},{value:"3. Upload Your Data",id:"3-upload-your-data",level:3},{value:"3. Choose a Model",id:"3-choose-a-model",level:3},{value:"4. Create and Train the Model",id:"4-create-and-train-the-model",level:3},{value:"5. Generate Texts",id:"5-generate-texts",level:3}];function c(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{id:"text-generation",children:"Text Generation"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.strong,{children:"Learn about our text-to-text model type and understand its fine-tuning process"})}),"\n",(0,i.jsx)("hr",{}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Input"}),": Text"]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Output"}),": Text"]}),"\n",(0,i.jsx)(t.p,{children:"A text-to-text model is a type of natural language processing (NLP) model that takes a text input and generates a text output. This framework can handle a variety of tasks within the same model architecture by framing all problems as text generation problems."}),"\n",(0,i.jsx)(t.p,{children:"For example, it could be used for:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Machine translation \u2014 Translating from one language to another (e.g., English to French)."}),"\n",(0,i.jsx)(t.li,{children:"Summarization \u2014 Condensing a longer document into a shorter summary."}),"\n",(0,i.jsx)(t.li,{children:"Text classification \u2014 Recasting classification tasks like sentiment analysis as a text generation problem."}),"\n",(0,i.jsx)(t.li,{children:"Question answering \u2014 Given a question, the model generates an appropriate text answer."}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Large language models (LLMs) are usually used to generate coherent and contextually appropriate text based on the instructions of the user. These foundation models, also referred to as pre-trained or base models, are massive models that have been trained on extensive amounts of data. You can use them as a starting point for text-generation tasks."}),"\n",(0,i.jsx)(t.p,{children:"Fine-tuning allows you to adapt the foundational text-to-text models to specific tasks or domains, making them more suitable for particular applications. By training on task-specific data, you can improve model performance on those tasks."}),"\n",(0,i.jsxs)(t.p,{children:["With fine-tuning, you can take advantage of ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/model/model-types/transfer-learning/",children:"transfer learning"})," and utilize the knowledge gained from a pre-trained text model to facilitate the learning process of a new model for a related problem."]}),"\n",(0,i.jsx)(t.admonition,{title:"Text Fine-Tuning Templates",type:"caution",children:(0,i.jsxs)(t.p,{children:["The text-to-text model type also comes with various ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/model/deep-training/text-templates",children:"templates"})," that give you the control to choose the specific architecture used by your neural network, as well as define a set of hyperparameters you can use to fine-tune the way your model learns."]})}),"\n",(0,i.jsx)(t.p,{children:"You may choose a text-to-text model type in cases where:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"You need a generative model that can effectively learn patterns and structures from training data, and use this learned knowledge to generate text that is coherent and contextually relevant based on the input it receives."}),"\n",(0,i.jsxs)(t.li,{children:['You need a text-to-text model to learn new features not recognized by the existing Clarifai models. In that case, you may need to "deep fine-tune" your custom model and integrate it directly within your ',(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/workflows/",children:"workflows"}),"."]}),"\n",(0,i.jsx)(t.li,{children:"You have a custom-tailored dataset, accurate labels, and the expertise and time to fine-tune models."}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"how-to-fine-tune-text-generation-models",children:"How to Fine-Tune Text Generation Models"}),"\n",(0,i.jsxs)(t.p,{children:["You can fine-tune a large language model for text generation tasks. In this example, we\u2019ll demonstrate how to fine-tune the ",(0,i.jsx)(t.a,{href:"https://clarifai.com/meta/Llama-3/models/Llama-3-8B-Instruct",children:"LLaMA 3.1 8B Instruct"})," model for a specific use case using Clarifai's no-code platform."]}),"\n",(0,i.jsx)(t.p,{children:"You can watch the video below for a step-by-step guide."}),"\n",(0,i.jsx)("div",{style:{position:"relative",width:"100%",overflow:"hidden","padding-top":"56.25%"},children:(0,i.jsx)("iframe",{width:"900",height:"500",style:{position:"absolute",top:"0",left:"0",bottom:"0",right:"0",width:"100%",height:"100%"},src:"https://www.youtube.com/embed/J2N4AbXlWZM",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0})}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)(t.p,{children:"You can also follow these steps to learn how to fine-tune a text-to-text model for generative or conversion tasks."}),"\n",(0,i.jsx)(t.h3,{id:"1-prepare-your-training-data",children:"1. Prepare Your Training Data"}),"\n",(0,i.jsx)(t.p,{children:"Fine-tuning a text-to-text model requires a dataset with examples in a specific format that includes both input and target sequences. The training data must be formatted according to the model's specific requirements to ensure effective learning."}),"\n",(0,i.jsx)(t.p,{children:"For example, when preparing data for training the LLaMA 3.1 8B Instruct model, you need to follow the following format:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",children:"<|begin_of_text|><|start_header_id|>system<|end_header_id|> {system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|> {prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"})}),"\n",(0,i.jsx)(t.p,{children:"The main purpose of this format is to clearly delineate the roles and contributions of different participants in the conversation: system instructions, user-provided input, and the model-generated output (assistant's response)."}),"\n",(0,i.jsx)(t.p,{children:"This type of standardized approach ensures clarity and facilitates easy parsing and processing during the training phase."}),"\n",(0,i.jsx)(t.p,{children:"Let\u2019s break down its meaning:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"<|begin_of_text|>"})," \u2014 This delimiter marks the beginning of the text content."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"<|start_header_id|>system<|end_header_id|>"})," \u2014 This indicates the beginning of a system-level instruction or context."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"{system_prompt}"})," \u2014 This placeholder is for the actual system-level instruction or context. It instructs the model on the specific task it should perform."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"<|eot_id|>"})," \u2014 This indicates the end of a text unit; in this case, the system prompt."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"<|start_header_id|>user<|end_header_id|>"})," \u2014 This marks the beginning of a user's input."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"{prompt}"})," \u2014 This placeholder represents the actual prompt or query from the user."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"<|eot_id|>"})," \u2014 This marks the end of a text unit; in this case, the user's input."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"<|start_header_id|>assistant<|end_header_id|>"})," \u2014 This indicates the beginning of the assistant's response (model-generated output)."]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Here is an example of training data you can use:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",children:'<|begin_of_text|> <|start_header_id|>system<|end_header_id|> You are a helpful AI assistant <|eot_id|> <|start_header_id|>user<|end_header_id|> Summarize the following text: The new smartphone model offers exceptional battery life and an improved camera. <|eot_id|> <|start_header_id|>assistant<|end_header_id|> {"summary": "The smartphone has great battery life and a better camera."} <|eot_id|>\n'})}),"\n",(0,i.jsxs)(t.p,{children:["To help you get started, you can download a ",(0,i.jsx)(t.code,{children:".csv"})," file with a simple dataset for fine-tuning the LLaMA 3.1 8B Instruct model ",(0,i.jsx)(t.a,{href:"https://docs.google.com/spreadsheets/d/1CE529pa0hhWSdP0TbnsHDIS2FqarOhLsRzLdvsQkcF4/edit?gid=0#gid=0",children:"here"}),"."]}),"\n",(0,i.jsx)(t.p,{children:"As you can see in the file, each example data is presented in an individual row. Also, note that the training data comprises two columns:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"input.data.text.raw"})," \u2014 This column houses the example data, with each row having its own instance."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"input.data.concepts[*].id"})," \u2014 This empty column is included to fulfill the prerequisites for ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/advanced-topics/csv-and-tsv/#csv-templates",children:"uploading a CSV file"})," to the Clarifai platform."]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:'The idea here is to create a dataset where the model learns to generate responses based on the context provided in the "user" section while adhering to the task defined in the "instruction" section. The above dataset is typically used for training a model to perform a wide range of text generation tasks.'}),"\n",(0,i.jsx)(t.p,{children:"This format is structured and labeled, making it suitable for supervised learning tasks where the model learns from examples with known correct answers. The model is trained to generate responses that align with the expected output for a given input context."}),"\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsx)(t.p,{children:"We recommend starting with more than 50 well-crafted examples for fine-tuning a text generation model. Nonetheless, the right number depends on your exact use case."})}),"\n",(0,i.jsx)(t.h3,{id:"2-create-an-app",children:"2. Create an App"}),"\n",(0,i.jsxs)(t.p,{children:["After preparing your dataset, the next step is to ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/clarifai-basics/applications/create-an-application/#create-an-application-on-the-portal",children:"create an application"}),"."]}),"\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsxs)(t.p,{children:["When creating an application, choose the ",(0,i.jsx)(t.strong,{children:"Text/Document"})," option as the primary input type. The ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/workflows/base-workflows/",children:"base workflow"})," will be automatically selected for you."]})}),"\n",(0,i.jsx)(t.h3,{id:"3-create-a-dataset",children:"3. Create a Dataset"}),"\n",(0,i.jsx)(t.p,{children:"Create a dataset within your application. Note that after adding inputs to the dataset, you'll need to create a version for it."}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete/",children:"Click here"})," to learn more about how to create and manage datasets."]}),"\n",(0,i.jsx)(t.h3,{id:"3-upload-your-data",children:"3. Upload Your Data"}),"\n",(0,i.jsxs)(t.p,{children:["In the collapsible left sidebar, select the ",(0,i.jsx)(t.strong,{children:"Inputs"})," option, then use the input uploader pop-up window to upload your prepared text data to the dataset you created."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"upload text data",src:n(46088).A+"",width:"1902",height:"894"})}),"\n",(0,i.jsx)(t.p,{children:"The data will be uploaded to your application."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(92790).A+"",width:"1879",height:"897"})}),"\n",(0,i.jsx)(t.p,{children:"After successfully uploading the data to a dataset, remember to update the dataset version."}),"\n",(0,i.jsx)(t.h3,{id:"3-choose-a-model",children:"3. Choose a Model"}),"\n",(0,i.jsxs)(t.p,{children:["Next, choose the ",(0,i.jsx)(t.strong,{children:"Models"})," option on the collapsible left sidebar. Click the ",(0,i.jsx)(t.strong,{children:"Add Model"})," button in the upper-right corner of the page."]}),"\n",(0,i.jsxs)(t.p,{children:["On the window that pops up, select the ",(0,i.jsx)(t.strong,{children:"Build a Custom Model"})," option and click the ",(0,i.jsx)(t.strong,{children:"Continue"})," button."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"model types",src:n(82947).A+"",width:"1910",height:"898"})}),"\n",(0,i.jsx)(t.p,{children:"You\u2019ll be redirected to a page where you can choose the type of model you want to fine-tune."}),"\n",(0,i.jsxs)(t.p,{children:["Select the ",(0,i.jsx)(t.strong,{children:"Text Generator"})," option."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"model types",src:n(77722).A+"",width:"1869",height:"829"})}),"\n",(0,i.jsx)(t.h3,{id:"4-create-and-train-the-model",children:"4. Create and Train the Model"}),"\n",(0,i.jsx)(t.p,{children:"The ensuing page allows you to create and train a text-to-text model for generation or conversion purposes."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"alt text",src:n(35669).A+"",width:"1572",height:"1443"})}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Model ID"})," \u2014 Provide an ID for your model."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Dataset"})," \u2014 Select the dataset you want to use to fine-tune the model. Also, select the version of your dataset."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Invalid Data Tolerance Percent"})," \u2014 Optionally, you can set a tolerance threshold (0 to 100) for the percentage of invalid inputs during training, and if this threshold is exceeded, training is stopped with an error. It's recommended to keep this value low to minimize invalid inputs."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Template"})," \u2014 Select a pre-configured model template you want to use to train on your data. You can select any of the following templates:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_Llama_3_1_8b_instruct_GPTQ_lora"})," \u2014 This is the recommended template, as shown in the screenshot above. It's the template we'll choose for fine-tuning the 3.1 version of the Llama model with 8 billion parameters optimized for instruction-based tasks. This version uses quantization (GPTQ) and Low-Rank Adaptation (LoRA) for efficient training."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_GPTNeo_125m_lora"})," \u2014 Template for the GPT-Neo model with 125 million parameters, using the LoRA method for efficient parameter adaptation, suitable for smaller-scale projects or less resource-intensive applications."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_GPTNeo_2p7b_lora"})," \u2014 Utilizes the 2.7 billion parameter GPT-Neo model, incorporating LoRA for effective fine-tuning, ideal for medium to large-scale natural language processing tasks."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_Llama_2_13b_chat_GPTQ_lora"})," \u2014 A fine-tuned 13 billion parameter Llama model for chat applications, using both quantization and LoRA for optimization, designed to handle complex dialog systems."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_Llama_2_7b_chat_GPTQ_lora"})," \u2014 Similar to the 13b version but with 7 billion parameters, this template is also geared towards chat applications, providing a balance between performance and computational efficiency."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_Mistral_7b_instruct_GPTQ_lora"})," \u2014 Template for the 7 billion parameter Mistral model, fine-tuned for instructional tasks with both GPTQ and LoRA, aimed at delivering high performance with efficient training."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_Mistral_7b_lora"})," \u2014 This template uses the Mistral model with 7 billion parameters optimized with LoRA only, suitable for diverse applications requiring fast model adaptation."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HuggingFace_AdvancedConfig"})," \u2014 Offers advanced configuration options for fine-tuning Hugging Face models, allowing for detailed customization to meet specific performance or application requirements."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Training Settings"})," \u2014 Optionally, you may configure the training and inference settings to enhance the performance of your model. Otherwise, you may use the provided default settings. These are some of the settings you may customize:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Model config"})," \u2014 Provide a dictionary of key-value pairs that define the pre-trained model to be used as a base."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Quantization config"})," \u2014 Provide a dictionary of key-value pairs that define how to fine-tune or adjust the behavior of quantization during the training or inference process."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Peft config"})," \u2014 Provide a dictionary of key-value pairs that define how to fine-tune a pre-trained model on a downstream task using a parameter-efficient fine-tuning (PEFT) method."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Tokenizer config"})," \u2014 Provide a dictionary of key-value pairs that define the configuration of a pre-trained tokenizer."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Trainer config"})," \u2014 Provide a dictionary of key-value pairs that define the configuration of the Transformers ",(0,i.jsx)(t.code,{children:"Trainer"})," class."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["Finally, click the ",(0,i.jsx)(t.strong,{children:"Train"})," button."]}),"\n",(0,i.jsx)(t.h3,{id:"5-generate-texts",children:"5. Generate Texts"}),"\n",(0,i.jsx)(t.p,{children:"After the model has been trained, you can start using it to make generative text-to-text predictions."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"alt text",src:n(52780).A+"",width:"1885",height:"743"})}),"\n",(0,i.jsxs)(t.p,{children:["To run an inference with the fine-tuned model, click the ",(0,i.jsx)(t.strong,{children:"Overview"})," tab and send a request to the model. For example, you can provide the following input:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",children:"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a helpful AI assistant<|eot_id|><|start_header_id|>user<|end_header_id|> Translate the following English sentence to Spanish: AI is a revolutionary industry in this age.<|eot_id|><|start_header_id|>assistant<|end_header_id|> \n"})}),"\n",(0,i.jsxs)(t.p,{children:["Click the ",(0,i.jsx)(t.strong,{children:"Generate"})," button. It will generate the output in JSON format, providing the response as a key-value pair."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"model types",src:n(21255).A+"",width:"1797",height:"881"})}),"\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/agent-system-operators/prompter/",children:"Click here"})," to learn more about the different prompt techniques you can use to instruct your text-to-text model."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/ppredict/generative-ai#inference-parameters",children:"Click here"})," to learn more about the different inference parameters you can specify to influence the output of LLMs."]}),"\n"]}),"\n"]})})]})}function h(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},92790:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/fine-tune-1-1-d77cb4d1ffa6ca7dff657d5a8f3a18fc.png"},46088:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/fine-tune-1-d66d2db5e641617a7d062337226cf243.png"},82947:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/fine-tune-2-707fb9331ad89118764aa59d17fca4f0.png"},77722:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/fine-tune-3-a255a2aa2a37474a65f073ffe85cb25e.png"},35669:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/fine-tune-4-982832a596a344d1ed67114195d4ebff.png"},52780:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/fine-tune-5-5704e340ce67c0882fd4b6fa944bee82.png"},21255:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/fine-tune-6-5c62483b7ddff4677e4c096c9eb7e6ae.png"},28453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>r});var i=n(96540);const a={},s=i.createContext(a);function o(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);