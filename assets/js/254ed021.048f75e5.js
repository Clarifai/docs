"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[7470],{61154:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>Z,contentTitle:()=>$,default:()=>tn,frontMatter:()=>X,metadata:()=>Q,toc:()=>nn});var a=t(74848),i=t(28453),o=t(11470),s=t(19365),l=t(21432);const d='from clarifai.client.input import Inputs\n\nimg_url = "https://samples.clarifai.com/metro-north.jpg"\ninput_obj = Inputs(user_id="user_id", app_id="test_app", pat="YOUR_PAT")\n# You can also upload data through Bytes and Filepath,\n\n# Upload from file\n# input_obj.upload_from_file(input_id=\'demo\', image_file=\u2019image_filepath\')\n\n# Upload from bytes\n# input_obj.upload_from_bytes(input_id=\'demo\', image_bytes=image)\n\ninput_obj.upload_from_url(input_id="demo", image_url=img_url)\n',r='import { Input } from "clarifai-nodejs";\n\n\nconst imageUrl = "https://samples.clarifai.com/metro-north.jpg";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nawait input.uploadFromUrl({\n  inputId: "demo",\n  imageUrl,\n});\n',p='from clarifai.client.input import Inputs\n\ninput_text = b"Write a tweet on future of AI"\ninput_obj = Inputs(user_id="user_id", app_id="test_app", pat="YOUR_PAT")\n\n# You can also upload data through URLand Filepath,\n\n# Upload from file\n# input_obj.upload_from_file(input_id=\'text_dat\', text_file=\u2019text_filepath\')\n\n# Upload from url\n# input_obj.upload_from_url(input_id=\'text,text_url=\u201dtext_url\u201d)\n\ninput_obj.upload_from_bytes(input_id="text_data", text_bytes=input_text)',u='import { Input } from "clarifai-nodejs";\n\n\nconst inputText = "Write a tweet on future of AI";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\ninput.uploadText({\n  inputId: "text_data",\n  rawText: inputText,\n});\n',c='from clarifai.client.input import Inputs\n\naudio_url = "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav"\ninput_obj = Inputs(user_id="user_id", app_id="test_app", pat="YOUR_PAT")\n\n# You can also upload data through Bytes and Filepath,\n\n# Upload from file\n# input_obj.upload_from_file(input_id=\'audio_data\', audio_file=\u2019audio_filepath\')\n\n# Upload from bytes\n# input_obj.upload_from_bytes(input_id=\'audio_data\u2019, audio_bytes=audio)\n\ninput_obj.upload_from_url(\n    input_id="audio_data",\n    audio_url=audio_url,\n)',h='import { Input } from "clarifai-nodejs";\n\n\nconst audioUrl =\n  "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\ninput.uploadFromUrl({\n  inputId: "audio_data",\n  audioUrl,\n});\n',m='from clarifai.client.input import Inputs\nvideo_url = "https://samples.clarifai.com/beer.mp4"\ninput_obj = Inputs(user_id="user_id", app_id="test_app", pat="YOUR_PAT")\n\n# You can also upload data through Bytes and Filepath,\n\n# Upload from file\n# input_obj.upload_from_file(input_id=\'video_data\', video_file=\u2019video_filepath\')\n\n# Upload from bytes\n# input_obj.upload_from_bytes(input_id=\'video_data\u2019, video_bytes=video)\n\ninput_obj.upload_from_url(\n    input_id="video_data", video_url= video_url\n)',_='import { Input } from "clarifai-nodejs";\n\n\nconst videoUrl = "https://samples.clarifai.com/beer.mp4";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nawait input.uploadFromUrl({\n  inputId: "video_data",\n  videoUrl,\n});\n',f='from clarifai.client.input import Inputs\n\ninput_obj = Inputs(user_id="user_id", app_id="test_app", pat="YOUR_PAT")\n\n# initialize inputs of different type\nprompt = "What time of day is it?"\nimage_url = "https://samples.clarifai.com/metro-north.jpg"\n\n# Here you can give the value for different types of inputs\ninput_obj.get_multimodal_input(\n    input_id="multimodal_data", image_url=image_url, raw_text=prompt\n)',g='import { Input } from "clarifai-nodejs";\n\n\nconst prompt = "What time of day is it?";\nconst imageUrl = "https://samples.clarifai.com/metro-north.jpg";\nconst multimodalInput = Input.getMultimodalInput({\n  inputId: "multimodal_data",\n  imageUrl,\n  rawText: prompt,\n});\nconsole.log(multimodalInput);\n',b='from clarifai.client.user import User\n\n# Create the input object\ninput_obj = User(user_id="user_id").app(app_id="test_app", pat="YOUR_PAT").inputs()\n# list the inputs with pagination\nall_inputs = list(input_obj.list_inputs(page_no=1,per_page=3))\nprint(all_inputs)',x='from clarifai.client.user import User\n\ninput_obj = User(user_id="user_id", pat="YOUR_PAT").app(app_id="test_app").inputs()\n# provide the inputs ids as parameters in delete_inputs function\ninput_obj.delete_inputs(list(input_obj.list_inputs()))',j='# Import necessary modules\nfrom google.protobuf.struct_pb2 import Struct\nfrom clarifai.client.input import Inputs\n\n# Create an Inputs object with user_id and app_id\ninput_object = Inputs(user_id="user_id", app_id="app_id", pat="YOUR_PAT")\n\n# Create a Struct object for metadata\nmetadata = Struct()\n\n# Update metadata with filename and split information\nmetadata.update({"filename": "XiJinping.jpg", "split": "train"})\n\n# URL of the image to upload\nurl = "https://samples.clarifai.com/XiJinping.jpg"\n\n# Upload the image from the URL with associated metadata\ninput_object.upload_from_url(input_id="metadata", image_url=url, metadata=metadata)',y='import { Input } from "clarifai-nodejs";\n\n\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nconst metadata = {\n  filename: "XiJinping.jpg",\n  split: "train",\n};\nconst imageUrl = "https://samples.clarifai.com/XiJinping.jpg";\nawait input.uploadFromUrl({\n  inputId: "image_with_metadata",\n  imageUrl,\n  metadata,\n});\n',I='from google.protobuf.struct_pb2 import Struct\nfrom clarifai.client.input import Inputs\n\n# Initialize an Inputs object with specified user_id and app_id\ninput_object = Inputs(user_id="user_id", app_id="app_id", pat="YOUR_PAT")\n\n# Define the URL of the video to upload\nvideo_url = "https://samples.clarifai.com/beer.mp4"\n\n# Create a Struct object to hold metadata\nmetadata = Struct()\n\n# Update the metadata with filename and split information\nmetadata.update({"filename": "drinks.jpg", "split": "train"})\n\n# Upload the video from the specified URL with the provided metadata\ninput_object.upload_from_url(\n    input_id="video_data_metadata", video_url=video_url, metadata=metadata\n)\n',v='import { Input } from "clarifai-nodejs";\n\n\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nconst metadata = {\n  filename: "beer.mp4",\n  split: "train",\n};\nconst videoUrl = "https://samples.clarifai.com/beer.mp4";\nawait input.uploadFromUrl({\n  inputId: "video_data_metadata",\n  videoUrl,\n  metadata,\n});\n',w='# Import necessary modules\nfrom google.protobuf.struct_pb2 import Struct\nfrom clarifai.client.input import Inputs\n\n# Define the input object with user_id and app_id\ninput_object = Inputs(user_id="user_id", app_id="app_id", pat="YOUR_PAT")\n\n# Define the input text\ninput_text = b"Write a tweet on future of AI"\n\n# Create a Struct object for metadata\nmetadata = Struct()\n\n# Update metadata with filename and split information\nmetadata.update({"filename": "tweet.txt", "split": "train"})\n\n# Upload the input from bytes with custom metadata\ninput_object.upload_from_bytes(input_id="text_data_metadata", text_bytes=input_text, metadata=metadata)\n',A='import { Input } from "clarifai-nodejs";\n\n\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nconst textBytes = Buffer.from("Write a tweet on future of AI");\nconst metadata = {\n  filename: "tweet.txt",\n  split: "train",\n};\nawait input.uploadFromBytes({\n  inputId: "text_with_metadata",\n  textBytes,\n  metadata,\n});\n',U='# Import necessary modules\nfrom clarifai.client.input import Inputs\nfrom google.protobuf.struct_pb2 import Struct\n\n\n# Define the input object with user_id and app_id\ninput_object = Inputs(user_id="user_id", app_id="app_id", pat="YOUR_PAT")\n\n# Define the URL of the audio file\naudio_url = "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav"\n\n# Create a new Struct to hold metadata\nmetadata = Struct()\n\n# Update the metadata with filename and split information\nmetadata.update({"filename": "goodmorning.wav", "split": "test"})\n\n# Upload the input from the specified URL with metadata\ninput_object.upload_from_url(\n    input_id="audio_data_metadata",  # Specify an ID for the input\n    audio_url=audio_url,  # URL of the audio file\n    metadata=metadata  # Custom metadata associated with the input\n)\n',R='import { Input } from "clarifai-nodejs";\n\n\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nconst metadata = {\n  filename: "goodmorning.wav",\n  split: "test",\n};\nconst audioUrl =\n  "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav";\nawait input.uploadFromUrl({\n  inputId: "audio_data_metadata",\n  audioUrl,\n  metadata,\n});\n',E='from clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Upload the image with a specific input ID\ninput_object.upload_from_url(input_id="bbox", image_url="https://samples.clarifai.com/BarackObama.jpg")\n\n# Upload initial bounding box annotations\nbbox_points = [.1, .1, .8, .9]  # Coordinates of the bounding box\nannotation = input_object.get_bbox_proto(input_id="bbox", label="face", bbox=bbox_points, label_id="id-face", annot_id="demo")\ninput_object.upload_annotations([annotation])\n\n# Update existing bounding box annotations with new coordinates\nbbox_points = [.35, .45, .6, .7]  # New coordinates of the bounding box\nannotation = input_object.get_bbox_proto(input_id="bbox", label="face", bbox=bbox_points, label_id="id-face", annot_id="demo")\ninput_object.patch_annotations([annotation], action=\'merge\')\n\n# Remove the bounding box annotations\nbbox_points = [.3, .3, .6, .7]  # Coordinates of the bounding box to be removed\nannotation = input_object.get_bbox_proto(input_id="bbox", label="face", bbox=bbox_points, label_id="id-face", annot_id="demo")\ninput_object.patch_annotations([annotation], action=\'remove\')',D='from clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Upload the image with a specific input ID\ninput_object.upload_from_url(input_id="polygon", image_url="https://samples.clarifai.com/BarackObama.jpg")\n\n# Upload initial polygon annotations\npolygon_pts = [[.1,.1],[.1,.9],[.9,.9],[.9,.1]] # Coordinates of the polygon\nannotation = input_object.get_mask_proto(input_id="polygon", label="label", polygons=polygon_pts, annot_id="annotation_id")\ninput_object.upload_annotations([annotation])\n\n# Update existing polygon annotations with new coordinates\npolygon_pts = [[.15,.15],[.15,.95],[.95,.95],[.95,.15]] # New coordinates of the polygon\nannotation = input_object.get_mask_proto(input_id="polygon", label="label", polygons=polygon_pts, annot_id="annotation_id")\ninput_object.patch_annotations([annotation],action=\'merge\')\n\n# Remove the polygon annotations\npolygon_pts = [[.3,.3],[.3,.7],[.8,.8],[.7,.3]] # Coordinates of the polygon to be removed\nannotation = input_object.get_mask_proto(input_id="polygon", label="label", polygons=polygon_pts, annot_id="annotation_id")\ninput_object.patch_annotations([annotation],action=\'remove\')\n',S='from clarifai.client.input import Inputs\nfrom google.protobuf.struct_pb2 import Struct\n\n# Metadata structure should be of Struct, so we create it, add the necessary details and provide it to input proto\nmetadata = Struct() \nmetadata.update({"split": "test"}) \n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\nnew_input = input_object._get_proto(input_id="YOUR_INPUT_ID_HERE", metadata= metadata)\n\n# Update the metadata\ninput_object.patch_inputs([new_input],action="merge")\n\n# Overwrite the metadata\ninput_object.patch_inputs([new_input],action=\'overwrite\')\n',C='from clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# This example changes the existing concept label "id-face" to "obama_face"\ninput_object.patch_concepts(\n    concept_ids=["id-face"],  # The ID of the concept you want to update\n    labels=["obama_face"],    # The new label name to overwrite the existing one\n    values=[],                \n    action=\'overwrite\'        \n)\n',O='from clarifai.client.input import Inputs\n\n# URL of the image to upload\nimage_url = "https://samples.clarifai.com/Ferrari.jpg"\n\n# Provide the Geoinfo to be added to the input\n# geo_info=[longitude, latitude]\ngeo_points = [102,73]\n\n# Create an Inputs object with user_id and app_id\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Upload the image from the URL with associated GeoInfo\ninput_object.upload_from_url(input_id="geo_info", image_url=image_url, geo_info=geo_points)\n',P='# Start by uploading the image with a specific input ID as described earlier\n# For example, you can upload this image: https://samples.clarifai.com/BarackObama.jpg\n# Then, after successfully uploading it, apply the bounding box annotations\n\nfrom clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Upload bounding box annotations\nbbox_points = [.1, .1, .8, .9]  # Coordinates of the bounding box\nannotation = input_object.get_bbox_proto(input_id="bbox", label="face", bbox=bbox_points, label_id="id-face", annot_id="demo")\ninput_object.upload_annotations([annotation])\n',T='# Start by uploading the image with a specific input ID as described earlier\n# For example, you can upload this image: https://samples.clarifai.com/airplane.jpeg\n# Then, after successfully uploading it, apply the polygon annotations\n\nfrom clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Upload polygon annotations\n#polygons=[[[x,y],...,[x,y]],...]\npolygon_pts = [[.15,.24],[.4,.78],[.77,.62],[.65,.15]]\nannotation = input_object.get_mask_proto(input_id="mask", label="airplane", polygons=polygon_pts)\ninput_object.upload_annotations([annotation])\n',k='from clarifai.client.input import Inputs\n\nurl = "https://samples.clarifai.com/featured-models/Llama2_Conversational-agent.txt"\n\n# Change this depending on the type of input you want to annotate\nconcepts = ["mobile","camera"]\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n                      \n# Upload text data with concepts\ninput_object.upload_from_url(input_id="text1", text_url=url, labels=concepts)\n\n# Upload image data with concepts\n#input_object.upload_from_url(input_id="image1", image_url="ADD_URL_HERE", labels=concepts)\n\n# Upload video data with concepts\n#input_object.upload_from_url(input_id="video1", video_url="ADD_URL_HERE", labels=concepts)\n\n# Upload audio data with concepts\n#input_object.upload_from_url(input_id="audio1", audio_url="ADD_URL_HERE", labels=concepts)',N='from clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n                      \n# Bulk delete annotations\ninput_object.delete_annotations(input_ids=["input_id1", "input_id1", "input_id2"], annotation_ids=["annot_id11", "annot_id12", "annot_id21"])\n',Y='from clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Download inputs  \ninput_object.download_inputs(list(input_object.list_inputs()))\n',F='from clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Remove unicode from text \ndef remove_unicode_and_upload(input_id, text):\n    string_encode = text.encode("ascii", "ignore")\n    string_decode = string_encode.decode()\n    input_object.upload_text(input_id=input_id,raw_text=string_decode)\n\nremove_unicode_and_upload(input_id=\'test\', text="This is a test \\u200c example. ")\n',L='\n2024-01-15 16:38:49 INFO     clarifai.client.input:                                                    input.py:669\n\n                             Inputs Uploaded                                                                       \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             details: "All inputs successfully added"                                              \n\n                             req_id: "a14eda72951b06cd25561381d70ced74"    ',H='2024-01-16 14:14:41 INFO     clarifai.client.input:                                                    input.py:669\n\n                             Inputs Uploaded                                                                       \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             details: "All inputs successfully added"                                              \n\n                             req_id: "80d2454a1dea0411e20fb03b2fe0c8b1"',B='\n2024-01-16 14:18:58 INFO     clarifai.client.input:                                                    input.py:669\n\n                             Inputs Uploaded                                                                       \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             details: "All inputs successfully added"                                              \n\n                             req_id: "c16d3dd066d7ee48d038744daacef6e8" ',q='2024-01-16 14:25:26 INFO     clarifai.client.input:                                                    input.py:669\n\n                             Inputs Uploaded                                                                       \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             details: "All inputs successfully added"                                              \n\n                             req_id: "00576d040a6254019942ab4eceb306ad" ',W='id: "multimodal_data"\ndata {\n  image {\n    url: "https://samples.clarifai.com/metro-north.jpg"\n  }\n  text {\n    raw: "What time of day is it?"\n  }\n}\n',M='[id: "demo1"\ndata {\n  image {\n    url: "https://samples.clarifai.com/metro-north.jpg"\n    hosted {\n      prefix: "https://data.clarifai.com"\n      suffix: "users/8tzpjy1a841y/apps/test_app/inputs/image/140c856dc82565d2c4d6ea720fceff78"\n      sizes: "orig"\n      sizes: "tiny"\n      sizes: "small"\n      sizes: "large"\n      crossorigin: "use-credentials"\n    }\n    image_info {\n      width: 512\n      height: 384\n      format: "JPEG"\n      color_mode: "YUV"\n    }\n  }\n}\ncreated_at {\n  seconds: 1705917660\n  nanos: 789409000\n}\n...\n  code: INPUT_DOWNLOAD_SUCCESS\n  description: "Download complete"\n}\n]\n',V='2024-01-16 14:44:28 INFO     clarifai.client.input:                                                    input.py:732\n\n                             Inputs Deleted                                                                        \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             req_id: "4ae26cd15c7da98a1c2d3647b03d2768"  ',z='2024-04-05 13:03:24 INFO     clarifai.client.input:                                                    input.py:674\n                             Inputs Uploaded                                                                       \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             details: "All inputs successfully added"                                              \n                             req_id: "951a64b950cccf05c8d274c8acc1f0f6"                                            \n                                                                                                                   \nINFO:clarifai.client.input:\nInputs Uploaded\ncode: SUCCESS\ndescription: "Ok"\ndetails: "All inputs successfully added"\nreq_id: "951a64b950cccf05c8d274c8acc1f0f6"\n\n(\'8557e0f57f464c22b3483de76757fb4f\',\n status {\n   code: SUCCESS\n   description: "Ok"\n   details: "All inputs successfully added"\n   req_id: "951a64b950cccf05c8d274c8acc1f0f6"\n }\n inputs {\n   id: "metadata"\n   data {\n     image {\n       url: "https://samples.clarifai.com/XiJinping.jpg"\n       image_info {\n         format: "UnknownImageFormat"\n         color_mode: "UnknownColorMode"\n       }\n     }\n     metadata {\n       fields {\n         key: "filename"\n         value {\n           string_value: "XiJinping.jpg"\n         }\n       }\n       fields {\n         key: "split"\n         value {\n           string_value: "train"\n         }\n       }\n     }\n   }\n   created_at {\n     seconds: 1712322204\n     nanos: 737881425\n   }\n   modified_at {\n     seconds: 1712322204\n     nanos: 737881425\n   }\n   status {\n     code: INPUT_DOWNLOAD_PENDING\n     description: "Download pending"\n   }\n }\n inputs_add_job {\n   id: "8557e0f57f464c22b3483de76757fb4f"\n   progress {\n     pending_count: 1\n   }\n   created_at {\n     seconds: 1712322204\n     nanos: 714751000\n   }\n   modified_at {\n     seconds: 1712322204\n     nanos: 714751000\n   }\n   status {\n     code: JOB_QUEUED\n     description: "Job is queued to be ran."\n   }\n })',J='2024-04-05 13:05:49 INFO     clarifai.client.input:                                                    input.py:674\n                             Inputs Uploaded                                                                       \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             details: "All inputs successfully added"                                              \n                             req_id: "72c9820d805efb9f3ee7f0508778c1f3"                                            \n                                                                                                                   \nINFO:clarifai.client.input:\nInputs Uploaded\ncode: SUCCESS\ndescription: "Ok"\ndetails: "All inputs successfully added"\nreq_id: "72c9820d805efb9f3ee7f0508778c1f3"\n\n(\'7fdc30b9c2a24f31b6a41b32bd9fea02\',\n status {\n   code: SUCCESS\n   description: "Ok"\n   details: "All inputs successfully added"\n   req_id: "72c9820d805efb9f3ee7f0508778c1f3"\n }\n inputs {\n   id: "video_data_metadata"\n   data {\n     video {\n       url: "https://samples.clarifai.com/beer.mp4"\n       video_info {\n         video_format: "UnknownVideoFormat"\n       }\n     }\n     metadata {\n       fields {\n         key: "filename"\n         value {\n           string_value: "drinks.jpg"\n         }\n       }\n       fields {\n         key: "split"\n         value {\n           string_value: "train"\n         }\n       }\n     }\n   }\n   created_at {\n     seconds: 1712322349\n     nanos: 628288634\n   }\n   modified_at {\n     seconds: 1712322349\n     nanos: 628288634\n   }\n   status {\n     code: INPUT_DOWNLOAD_PENDING\n     description: "Download pending"\n   }\n }\n inputs_add_job {\n   id: "7fdc30b9c2a24f31b6a41b32bd9fea02"\n   progress {\n     pending_count: 1\n   }\n   created_at {\n     seconds: 1712322349\n     nanos: 602487000\n   }\n   modified_at {\n     seconds: 1712322349\n     nanos: 602487000\n   }\n   status {\n     code: JOB_QUEUED\n     description: "Job is queued to be ran."\n   }\n })',G='2024-04-05 13:07:04 INFO     clarifai.client.input:                                                    input.py:674\n                             Inputs Uploaded                                                                       \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             details: "All inputs successfully added"                                              \n                             req_id: "835f6c736f032947d1f4067e39c10b72"                                            \n                                                                                                                   \nINFO:clarifai.client.input:\nInputs Uploaded\ncode: SUCCESS\ndescription: "Ok"\ndetails: "All inputs successfully added"\nreq_id: "835f6c736f032947d1f4067e39c10b72"\n\n(\'e3de274f644a4e98a488e7c85f94c0d1\',\n status {\n   code: SUCCESS\n   description: "Ok"\n   details: "All inputs successfully added"\n   req_id: "835f6c736f032947d1f4067e39c10b72"\n }\n inputs {\n   id: "text_data_metadata"\n   data {\n     metadata {\n       fields {\n         key: "filename"\n         value {\n           string_value: "tweet.txt"\n         }\n       }\n       fields {\n         key: "split"\n         value {\n           string_value: "train"\n         }\n       }\n     }\n     text {\n       url: "https://data.clarifai.com/orig/users/8tzpjy1a841y/apps/visual_classifier_eval/inputs/text/c439598b04d8112867eec70097aa00c2"\n       text_info {\n         encoding: "UnknownTextEnc"\n       }\n     }\n   }\n   created_at {\n     seconds: 1712322424\n     nanos: 56818659\n   }\n   modified_at {\n     seconds: 1712322424\n     nanos: 56818659\n   }\n   status {\n     code: INPUT_DOWNLOAD_PENDING\n     description: "Download pending"\n   }\n }\n inputs_add_job {\n   id: "e3de274f644a4e98a488e7c85f94c0d1"\n   progress {\n     pending_count: 1\n   }\n   created_at {\n     seconds: 1712322423\n     nanos: 941401000\n   }\n   modified_at {\n     seconds: 1712322423\n     nanos: 941401000\n   }\n   status {\n     code: JOB_QUEUED\n     description: "Job is queued to be ran."\n   }\n })',K='2024-04-08 06:39:32 INFO     clarifai.client.input:                                                    input.py:674\n                             Inputs Uploaded                                                                       \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             details: "All inputs successfully added"                                              \n                             req_id: "4c96e4167170c174838c7987101f3478"                                            \n                                                                                                                   \nINFO:clarifai.client.input:\nInputs Uploaded\ncode: SUCCESS\ndescription: "Ok"\ndetails: "All inputs successfully added"\nreq_id: "4c96e4167170c174838c7987101f3478"\n\n(\'109349aa790a404db39f6324415a47a5\',\n status {\n   code: SUCCESS\n   description: "Ok"\n   details: "All inputs successfully added"\n   req_id: "4c96e4167170c174838c7987101f3478"\n }\n inputs {\n   id: "audio_data_metadata"\n   data {\n     metadata {\n       fields {\n         key: "filename"\n         value {\n           string_value: "goodmorning.wav"\n         }\n       }\n       fields {\n         key: "split"\n         value {\n           string_value: "test"\n         }\n       }\n     }\n     audio {\n       url: "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav"\n       audio_info {\n         audio_format: "UnknownAudioFormat"\n       }\n     }\n   }\n   created_at {\n     seconds: 1712558372\n     nanos: 764691920\n   }\n   modified_at {\n     seconds: 1712558372\n     nanos: 764691920\n   }\n   status {\n     code: INPUT_DOWNLOAD_PENDING\n     description: "Download pending"\n   }\n }\n inputs_add_job {\n   id: "109349aa790a404db39f6324415a47a5"\n   progress {\n     pending_count: 1\n   }\n   created_at {\n     seconds: 1712558372\n     nanos: 751997000\n   }\n   modified_at {\n     seconds: 1712558372\n     nanos: 751997000\n   }\n   status {\n     code: JOB_QUEUED\n     description: "Job is queued to be ran."\n   }\n })',X={sidebar_position:5},$="Managing Inputs",Q={id:"sdk/managing-inputs",title:"Managing Inputs",description:"Learn how to interact with inputs using Clarifai SDKs",source:"@site/docs/sdk/managing-inputs.md",sourceDirName:"sdk",slug:"/sdk/managing-inputs",permalink:"/sdk/managing-inputs",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/sdk/managing-inputs.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"Advanced Concept Management",permalink:"/sdk/advanced-concept-management"},next:{title:"Inference from AI Models",permalink:"/sdk/Inference-from-AI-Models/"}},Z={},nn=[{value:"Upload Image Data",id:"upload-image-data",level:2},{value:"Upload Text Data",id:"upload-text-data",level:2},{value:"Remove Unicode From Text",id:"remove-unicode-from-text",level:3},{value:"Upload Audio Data",id:"upload-audio-data",level:2},{value:"Upload Video Data",id:"upload-video-data",level:2},{value:"Upload Multimodal Data",id:"upload-multimodal-data",level:2},{value:"Upload Custom Metadata",id:"upload-custom-metadata",level:2},{value:"Image With Metadata",id:"image-with-metadata",level:3},{value:"Video With Metadata",id:"video-with-metadata",level:3},{value:"Text With Metadata",id:"text-with-metadata",level:3},{value:"Audio With Metadata",id:"audio-with-metadata",level:3},{value:"Upload Inputs With Geoinfo",id:"upload-inputs-with-geoinfo",level:2},{value:"Upload Inputs With Annotations",id:"upload-inputs-with-annotations",level:2},{value:"Bounding Box Annotations",id:"bounding-box-annotations",level:3},{value:"Polygon Annotations",id:"polygon-annotations",level:3},{value:"Concepts Annotations",id:"concepts-annotations",level:3},{value:"Bulk Delete Input Annotations",id:"bulk-delete-input-annotations",level:2},{value:"List inputs",id:"list-inputs",level:2},{value:"Download Inputs",id:"download-inputs",level:2},{value:"Delete Inputs",id:"delete-inputs",level:2},{value:"Patch Inputs",id:"patch-inputs",level:2},{value:"Metadata",id:"metadata",level:3},{value:"Bounding Box Annotation",id:"bounding-box-annotation",level:3},{value:"Polygon Annotation",id:"polygon-annotation",level:3},{value:"Concepts",id:"concepts",level:3}];function en(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...n.components},{Details:t}=e;return t||function(n,e){throw new Error("Expected "+(e?"component":"object")+" `"+n+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.h1,{id:"managing-inputs",children:"Managing Inputs"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Learn how to interact with inputs using Clarifai SDKs"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsx)(e.p,{children:"Effortlessly handle and organize your input data with Clarifai SDKs. The Input Management feature empowers you to efficiently manage various types of data, including images, videos, and text, facilitating seamless integration into your machine learning workflows. Take control of your inputs, whether sourced from URLs, file paths, or raw bytes, and streamline the preparation process for predictive model inferences. Clarifai's Input Management simplifies the task of organizing and preparing data for an enhanced and streamlined machine learning experience."}),"\n",(0,a.jsx)(e.h2,{id:"upload-image-data",children:"Upload Image Data"}),"\n",(0,a.jsx)(e.p,{children:"The Clarifai SDKs empowers you to seamlessly upload image data through various methods, providing flexibility and ease of integration. Whether your images are hosted online via URLs, stored locally as file paths, or represented as bytes within your application, our API accommodates all these formats. This versatility ensures a smooth and efficient workflow, allowing you to leverage Clarifai's powerful capabilities with the convenience that suits your specific use case."}),"\n",(0,a.jsxs)(e.p,{children:["Visit this ",(0,a.jsx)(e.a,{href:"https://docs.clarifai.com/api-guide/data/create-get-update-delete",children:"page"})," for more information."]}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:d}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:L})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:r})})]}),"\n",(0,a.jsx)(e.h2,{id:"upload-text-data",children:"Upload Text Data"}),"\n",(0,a.jsx)(e.p,{children:"Use the potential of the Clarifai SDKs to effortlessly upload text data through diverse methods, providing a seamless experience and fostering adaptability in your integration process. Whether your text is accessible online via URLs, resides locally as file paths, or is represented as bytes within your application, our API seamlessly accommodates these formats. This versatility ensures a fluid and effective workflow, enabling you to unlock Clarifai's robust capabilities with the utmost convenience tailored to your specific use case."}),"\n",(0,a.jsxs)(e.p,{children:["Visit this ",(0,a.jsx)(e.a,{href:"https://docs.clarifai.com/api-guide/data/create-get-update-delete",children:"page"})," for more information."]}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:p}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:H})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:u})})]}),"\n",(0,a.jsx)(e.h3,{id:"remove-unicode-from-text",children:"Remove Unicode From Text"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to clean text by removing Unicode characters before uploading it to the Clarifai Platform."}),"\n",(0,a.jsx)(e.p,{children:"Note that you can add any of your own custom functionalities with ease."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:F})})}),"\n",(0,a.jsx)(e.h2,{id:"upload-audio-data",children:"Upload Audio Data"}),"\n",(0,a.jsx)(e.p,{children:"Unlock the potential of audio analysis with the Clarifai SDKs, offering seamless integration for uploading audio data through multiple avenues. Whether your audio files reside on external servers accessible via URLs, are stored locally with file paths, or are represented as raw bytes within your application, our API effortlessly accommodates each of these formats. This adaptability ensures a streamlined and user-friendly workflow, providing you the freedom to harness Clarifai's advanced capabilities with the utmost convenience tailored to your specific use case."}),"\n",(0,a.jsxs)(e.p,{children:["Visit this ",(0,a.jsx)(e.a,{href:"https://docs.clarifai.com/api-guide/data/create-get-update-delete",children:"page"})," for more information."]}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:c}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:B})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:h})})]}),"\n",(0,a.jsx)(e.h2,{id:"upload-video-data",children:"Upload Video Data"}),"\n",(0,a.jsx)(e.p,{children:"Unlock the potential of video analysis with the Clarifai SDKs, offering seamless integration for uploading video data through various methods. Whether your videos are accessible online via URLs, residing locally as file paths, or encapsulated as bytes within your application, our API effortlessly accommodates these diverse formats."}),"\n",(0,a.jsxs)(e.p,{children:["Visit this ",(0,a.jsx)(e.a,{href:"https://docs.clarifai.com/api-guide/data/create-get-update-delete",children:"page"})," for more information."]}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:m}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:q})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:_})})]}),"\n",(0,a.jsx)(e.h2,{id:"upload-multimodal-data",children:"Upload Multimodal Data"}),"\n",(0,a.jsx)(e.p,{children:"With the Clarifai SDKs, the integration of multimodal inputs becomes a seamless and intuitive process. Unlock the power of combining various types of inputs by leveraging our API. Whether you're incorporating a mix of images, text, or other data sources, our SDK allows you to specify and upload these multimodal inputs effortlessly. For now the Clarifai platform only supports multimodal inputs like [Image ,Text]->text."}),"\n",(0,a.jsxs)(e.p,{children:["Visit this ",(0,a.jsx)(e.a,{href:"https://docs.clarifai.com/api-guide/data/create-get-update-delete",children:"page"})," for more information."]}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:f}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:W})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:g})})]}),"\n",(0,a.jsx)(e.h2,{id:"upload-custom-metadata",children:"Upload Custom Metadata"}),"\n",(0,a.jsx)(e.p,{children:"When working with the Clarifai SDKs, you can add inputs with custom metadata in addition to concepts. This allows you to attach additional information  to your inputs, which can be useful for various purposes such as categorization, filtering, or later reference."}),"\n",(0,a.jsxs)(e.p,{children:["Visit this ",(0,a.jsx)(e.a,{href:"https://docs.clarifai.com/api-guide/data/create-get-update-delete#add-inputs-with-custom-metadata",children:"page"})," for more information."]}),"\n",(0,a.jsx)(e.h3,{id:"image-with-metadata",children:"Image With Metadata"}),"\n",(0,a.jsx)(e.p,{children:"In the below example we are uploading an image with metadata that includes details about the filename and to which split it belongs to."}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:j}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:z})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:y})})]}),"\n",(0,a.jsx)(e.h3,{id:"video-with-metadata",children:"Video With Metadata"}),"\n",(0,a.jsx)(e.p,{children:"In the below example we are uploading a video file  with metadata that includes details about the filename and to which split it belongs to."}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:I}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:J})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:v})})]}),"\n",(0,a.jsx)(e.h3,{id:"text-with-metadata",children:"Text With Metadata"}),"\n",(0,a.jsx)(e.p,{children:"In the below example we are uploading a text file with metadata that includes details about the filename and to which split it belongs to."}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:w}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:G})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:A})})]}),"\n",(0,a.jsx)(e.h3,{id:"audio-with-metadata",children:"Audio With Metadata"}),"\n",(0,a.jsx)(e.p,{children:"In the below example we are uploading an audio file with metadata that includes details about the filename and to which split it belongs to."}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:U}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:K})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:R})})]}),"\n",(0,a.jsx)(e.h2,{id:"upload-inputs-with-geoinfo",children:"Upload Inputs With Geoinfo"}),"\n",(0,a.jsx)(e.p,{children:"When uploading inputs, you can provide geospatial points information to them, consisting of longitudes and latitudes in the GPS coordinate system. There can be at most one single geospatial point associated with each input."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:O})})}),"\n",(0,a.jsx)(e.h2,{id:"upload-inputs-with-annotations",children:"Upload Inputs With Annotations"}),"\n",(0,a.jsx)(e.p,{children:"You can upload inputs along with their corresponding annotations, such as bounding boxes or polygons."}),"\n",(0,a.jsx)(e.h3,{id:"bounding-box-annotations",children:"Bounding Box Annotations"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to label a new rectangular bounding box for a specific region within an image. The bounding box coordinates should be normalized to the image dimensions, with values scaled to the range of [0, 1.0]."}),"\n",(0,a.jsx)(e.p,{children:"This ensures that the coordinates are independent of the image resolution, making the annotations consistent across different image sizes."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:P})})}),"\n",(0,a.jsx)(e.h3,{id:"polygon-annotations",children:"Polygon Annotations"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to annotate any polygon-shaped region within an image."}),"\n",(0,a.jsx)(e.p,{children:"A polygon is defined by a list of points, each specified by:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"row"})," \u2014 The row position of the point, represented as a value between 0.0 and 1.0, where 0.0 corresponds to the top row and 1.0 corresponds to the bottom."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"col"})," \u2014 The column position of the point, represented as a value between 0.0 and 1.0, where 0.0 corresponds to the left column of the image and 1.0 corresponds to the right column."]}),"\n"]}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:T})})}),"\n",(0,a.jsx)(e.h3,{id:"concepts-annotations",children:"Concepts Annotations"}),"\n",(0,a.jsxs)(e.p,{children:["Below is an example of how to annotate different types of inputs with ",(0,a.jsx)(e.a,{href:"http://localhost:3000/portal-guide/inputs-manager/concepts",children:"concepts"}),"."]}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:k})})}),"\n",(0,a.jsx)(e.h2,{id:"bulk-delete-input-annotations",children:"Bulk Delete Input Annotations"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to delete all the annotations associated with a given input by setting the input ID(s)."}),"\n",(0,a.jsxs)(e.p,{children:["The ",(0,a.jsx)(e.code,{children:"annotation_ids"})," parameter is optional. However, if provided, the number and order of ",(0,a.jsx)(e.code,{children:"annotation_ids"})," must match the corresponding ",(0,a.jsx)(e.code,{children:"input_ids"}),"."]}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:N})})}),"\n",(0,a.jsx)(e.h2,{id:"list-inputs",children:"List inputs"}),"\n",(0,a.jsxs)(e.p,{children:["Effortlessly explore and manage your inputs with the Clarifai SDKs. By utilizing the list_inputs() method, you gain the ability to seamlessly view all inputs within your app. This powerful function supports features like pagination, enabling a well-organized display of information. Tailor your queries by setting parameters such as ",(0,a.jsx)(e.code,{children:"page_no"})," and ",(0,a.jsx)(e.code,{children:"per_page"})," to align with your specific requirements."]}),"\n",(0,a.jsxs)(e.p,{children:["Visit this ",(0,a.jsx)(e.a,{href:"https://docs.clarifai.com/api-guide/data/create-get-update-delete",children:"page"})," for more information."]}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:b})})}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:M})]}),"\n",(0,a.jsx)(e.h2,{id:"download-inputs",children:"Download Inputs"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to download inputs from your app."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:Y})})}),"\n",(0,a.jsx)(e.h2,{id:"delete-inputs",children:"Delete Inputs"}),"\n",(0,a.jsx)(e.p,{children:"Effortlessly manage your input data with the Clarifai SDKs's Delete Inputs feature. Through the API, you gain the ability to delete inputs seamlessly by providing a list of input IDs. This straightforward and intuitive process empowers you to maintain control over your dataset, allowing for efficient removal of specific inputs as needed."}),"\n",(0,a.jsx)(e.admonition,{type:"caution",children:(0,a.jsx)(e.p,{children:"Be certain that you want to delete a particular input as the operation cannot be undone."})}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:x})})}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:V})]}),"\n",(0,a.jsx)(e.h2,{id:"patch-inputs",children:"Patch Inputs"}),"\n",(0,a.jsx)(e.p,{children:"You can apply patch operations to an input, allowing for the merging or removal of items. By default, these actions overwrite existing data, but they behave differently when handling lists of objects."}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["The ",(0,a.jsx)(e.code,{children:"merge"})," action replaces a ",(0,a.jsx)(e.code,{children:"key:value"})," pair with a ",(0,a.jsx)(e.code,{children:"key:new_value"}),", or appends new values to an existing list. When dealing with dictionaries, it merges entries that share the same ",(0,a.jsx)(e.code,{children:"id"})," field."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["The ",(0,a.jsx)(e.code,{children:"remove"})," action replaces a ",(0,a.jsx)(e.code,{children:"key:value"})," pair with a ",(0,a.jsx)(e.code,{children:"key:new_value"}),", or removes any items from a list that match the IDs of the provided values."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["The ",(0,a.jsx)(e.code,{children:"overwrite"})," action fully replaces an existing object with a new one."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"metadata",children:"Metadata"}),"\n",(0,a.jsx)(e.p,{children:"Here is an example of how to patch the metadata of an input."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:S})})}),"\n",(0,a.jsx)(e.h3,{id:"bounding-box-annotation",children:"Bounding Box Annotation"}),"\n",(0,a.jsx)(e.p,{children:"Here is an example of how to patch a bounding box annotation on an input."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:E})})}),"\n",(0,a.jsx)(e.h3,{id:"polygon-annotation",children:"Polygon Annotation"}),"\n",(0,a.jsx)(e.p,{children:"Here is an example of how to patch a polygon annotation on an input."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:D})})}),"\n",(0,a.jsx)(e.h3,{id:"concepts",children:"Concepts"}),"\n",(0,a.jsxs)(e.p,{children:["Below is an example of performing a patch operation on concepts. Currently, only the ",(0,a.jsx)(e.code,{children:"overwrite"})," action is supported, allowing you to update the label names associated with an input."]}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:C})})})]})}function tn(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(en,{...n})}):en(n)}},19365:(n,e,t)=>{t.d(e,{A:()=>s});t(96540);var a=t(18215);const i={tabItem:"tabItem_Ymn6"};var o=t(74848);function s(n){let{children:e,hidden:t,className:s}=n;return(0,o.jsx)("div",{role:"tabpanel",className:(0,a.A)(i.tabItem,s),hidden:t,children:e})}},11470:(n,e,t)=>{t.d(e,{A:()=>I});var a=t(96540),i=t(18215),o=t(23104),s=t(56347),l=t(205),d=t(57485),r=t(31682),p=t(70679);function u(n){return a.Children.toArray(n).filter((n=>"\n"!==n)).map((n=>{if(!n||(0,a.isValidElement)(n)&&function(n){const{props:e}=n;return!!e&&"object"==typeof e&&"value"in e}(n))return n;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof n.type?n.type:n.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function c(n){const{values:e,children:t}=n;return(0,a.useMemo)((()=>{const n=e??function(n){return u(n).map((n=>{let{props:{value:e,label:t,attributes:a,default:i}}=n;return{value:e,label:t,attributes:a,default:i}}))}(t);return function(n){const e=(0,r.X)(n,((n,e)=>n.value===e.value));if(e.length>0)throw new Error(`Docusaurus error: Duplicate values "${e.map((n=>n.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(n),n}),[e,t])}function h(n){let{value:e,tabValues:t}=n;return t.some((n=>n.value===e))}function m(n){let{queryString:e=!1,groupId:t}=n;const i=(0,s.W6)(),o=function(n){let{queryString:e=!1,groupId:t}=n;if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,d.aZ)(o),(0,a.useCallback)((n=>{if(!o)return;const e=new URLSearchParams(i.location.search);e.set(o,n),i.replace({...i.location,search:e.toString()})}),[o,i])]}function _(n){const{defaultValue:e,queryString:t=!1,groupId:i}=n,o=c(n),[s,d]=(0,a.useState)((()=>function(n){let{defaultValue:e,tabValues:t}=n;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!h({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map((n=>n.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const a=t.find((n=>n.default))??t[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:e,tabValues:o}))),[r,u]=m({queryString:t,groupId:i}),[_,f]=function(n){let{groupId:e}=n;const t=function(n){return n?`docusaurus.tab.${n}`:null}(e),[i,o]=(0,p.Dv)(t);return[i,(0,a.useCallback)((n=>{t&&o.set(n)}),[t,o])]}({groupId:i}),g=(()=>{const n=r??_;return h({value:n,tabValues:o})?n:null})();(0,l.A)((()=>{g&&d(g)}),[g]);return{selectedValue:s,selectValue:(0,a.useCallback)((n=>{if(!h({value:n,tabValues:o}))throw new Error(`Can't select invalid tab value=${n}`);d(n),u(n),f(n)}),[u,f,o]),tabValues:o}}var f=t(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var b=t(74848);function x(n){let{className:e,block:t,selectedValue:a,selectValue:s,tabValues:l}=n;const d=[],{blockElementScrollPositionUntilNextRender:r}=(0,o.a_)(),p=n=>{const e=n.currentTarget,t=d.indexOf(e),i=l[t].value;i!==a&&(r(e),s(i))},u=n=>{let e=null;switch(n.key){case"Enter":p(n);break;case"ArrowRight":{const t=d.indexOf(n.currentTarget)+1;e=d[t]??d[0];break}case"ArrowLeft":{const t=d.indexOf(n.currentTarget)-1;e=d[t]??d[d.length-1];break}}e?.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":t},e),children:l.map((n=>{let{value:e,label:t,attributes:o}=n;return(0,b.jsx)("li",{role:"tab",tabIndex:a===e?0:-1,"aria-selected":a===e,ref:n=>d.push(n),onKeyDown:u,onClick:p,...o,className:(0,i.A)("tabs__item",g.tabItem,o?.className,{"tabs__item--active":a===e}),children:t??e},e)}))})}function j(n){let{lazy:e,children:t,selectedValue:i}=n;const o=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const n=o.find((n=>n.props.value===i));return n?(0,a.cloneElement)(n,{className:"margin-top--md"}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:o.map(((n,e)=>(0,a.cloneElement)(n,{key:e,hidden:n.props.value!==i})))})}function y(n){const e=_(n);return(0,b.jsxs)("div",{className:(0,i.A)("tabs-container",g.tabList),children:[(0,b.jsx)(x,{...e,...n}),(0,b.jsx)(j,{...e,...n})]})}function I(n){const e=(0,f.A)();return(0,b.jsx)(y,{...n,children:u(n.children)},String(e))}}}]);