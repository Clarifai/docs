"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[2031],{52249:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>f,contentTitle:()=>E,default:()=>I,frontMatter:()=>_,metadata:()=>r,toc:()=>g});const r=JSON.parse('{"id":"compute/models/inference/api-legacy","title":"Legacy Inference via the API","description":"Perform predictions using our older method","source":"@site/docs/compute/models/inference/api-legacy.md","sourceDirName":"compute/models/inference","slug":"/compute/models/inference/api-legacy","permalink":"/compute/models/inference/api-legacy","draft":false,"unlisted":false,"editUrl":"https://github.com/Clarifai/docs/blob/main/docs/compute/models/inference/api-legacy.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"description":"Perform predictions using our older method","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Inference via the API","permalink":"/compute/models/inference/api"},"next":{"title":"Inference via the UI","permalink":"/compute/models/inference/ui"}}');var i=t(74848),a=t(28453),s=t(65537),o=t(79329),l=t(58069);const d='##################################################################################################\n# Change these strings to run your own example\n##################################################################################################\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "YOUR_USER_ID_HERE"\nIMAGE_URL = "https://samples.clarifai.com/birds.jpg"\nMODEL_URL = "https://clarifai.com/qwen/qwen-VL/models/Qwen2_5-VL-7B-Instruct"\nDEPLOYMENT_ID = "YOUR_DEPLOYMENT_ID_HERE"\n\n##################################################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##################################################################################################\n\nfrom clarifai.client.model import Model\n\n# Initialize the model\nmodel = Model(\n    url=MODEL_URL, # Or, use model_id="YOUR_MODEL_ID_HERE"\n    pat=PAT\n)\n\n# Make a unary-unary prediction using the image URL\nmodel_prediction = model.predict_by_url(\n    IMAGE_URL,\n    input_type="image",\n    user_id=USER_ID,\n    deployment_id=DEPLOYMENT_ID\n)\n\n# Output the model\'s response\nprint(model_prediction.outputs[0].data.text.raw)\n\n##################################################################################################\n# ADDITIONAL EXAMPLES\n##################################################################################################\n\n# Example prediction using a cluster and nodepool (no deployment ID needed):\n# model_prediction = Model(url=MODEL_URL, pat="YOUR_PAT_HERE").predict_by_url("INPUT_URL_HERE", input_type="image", user_id="YOUR_USER_ID_HERE", compute_cluster_id="YOUR_CLUSTER_ID_HERE", nodepool_id="YOUR_NODEPOOL_ID_HERE")\n\n# Example prediction via bytes:\n# model_prediction = Model(url=MODEL_URL, pat="YOUR_PAT_HERE").predict_by_bytes("INPUT_TEXT_HERE".encode(), input_type="text", user_id="YOUR_USER_ID_HERE", deployment_id="YOUR_DEPLOYMENT_ID_HERE")\n\n# Example prediction via filepath:\n# model_prediction = Model(url=MODEL_URL, pat="YOUR_PAT_HERE").predict_by_filepath("INPUT_FILEPATH_HERE", input_type="text", user_id="YOUR_USER_ID_HERE", deployment_id="YOUR_DEPLOYMENT_ID_HERE")\n',c='# Use the CLI to log in to the Clarifai platform first: https://docs.clarifai.com/additional-resources/api-overview/cli#login\n\nclarifai model predict --model_url https://clarifai.com/qwen/qwen-VL/models/Qwen2_5-VL-7B-Instruct --url https://samples.clarifai.com/birds.jpg --input_type image --deployment_id "YOUR_DEPLOYMENT_ID_HERE"\n',u='##################################################################################################\n# Change these strings to run your own example\n##################################################################################################\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "YOUR_USER_ID_HERE"\nPROMPT = "What is the future of AI?"\nMODEL_URL = "https://clarifai.com/meta/Llama-3/models/Llama-3_2-3B-Instruct"\nDEPLOYMENT_ID = "YOUR_DEPLOYMENT_ID_HERE"\n\n##################################################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##################################################################################################\n\nfrom clarifai.client.model import Model\n\n# Initialize the model\nmodel = Model(\n    url=MODEL_URL,  # Or, use model_id="YOUR_MODEL_ID_HERE"\n    pat=PAT\n)\n\n# Make a unary-stream prediction using the prompt as bytes\nresponse_stream = model.generate_by_bytes(\n    PROMPT.encode(),\n    input_type="text",\n    user_id=USER_ID,\n    deployment_id=DEPLOYMENT_ID\n)\n\n# Iterate through streamed responses and print them\nfor response in response_stream:\n    if response.outputs and response.outputs[0].data.text:\n        print(response.outputs[0].data.text.raw)\n\n# Print a newline at the end for better formatting\nprint()\n\n##################################################################################################\n# ADDITIONAL EXAMPLES\n##################################################################################################\n\n# Example stream prediction using a cluster and nodepool (no deployment ID needed):\n# for response in Model(url=MODEL_URL, pat="YOUR_PAT_HERE").generate_by_bytes("YOUR_PROMPT_HERE".encode(), input_type="text", user_id="YOUR_USER_ID_HERE", compute_cluster_id="YOUR_CLUSTER_ID", nodepool_id="YOUR_NODEPOOL_ID"):\n#     print(response.outputs[0].data.text.raw)\n\n# Example unary-stream prediction via URL:\n# for response in Model(url=MODEL_URL, pat="YOUR_PAT_HERE").generate_by_url("INPUT_URL_HERE", input_type="text", user_id="YOUR_USER_ID_HERE", deployment_id="YOUR_DEPLOYMENT_ID_HERE"):\n#     print(response.outputs[0].data.text.raw)\n\n# Example unary-stream prediction via filepath:\n# for response in Model(url=MODEL_URL, pat="YOUR_PAT_HERE").generate_by_filepath("INPUT_FILEPATH_HERE", input_type="text", user_id="YOUR_USER_ID_HERE", deployment_id="YOUR_DEPLOYMENT_ID_HERE"):\n#     print(response.outputs[0].data.text.raw)\n',p='##################################################################################################\n# Change these strings to run your own example\n##################################################################################################\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "YOUR_USER_ID_HERE"\nPROMPTS = [\n    "What is the future of AI?",\n    "Explain quantum computing in simple terms.",\n    "How does climate change affect global economies?"\n]\nMODEL_URL = "https://clarifai.com/meta/Llama-3/models/Llama-3_2-3B-Instruct"\nDEPLOYMENT_ID = "YOUR_DEPLOYMENT_ID_HERE"\n\n##################################################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##################################################################################################\n\nfrom clarifai.client.model import Model\n\n# Initialize the model\nmodel = Model(\n    url=MODEL_URL, # Or, use model_id="YOUR_MODEL_ID_HERE"\n    pat=PAT\n)\n\n# Prepare input iterator: each item is a bytes-encoded prompt\ninput_stream = (prompt.encode() for prompt in PROMPTS)\n\n# Stream-stream prediction using bytes\nresponse_stream = model.stream_by_bytes(\n    input_stream,\n    input_type="text",\n    user_id=USER_ID,\n    deployment_id=DEPLOYMENT_ID\n)\n\n# Iterate through streamed responses and print them\nfor response in response_stream:\n    if response.outputs and response.outputs[0].data.text:\n        print(response.outputs[0].data.text.raw)\n\n# Print a newline at the end for better formatting\nprint()\n\n##################################################################################################\n# ADDITIONAL EXAMPLES\n##################################################################################################\n\n# Example stream prediction using a cluster and nodepool (no deployment ID needed):\n# response_stream = Model(url=MODEL_URL, pat="YOUR_PAT_HERE").stream_by_bytes((prompt.encode() for prompt in PROMPTS), input_type="text", user_id="YOUR_USER_ID_HERE", compute_cluster_id="YOUR_CLUSTER_ID", nodepool_id="YOUR_NODEPOOL_ID")\n# for response in response_stream:\n#     print(response.outputs[0].data.text.raw)\n\n# Example stream prediction via URL:\n# response_stream = Model(url=MODEL_URL, pat="YOUR_PAT_HERE").stream_by_url(["INPUT_URL_1", "INPUT_URL_2"], input_type="text", user_id="YOUR_USER_ID_HERE", deployment_id="YOUR_DEPLOYMENT_ID_HERE")\n# for response in response_stream:\n#     print(response.outputs[0].data.text.raw)\n\n# Example stream prediction via filepath:\n# response_stream = Model(url=MODEL_URL, pat="YOUR_PAT_HERE").stream_by_filepath(["file1.txt", "file2.txt"], input_type="text", user_id="YOUR_USER_ID_HERE", deployment_id="YOUR_DEPLOYMENT_ID_HERE")\n# for response in response_stream:\n#     print(response.outputs[0].data.text.raw)\n',m="2025-04-04 13:27:15.990657 INFO     Qwen2_5-VL-7B-Instruct model is still deploying, please wait...         model.py:443\n2025-04-04 13:27:30.233847 INFO     Qwen2_5-VL-7B-Instruct model is still deploying, please wait...         model.py:443\n2025-04-04 13:27:45.624827 INFO     Qwen2_5-VL-7B-Instruct model is still deploying, please wait...         model.py:443\n2025-04-04 13:28:02.551081 INFO     Qwen2_5-VL-7B-Instruct model is still deploying, please wait...         model.py:443\nThis image captures three seagulls in flight over a body of water, likely a lake or river. The background is a natural setting with dry grass and trees, suggesting it might be late autumn or early spring. The seagulls appear to be gliding close to the water's surface, possibly searching for food. The lighting indicates it could be a sunny day. This scene is typical of coastal or lakeside environments where seagulls often congregate.\n",h="2025-04-04 15:10:09.952752 INFO     Llama-3_2-3B-Instruct model is still     model.py:726\n                                    deploying, please wait...\n2025-04-04 15:10:24.522422 INFO     Llama-3_2-3B-Instruct model is still     model.py:726\n                                    deploying, please wait...\nThe\n future\n of\n Artificial\n Intelligence\n (\nAI\n)\n is\n vast\n and\n rapidly\n evolving\n.\n Based\n on\n current\n trends\n and\n advancements\n,\n here\n are\n some\n potential\n developments\n that\n may\n shape\n the\n future\n of\n AI\n:\n\n\n**\nShort\n-term\n (\n202\n5\n-\n203\n0\n)**\n\n\n\n1\n.\n **\nIncreased\n Adoption\n**:\n AI\n will\n become\n more\n ubiquitous\n in\n various\n industries\n,\n including\n healthcare\n,\n finance\n,\n transportation\n,\n and\n education\n.\n\n2\n.\n **\nImproved\n Natural\n Language\n Processing\n (\nN\nLP\n)**\n:\n N\nLP\n will\n continue\n to\n advance\n,\n enabling\n more\n accurate\n and\n effective\n human\n-com\nputer\n interactions\n.\n\n3\n.\n **\nEnh\nanced\n Machine\n Learning\n (\nML\n)**\n:\n ML\n will\n become\n more\n sophisticated\n,\n allowing\n for\n more\n accurate\n predictions\n and\n decision\n-making\n.\n\n4\n.\n **\nR\nise\n of\n Explain\nable\n AI\n (\nX\nAI\n)**\n:\n X\nAI\n will\n become\n more\n prominent\n,\n enabling\n users\n to\n understand\n the\n reasoning\n behind\n AI\n decisions\n.\n\n\n**\nMid\n-term\n (\n203\n0\n-\n204\n0\n)**\n\n\n\n1\n.\n **\nArt\nificial\n General\n Intelligence\n (\nAG\nI\n)**\n:\n AG\nI\n,\n which\n refers\n to\n AI\n systems\n that\n can\n perform\n any\n intellectual\n task\n,\n may\n emerge\n.\n\n2\n.\n **\nQuant\num\n AI\n**:\n Quantum\n computing\n will\n be\n integrated\n with\n AI\n,\n leading\n to\n exponential\n advancements\n in\n processing\n power\n and\n AI\n capabilities\n.\n\n3\n.\n **\nEdge\n AI\n**:\n Edge\n AI\n will\n become\n more\n prevalent\n,\n enabling\n AI\n to\n be\n deployed\n at\n the\n edge\n of\n networks\n,\n reducing\n latency\n,\n and\n improving\n real\n-time\n decision\n-making\n.\n\n4\n.\n **\nHuman\n-A\nI\n Collaboration\n**:\n Humans\n and\n AI\n systems\n will\n collaborate\n more\n effectively\n,\n leading\n to\n increased\n productivity\n and\n innovation\n.\n\n\n**\nLong\n-term\n (\n204\n0\n-\n205\n0\n)**\n\n\n\n1\n.\n **\nM\nerging\n of\n Human\n and\n Machine\n Intelligence\n**:\n The\n line\n between\n human\n and\n machine\n intelligence\n will\n blur\n,\n leading\n to\n new\n forms\n of\n intelligence\n and\n cognition\n.\n\n2\n.\n **\nAut\nonomous\n Systems\n**:\n Autonomous\n systems\n,\n such\n as\n self\n-driving\n cars\n and\n drones\n,\n will\n become\n more\n common\n,\n revolution\nizing\n industries\n like\n transportation\n and\n logistics\n.\n\n3\n.\n **\nC\nognitive\n Architect\nures\n**:\n Cognitive\n architectures\n,\n which\n aim\n to\n create\n AI\n systems\n that\n can\n reason\n and\n learn\n like\n humans\n,\n will\n emerge\n.\n\n4\n.\n **\nAI\n Ethics\n and\n Governance\n**:\n As\n AI\n becomes\n more\n pervasive\n,\n there\n will\n be\n a\n growing\n need\n for\n AI\n ethics\n and\n governance\n frameworks\n to\n ensure\n responsible\n AI\n development\n and\n deployment\n.\n\n\n**\nPotential\n Ris\nks\n and\n Challenges\n**\n\n\n1\n.\n **\nJob\n Dis\nplacement\n**:\n AI\n may\n dis\nplace\n certain\n jobs\n,\n leading\n to\n significant\n social\n and\n economic\n impacts\n.\n\n2\n.\n **\nBias\n and\n Fair\nness\n**:\n AI\n systems\n may\n perpet\nuate\n existing\n biases\n and\n inequalities\n,\n highlighting\n the\n need\n for\n more\n diverse\n and\n inclusive\n AI\n development\n.\n\n3\n.\n **\nSecurity\n and\n Safety\n**:\n AI\n systems\n may\n pose\n new\n security\n and\n safety\n risks\n,\n such\n as\n autonomous\n systems\n malfunction\ning\n or\n being\n exploited\n.\n\n4\n.\n **\nValue\n Alignment\n**:\n AI\n systems\n may\n not\n align\n with\n human\n",_={description:"Perform predictions using our older method",sidebar_position:2},E="Legacy Inference via the API",f={},g=[{value:"Unary-Unary Predict Call",id:"unary-unary-predict-call",level:2},{value:"Unary-Stream Predict Call",id:"unary-stream-predict-call",level:2},{value:"Stream-Stream Predict Call",id:"stream-stream-predict-call",level:2}];function y(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...n.components},{Details:t}=e;return t||function(n,e){throw new Error("Expected "+(e?"component":"object")+" `"+n+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"legacy-inference-via-the-api",children:"Legacy Inference via the API"})}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Perform predictions using our older method"})}),"\n",(0,i.jsx)("hr",{}),"\n",(0,i.jsx)(e.p,{children:"The legacy inference technique uses our previous API structure and is best suited for models built using the older techniques."}),"\n",(0,i.jsxs)(e.p,{children:["While this method remains functional, we recommend transitioning to the ",(0,i.jsx)(e.a,{href:"/compute/models/inference/api",children:"new inference method"})," for improved efficiency, scalability, and access to the latest features."]}),"\n",(0,i.jsx)(e.admonition,{type:"info",children:(0,i.jsxs)(e.p,{children:["Before making a prediction, ensure that your model has been deployed, ",(0,i.jsx)(e.a,{href:"/compute/models/inference/",children:"as mentioned previously"}),". Otherwise, the prediction will default to the ",(0,i.jsx)(e.code,{children:"Clarifai Shared"})," deployment type."]})}),"\n","\n","\n","\n",(0,i.jsx)(e.h2,{id:"unary-unary-predict-call",children:"Unary-Unary Predict Call"}),"\n",(0,i.jsx)(e.p,{children:"This is the simplest type of prediction. In this method, a single input is sent to the model, and it returns a single response. This is ideal for tasks where a quick, non-streaming prediction is required, such as classifying an image."}),"\n",(0,i.jsx)(e.p,{children:"It supports the following prediction methods:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"predict_by_url"}),"  \u2014 Use a publicly accessible URL for the input."]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"predict_by_bytes"})," \u2014 Pass raw input data directly."]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"predict_by_filepath"})," \u2014 Provide the local file path for the input."]}),"\n"]}),"\n",(0,i.jsxs)(s.A,{children:[(0,i.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:d})}),(0,i.jsx)(o.A,{value:"bash",label:"CLI",children:(0,i.jsx)(l.A,{className:"language-yaml",children:c})})]}),"\n",(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:"Example Output"}),(0,i.jsx)(l.A,{className:"language-text",children:m})]}),"\n",(0,i.jsx)(e.h2,{id:"unary-stream-predict-call",children:"Unary-Stream Predict Call"}),"\n",(0,i.jsxs)(e.p,{children:["The ",(0,i.jsx)(e.strong,{children:"Unary-Stream"})," predict call processes a single input, but returns a stream of responses. It is particularly useful for tasks where multiple outputs are generated from a single input, such as generating text completions from a prompt."]}),"\n",(0,i.jsx)(e.p,{children:"It supports the following prediction methods:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"generate_by_url"}),"  \u2014 Provide a publicly accessible URL and handle the streamed responses iteratively."]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"generate_by_bytes"})," \u2014 Use raw input data."]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"generate_by_filepath"})," \u2014 Use a local file path for the input."]}),"\n"]}),"\n",(0,i.jsx)(s.A,{children:(0,i.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:u})})}),"\n",(0,i.jsxs)(t,{children:[(0,i.jsx)("summary",{children:"Example Output"}),(0,i.jsx)(l.A,{className:"language-text",children:h})]}),"\n",(0,i.jsx)(e.h2,{id:"stream-stream-predict-call",children:"Stream-Stream Predict Call"}),"\n",(0,i.jsxs)(e.p,{children:["The ",(0,i.jsx)(e.strong,{children:"stream-stream"})," predict call enables bidirectional streaming of both inputs and outputs, making it highly effective for processing large datasets or real-time applications."]}),"\n",(0,i.jsx)(e.p,{children:"In this setup, multiple inputs can be continuously sent to the model, and the corresponding multiple predictions are streamed back in real-time. This is ideal for tasks like real-time video processing/predictions or live sensor data analysis."}),"\n",(0,i.jsx)(e.p,{children:"It supports the following prediction methods:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"stream_by_url"})," \u2014 Stream a list of publicly accessible URLs and receive a stream of predictions. It takes an iterator of inputs and returns a stream of predictions."]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"stream_by_bytes"})," \u2014 Stream raw input data."]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"stream_by_filepath"})," \u2014 Stream inputs from local file paths."]}),"\n"]}),"\n",(0,i.jsx)(s.A,{children:(0,i.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:p})})})]})}function I(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(y,{...n})}):y(n)}},65537:(n,e,t)=>{t.d(e,{A:()=>R});var r=t(96540),i=t(18215),a=t(65627),s=t(56347),o=t(50372),l=t(30604),d=t(11861),c=t(78749);function u(n){return r.Children.toArray(n).filter((n=>"\n"!==n)).map((n=>{if(!n||(0,r.isValidElement)(n)&&function(n){const{props:e}=n;return!!e&&"object"==typeof e&&"value"in e}(n))return n;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof n.type?n.type:n.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(n){const{values:e,children:t}=n;return(0,r.useMemo)((()=>{const n=e??function(n){return u(n).map((n=>{let{props:{value:e,label:t,attributes:r,default:i}}=n;return{value:e,label:t,attributes:r,default:i}}))}(t);return function(n){const e=(0,d.XI)(n,((n,e)=>n.value===e.value));if(e.length>0)throw new Error(`Docusaurus error: Duplicate values "${e.map((n=>n.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(n),n}),[e,t])}function m(n){let{value:e,tabValues:t}=n;return t.some((n=>n.value===e))}function h(n){let{queryString:e=!1,groupId:t}=n;const i=(0,s.W6)(),a=function(n){let{queryString:e=!1,groupId:t}=n;if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,l.aZ)(a),(0,r.useCallback)((n=>{if(!a)return;const e=new URLSearchParams(i.location.search);e.set(a,n),i.replace({...i.location,search:e.toString()})}),[a,i])]}function _(n){const{defaultValue:e,queryString:t=!1,groupId:i}=n,a=p(n),[s,l]=(0,r.useState)((()=>function(n){let{defaultValue:e,tabValues:t}=n;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map((n=>n.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const r=t.find((n=>n.default))??t[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:e,tabValues:a}))),[d,u]=h({queryString:t,groupId:i}),[_,E]=function(n){let{groupId:e}=n;const t=function(n){return n?`docusaurus.tab.${n}`:null}(e),[i,a]=(0,c.Dv)(t);return[i,(0,r.useCallback)((n=>{t&&a.set(n)}),[t,a])]}({groupId:i}),f=(()=>{const n=d??_;return m({value:n,tabValues:a})?n:null})();(0,o.A)((()=>{f&&l(f)}),[f]);return{selectedValue:s,selectValue:(0,r.useCallback)((n=>{if(!m({value:n,tabValues:a}))throw new Error(`Can't select invalid tab value=${n}`);l(n),u(n),E(n)}),[u,E,a]),tabValues:a}}var E=t(9136);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var g=t(74848);function y(n){let{className:e,block:t,selectedValue:r,selectValue:s,tabValues:o}=n;const l=[],{blockElementScrollPositionUntilNextRender:d}=(0,a.a_)(),c=n=>{const e=n.currentTarget,t=l.indexOf(e),i=o[t].value;i!==r&&(d(e),s(i))},u=n=>{let e=null;switch(n.key){case"Enter":c(n);break;case"ArrowRight":{const t=l.indexOf(n.currentTarget)+1;e=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(n.currentTarget)-1;e=l[t]??l[l.length-1];break}}e?.focus()};return(0,g.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":t},e),children:o.map((n=>{let{value:e,label:t,attributes:a}=n;return(0,g.jsx)("li",{role:"tab",tabIndex:r===e?0:-1,"aria-selected":r===e,ref:n=>{l.push(n)},onKeyDown:u,onClick:c,...a,className:(0,i.A)("tabs__item",f.tabItem,a?.className,{"tabs__item--active":r===e}),children:t??e},e)}))})}function I(n){let{lazy:e,children:t,selectedValue:a}=n;const s=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const n=s.find((n=>n.props.value===a));return n?(0,r.cloneElement)(n,{className:(0,i.A)("margin-top--md",n.props.className)}):null}return(0,g.jsx)("div",{className:"margin-top--md",children:s.map(((n,e)=>(0,r.cloneElement)(n,{key:e,hidden:n.props.value!==a})))})}function b(n){const e=_(n);return(0,g.jsxs)("div",{className:(0,i.A)("tabs-container",f.tabList),children:[(0,g.jsx)(y,{...e,...n}),(0,g.jsx)(I,{...e,...n})]})}function R(n){const e=(0,E.A)();return(0,g.jsx)(b,{...n,children:u(n.children)},String(e))}},79329:(n,e,t)=>{t.d(e,{A:()=>s});t(96540);var r=t(18215);const i={tabItem:"tabItem_Ymn6"};var a=t(74848);function s(n){let{children:e,hidden:t,className:s}=n;return(0,a.jsx)("div",{role:"tabpanel",className:(0,r.A)(i.tabItem,s),hidden:t,children:e})}}}]);