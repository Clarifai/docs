"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[2908],{40118:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>G,contentTitle:()=>H,default:()=>F,frontMatter:()=>z,metadata:()=>q,toc:()=>M});var l=t(74848),o=t(28453),s=t(11470),i=t(19365),r=t(21432);const a='compute_cluster:\n  id: "test-compute-cluster"\n  description: "My AWS compute cluster"\n  cloud_provider:\n      id: "aws"\n  region: "us-east-1"\n  managed_by: "clarifai"\n  cluster_type: "dedicated"\n  visibility:\n    gettable: 10',c='from clarifai.client.user import User\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" \n\n# Initialize the client\nclient = User(\n    user_id="YOUR_USER_ID_HERE",\n    base_url="https://api.clarifai.com"\n)\n\n# Create a new compute cluster\ncompute_cluster = client.create_compute_cluster(\n    compute_cluster_id="test-compute-cluster",\n    config_filepath="./configs/compute_cluster_config.yaml"\n)\n',d='from clarifai.client.user import User\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE"  \n\n# Initialize the client\nclient = User(\n    user_id="YOUR_USER_ID_HERE",\n    base_url="https://api.clarifai.com"\n)\n\n# Get and print the compute cluster\ncompute_cluster = client.compute_cluster(\n    compute_cluster_id="test-compute-cluster"\n)\nprint(compute_cluster)\n',p='from clarifai.client.user import User\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE"  \n\n# Initialize the client\nclient = User(\n    user_id="YOUR_USER_ID_HERE",\n    base_url="https://api.clarifai.com"\n)\n\n# Get and print all the compute clusters\nall_compute_clusters = list(\n    client.list_compute_clusters()\n)\nprint(all_compute_clusters)',u='from clarifai.client.compute_cluster import ComputeCluster\n\n# Initialize the ComputeCluster instance\ncompute_cluster = ComputeCluster(\n    user_id="YOUR_USER_ID_HERE",           \n    compute_cluster_id="test-compute-cluster",\n    base_url="https://api.clarifai.com"          \n)\n',h='nodepool:\n  id: "test-nodepool"\n  compute_cluster:\n    id: "test-compute-cluster"\n  description: "First nodepool in AWS in a proper compute cluster"\n  instance_types:\n    - id: "g5.xlarge"\n      compute_info:\n        cpu_limit: "8"\n        cpu_memory: "16Gi"\n        accelerator_type:\n          - "a10"\n        num_accelerators: 1\n        accelerator_memory: "40Gi"\n  node_capacity_type:\n    capacity_types:\n      - 1\n      - 2\n  max_instances: 1',m='from clarifai.client.compute_cluster import ComputeCluster\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE"  \n\n# Initialize the ComputeCluster instance\ncompute_cluster = ComputeCluster(\n    user_id="YOUR_USER_ID_HERE",\n    compute_cluster_id="test-compute-cluster",\n    base_url="https://api.clarifai.com"\n)\n\n# Create a new nodepool \nnodepool = compute_cluster.create_nodepool(\n    nodepool_id="test-nodepool",\n    config_filepath="./configs/nodepool_config.yaml"\n)\n',_='from clarifai.client.compute_cluster import ComputeCluster\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" \n\n# Initialize the ComputeCluster instance\ncompute_cluster = ComputeCluster(\n    user_id="YOUR_USER_ID_HERE",\n    compute_cluster_id="test-compute-cluster",\n    base_url="https://api.clarifai.com"\n)\n\n# Get and print the nodepool \nnodepool = compute_cluster.nodepool(\n    nodepool_id="test-nodepool"\n)\nprint(nodepool)',y='from clarifai.client.compute_cluster import ComputeCluster\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" \n\n# Initialize the ComputeCluster instance\ncompute_cluster = ComputeCluster(\n    user_id="YOUR_USER_ID_HERE",\n    compute_cluster_id="test-compute-cluster",\n    base_url="https://api.clarifai.com"\n)\n\n# Get and print all the nodepools \nall_nodepools = list(\n    compute_cluster.list_nodepools()\n)\nprint(all_nodepools)\n',f='from clarifai.client.nodepool import Nodepool\n\n# Initialize the Nodepool instance\nnodepool = Nodepool(\n    user_id="YOUR_USER_ID_HERE",            \n    nodepool_id="test-nodepool",   \n    base_url="https://api.clarifai.com"            \n)\n',x='deployment:\n id: "test-deployment"\n description: "some random deployment"\n autoscale_config:\n   min_replicas: 0\n   max_replicas: 1\n   traffic_history_seconds: 100\n   scale_down_delay_seconds: 30\n   scale_up_delay_seconds: 30\n   enable_packing: true\n worker:\n   model:\n     id: "got-ocr-2_0"\n     model_version:\n       id: "5d92321db5d341b5b4cf407ab34f618f"\n     user_id: "stepfun-ai"\n     app_id: "ocr"\n scheduling_choice: 4\n nodepools:\n   - id: "test-nodepool"\n     compute_cluster:\n         id: "test-compute-cluster"\n',j='from clarifai.client.nodepool import Nodepool\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" \n\n# Initialize the Nodepool instance\nnodepool = Nodepool(\n    user_id="YOUR_USER_ID_HERE",            \n    nodepool_id="test-nodepool",   \n    base_url="https://api.clarifai.com"            \n)\n\n# Create a new deployment\ndeployment = nodepool.create_deployment(\n    deployment_id="test-deployment", \n    config_filepath="./configs/deployment_config.yaml"\n)',g='from clarifai.client.nodepool import Nodepool\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" \n\n# Initialize the Nodepool instance\nnodepool = Nodepool(\n    user_id="YOUR_USER_ID_HERE",            \n    nodepool_id="test-nodepool",   \n    base_url="https://api.clarifai.com"            \n)\n\n## Get and print the deployment\ndeployment = nodepool.deployment(\n    deployment_id="test-deployment"\n)\nprint(deployment)',b='from clarifai.client.nodepool import Nodepool\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" \n\n# Initialize the Nodepool instance\nnodepool = Nodepool(\n    user_id="YOUR_USER_ID_HERE",            \n    nodepool_id="test-nodepool",   \n    base_url="https://api.clarifai.com"            \n)\n\n# Get and print all the deployments \nall_deployments = list(\n    nodepool.list_deployments()\n)\nprint(all_deployments)',A='from clarifai.client.deployment import Deployment\n\n# Initialize the deployment\ndeployment = Deployment(\n    user_id="YOUR_USER_ID_HERE", \n    deployment_id="test-deployment",\n    base_url="https://api.clarifai.com"\n)\n',v='from clarifai.client.nodepool import Nodepool\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" \n\n# Initialize the Nodepool instance\nnodepool = Nodepool(\n    user_id="YOUR_USER_ID_HERE",\n    nodepool_id="test-nodepool",\n    base_url="https://api.clarifai.com"\n)\n\n# Get all the deployments in the nodepool\nall_deployments = list(nodepool.list_deployments())\n\n# Extract deployment IDs for deletion\ndeployment_ids = [deployment.id for deployment in all_deployments]\n\n# Delete a specific deployment by providing its deployment ID\n# deployment_ids = ["test-deployment"]\n\n# Delete the deployments\nnodepool.delete_deployments(deployment_ids=deployment_ids)\n',C='from clarifai.client.compute_cluster import ComputeCluster\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" \n\n# Initialize the ComputeCluster instance\ncompute_cluster = ComputeCluster(\n    user_id="YOUR_USER_ID_HERE",           \n    compute_cluster_id="test-compute-cluster",\n    base_url="https://api.clarifai.com"\n)\n\n# Get all nodepools within the compute cluster\nall_nodepools = list(compute_cluster.list_nodepools())\n\n# Extract nodepool IDs for deletion\nnodepool_ids = [nodepool.id for nodepool in all_nodepools]\n\n# Delete a specific nodepool by providing its ID\n# nodepool_ids = ["test-nodepool"]\n\n# Delete the nodepools\ncompute_cluster.delete_nodepools(nodepool_ids=nodepool_ids)\n',I='from clarifai.client.user import User\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" \n\n# Initialize the User client\nclient = User(\n    user_id="YOUR_USER_ID_HERE",           \n    base_url="https://api.clarifai.com"\n)\n\n# Get all compute clusters associated with the user\nall_compute_clusters = list(client.list_compute_clusters())\n\n# Extract compute cluster IDs for deletion\ncompute_cluster_ids = [compute_cluster.id for compute_cluster in all_compute_clusters]\n\n# Delete a specific nodepool by providing its ID\n# compute_cluster_ids = ["test-compute-cluster"]\n\n# Delete the compute clusters\nclient.delete_compute_clusters(compute_cluster_ids=compute_cluster_ids)\n',R='from clarifai.client.model import Model\n\nmodel_url = "https://clarifai.com/stepfun-ai/ocr/models/got-ocr-2_0"\n\n# URL of the image to analyze\nimage_url = "https://samples.clarifai.com/featured-models/model-ocr-scene-text-las-vegas-sign.png"\n\n# Initialize the model \nmodel = Model(\n    url=model_url, \n    pat="YOUR_PAT_HERE" \n)\n\n# Make a prediction using the model with the specified compute cluster and nodepool\nmodel_prediction = model.predict_by_url(\n    image_url,\n    input_type="image",\n    deployment_id="test-deployment"     \n)\n\n# Print the output\nprint(model_prediction.outputs[0].data.text.raw)\n',E='from clarifai.client.model import Model\n\nmodel_url = "https://clarifai.com/meta/Llama-3/models/llama-3_2-3b-instruct"\n\n# URL of the prompt text\ntext_url = "https://samples.clarifai.com/featured-models/falcon-instruction-guidance.txt"\n\n# Initialize the model \nmodel = Model(\n    url=model_url, \n    pat="YOUR_PAT_HERE" \n)\n\n# Perform unary-stream prediction with the specified compute cluster and nodepool\nstream_response = model.generate_by_url(\n    text_url, \n    input_type="text",\n    compute_cluster_id="test-compute-cluster", \n    nodepool_id="test-nodepool"\n)\n\n# Handle the stream of responses\nlist_stream_response = [response for response in stream_response]\n',T='from clarifai.client.model import Model\n\nmodel_url = "https://clarifai.com/meta/Llama-3/models/llama-3_2-3b-instruct"\n\n# URL of the prompt text\ntext_url = "https://samples.clarifai.com/featured-models/falcon-instruction-guidance.txt"\n\n# Initialize the model \nmodel = Model(\n    url=model_url, \n    pat="YOUR_PAT_HERE" \n)\n\n# Perform stream-stream prediction with the specified compute cluster and nodepool\nstream_response = model.stream_by_url(\n    iter([text_url]), \n    input_type="text",\n    compute_cluster_id="compute_cluster_id", \n    nodepool_id="nodepool_id"\n)\n\n# Handle the stream of responses\nlist_stream_response = [response for response in stream_response]\n',P='user_id: "YOUR_USER_ID_HERE"\npat: "YOUR_PAT_HERE"  ',U="$ clarifai computecluster create --config <compute-cluster-config-filepath>",w="$ clarifai nodepool create --config <nodepool-config-filepath>",N="$ clarifai deployment create --config <deployment-config-filepath>",D="$ clarifai computecluster list",k="$ clarifai nodepool list --compute_cluster_id <compute-cluster-id>",O="$ clarifai deployment list --nodepool_id <nodepool-id>",S="$ clarifai computecluster delete --compute_cluster_id <compute-cluster-id>",L="$ clarifai nodepool delete --compute_cluster_id <compute-cluster-id> --nodepool_id <nodepool-id>",Y="$ clarifai deployment delete --nodepool_id <nodepool-id> --deployment_id <deployment-id>",z={description:"Train and deploy any model on any compute infrastructure, at any scale",pagination_prev:null,sidebar_position:6.1},H="Compute Orchestration",q={id:"sdk/compute-orchestration",title:"Compute Orchestration",description:"Train and deploy any model on any compute infrastructure, at any scale",source:"@site/docs/sdk/compute-orchestration.md",sourceDirName:"sdk",slug:"/sdk/compute-orchestration",permalink:"/sdk/compute-orchestration",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/sdk/compute-orchestration.md",tags:[],version:"current",sidebarPosition:6.1,frontMatter:{description:"Train and deploy any model on any compute infrastructure, at any scale",pagination_prev:null,sidebar_position:6.1},sidebar:"tutorialSidebar",next:{title:"Building Workflow Graphs",permalink:"/sdk/Building-Workflow-Graphs/"}},G={},M=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Installation",id:"installation",level:4},{value:"Get a PAT",id:"get-a-pat",level:4},{value:"Set up Project Directory",id:"set-up-project-directory",level:4},{value:"Cluster Operations",id:"cluster-operations",level:2},{value:"Create a Compute Cluster",id:"create-a-compute-cluster",level:4},{value:"Get a Cluster",id:"get-a-cluster",level:4},{value:"List All Clusters",id:"list-all-clusters",level:4},{value:"Initialize the <code>ComputeCluster</code> Class",id:"initialize-the-computecluster-class",level:4},{value:"Nodepool Operations",id:"nodepool-operations",level:2},{value:"Create a Nodepool",id:"create-a-nodepool",level:4},{value:"Get a Nodepool",id:"get-a-nodepool",level:4},{value:"List All Nodepools",id:"list-all-nodepools",level:4},{value:"Initialize the <code>Nodepool</code> Class",id:"initialize-the-nodepool-class",level:4},{value:"Deployment Operations",id:"deployment-operations",level:2},{value:"Create a Deployment",id:"create-a-deployment",level:4},{value:"Get a Deployment",id:"get-a-deployment",level:4},{value:"List All Deployments",id:"list-all-deployments",level:4},{value:"Initialize the <code>Deployment</code> Class",id:"initialize-the-deployment-class",level:4},{value:"Predict With Deployed Model",id:"predict-with-deployed-model",level:2},{value:"Unary-Unary Predict Call",id:"unary-unary-predict-call",level:3},{value:"Unary-Stream Predict Call",id:"unary-stream-predict-call",level:3},{value:"Stream-Stream Predict Call",id:"stream-stream-predict-call",level:3},{value:"Delete Resources",id:"delete-resources",level:2},{value:"Delete Deployments",id:"delete-deployments",level:4},{value:"Delete Nodepools",id:"delete-nodepools",level:4},{value:"Delete Compute Clusters",id:"delete-compute-clusters",level:4}];function V(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.h1,{id:"compute-orchestration",children:"Compute Orchestration"}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Train and deploy any model on any compute infrastructure, at any scale"})}),"\n",(0,l.jsx)("hr",{}),"\n",(0,l.jsx)(n.admonition,{type:"note",children:(0,l.jsxs)(n.p,{children:["Compute Orchestration is currently in ",(0,l.jsx)(n.a,{href:"https://docs.clarifai.com/product-updates/changelog/release-types",children:"Public Preview"}),". To request access, please contact us ",(0,l.jsx)(n.a,{href:"https://www.clarifai.com/explore/contact-us-co",children:"here"}),"."]})}),"\n",(0,l.jsx)(n.p,{children:"Clarifai\u2019s Compute Orchestration offers a streamlined solution for managing the infrastructure required for training, deploying, and scaling machine learning models and workflows."}),"\n",(0,l.jsx)(n.p,{children:"This flexible system supports any compute instance \u2014 across various hardware providers and deployment methods \u2014 and provides automatic scaling to match workload demands."}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/compute-orchestration",children:"Click here"})," to learn more about our Compute Orchestration system."]}),"\n",(0,l.jsx)(n.admonition,{title:"Tips",type:"tip",children:(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:["Run the following command to clone the repository containing various Compute Orchestration examples: ",(0,l.jsx)(n.code,{children:"git clone https://github.com/Clarifai/examples.git"}),". After cloning, navigate to the ",(0,l.jsx)(n.code,{children:"ComputeOrchestration"})," folder to follow along with the tutorial."]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:["For a step-by-step tutorial, check the ",(0,l.jsx)(n.a,{href:"https://github.com/Clarifai/examples/blob/main/ComputeOrchestration/crud_operations.ipynb",children:"CRUD operations notebook"}),"."]}),"\n"]}),"\n"]})}),"\n",(0,l.jsx)(n.admonition,{title:"Clarifai CLI",type:"info",children:(0,l.jsxs)(n.p,{children:["Clarifai provides a user-friendly command line interface (CLI) that simplifies Compute Orchestration tasks. With the CLI, you can easily manage the infrastructure required for deploying and scaling machine learning models, even without extensive MLOps expertise.\nThis tool makes it easy to set up clusters, configure nodepools, and deploy models directly from the command line. You can follow its step-by-step tutorial provided ",(0,l.jsx)(n.a,{href:"https://github.com/Clarifai/clarifai-python/blob/master/clarifai/cli/README.md",children:"here"}),"."]})}),"\n","\n","\n","\n",(0,l.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,l.jsx)(n.h4,{id:"installation",children:"Installation"}),"\n",(0,l.jsxs)(n.p,{children:["To begin, install the latest version of the ",(0,l.jsx)(n.code,{children:"clarifai"})," Python package."]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-text",children:"pip install --upgrade clarifai\n"})}),"\n",(0,l.jsx)(n.h4,{id:"get-a-pat",children:"Get a PAT"}),"\n",(0,l.jsxs)(n.p,{children:["You need a PAT (Personal Access Token) key to authenticate your connection to the Clarifai platform. You can generate it in your Personal Settings page by navigating to the ",(0,l.jsx)(n.a,{href:"https://clarifai.com/settings/security",children:"Security section"}),"."]}),"\n",(0,l.jsx)(n.p,{children:"Then, set it as an environment variable in your script."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-text",children:'import os\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" # replace with your own PAT key \n'})}),"\n",(0,l.jsx)(n.h4,{id:"set-up-project-directory",children:"Set up Project Directory"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Create a directory to store your project files."}),"\n",(0,l.jsx)(n.li,{children:"Inside this directory, create a Python file for your Compute Orchestration code."}),"\n",(0,l.jsxs)(n.li,{children:["Create a ",(0,l.jsx)(n.code,{children:"configs"})," folder to store your YAML configuration files for clusters, nodepools, and deployments."]}),"\n"]}),"\n",(0,l.jsxs)(n.p,{children:["In the ",(0,l.jsx)(n.code,{children:"configs"})," folder:"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"1."})," ",(0,l.jsx)(n.code,{children:"compute_cluster_config.yaml"}),":"]}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"yaml",label:"YAML",children:(0,l.jsx)(r.A,{className:"language-yaml",children:a})})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"2."})," ",(0,l.jsx)(n.code,{children:"nodepool_config.yaml"}),":"]}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"yaml",label:"YAML",children:(0,l.jsx)(r.A,{className:"language-yaml",children:h})})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"3."})," ",(0,l.jsx)(n.code,{children:"deployment_config.yaml"}),":"]}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"yaml",label:"YAML",children:(0,l.jsx)(r.A,{className:"language-yaml",children:x})})}),"\n",(0,l.jsx)(n.p,{children:"Optionally, if you want to use the Clarifai CLI, create a login configuration file for storing your account credentials:"}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"yaml",label:"YAML",children:(0,l.jsx)(r.A,{className:"language-yaml",children:P})})}),"\n",(0,l.jsx)(n.p,{children:"Then, authenticate your CLI session with Clarifai using the stored credentials in the configuration file:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"$ clarifai login --config <config-filepath>\n"})}),"\n",(0,l.jsx)(n.h2,{id:"cluster-operations",children:"Cluster Operations"}),"\n",(0,l.jsx)(n.h4,{id:"create-a-compute-cluster",children:"Create a Compute Cluster"}),"\n",(0,l.jsxs)(n.p,{children:["To create a new compute cluster, pass the ",(0,l.jsx)(n.code,{children:"compute_cluster_id"})," and ",(0,l.jsx)(n.code,{children:"config_filepath"})," as arguments to the ",(0,l.jsx)(n.code,{children:"create_compute_cluster"})," method of the ",(0,l.jsx)(n.code,{children:"User"})," class."]}),"\n",(0,l.jsxs)(s.A,{children:[(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:c})}),(0,l.jsx)(i.A,{value:"bash",label:"Bash",children:(0,l.jsx)(r.A,{className:"language-yaml",children:U})})]}),"\n",(0,l.jsx)(n.h4,{id:"get-a-cluster",children:"Get a Cluster"}),"\n",(0,l.jsxs)(n.p,{children:["To get a specific compute cluster, pass the ",(0,l.jsx)(n.code,{children:"compute_cluster_id"})," to the ",(0,l.jsx)(n.code,{children:"compute_cluster"})," method of the ",(0,l.jsx)(n.code,{children:"User"})," class."]}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:d})})}),"\n",(0,l.jsx)(n.h4,{id:"list-all-clusters",children:"List All Clusters"}),"\n",(0,l.jsxs)(n.p,{children:["To list your existing compute clusters, call the ",(0,l.jsx)(n.code,{children:"list_compute_clusters"})," method of the ",(0,l.jsx)(n.code,{children:"User"})," class."]}),"\n",(0,l.jsxs)(s.A,{children:[(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:p})}),(0,l.jsx)(i.A,{value:"bash",label:"Bash",children:(0,l.jsx)(r.A,{className:"language-yaml",children:D})})]}),"\n",(0,l.jsxs)(n.h4,{id:"initialize-the-computecluster-class",children:["Initialize the ",(0,l.jsx)(n.code,{children:"ComputeCluster"})," Class"]}),"\n",(0,l.jsxs)(n.p,{children:["To initialize the ",(0,l.jsx)(n.code,{children:"ComputeCluster"})," class, provide the ",(0,l.jsx)(n.code,{children:"user_id"})," and ",(0,l.jsx)(n.code,{children:"compute_cluster_id"})," as parameters."]}),"\n",(0,l.jsx)(n.p,{children:"Initialization is essential because it establishes the specific user and compute cluster context, which allows the subsequent operations to accurately target and manage the intended resources."}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:u})})}),"\n",(0,l.jsx)(n.h2,{id:"nodepool-operations",children:"Nodepool Operations"}),"\n",(0,l.jsx)(n.h4,{id:"create-a-nodepool",children:"Create a Nodepool"}),"\n",(0,l.jsxs)(n.p,{children:["To create a new nodepool, use the ",(0,l.jsx)(n.code,{children:"create_nodepool"})," method with the ",(0,l.jsx)(n.code,{children:"nodepool_id"})," and ",(0,l.jsx)(n.code,{children:"config_filepath"})," as parameters."]}),"\n",(0,l.jsxs)(s.A,{children:[(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:m})}),(0,l.jsx)(i.A,{value:"bash",label:"Bash",children:(0,l.jsx)(r.A,{className:"language-yaml",children:w})})]}),"\n",(0,l.jsx)(n.h4,{id:"get-a-nodepool",children:"Get a Nodepool"}),"\n",(0,l.jsxs)(n.p,{children:["To get a specific nodepool, provide the ",(0,l.jsx)(n.code,{children:"nodepool_id"})," to the ",(0,l.jsx)(n.code,{children:"nodepool"})," method of the ",(0,l.jsx)(n.code,{children:"ComputeCluster"})," class."]}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:_})})}),"\n",(0,l.jsx)(n.h4,{id:"list-all-nodepools",children:"List All Nodepools"}),"\n",(0,l.jsxs)(n.p,{children:["To list the existing nodepools, call the ",(0,l.jsx)(n.code,{children:"list_nodepools"})," method of the ",(0,l.jsx)(n.code,{children:"ComputeCluster"})," class."]}),"\n",(0,l.jsxs)(s.A,{children:[(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:y})}),(0,l.jsx)(i.A,{value:"bash",label:"Bash",children:(0,l.jsx)(r.A,{className:"language-yaml",children:k})})]}),"\n",(0,l.jsxs)(n.h4,{id:"initialize-the-nodepool-class",children:["Initialize the ",(0,l.jsx)(n.code,{children:"Nodepool"})," Class"]}),"\n",(0,l.jsxs)(n.p,{children:["To initialize the ",(0,l.jsx)(n.code,{children:"Nodepool"})," class, provide the ",(0,l.jsx)(n.code,{children:"user_id"})," and ",(0,l.jsx)(n.code,{children:"nodepool_id"})," parameters."]}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:f})})}),"\n",(0,l.jsx)(n.h2,{id:"deployment-operations",children:"Deployment Operations"}),"\n",(0,l.jsx)(n.h4,{id:"create-a-deployment",children:"Create a Deployment"}),"\n",(0,l.jsxs)(n.p,{children:["To deploy a model within a nodepool, provide the ",(0,l.jsx)(n.code,{children:"deployment_id"})," and ",(0,l.jsx)(n.code,{children:"config_filepath"})," parameters to the ",(0,l.jsx)(n.code,{children:"create_deployment"})," method of the ",(0,l.jsx)(n.code,{children:"Nodepool"})," class."]}),"\n",(0,l.jsx)(n.admonition,{type:"note",children:(0,l.jsx)(n.p,{children:"Each model or workflow can only have one deployment per nodepool."})}),"\n",(0,l.jsxs)(s.A,{children:[(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:j})}),(0,l.jsx)(i.A,{value:"bash",label:"Bash",children:(0,l.jsx)(r.A,{className:"language-yaml",children:N})})]}),"\n",(0,l.jsx)(n.h4,{id:"get-a-deployment",children:"Get a Deployment"}),"\n",(0,l.jsxs)(n.p,{children:["To get a specific deployment, provide the ",(0,l.jsx)(n.code,{children:"deployment_id"})," to the ",(0,l.jsx)(n.code,{children:"deployment"})," method of the ",(0,l.jsx)(n.code,{children:"Nodepool"})," class."]}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:g})})}),"\n",(0,l.jsx)(n.h4,{id:"list-all-deployments",children:"List All Deployments"}),"\n",(0,l.jsxs)(n.p,{children:["To list existing deployments, call the ",(0,l.jsx)(n.code,{children:"list_deployments"})," method of the ",(0,l.jsx)(n.code,{children:"Nodepool"})," class."]}),"\n",(0,l.jsxs)(s.A,{children:[(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:b})}),(0,l.jsx)(i.A,{value:"bash",label:"Bash",children:(0,l.jsx)(r.A,{className:"language-yaml",children:O})})]}),"\n",(0,l.jsxs)(n.h4,{id:"initialize-the-deployment-class",children:["Initialize the ",(0,l.jsx)(n.code,{children:"Deployment"})," Class"]}),"\n",(0,l.jsxs)(n.p,{children:["To initialize the ",(0,l.jsx)(n.code,{children:"Deployment"})," class, provide the ",(0,l.jsx)(n.code,{children:"user_id"})," and ",(0,l.jsx)(n.code,{children:"deployment_id"})," parameters."]}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:A})})}),"\n",(0,l.jsx)(n.h2,{id:"predict-with-deployed-model",children:"Predict With Deployed Model"}),"\n",(0,l.jsx)(n.p,{children:"Once your model is deployed, it can be used to make predictions by calling the appropriate prediction methods. Clarifai's Compute Orchestration system offers different types of prediction calls to suit various use cases."}),"\n",(0,l.jsxs)(n.p,{children:["To ensure proper routing and execution, you must specify the ",(0,l.jsx)(n.code,{children:"deployment_id"})," parameter. This parameter is essential for routing prediction requests within the Clarifai's Compute Orchestration system."]}),"\n",(0,l.jsx)(n.admonition,{type:"tip",children:(0,l.jsxs)(n.p,{children:["The following examples illustrate how to make predictions with inputs provided as publicly accessible URLs. ",(0,l.jsx)(n.a,{href:"https://docs.clarifai.com/sdk/Inference-from-AI-Models/",children:"Click here"})," to learn how to make predictions using other types of inputs and models."]})}),"\n",(0,l.jsx)(n.h3,{id:"unary-unary-predict-call",children:"Unary-Unary Predict Call"}),"\n",(0,l.jsx)(n.p,{children:"This is the simplest type of prediction. In this method, a single input is sent to the model, and it returns a single response. This is ideal for tasks where a quick, non-streaming prediction is required, such as classifying an image."}),"\n",(0,l.jsx)(n.p,{children:"It supports the following prediction methods:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"predict_by_url"}),"  \u2014 Use a publicly accessible URL for the input."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"predict_by_bytes"})," \u2014 Pass raw input data directly."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"predict_by_filepath"})," \u2014 Provide the local file path for the input."]}),"\n"]}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:R})})}),"\n",(0,l.jsx)(n.h3,{id:"unary-stream-predict-call",children:"Unary-Stream Predict Call"}),"\n",(0,l.jsxs)(n.p,{children:["The ",(0,l.jsx)(n.strong,{children:"Unary-Stream"})," predict call processes a single input, but returns a stream of responses. It is particularly useful for tasks where multiple outputs are generated from a single input, such as generating text completions from a prompt."]}),"\n",(0,l.jsx)(n.p,{children:"It supports the following prediction methods:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"generate_by_url"}),"  \u2014 Provide a publicly accessible URL and handle the streamed responses iteratively."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"generate_by_bytes"})," \u2014 Use raw input data."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"generate_by_filepath"})," \u2014 Use a local file path for the input."]}),"\n"]}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:E})})}),"\n",(0,l.jsx)(n.h3,{id:"stream-stream-predict-call",children:"Stream-Stream Predict Call"}),"\n",(0,l.jsxs)(n.p,{children:["The ",(0,l.jsx)(n.strong,{children:"stream-stream"})," predict call enables streaming of both inputs and outputs, making it highly effective for processing large datasets or real-time applications."]}),"\n",(0,l.jsx)(n.p,{children:"In this setup, multiple inputs can be continuously sent to the model, and the corresponding predictions are streamed back in real-time. This is ideal for tasks like real-time video processing/predictions or live sensor data analysis."}),"\n",(0,l.jsx)(n.p,{children:"It supports the following prediction methods:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"stream_by_url"})," \u2014 Stream a list of publicly accessible URLs and receive a stream of predictions. It takes an iterator of inputs and returns a stream of predictions."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"stream_by_bytes"})," \u2014 Stream raw input data."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"stream_by_filepath"})," \u2014 Stream inputs from local file paths."]}),"\n"]}),"\n",(0,l.jsx)(s.A,{children:(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:T})})}),"\n",(0,l.jsx)(n.h2,{id:"delete-resources",children:"Delete Resources"}),"\n",(0,l.jsx)(n.h4,{id:"delete-deployments",children:"Delete Deployments"}),"\n",(0,l.jsxs)(n.p,{children:["To delete deployments, pass a list of deployment IDs to the ",(0,l.jsx)(n.code,{children:"delete_deployments"})," method of the ",(0,l.jsx)(n.code,{children:"Nodepool"})," class."]}),"\n",(0,l.jsxs)(s.A,{children:[(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:v})}),(0,l.jsx)(i.A,{value:"bash",label:"Bash",children:(0,l.jsx)(r.A,{className:"language-yaml",children:Y})})]}),"\n",(0,l.jsx)(n.h4,{id:"delete-nodepools",children:"Delete Nodepools"}),"\n",(0,l.jsxs)(n.p,{children:["To delete nodepools, provide a list of nodepool IDs to the ",(0,l.jsx)(n.code,{children:"delete_nodepools"})," method of the ",(0,l.jsx)(n.code,{children:"ComputeCluster"})," class."]}),"\n",(0,l.jsxs)(s.A,{children:[(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:C})}),(0,l.jsx)(i.A,{value:"bash",label:"Bash",children:(0,l.jsx)(r.A,{className:"language-yaml",children:L})})]}),"\n",(0,l.jsx)(n.h4,{id:"delete-compute-clusters",children:"Delete Compute Clusters"}),"\n",(0,l.jsxs)(n.p,{children:["To delete compute clusters, provide a list of compute cluster IDs to the ",(0,l.jsx)(n.code,{children:"delete_compute_clusters"})," method of the ",(0,l.jsx)(n.code,{children:"User"})," class."]}),"\n",(0,l.jsxs)(s.A,{children:[(0,l.jsx)(i.A,{value:"python",label:"Python",children:(0,l.jsx)(r.A,{className:"language-python",children:I})}),(0,l.jsx)(i.A,{value:"bash",label:"Bash",children:(0,l.jsx)(r.A,{className:"language-yaml",children:S})})]})]})}function F(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(V,{...e})}):V(e)}},19365:(e,n,t)=>{t.d(n,{A:()=>i});t(96540);var l=t(18215);const o={tabItem:"tabItem_Ymn6"};var s=t(74848);function i(e){let{children:n,hidden:t,className:i}=e;return(0,s.jsx)("div",{role:"tabpanel",className:(0,l.A)(o.tabItem,i),hidden:t,children:n})}},11470:(e,n,t)=>{t.d(n,{A:()=>A});var l=t(96540),o=t(18215),s=t(23104),i=t(56347),r=t(205),a=t(57485),c=t(31682),d=t(70679);function p(e){return l.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,l.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function u(e){const{values:n,children:t}=e;return(0,l.useMemo)((()=>{const e=n??function(e){return p(e).map((e=>{let{props:{value:n,label:t,attributes:l,default:o}}=e;return{value:n,label:t,attributes:l,default:o}}))}(t);return function(e){const n=(0,c.X)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function h(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function m(e){let{queryString:n=!1,groupId:t}=e;const o=(0,i.W6)(),s=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,a.aZ)(s),(0,l.useCallback)((e=>{if(!s)return;const n=new URLSearchParams(o.location.search);n.set(s,e),o.replace({...o.location,search:n.toString()})}),[s,o])]}function _(e){const{defaultValue:n,queryString:t=!1,groupId:o}=e,s=u(e),[i,a]=(0,l.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!h({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const l=t.find((e=>e.default))??t[0];if(!l)throw new Error("Unexpected error: 0 tabValues");return l.value}({defaultValue:n,tabValues:s}))),[c,p]=m({queryString:t,groupId:o}),[_,y]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[o,s]=(0,d.Dv)(t);return[o,(0,l.useCallback)((e=>{t&&s.set(e)}),[t,s])]}({groupId:o}),f=(()=>{const e=c??_;return h({value:e,tabValues:s})?e:null})();(0,r.A)((()=>{f&&a(f)}),[f]);return{selectedValue:i,selectValue:(0,l.useCallback)((e=>{if(!h({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);a(e),p(e),y(e)}),[p,y,s]),tabValues:s}}var y=t(92303);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=t(74848);function j(e){let{className:n,block:t,selectedValue:l,selectValue:i,tabValues:r}=e;const a=[],{blockElementScrollPositionUntilNextRender:c}=(0,s.a_)(),d=e=>{const n=e.currentTarget,t=a.indexOf(n),o=r[t].value;o!==l&&(c(n),i(o))},p=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const t=a.indexOf(e.currentTarget)+1;n=a[t]??a[0];break}case"ArrowLeft":{const t=a.indexOf(e.currentTarget)-1;n=a[t]??a[a.length-1];break}}n?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":t},n),children:r.map((e=>{let{value:n,label:t,attributes:s}=e;return(0,x.jsx)("li",{role:"tab",tabIndex:l===n?0:-1,"aria-selected":l===n,ref:e=>a.push(e),onKeyDown:p,onClick:d,...s,className:(0,o.A)("tabs__item",f.tabItem,s?.className,{"tabs__item--active":l===n}),children:t??n},n)}))})}function g(e){let{lazy:n,children:t,selectedValue:o}=e;const s=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=s.find((e=>e.props.value===o));return e?(0,l.cloneElement)(e,{className:"margin-top--md"}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:s.map(((e,n)=>(0,l.cloneElement)(e,{key:n,hidden:e.props.value!==o})))})}function b(e){const n=_(e);return(0,x.jsxs)("div",{className:(0,o.A)("tabs-container",f.tabList),children:[(0,x.jsx)(j,{...n,...e}),(0,x.jsx)(g,{...n,...e})]})}function A(e){const n=(0,y.A)();return(0,x.jsx)(b,{...e,children:p(e.children)},String(n))}}}]);