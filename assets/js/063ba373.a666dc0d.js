"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[5700],{4158:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>T,contentTitle:()=>b,default:()=>k,frontMatter:()=>_,metadata:()=>a,toc:()=>w});const a=JSON.parse('{"id":"create/models/deep-fine-tuning/text-to-text","title":"Text Generation","description":"Learn about our text-to-text model type and understand its fine-tuning process","source":"@site/docs/create/models/deep-fine-tuning/text-to-text.md","sourceDirName":"create/models/deep-fine-tuning","slug":"/create/models/deep-fine-tuning/text-to-text","permalink":"/create/models/deep-fine-tuning/text-to-text","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":9,"frontMatter":{"description":"Learn about our text-to-text model type and understand its fine-tuning process","sidebar_position":9},"sidebar":"tutorialSidebar","previous":{"title":"Text Classifier","permalink":"/create/models/deep-fine-tuning/text-classifier"},"next":{"title":"Training Templates","permalink":"/create/models/templates/"}}');var i=n(74848),s=n(28453),r=n(65537),o=n(79329),l=n(58069);const d='from clarifai.client.user import User\n#replace your "user_id"\nclient = User(user_id="user_id")\napp = client.create_app(app_id="demo_train", base_workflow="Universal")',h="#importing load_module_dataloader for calling the dataloader object in dataset.py in the local data folder\nfrom clarifai.datasets.upload.utils import load_module_dataloader\n\n\n# Construct the path to the dataset folder\nCSV_PATH = os.path.join(os.getcwd().split('/models/model_train')[0],'datasets/upload/data/imdb.csv')\n\n\n# Create a Clarifai dataset with the specified dataset_id \ndataset = app.create_dataset(dataset_id=\"text_dataset\")\n# Upload the dataset using the provided dataloader and get the upload status\ndataset.upload_from_csv(csv_path=CSV_PATH,input_type='text',csv_type='raw', labels=True)\n",c="print(app.list_trainable_model_types())",p='MODEL_ID = "model_text_to_text"\nMODEL_TYPE_ID = "text-to-text"\n\n# Create a model by passing the model name and model type as parameter\nmodel = app.create_model(model_id=MODEL_ID, model_type_id=MODEL_TYPE_ID)\n',u="print(model.list_training_templates())\n",f="# get the model params\nmodel_params = model.get_params(template='HuggingFace_AdvancedConfig')\n# update dataset field \nmodel.update_params(dataset_id = 'text_dataset')\nprint(model.training_params)",m='import time\n#Starting the training\nmodel_version_id = model.train()\n\n#Checking the status of training\nwhile True:\n    status = model.training_status(version_id=model_version_id,training_logs=False)\n    if status.code == 21106: #MODEL_TRAINING_FAILED\n        print(status)\n        break\n    elif status.code == 21100: #MODEL_TRAINED\n        print(status)\n        break\n    else:\n        print("Current Status:",status)\n        print("Waiting---")\n        time.sleep(120)\n',g='# Getting the predictions\nTEXT = b"This is a great place to work"\nmodel_prediction = model.predict_by_bytes(TEXT, input_type="text")\n\n# Get the output\nprint(\'Input: \',TEXT)\nprint(model_prediction.outputs[0].data.text)',x="['visual-classifier',\n 'visual-detector',\n 'visual-segmenter',\n 'visual-embedder',\n 'clusterer',\n 'text-classifier',\n 'embedding-classifier',\n 'text-to-text']",y="['HF_GPTNeo_125m_lora',\n 'HF_GPTNeo_2p7b_lora',\n 'HF_Llama_2_13b_chat_GPTQ_lora',\n 'HF_Llama_2_7b_chat_GPTQ_lora',\n 'HF_Mistral_7b_instruct_GPTQ_lora',\n 'HuggingFace_AdvancedConfig']\n",j="{'dataset_id': 'text_dataset',\n 'dataset_version_id': '',\n 'train_params': {'invalid_data_tolerance_percent': 5.0,\n  'template': 'HuggingFace_AdvancedConfig',\n  'model_config': {'pretrained_model_name_or_path': 'facebook/opt-125m',\n   'torch_dtype': 'torch.float32'},\n  'tokenizer_config': {'model_max_length': 512.0},\n  'trainer_config': {'num_train_epochs': 1.0,\n   'auto_find_batch_size': True,\n   'output_dir': 'checkpoint'}}}\n",v='\nInput:  b\'This is a great place to work\'\n\nraw: ". The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food is good. The staff is very friendly and helpful. The food"\n\ntext_info {\n\n  encoding: "UnknownTextEnc"\n\n}',_={description:"Learn about our text-to-text model type and understand its fine-tuning process",sidebar_position:9},b="Text Generation",T={},w=[{value:"Fine-Tune via the UI",id:"fine-tune-via-the-ui",level:2},{value:"Step 1: Prepare Your Training Data",id:"step-1-prepare-your-training-data",level:3},{value:"Step 2: Create an App",id:"step-2-create-an-app",level:3},{value:"Step 3: Create a Dataset",id:"step-3-create-a-dataset",level:3},{value:"Step 4: Upload Your Data",id:"step-4-upload-your-data",level:3},{value:"Step 5: Choose a Model",id:"step-5-choose-a-model",level:3},{value:"Step 6: Create and Train the Model",id:"step-6-create-and-train-the-model",level:3},{value:"Step 7: Generate Texts",id:"step-7-generate-texts",level:3},{value:"Fine-Tune via the API",id:"fine-tune-via-the-api",level:2},{value:"Step 1: App Creation",id:"step-1-app-creation",level:3},{value:"Step 2: Dataset Upload",id:"step-2-dataset-upload",level:3},{value:"Step 3: Model Creation",id:"step-3-model-creation",level:3},{value:"Step 4: Template Selection",id:"step-4-template-selection",level:3},{value:"Step 5: Set Up Model Parameters",id:"step-5-set-up-model-parameters",level:3},{value:"Step 6: Initiate Model Training",id:"step-6-initiate-model-training",level:3},{value:"Step 7: Model Prediction",id:"step-7-model-prediction",level:3}];function A(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components},{Details:a}=t;return a||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"text-generation",children:"Text Generation"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.strong,{children:"Learn about our text-to-text model type and understand its fine-tuning process"})}),"\n",(0,i.jsx)("hr",{}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Input"}),": Text"]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Output"}),": Text"]}),"\n",(0,i.jsx)(t.p,{children:"A text-to-text model is a type of natural language processing (NLP) model that takes a text input and generates a text output. This framework can handle a variety of tasks within the same model architecture by framing all problems as text generation problems."}),"\n",(0,i.jsx)(t.p,{children:"For example, it could be used for:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Machine translation \u2014 Translating from one language to another (e.g., English to French)."}),"\n",(0,i.jsx)(t.li,{children:"Summarization \u2014 Condensing a longer document into a shorter summary."}),"\n",(0,i.jsx)(t.li,{children:"Text classification \u2014 Recasting classification tasks like sentiment analysis as a text generation problem."}),"\n",(0,i.jsx)(t.li,{children:"Question answering \u2014 Given a question, the model generates an appropriate text answer."}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Large language models (LLMs) are usually used to generate coherent and contextually appropriate text based on the instructions of the user. These foundation models, also referred to as pre-trained or base models, are massive models that have been trained on extensive amounts of data. You can use them as a starting point for text-generation tasks."}),"\n",(0,i.jsx)(t.p,{children:"Fine-tuning allows you to adapt the foundational text-to-text models to specific tasks or domains, making them more suitable for particular applications. By training on task-specific data, you can improve model performance on those tasks."}),"\n",(0,i.jsxs)(t.p,{children:["With fine-tuning, you can take advantage of ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/model/model-types/transfer-learning/",children:"transfer learning"})," and utilize the knowledge gained from a pre-trained text model to facilitate the learning process of a new model for a related problem."]}),"\n",(0,i.jsx)(t.admonition,{title:"Text Fine-Tuning Templates",type:"caution",children:(0,i.jsxs)(t.p,{children:["The text-to-text model type also comes with various ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/model/deep-training/text-templates",children:"templates"})," that give you the control to choose the specific architecture used by your neural network, as well as define a set of hyperparameters you can use to fine-tune the way your model learns."]})}),"\n",(0,i.jsx)(t.p,{children:"You may choose a text-to-text model type in cases where:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"You need a generative model that can effectively learn patterns and structures from training data, and use this learned knowledge to generate text that is coherent and contextually relevant based on the input it receives."}),"\n",(0,i.jsxs)(t.li,{children:['You need a text-to-text model to learn new features not recognized by the existing Clarifai models. In that case, you may need to "deep fine-tune" your custom model and integrate it directly within your ',(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/workflows/",children:"workflows"}),"."]}),"\n",(0,i.jsx)(t.li,{children:"You have a custom-tailored dataset, accurate labels, and the expertise and time to fine-tune models."}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"fine-tune-via-the-ui",children:"Fine-Tune via the UI"}),"\n",(0,i.jsxs)(t.p,{children:["You can fine-tune a large language model for text generation tasks. In this example, we\u2019ll demonstrate how to fine-tune the ",(0,i.jsx)(t.a,{href:"https://clarifai.com/meta/Llama-3/models/Llama-3-8B-Instruct",children:"LLaMA 3.1 8B Instruct"})," model for a specific use case using Clarifai's no-code platform."]}),"\n",(0,i.jsx)(t.p,{children:"You can watch the video below for a step-by-step guide."}),"\n",(0,i.jsx)("div",{style:{position:"relative",width:"100%",overflow:"hidden","padding-top":"56.25%"},children:(0,i.jsx)("iframe",{width:"900",height:"500",style:{position:"absolute",top:"0",left:"0",bottom:"0",right:"0",width:"100%",height:"100%"},src:"https://www.youtube.com/embed/J2N4AbXlWZM",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0})}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)(t.p,{children:"You can also follow these steps to learn how to fine-tune a text-to-text model for generative or conversion tasks."}),"\n",(0,i.jsx)(t.h3,{id:"step-1-prepare-your-training-data",children:"Step 1: Prepare Your Training Data"}),"\n",(0,i.jsx)(t.p,{children:"Fine-tuning a text-to-text model requires a dataset with examples in a specific format that includes both input and target sequences. The training data must be formatted according to the model's specific requirements to ensure effective learning."}),"\n",(0,i.jsx)(t.p,{children:"For example, when preparing data for training the LLaMA 3.1 8B Instruct model, you need to follow the following format:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",children:"<|begin_of_text|><|start_header_id|>system<|end_header_id|> {system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|> {prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"})}),"\n",(0,i.jsx)(t.p,{children:"The main purpose of this format is to clearly delineate the roles and contributions of different participants in the conversation: system instructions, user-provided input, and the model-generated output (assistant's response)."}),"\n",(0,i.jsx)(t.p,{children:"This type of standardized approach ensures clarity and facilitates easy parsing and processing during the training phase."}),"\n",(0,i.jsx)(t.p,{children:"Let\u2019s break down its meaning:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"<|begin_of_text|>"})," \u2014 This delimiter marks the beginning of the text content."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"<|start_header_id|>system<|end_header_id|>"})," \u2014 This indicates the beginning of a system-level instruction or context."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"{system_prompt}"})," \u2014 This placeholder is for the actual system-level instruction or context. It instructs the model on the specific task it should perform."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"<|eot_id|>"})," \u2014 This indicates the end of a text unit; in this case, the system prompt."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"<|start_header_id|>user<|end_header_id|>"})," \u2014 This marks the beginning of a user's input."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"{prompt}"})," \u2014 This placeholder represents the actual prompt or query from the user."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"<|eot_id|>"})," \u2014 This marks the end of a text unit; in this case, the user's input."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"<|start_header_id|>assistant<|end_header_id|>"})," \u2014 This indicates the beginning of the assistant's response (model-generated output)."]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Here is an example of training data you can use:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",children:'<|begin_of_text|> <|start_header_id|>system<|end_header_id|> You are a helpful AI assistant <|eot_id|> <|start_header_id|>user<|end_header_id|> Summarize the following text: The new smartphone model offers exceptional battery life and an improved camera. <|eot_id|> <|start_header_id|>assistant<|end_header_id|> {"summary": "The smartphone has great battery life and a better camera."} <|eot_id|>\n'})}),"\n",(0,i.jsxs)(t.p,{children:["To help you get started, you can download a ",(0,i.jsx)(t.code,{children:".csv"})," file with a simple dataset for fine-tuning the LLaMA 3.1 8B Instruct model ",(0,i.jsx)(t.a,{href:"https://docs.google.com/spreadsheets/d/1CE529pa0hhWSdP0TbnsHDIS2FqarOhLsRzLdvsQkcF4/edit?gid=0#gid=0",children:"here"}),"."]}),"\n",(0,i.jsx)(t.p,{children:"As you can see in the file, each example data is presented in an individual row. Also, note that the training data comprises two columns:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"input.data.text.raw"})," \u2014 This column houses the example data, with each row having its own instance."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"input.data.concepts[*].id"})," \u2014 This empty column is included to fulfill the prerequisites for ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/advanced-topics/csv-and-tsv/#csv-templates",children:"uploading a CSV file"})," to the Clarifai platform."]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:'The idea here is to create a dataset where the model learns to generate responses based on the context provided in the "user" section while adhering to the task defined in the "instruction" section. The above dataset is typically used for training a model to perform a wide range of text generation tasks.'}),"\n",(0,i.jsx)(t.p,{children:"This format is structured and labeled, making it suitable for supervised learning tasks where the model learns from examples with known correct answers. The model is trained to generate responses that align with the expected output for a given input context."}),"\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsx)(t.p,{children:"We recommend starting with more than 50 well-crafted examples for fine-tuning a text generation model. Nonetheless, the right number depends on your exact use case."})}),"\n",(0,i.jsx)(t.h3,{id:"step-2-create-an-app",children:"Step 2: Create an App"}),"\n",(0,i.jsxs)(t.p,{children:["After preparing your dataset, the next step is to ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/clarifai-basics/applications/create-an-application/#create-an-application-on-the-portal",children:"create an application"}),"."]}),"\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsxs)(t.p,{children:["When creating an application, choose the ",(0,i.jsx)(t.strong,{children:"Text/Document"})," option as the primary input type. The ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/workflows/base-workflows/",children:"base workflow"})," will be automatically selected for you."]})}),"\n",(0,i.jsx)(t.h3,{id:"step-3-create-a-dataset",children:"Step 3: Create a Dataset"}),"\n",(0,i.jsx)(t.p,{children:"Create a dataset within your application. Note that after adding inputs to the dataset, you'll need to create a version for it."}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete/",children:"Click here"})," to learn more about how to create and manage datasets."]}),"\n",(0,i.jsx)(t.h3,{id:"step-4-upload-your-data",children:"Step 4: Upload Your Data"}),"\n",(0,i.jsxs)(t.p,{children:["In the collapsible left sidebar, select the ",(0,i.jsx)(t.strong,{children:"Inputs"})," option, then use the input uploader pop-up window to upload your prepared text data to the dataset you created."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"upload text data",src:n(46088).A+"",width:"1902",height:"894"})}),"\n",(0,i.jsx)(t.p,{children:"The data will be uploaded to your application."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(92790).A+"",width:"1879",height:"897"})}),"\n",(0,i.jsx)(t.p,{children:"After successfully uploading the data to a dataset, remember to update the dataset version."}),"\n",(0,i.jsx)(t.h3,{id:"step-5-choose-a-model",children:"Step 5: Choose a Model"}),"\n",(0,i.jsxs)(t.p,{children:["Next, choose the ",(0,i.jsx)(t.strong,{children:"Models"})," option on the collapsible left sidebar. Click the ",(0,i.jsx)(t.strong,{children:"Add Model"})," button in the upper-right corner of the page."]}),"\n",(0,i.jsxs)(t.p,{children:["On the window that pops up, select the ",(0,i.jsx)(t.strong,{children:"Build a Custom Model"})," option and click the ",(0,i.jsx)(t.strong,{children:"Continue"})," button."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"model types",src:n(82947).A+"",width:"1910",height:"898"})}),"\n",(0,i.jsx)(t.p,{children:"You\u2019ll be redirected to a page where you can choose the type of model you want to fine-tune."}),"\n",(0,i.jsxs)(t.p,{children:["Select the ",(0,i.jsx)(t.strong,{children:"Text Generator"})," option."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"model types",src:n(77722).A+"",width:"1869",height:"829"})}),"\n",(0,i.jsx)(t.h3,{id:"step-6-create-and-train-the-model",children:"Step 6: Create and Train the Model"}),"\n",(0,i.jsx)(t.p,{children:"The ensuing page allows you to create and train a text-to-text model for generation or conversion purposes."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"alt text",src:n(35669).A+"",width:"1572",height:"1443"})}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Model ID"})," \u2014 Provide an ID for your model."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Dataset"})," \u2014 Select the dataset you want to use to fine-tune the model. Also, select the version of your dataset."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Invalid Data Tolerance Percent"})," \u2014 Optionally, you can set a tolerance threshold (0 to 100) for the percentage of invalid inputs during training, and if this threshold is exceeded, training is stopped with an error. It's recommended to keep this value low to minimize invalid inputs."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Template"})," \u2014 Select a pre-configured model template you want to use to train on your data. You can select any of the following templates:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_Llama_3_1_8b_instruct_GPTQ_lora"})," \u2014 This is the recommended template, as shown in the screenshot above. It's the template we'll choose for fine-tuning the 3.1 version of the Llama model with 8 billion parameters optimized for instruction-based tasks. This version uses quantization (GPTQ) and Low-Rank Adaptation (LoRA) for efficient training."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_GPTNeo_125m_lora"})," \u2014 Template for the GPT-Neo model with 125 million parameters, using the LoRA method for efficient parameter adaptation, suitable for smaller-scale projects or less resource-intensive applications."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_GPTNeo_2p7b_lora"})," \u2014 Utilizes the 2.7 billion parameter GPT-Neo model, incorporating LoRA for effective fine-tuning, ideal for medium to large-scale natural language processing tasks."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_Llama_2_13b_chat_GPTQ_lora"})," \u2014 A fine-tuned 13 billion parameter Llama model for chat applications, using both quantization and LoRA for optimization, designed to handle complex dialog systems."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_Llama_2_7b_chat_GPTQ_lora"})," \u2014 Similar to the 13b version but with 7 billion parameters, this template is also geared towards chat applications, providing a balance between performance and computational efficiency."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_Mistral_7b_instruct_GPTQ_lora"})," \u2014 Template for the 7 billion parameter Mistral model, fine-tuned for instructional tasks with both GPTQ and LoRA, aimed at delivering high performance with efficient training."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HF_Mistral_7b_lora"})," \u2014 This template uses the Mistral model with 7 billion parameters optimized with LoRA only, suitable for diverse applications requiring fast model adaptation."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"HuggingFace_AdvancedConfig"})," \u2014 Offers advanced configuration options for fine-tuning Hugging Face models, allowing for detailed customization to meet specific performance or application requirements."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Training Settings"})," \u2014 Optionally, you may configure the training and inference settings to enhance the performance of your model. Otherwise, you may use the provided default settings. These are some of the settings you may customize:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Model config"})," \u2014 Provide a dictionary of key-value pairs that define the pre-trained model to be used as a base."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Quantization config"})," \u2014 Provide a dictionary of key-value pairs that define how to fine-tune or adjust the behavior of quantization during the training or inference process."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Peft config"})," \u2014 Provide a dictionary of key-value pairs that define how to fine-tune a pre-trained model on a downstream task using a parameter-efficient fine-tuning (PEFT) method."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Tokenizer config"})," \u2014 Provide a dictionary of key-value pairs that define the configuration of a pre-trained tokenizer."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Trainer config"})," \u2014 Provide a dictionary of key-value pairs that define the configuration of the Transformers ",(0,i.jsx)(t.code,{children:"Trainer"})," class."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["Finally, click the ",(0,i.jsx)(t.strong,{children:"Train"})," button."]}),"\n",(0,i.jsx)(t.h3,{id:"step-7-generate-texts",children:"Step 7: Generate Texts"}),"\n",(0,i.jsx)(t.p,{children:"After the model has been trained, you can start using it to make generative text-to-text predictions."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"alt text",src:n(52780).A+"",width:"1885",height:"743"})}),"\n",(0,i.jsxs)(t.p,{children:["To run an inference with the fine-tuned model, click the ",(0,i.jsx)(t.strong,{children:"Overview"})," tab and send a request to the model. For example, you can provide the following input:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",children:"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a helpful AI assistant<|eot_id|><|start_header_id|>user<|end_header_id|> Translate the following English sentence to Spanish: AI is a revolutionary industry in this age.<|eot_id|><|start_header_id|>assistant<|end_header_id|> \n"})}),"\n",(0,i.jsxs)(t.p,{children:["Click the ",(0,i.jsx)(t.strong,{children:"Generate"})," button. It will generate the output in JSON format, providing the response as a key-value pair."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"model types",src:n(21255).A+"",width:"1797",height:"881"})}),"\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/agent-system-operators/prompter/",children:"Click here"})," to learn more about the different prompt techniques you can use to instruct your text-to-text model."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/ppredict/generative-ai#inference-parameters",children:"Click here"})," to learn more about the different inference parameters you can specify to influence the output of LLMs."]}),"\n"]}),"\n"]})}),"\n",(0,i.jsx)(t.h2,{id:"fine-tune-via-the-api",children:"Fine-Tune via the API"}),"\n",(0,i.jsx)(t.p,{children:"Let's demonstrate how to fine-tune a text-to-text model using our API."}),"\n",(0,i.jsx)(t.admonition,{type:"info",children:(0,i.jsxs)(t.p,{children:["Before using the ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/python-sdk",children:"Python SDK"}),", ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/nodejs-sdk",children:"Node.js SDK"}),", or any of our ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/grpc-clients",children:"gRPC clients"}),", ensure they are properly installed on your machine. Refer to their respective installation guides for instructions on how to install and initialize them."]})}),"\n","\n","\n","\n",(0,i.jsx)(t.h3,{id:"step-1-app-creation",children:"Step 1: App Creation"}),"\n",(0,i.jsxs)(t.p,{children:["Let's start by creating an ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/create-manage/applications/create",children:"app"}),"."]}),"\n",(0,i.jsx)(r.A,{groupId:"code",children:(0,i.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:d})})}),"\n",(0,i.jsx)(t.h3,{id:"step-2-dataset-upload",children:"Step 2: Dataset Upload"}),"\n",(0,i.jsxs)(t.p,{children:["Next, let\u2019s upload the ",(0,i.jsx)(t.a,{href:"https://docs.clarifai.com/create-manage/datasets/upload",children:"dataset"})," that will be used to train the model to the app."]}),"\n",(0,i.jsxs)(t.p,{children:["You can find the dataset we used ",(0,i.jsx)(t.a,{href:"https://github.com/Clarifai/examples/tree/main/datasets/upload/data",children:"here"}),"."]}),"\n",(0,i.jsx)(r.A,{groupId:"code",children:(0,i.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:h})})}),"\n",(0,i.jsx)(t.h3,{id:"step-3-model-creation",children:"Step 3: Model Creation"}),"\n",(0,i.jsx)(t.p,{children:"Let's list all the available trainable model types in the Clarifai platform."}),"\n",(0,i.jsx)(r.A,{groupId:"code",children:(0,i.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:c})})}),"\n",(0,i.jsxs)(a,{children:[(0,i.jsx)("summary",{children:"Output"}),(0,i.jsx)(l.A,{className:"language-text",children:x})]}),"\n",(0,i.jsxs)(t.p,{children:["Next, let's select the ",(0,i.jsx)(t.code,{children:"text-to-text"})," model type and use it to create a model."]}),"\n",(0,i.jsx)(r.A,{groupId:"code",children:(0,i.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:p})})}),"\n",(0,i.jsx)(t.h3,{id:"step-4-template-selection",children:"Step 4: Template Selection"}),"\n",(0,i.jsx)(t.p,{children:"Let's list all the available training templates in the Clarifai platform."}),"\n",(0,i.jsx)(r.A,{groupId:"code",children:(0,i.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:u})})}),"\n",(0,i.jsxs)(a,{children:[(0,i.jsx)("summary",{children:"Output"}),(0,i.jsx)(l.A,{className:"language-text",children:y})]}),"\n",(0,i.jsxs)(t.p,{children:["Next, let's choose the ",(0,i.jsx)(t.code,{children:"'HuggingFace_AdvancedConfig' "}),"template to use for training our model, as demonstrated below."]}),"\n",(0,i.jsx)(t.h3,{id:"step-5-set-up-model-parameters",children:"Step 5: Set Up Model Parameters"}),"\n",(0,i.jsx)(t.p,{children:"You can customize the model parameters as needed before starting the training process."}),"\n",(0,i.jsx)(r.A,{groupId:"code",children:(0,i.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:f})})}),"\n",(0,i.jsxs)(a,{children:[(0,i.jsx)("summary",{children:"Output"}),(0,i.jsx)(l.A,{className:"language-text",children:j})]}),"\n",(0,i.jsx)(t.h3,{id:"step-6-initiate-model-training",children:"Step 6: Initiate Model Training"}),"\n",(0,i.jsxs)(t.p,{children:["To initiate the model training process, call the ",(0,i.jsx)(t.code,{children:"model.train()"})," method. The Clarifai API also provides features for monitoring training status and saving training logs to a local file."]}),"\n",(0,i.jsx)(t.admonition,{type:"note",children:(0,i.jsxs)(t.p,{children:["If the training status code returns ",(0,i.jsx)(t.code,{children:"MODEL-TRAINED"}),", it means the model has successfully completed training and is ready for use."]})}),"\n",(0,i.jsx)(r.A,{groupId:"code",children:(0,i.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:m})})}),"\n",(0,i.jsx)(t.h3,{id:"step-7-model-prediction",children:"Step 7: Model Prediction"}),"\n",(0,i.jsx)(t.p,{children:"After the model is trained and ready to use, you can run some predictions with it."}),"\n",(0,i.jsx)(r.A,{groupId:"code",children:(0,i.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:g})})}),"\n",(0,i.jsxs)(a,{children:[(0,i.jsx)("summary",{children:"Output"}),(0,i.jsx)(l.A,{className:"language-text",children:v})]})]})}function k(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(A,{...e})}):A(e)}},21255:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/fine-tune-6-5c62483b7ddff4677e4c096c9eb7e6ae.png"},35669:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/fine-tune-4-982832a596a344d1ed67114195d4ebff.png"},46088:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/fine-tune-1-d66d2db5e641617a7d062337226cf243.png"},52780:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/fine-tune-5-5704e340ce67c0882fd4b6fa944bee82.png"},65537:(e,t,n)=>{n.d(t,{A:()=>b});var a=n(96540),i=n(18215),s=n(65627),r=n(56347),o=n(50372),l=n(30604),d=n(11861),h=n(78749);function c(e){return a.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(e){const{values:t,children:n}=e;return(0,a.useMemo)((()=>{const e=t??function(e){return c(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:i}}=e;return{value:t,label:n,attributes:a,default:i}}))}(n);return function(e){const t=(0,d.XI)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function u(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function f(e){let{queryString:t=!1,groupId:n}=e;const i=(0,r.W6)(),s=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,l.aZ)(s),(0,a.useCallback)((e=>{if(!s)return;const t=new URLSearchParams(i.location.search);t.set(s,e),i.replace({...i.location,search:t.toString()})}),[s,i])]}function m(e){const{defaultValue:t,queryString:n=!1,groupId:i}=e,s=p(e),[r,l]=(0,a.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!u({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:s}))),[d,c]=f({queryString:n,groupId:i}),[m,g]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[i,s]=(0,h.Dv)(n);return[i,(0,a.useCallback)((e=>{n&&s.set(e)}),[n,s])]}({groupId:i}),x=(()=>{const e=d??m;return u({value:e,tabValues:s})?e:null})();(0,o.A)((()=>{x&&l(x)}),[x]);return{selectedValue:r,selectValue:(0,a.useCallback)((e=>{if(!u({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);l(e),c(e),g(e)}),[c,g,s]),tabValues:s}}var g=n(9136);const x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var y=n(74848);function j(e){let{className:t,block:n,selectedValue:a,selectValue:r,tabValues:o}=e;const l=[],{blockElementScrollPositionUntilNextRender:d}=(0,s.a_)(),h=e=>{const t=e.currentTarget,n=l.indexOf(t),i=o[n].value;i!==a&&(d(t),r(i))},c=e=>{let t=null;switch(e.key){case"Enter":h(e);break;case"ArrowRight":{const n=l.indexOf(e.currentTarget)+1;t=l[n]??l[0];break}case"ArrowLeft":{const n=l.indexOf(e.currentTarget)-1;t=l[n]??l[l.length-1];break}}t?.focus()};return(0,y.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":n},t),children:o.map((e=>{let{value:t,label:n,attributes:s}=e;return(0,y.jsx)("li",{role:"tab",tabIndex:a===t?0:-1,"aria-selected":a===t,ref:e=>{l.push(e)},onKeyDown:c,onClick:h,...s,className:(0,i.A)("tabs__item",x.tabItem,s?.className,{"tabs__item--active":a===t}),children:n??t},t)}))})}function v(e){let{lazy:t,children:n,selectedValue:s}=e;const r=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=r.find((e=>e.props.value===s));return e?(0,a.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,y.jsx)("div",{className:"margin-top--md",children:r.map(((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==s})))})}function _(e){const t=m(e);return(0,y.jsxs)("div",{className:(0,i.A)("tabs-container",x.tabList),children:[(0,y.jsx)(j,{...t,...e}),(0,y.jsx)(v,{...t,...e})]})}function b(e){const t=(0,g.A)();return(0,y.jsx)(_,{...e,children:c(e.children)},String(t))}},77722:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/fine-tune-3-a255a2aa2a37474a65f073ffe85cb25e.png"},79329:(e,t,n)=>{n.d(t,{A:()=>r});n(96540);var a=n(18215);const i={tabItem:"tabItem_Ymn6"};var s=n(74848);function r(e){let{children:t,hidden:n,className:r}=e;return(0,s.jsx)("div",{role:"tabpanel",className:(0,a.A)(i.tabItem,r),hidden:n,children:t})}},82947:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/fine-tune-2-707fb9331ad89118764aa59d17fca4f0.png"},92790:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/fine-tune-1-1-d77cb4d1ffa6ca7dff657d5a8f3a18fc.png"}}]);