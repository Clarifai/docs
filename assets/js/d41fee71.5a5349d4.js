"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[8496],{68332:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>R,contentTitle:()=>v,default:()=>T,frontMatter:()=>j,metadata:()=>_,toc:()=>k});var a=t(74848),r=t(28453),i=t(11470),o=t(19365),s=t(21432);const l="# Import the RAG module from Clarifai for conversational AI tasks\nfrom clarifai.rag import RAG\n\n# Set the user ID for authentication (For creating a new App)\nUSER_ID = 'USER_ID'\n\n# Alternatively, initialize RAG system using an existing app's URL\nrag_agent = RAG.setup (app_url=\"APP_URL\")\n\n# Define the URL of the Mistral-7B language model\nLLM_URL = 'https://clarifai.com/mistralai/completion/models/mistral-7B-Instruct'\n\n# Define a template string for generating prompts during inference\nRAG_PROMPT_TEMPLATE = \"<s>[INST] Context information is below:\\n{data.hits}\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {data.text.raw}\\nAnswer:  [/INST]\"\n\n# Setup a RAG object with specified parameters such as user ID, model URL, minimum score threshold, and prompt template\n\n# Option 1: Setup a RAG object with specified parameters using the user_id to create a new app\nrag_object_user = RAG.setup(\n    user_id=USER_ID,\n    pat=PAT,\n    llm_url=LLM_URL,\n    min_score=0.5,\n    max_results=2,\n    prompt_template=RAG_PROMPT_TEMPLATE\n)\n\n# Option 2: Alternatively, setup a RAG object using an existing app's URL\nrag_object_app = RAG.setup(\n    app_url=APP_URL,\n    pat=PAT,\n    llm_url=LLM_URL,\n    min_score=0.5,\n    max_results=2,\n    prompt_template=RAG_PROMPT_TEMPLATE\n)\n# Choose which initialization method to use based on your setup:\n# For new app creation:\nprint(rag_object_user.prompt_workflow)\n\n# For existing app initialization:\nprint(rag_object_app.prompt_workflow)",c='import { RAG } from "clarifai-nodejs";\n\n// Import the RAG module from Clarifai for conversational AI tasks\n\n// Define the URL of the Mistral-7B language model\nconst llmUrl =\n  "https://clarifai.com/mistralai/completion/models/mistral-7B-Instruct";\n\n// Define a template string for generating prompts during inference\nconst ragPromptTemplate =\n  "<s>[INST] Context information is below:\\n{data.hits}\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {data.text.raw}\\nAnswer:  [/INST]";\n\n// Setup a RAG object with specified parameters such as user ID, model URL, minimum score threshold, and prompt template\n\n// Option 1: Initialize using userId and create a new app\nconst ragObject = await RAG.setup({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n  },\n  llmUrl,\n  minScore: 0.5,\n  maxResults: 2,\n  promptTemplate: ragPromptTemplate,\n});\n\n// Option 2: Alternatively, initialize using an existing app\'s URL\nconst ragObjectApp = await RAG.setup({\n  authConfig: {\n    appUrl: process.env.CLARIFAI_APP_URL,\n    pat: process.env.CLARIFAI_PAT,\n  },\n  llmUrl,\n  minScore: 0.5,\n  maxResults: 2,\n  promptTemplate: ragPromptTemplate,\n});\n\n  // Choose which initialization method to use based on your setup:\n  // For new app creation:\n  console.log(ragObject.promptWorkflow);\n\n  // For existing app initialization:\n  console.log(ragObjectApp.promptWorkflow);\n',u='FILE_PATH="RAG/data/Crawfords_Auto_Repair_Guide.txt"\nrag_object.upload(file_path=FILE_PATH,chunk_size= 1024) #parameters to split the document into chunks',p='import { RAG } from "clarifai-nodejs";\nimport path from "path";\n\n// Import the RAG module from Clarifai for conversational AI tasks\n\n// Define the URL of the Mistral-7B language model\nconst llmUrl =\n  "https://clarifai.com/mistralai/completion/models/mistral-7B-Instruct";\n\n// Define a template string for generating prompts during inference\nconst ragPromptTemplate =\n  "<s>[INST] Context information is below:\\n{data.hits}\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {data.text.raw}\\nAnswer:  [/INST]";\n\n// Setup a RAG object with specified parameters such as user ID, model URL,\n// minimum score threshold, and prompt template\nconst ragObject = await RAG.setup({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n  },\n  llmUrl,\n  minScore: 0.5,\n  maxResults: 2,\n  promptTemplate: ragPromptTemplate,\n});\n\nconst filePath = path.resolve(__dirname, "../../assets/ragInput.txt");\nawait ragObject.upload({\n  filePath,\n  chunkSize: 1024,\n});\n',d='# Initiating a conversation with the RAG (Retrieval Augmented Generation) model object (`rag_object_gpt`).\n# Sending a message containing the query "How to change brake fluid" to the model and awaiting a response.\nresult = rag_object.chat(messages=[{"role": "human", "content": "How to change brake fluid"}])\n\n# Extracting the content of the response from the result.\nanswer = result[0]["content"]\n\n# Printing out the response\nprint(answer)',h='import { RAG } from "clarifai-nodejs";\nimport path from "path";\n\n// Import the RAG module from Clarifai for conversational AI tasks\n\n// Define the URL of the Mistral-7B language model\nconst llmUrl =\n  "https://clarifai.com/mistralai/completion/models/mistral-7B-Instruct";\n\n// Define a template string for generating prompts during inference\nconst ragPromptTemplate =\n  "<s>[INST] Context information is below:\\n{data.hits}\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {data.text.raw}\\nAnswer:  [/INST]";\n\n// Setup a RAG object with specified parameters such as user ID, model URL,\n// minimum score threshold, and prompt template\nconst ragObject = await RAG.setup({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n  },\n  llmUrl,\n  minScore: 0.5,\n  maxResults: 2,\n  promptTemplate: ragPromptTemplate,\n});\n\nconst filePath = path.resolve(__dirname, "../../assets/ragInput.txt");\nawait ragObject.upload({\n  filePath,\n  chunkSize: 1024,\n});\n\n// Initiating a conversation with the RAG (Retrieval Augmented Generation) model object (`ragObject`).\n// Sending a message containing the query "How to change brake fluid" to the model and awaiting a response.\nconst result = await ragObject.chat({\n  messages: [{ role: "human", content: "How to change brake fluid" }],\n});\n\n// Extracting the content of the response from the result.\nconst answer = result[1].content;\n\n// Printing out the response\nconsole.log(answer);\n\nconst result2 = await ragObject.chat({\n  messages: [\n    { role: "human", content: "procedure after following the above steps" },\n  ],\n});\n\nconst answer2 = result2[1].content;\n\n// Printing out the response\nconsole.log(answer2);\n',m='result=rag_object.chat(messages=[{"role":"human", "content":"procedure after following the above steps"}])\n\nanswer=result[0]["content"]\n\nprint(answer)',f="#initialize  RAG using workflow URL\nWORKFLOW_URL = 'workflow_URL'\nrag_object_from_url = RAG(workflow_url = WORKFLOW_URL)",g="#initialize  RAG using workflow ID\nUSER_ID = 'user_id'\nLLM_URL = 'https://clarifai.com/openai/chat-completion/models/GPT-4'\nRAG_PROMPT_TEMPLATE = \"Context information is below:\\n{data.hits}\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {data.text.raw}\\nAnswer: \"\nrag_object_gpt = RAG.setup(user_id=USER_ID,llm_url=LLM_URL, min_score=0.5, prompt_template=RAG_PROMPT_TEMPLATE,workflow_id=\"workflow_id\")",b='2024-03-20 10:34:02 INFO     clarifai.client.input:                                                    input.py:674\n\n                             Inputs Uploaded                                                                       \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             details: "All inputs successfully added"                                              \n\n                             req_id: "848c5233f9d67f1904da10c33a214ff9"                                            \n\n                                                                                                                   \n\nINFO:clarifai.client.input:\n\nInputs Uploaded\n\ncode: SUCCESS\n\ndescription: "Ok"\n\ndetails: "All inputs successfully added"\n\nreq_id: "848c5233f9d67f1904da10c33a214ff9"',w="To change the brake fluid, you will need to follow these steps: \n\n \n\n1. Locate the brake fluid reservoir in your vehicle. It is usually a clear plastic container with MAX and MIN markings on it. \n\n \n\n2. Use a turkey baster or a brake fluid pump to remove the old brake fluid from the reservoir. Be careful not to spill any brake fluid on the car's paint as it can damage the finish. \n\n \n\n3. Once the old fluid is removed, clean the reservoir with a lint-free cloth to ensure there is no contamination. \n\n \n\n4. Refill the reservoir with new brake fluid that is recommended for your specific vehicle. Make sure to use the type of brake fluid specified in your owner's manual. \n\n \n\n5. Slowly pour the new brake fluid into the reservoir up to the MAX marking. Avoid overfilling. \n\n \n\n6. After filling the reservoir, you may need to bleed the brake system to remove any air bubbles. This process may vary depending on your vehicle, so it's best to consult your owner's manual or a professional mechanic for guidance. \n\n \n\n7. Once the brake fluid is changed and the system is bled, check for any leaks or issues before driving the vehicle. \n\n \n\nRemember, if you are not comfortable or experienced with changing brake fluid, it is recommended to have this task done by a professional mechanic. Brake fluid is a critical component of your vehicle's braking system, and proper maintenance is essential for your safety on the road. ",A=" After following the steps to drain, flush, and pressure test the cooling system as described in the text, the next procedure would be to check for any leaks in the cooling system. This can be done by inspecting the entire cooling system, including the radiator, hoses, water pump, and heater core, for any signs of leaks. If there is less pressure on the gauge after the pressure test, there is probably a leak. Additionally, the engine should be started and the temperature gauge should be monitored to ensure that the cooling system is functioning properly. If the engine overheats or the temperature gauge reads high, further diagnosis and repair may be necessary.",x="2024-05-08 12:21:25 INFO     clarifai.rag.rag:                                                            rag.py:43\n                             workflow_url:https://clarifai.com/8tzpjy1a841y/unst-clf/workflows/rag                 \nINFO:clarifai.rag.rag:workflow_url:https://clarifai.com/8tzpjy1a841y/unst-clf/workflows/rag",y='2024-05-08 12:28:09 INFO     clarifai.client.app:                                                        app.py:431\n                             Workflow created                                                                      \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             req_id: "73cd1b5a80ba9e7280542b6b176213fe"                                            \n                                                                                                                   \nINFO:clarifai.client.app:\nWorkflow created\ncode: SUCCESS\ndescription: "Ok"\nreq_id: "73cd1b5a80ba9e7280542b6b176213fe"\n\n Input\n\u255a\u2550\u2550                                Node: rag-prompter                               \n    \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n    \u2503 id                       \u2503 model_type_id \u2503 app_id             \u2503 user_id      \u2503\n    \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n    \u2502 prompter-rag3-def6cc6378 \u2502 rag-prompter  \u2502 rag_app_def6cc6378 \u2502 8tzpjy1a841y \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u255a\u2550\u2550                       Node: llm                      \n        \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n        \u2503 id    \u2503 model_type_id \u2503 app_id          \u2503 user_id \u2503\n        \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n        \u2502 GPT-4 \u2502 text-to-text  \u2502 chat-completion \u2502 openai  \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518',j={sidebar_position:9},v="Building RAG Applications",_={id:"sdk/rag",title:"Building RAG Applications",description:"Learn how to build a RAG application using Clarifai SDKs",source:"@site/docs/sdk/rag.md",sourceDirName:"sdk",slug:"/sdk/rag",permalink:"/sdk/rag",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/sdk/rag.md",tags:[],version:"current",sidebarPosition:9,frontMatter:{sidebar_position:9},sidebar:"tutorialSidebar",previous:{title:"Model Export",permalink:"/sdk/advance-model-operations/model-export"},next:{title:"Python SDK Notebook Examples",permalink:"/sdk/notebook-examples"}},R={},k=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Initialising RAG",id:"initialising-rag",level:2},{value:"Dataset Upload",id:"dataset-upload",level:2},{value:"Chat",id:"chat",level:2}];function I(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"building-rag-applications",children:"Building RAG Applications"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Learn how to build a RAG application using Clarifai SDKs"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsx)(n.p,{children:"In the realm of text generation, Retrieval Augmented Generation (RAG) steps up the game for Large Language Models (LLMs) by fusing information retrieval capabilities with text generation skills, tackling key drawbacks of LLMs. When presented with a query, RAG fetches relevant information from an external knowledge base, which increases precision and contextual appropriateness through the integration of this retrieved data into the input. The Clarifai SDKs allows you to create RAG-based applications with ease by reducing the number of steps in the process."}),"\n",(0,a.jsxs)(n.p,{children:["Click ",(0,a.jsx)(n.a,{href:"https://www.clarifai.com/blog/what-is-rag-retrieval-augmented-generation",children:"here"})," to learn more about RAG."]}),"\n",(0,a.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Setting up the Clarifai SDKs along with PAT. Refer to the installation and configuration with the PAT token ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/python-sdk/sdk-overview/",children:"here"}),"."]}),"\n"]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Guide to get your ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/clarifai-basics/authentication/personal-access-tokens",children:"PAT"})]})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Clone the Clarifai Examples repository to get the data files required for the building RAG."}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"!git clone https://github.com/Clarifai/examples.git\n%cd /content/examples/\n"})}),"\n",(0,a.jsx)(n.admonition,{type:"info",children:(0,a.jsx)(n.p,{children:"To run on a local system use: cd examples/"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Before you proceed install ",(0,a.jsx)(n.code,{children:"llama_index"})," using ",(0,a.jsx)(n.code,{children:"pip install llama-index-core==0.10.24"})]})}),"\n",(0,a.jsx)(n.h2,{id:"initialising-rag",children:"Initialising RAG"}),"\n",(0,a.jsx)(n.p,{children:"The first part of creating a RAG-based application includes setting up the RAG object. Just by setting up the RAG object, Clarifai SDKs will automatically create the app along with a prompter model and workflow containing the RAG prompter and the LLM Model."}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:["You can set a specific version of LLM by using ",(0,a.jsx)(n.code,{children:"https://clarifai.com/mistralai/completion/models/mistral-7B-Instruct/model_version/version_id"}),"."]})}),"\n",(0,a.jsxs)(i.A,{children:[(0,a.jsxs)(o.A,{value:"python",label:"Python",children:[(0,a.jsx)(s.A,{className:"language-python",children:l}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Image Output"}),(0,a.jsx)("img",{src:"/img/python-sdk/rag_init.png"})]})]}),(0,a.jsx)(o.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(s.A,{className:"language-typescript",children:c})})]}),"\n",(0,a.jsxs)(n.p,{children:["Here we are opting for Mistral-7B-Instruct as the LLM Model. You can choose different LLM Models for the RAG agent from Clarifai Community ",(0,a.jsx)(n.a,{href:"https://clarifai.com/explore/models?filterData=%5B%7B%22field%22%3A%22use_cases%22%2C%22value%22%3A%5B%22llm%22%5D%7D%5D&page=1&perPage=24",children:"Models"}),". The Clarifai SDKs also allows you to set parameters like min_score,max_results and prompt_template  for retrieving relevant data."]}),"\n",(0,a.jsx)(n.p,{children:"The Clarifai SDKs also enables users to initialize RAG using a workflow you have created in the portal which should contain a RAG prompter.\nThere are two ways you can set up RAG using workflows.\nIn the first method, you can provide the workflow URL as a parameter,"}),"\n",(0,a.jsx)(n.admonition,{type:"info",children:(0,a.jsxs)(n.p,{children:["You should only use ",(0,a.jsx)(n.code,{children:"RAG(workflow_url)"})," or ",(0,a.jsx)(n.code,{children:"RAG(workflow)"})," when a rag workflow already exists in your app."]})}),"\n",(0,a.jsx)(i.A,{children:(0,a.jsx)(o.A,{value:"python",label:"Python",children:(0,a.jsx)(s.A,{className:"language-python",children:f})})}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(s.A,{className:"language-python",children:x})]}),"\n",(0,a.jsxs)(n.p,{children:["The next option is to pass ",(0,a.jsx)(n.code,{children:"workflow_id"})," parameter in ",(0,a.jsx)(n.code,{children:"RAG.setup()"}),", this will create a new workflow in your app with the defined parameters."]}),"\n",(0,a.jsx)(i.A,{children:(0,a.jsx)(o.A,{value:"python",label:"Python",children:(0,a.jsx)(s.A,{className:"language-python",children:g})})}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(s.A,{className:"language-python",children:y})]}),"\n",(0,a.jsx)(n.h2,{id:"dataset-upload",children:"Dataset Upload"}),"\n",(0,a.jsx)(n.p,{children:"The next step involves uploading the dataset. In this example, we are using a Vehicle Repair Manual as data for the RAG. You can use the RAG object we created earlier for the data upload process. Now comes the perks of using Clarifai SDKs. When you upload the data the Clarifai platform will automatically generate embeddings for the inputs and store them in the vector database which makes it ready for retrieval seconds after uploading data."}),"\n",(0,a.jsx)(n.admonition,{type:"info",children:(0,a.jsx)(n.p,{children:"Supported formats for upload are Doc, PDF, Text, Folder Containing PDF, Doc and URL of PDF,Doc, Text files."})}),"\n",(0,a.jsxs)(i.A,{children:[(0,a.jsxs)(o.A,{value:"python",label:"Python",children:[(0,a.jsx)(s.A,{className:"language-python",children:u}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(s.A,{className:"language-python",children:b})]})]}),(0,a.jsx)(o.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(s.A,{className:"language-typescript",children:p})})]}),"\n",(0,a.jsx)(n.h2,{id:"chat",children:"Chat"}),"\n",(0,a.jsx)(n.p,{children:"In the final step, we are going to perform information retrieval using RAG based on the data we provided."}),"\n",(0,a.jsxs)(i.A,{children:[(0,a.jsxs)(o.A,{value:"python",label:"Python",children:[(0,a.jsx)(s.A,{className:"language-python",children:d}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(s.A,{className:"language-python",children:w})]})]}),(0,a.jsx)(o.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(s.A,{className:"language-typescript",children:h})})]}),"\n",(0,a.jsx)(n.p,{children:"Now let's ask questions that are related to the answer we received before so that we can be sure the RAG has understood the context properly."}),"\n",(0,a.jsx)(i.A,{children:(0,a.jsx)(o.A,{value:"python",label:"Python",children:(0,a.jsx)(s.A,{className:"language-python",children:m})})}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(s.A,{className:"language-python",children:A})]})]})}function T(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(I,{...e})}):I(e)}},19365:(e,n,t)=>{t.d(n,{A:()=>o});t(96540);var a=t(18215);const r={tabItem:"tabItem_Ymn6"};var i=t(74848);function o(e){let{children:n,hidden:t,className:o}=e;return(0,i.jsx)("div",{role:"tabpanel",className:(0,a.A)(r.tabItem,o),hidden:t,children:n})}},11470:(e,n,t)=>{t.d(n,{A:()=>j});var a=t(96540),r=t(18215),i=t(23104),o=t(56347),s=t(205),l=t(57485),c=t(31682),u=t(70679);function p(e){return a.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function d(e){const{values:n,children:t}=e;return(0,a.useMemo)((()=>{const e=n??function(e){return p(e).map((e=>{let{props:{value:n,label:t,attributes:a,default:r}}=e;return{value:n,label:t,attributes:a,default:r}}))}(t);return function(e){const n=(0,c.X)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function h(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function m(e){let{queryString:n=!1,groupId:t}=e;const r=(0,o.W6)(),i=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,l.aZ)(i),(0,a.useCallback)((e=>{if(!i)return;const n=new URLSearchParams(r.location.search);n.set(i,e),r.replace({...r.location,search:n.toString()})}),[i,r])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:r}=e,i=d(e),[o,l]=(0,a.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!h({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const a=t.find((e=>e.default))??t[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:n,tabValues:i}))),[c,p]=m({queryString:t,groupId:r}),[f,g]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[r,i]=(0,u.Dv)(t);return[r,(0,a.useCallback)((e=>{t&&i.set(e)}),[t,i])]}({groupId:r}),b=(()=>{const e=c??f;return h({value:e,tabValues:i})?e:null})();(0,s.A)((()=>{b&&l(b)}),[b]);return{selectedValue:o,selectValue:(0,a.useCallback)((e=>{if(!h({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);l(e),p(e),g(e)}),[p,g,i]),tabValues:i}}var g=t(92303);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var w=t(74848);function A(e){let{className:n,block:t,selectedValue:a,selectValue:o,tabValues:s}=e;const l=[],{blockElementScrollPositionUntilNextRender:c}=(0,i.a_)(),u=e=>{const n=e.currentTarget,t=l.indexOf(n),r=s[t].value;r!==a&&(c(n),o(r))},p=e=>{let n=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return(0,w.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":t},n),children:s.map((e=>{let{value:n,label:t,attributes:i}=e;return(0,w.jsx)("li",{role:"tab",tabIndex:a===n?0:-1,"aria-selected":a===n,ref:e=>l.push(e),onKeyDown:p,onClick:u,...i,className:(0,r.A)("tabs__item",b.tabItem,i?.className,{"tabs__item--active":a===n}),children:t??n},n)}))})}function x(e){let{lazy:n,children:t,selectedValue:r}=e;const i=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=i.find((e=>e.props.value===r));return e?(0,a.cloneElement)(e,{className:"margin-top--md"}):null}return(0,w.jsx)("div",{className:"margin-top--md",children:i.map(((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==r})))})}function y(e){const n=f(e);return(0,w.jsxs)("div",{className:(0,r.A)("tabs-container",b.tabList),children:[(0,w.jsx)(A,{...n,...e}),(0,w.jsx)(x,{...n,...e})]})}function j(e){const n=(0,g.A)();return(0,w.jsx)(y,{...e,children:p(e.children)},String(n))}}}]);