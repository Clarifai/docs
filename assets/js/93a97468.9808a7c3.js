"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[9454],{11470:(e,n,t)=>{t.d(n,{A:()=>T});var i=t(96540),a=t(18215),r=t(23104),s=t(56347),o=t(205),l=t(57485),c=t(31682),d=t(70679);function u(e){return i.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p(e){const{values:n,children:t}=e;return(0,i.useMemo)(()=>{const e=n??function(e){return u(e).map(({props:{value:e,label:n,attributes:t,default:i}})=>({value:e,label:n,attributes:t,default:i}))}(t);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function m({value:e,tabValues:n}){return n.some(n=>n.value===e)}function h({queryString:e=!1,groupId:n}){const t=(0,s.W6)(),a=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,l.aZ)(a),(0,i.useCallback)(e=>{if(!a)return;const n=new URLSearchParams(t.location.search);n.set(a,e),t.replace({...t.location,search:n.toString()})},[a,t])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:a}=e,r=p(e),[s,l]=(0,i.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:r})),[c,u]=h({queryString:t,groupId:a}),[f,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,a]=(0,d.Dv)(n);return[t,(0,i.useCallback)(e=>{n&&a.set(e)},[n,a])]}({groupId:a}),_=(()=>{const e=c??f;return m({value:e,tabValues:r})?e:null})();(0,o.A)(()=>{_&&l(_)},[_]);return{selectedValue:s,selectValue:(0,i.useCallback)(e=>{if(!m({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),g(e)},[u,g,r]),tabValues:r}}var g=t(92303);const _={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var E=t(74848);function b({className:e,block:n,selectedValue:t,selectValue:i,tabValues:s}){const o=[],{blockElementScrollPositionUntilNextRender:l}=(0,r.a_)(),c=e=>{const n=e.currentTarget,a=o.indexOf(n),r=s[a].value;r!==t&&(l(n),i(r))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=o.indexOf(e.currentTarget)+1;n=o[t]??o[0];break}case"ArrowLeft":{const t=o.indexOf(e.currentTarget)-1;n=o[t]??o[o.length-1];break}}n?.focus()};return(0,E.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":n},e),children:s.map(({value:e,label:n,attributes:i})=>(0,E.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{o.push(e)},onKeyDown:d,onClick:c,...i,className:(0,a.A)("tabs__item",_.tabItem,i?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function x({lazy:e,children:n,selectedValue:t}){const r=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=r.find(e=>e.props.value===t);return e?(0,i.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,E.jsx)("div",{className:"margin-top--md",children:r.map((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function I(e){const n=f(e);return(0,E.jsxs)("div",{className:(0,a.A)("tabs-container",_.tabList),children:[(0,E.jsx)(b,{...n,...e}),(0,E.jsx)(x,{...n,...e})]})}function T(e){const n=(0,g.A)();return(0,E.jsx)(I,{...e,children:u(e.children)},String(n))}},14795:(e,n,t)=>{t.d(n,{A:()=>x});t(96540);var i=t(18215),a=t(26972),r=t(28774),s=t(53465),o=t(16654),l=t(21312),c=t(51107);const d={cardContainer:"cardContainer_fWXF",cardTitle:"cardTitle_rnsV",cardDescription:"cardDescription_PWke"};var u=t(74848);function p({className:e,href:n,children:t}){return(0,u.jsx)(r.A,{href:n,className:(0,i.A)("card padding--lg",d.cardContainer,e),children:t})}function m({className:e,href:n,icon:t,title:a,description:r}){return(0,u.jsxs)(p,{href:n,className:e,children:[(0,u.jsxs)(c.A,{as:"h2",className:(0,i.A)("text--truncate",d.cardTitle),title:a,children:[t," ",a]}),r&&(0,u.jsx)("p",{className:(0,i.A)("text--truncate",d.cardDescription),title:r,children:r})]})}function h({item:e}){const n=(0,a.Nr)(e),t=function(){const{selectMessage:e}=(0,s.W)();return n=>e(n,(0,l.T)({message:"1 item|{count} items",id:"theme.docs.DocCard.categoryDescription.plurals",description:"The default description for a category card in the generated index about how many items this category includes"},{count:n}))}();return n?(0,u.jsx)(m,{className:e.className,href:n,icon:"\ud83d\uddc3\ufe0f",title:e.label,description:e.description??t(e.items.length)}):null}function f({item:e}){const n=(0,o.A)(e.href)?"\ud83d\udcc4\ufe0f":"\ud83d\udd17",t=(0,a.cC)(e.docId??void 0);return(0,u.jsx)(m,{className:e.className,href:e.href,icon:n,title:e.label,description:e.description??t?.description})}function g({item:e}){switch(e.type){case"link":return(0,u.jsx)(f,{item:e});case"category":return(0,u.jsx)(h,{item:e});default:throw new Error(`unknown item type ${JSON.stringify(e)}`)}}const _={docCardListItem:"docCardListItem_W1sv"};function E({className:e}){const n=(0,a.a4)();return(0,u.jsx)(x,{items:n,className:e})}function b({item:e}){return(0,u.jsx)("article",{className:(0,i.A)(_.docCardListItem,"col col--6"),children:(0,u.jsx)(g,{item:e})})}function x(e){const{items:n,className:t}=e;if(!n)return(0,u.jsx)(E,{...e});const r=(0,a.d1)(n);return(0,u.jsx)("section",{className:(0,i.A)("row",t),children:r.map((e,n)=>(0,u.jsx)(b,{item:e},n))})}},19365:(e,n,t)=>{t.d(n,{A:()=>s});t(96540);var i=t(18215);const a={tabItem:"tabItem_Ymn6"};var r=t(74848);function s({children:e,hidden:n,className:t}){return(0,r.jsx)("div",{role:"tabpanel",className:(0,i.A)(a.tabItem,t),hidden:n,children:e})}},53465:(e,n,t)=>{t.d(n,{W:()=>c});var i=t(96540),a=t(44586);const r=["zero","one","two","few","many","other"];function s(e){return r.filter(n=>e.includes(n))}const o={locale:"en",pluralForms:s(["one","other"]),select:e=>1===e?"one":"other"};function l(){const{i18n:{currentLocale:e}}=(0,a.A)();return(0,i.useMemo)(()=>{try{return function(e){const n=new Intl.PluralRules(e);return{locale:e,pluralForms:s(n.resolvedOptions().pluralCategories),select:e=>n.select(e)}}(e)}catch(n){return console.error(`Failed to use Intl.PluralRules for locale "${e}".\nDocusaurus will fallback to the default (English) implementation.\nError: ${n.message}\n`),o}},[e])}function c(){const e=l();return{selectMessage:(n,t)=>function(e,n,t){const i=e.split("|");if(1===i.length)return i[0];i.length>t.pluralForms.length&&console.error(`For locale=${t.locale}, a maximum of ${t.pluralForms.length} plural forms are expected (${t.pluralForms.join(",")}), but the message contains ${i.length}: ${e}`);const a=t.select(n),r=t.pluralForms.indexOf(a);return i[Math.min(r,i.length-1)]}(t,n,e)}}},75249:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>T,contentTitle:()=>I,default:()=>v,frontMatter:()=>x,metadata:()=>i,toc:()=>D});const i=JSON.parse('{"id":"create/models/deep-fine-tuning/README","title":"Deep Fine-Tuning","description":"Learn how to fine-tune pre-trained models","source":"@site/docs/create/models/deep-fine-tuning/README.mdx","sourceDirName":"create/models/deep-fine-tuning","slug":"/create/models/deep-fine-tuning/","permalink":"/create/models/deep-fine-tuning/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"description":"Learn how to fine-tune pre-trained models"},"sidebar":"tutorialSidebar","previous":{"title":"Visual Classifier","permalink":"/create/models/transfer-learning/visual-classifier"},"next":{"title":"Visual Classifier","permalink":"/create/models/deep-fine-tuning/visual-classifier"}}');var a=t(74848),r=t(28453),s=t(11470),o=t(19365),l=t(73748);const c='###################################################################################################\n# In this section, we set the user authentication, app ID, model ID, and estimated input count.\n# Change these strings to run your own example.\n##################################################################################################\n\nUSER_ID = "YOUR_USER_ID_HERE"\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nAPP_ID = "YOUR_APP_ID_HERE"\n# Change these to get your training time estimate\nMODEL_ID = "YOUR_CUSTOM_MODEL_ID_HERE"\nESTIMATED_INPUT_COUNT = 100\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\nfrom google.protobuf.struct_pb2 import Struct\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nparams = Struct()\nparams.update({\n        "template": "MMDetection_FasterRCNN"\n    })\n\nmetadata = (("authorization", "Key " + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\ntraining_time_estimate_response = stub.PostModelVersionsTrainingTimeEstimate(\n    service_pb2.PostModelVersionsTrainingTimeEstimateRequest(\n        user_app_id=userDataObject,\n        model_id=MODEL_ID,\n        model_versions=[\n            resources_pb2.ModelVersion(\n                train_info=resources_pb2.TrainInfo(params=params)\n            ),\n        ],\n        estimated_input_count=ESTIMATED_INPUT_COUNT\n    ),\n    metadata=metadata,\n)\n\nif training_time_estimate_response.status.code != status_code_pb2.SUCCESS:\n    print(training_time_estimate_response.status)\n    raise Exception("Post model outputs failed, status: " + training_time_estimate_response.status.description)\n\nprint(training_time_estimate_response)\n',d='\x3c!--index.html file--\x3e\n\n<script>\n    ///////////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and estimated input count.\n    // Change these strings to run your own example.\n    //////////////////////////////////////////////////////////////////////////////////////////////////\n\n    const USER_ID = "YOUR_USER_ID_HERE";\n    // Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    const PAT = "YOUR_PAT_HERE";\n    const APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to get your training time estimate\n    const MODEL_ID = "YOUR_CUSTOM_MODEL_ID_HERE";\n    const ESTIMATED_INPUT_COUNT = 100;\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    const raw = JSON.stringify({\n        "user_app_id": {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        "model_versions": [{\n            "train_info": {\n                "params": {\n                    "template": "MMDetection_FasterRCNN"\n                }\n            },\n\n        }],\n        "estimated_input_count": ESTIMATED_INPUT_COUNT\n\n    });\n\n    const requestOptions = {\n        method: "POST",\n        headers: {\n            "Content-Type": "application/json",\n            "Authorization": "Key " + PAT\n        },\n        body: raw\n    };\n\n    fetch(`https://api.clarifai.com/v2/users/${USER_ID}/apps/${APP_ID}/models/${MODEL_ID}/versions/time_estimate/`, requestOptions)\n        .then(response => response.text())\n        .then(result => console.log(result))\n        .catch(error => console.log("error", error));\n\n<\/script>',u='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.status.StatusCode;\nimport com.google.protobuf.Struct;\nimport com.google.protobuf.Value;\n\npublic class ClarifaiExample {\n\n    //////////////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and estimated input count.\n    // Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    // Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to get your training time estimate\n    static final String MODEL_ID = "YOUR_CUSTOM_MODEL_ID_HERE";\n    static final int ESTIMATED_INPUT_COUNT = 100;\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\t\n\n    public static void main(String[] args) {\n        \n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n                .withCallCredentials(new ClarifaiCallCredentials(PAT));\n        \n        Struct.Builder params = Struct.newBuilder()\n                .putFields("template", Value.newBuilder().setStringValue("MMDetection_FasterRCNN").build());\n        \n        MultiTrainingTimeEstimateResponse trainingTimeEstimateResponse = stub.postModelVersionsTrainingTimeEstimate(\n                PostModelVersionsTrainingTimeEstimateRequest.newBuilder()\n                        .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n                        .setModelId(MODEL_ID)\n                        .addModelVersions(ModelVersion.newBuilder()\n                                .setTrainInfo(TrainInfo.newBuilder()\n                                        .setParams(params)\n                                )\n                        )\n                        .setEstimatedInputCount(ESTIMATED_INPUT_COUNT)\n                        .build()\n        );\n        \n        if (trainingTimeEstimateResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post model outputs failed, status: " + trainingTimeEstimateResponse.getStatus());\n        }\n        \n        System.out.print(trainingTimeEstimateResponse);\n        \n    }\n}\n',p='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models/YOUR_MODEL_ID_HERE/versions/time_estimate/" \\\n  -H "Authorization: Key YOUR_PAT_HERE" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n        "model_versions": [{\n            "train_info": {\n                "params": {\n                    "template": "MMDetection_FasterRCNN"                    \n                }\n            }\n        }],\n        "estimated_input_count": 100\n  }\'',m='status {\n    code: SUCCESS\n    description: "Ok"\n    req_id: "f45dfcf36746a567f690744f0b3805a7"\n  }\n  training_time_estimates {\n    seconds: 308\n  }\n  ',h='###################################################################################################\n# In this section, we set the user authentication, app ID, and details for incremental training.\n# Change these strings to run your own example.\n###################################################################################################\n\nUSER_ID = "YOUR_USER_ID_HERE"\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nAPP_ID = "YOUR_APP_ID_HERE"\n# Change these to incrementally train your own model\nMODEL_ID = "detection-test"\nMODEL_VERSION_ID = "5af1bd0fb79d47289ab82d5bb2325c81"\nCONCEPT_ID = "face"\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\nfrom google.protobuf.struct_pb2 import Struct\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nparams = Struct()\nparams.update({\n    "template": "MMDetection_SSD", \n    "num_epochs": 1\n    })\n\nmetadata = (("authorization", "Key " + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\npost_model_versions = stub.PostModelVersions(\n    service_pb2.PostModelVersionsRequest(\n        user_app_id=userDataObject,\n        model_id=MODEL_ID,\n        model_versions=[\n            resources_pb2.ModelVersion(\n                train_info=resources_pb2.TrainInfo(\n                    params=params,\n                    resume_from_model=resources_pb2.Model(\n                        id=MODEL_ID,\n                        model_version=resources_pb2.ModelVersion(id=MODEL_VERSION_ID),\n                    ),\n                ),\n                output_info=resources_pb2.OutputInfo(\n                    data=resources_pb2.Data(\n                        concepts=[resources_pb2.Concept(id=CONCEPT_ID)]\n                    ),\n                ),\n            )\n        ],\n    ),\n    metadata=metadata,\n)\n\nif post_model_versions.status.code != status_code_pb2.SUCCESS:\n    print(post_model_versions.status)\n    raise Exception(\n        "Post models versions failed, status: " + post_model_versions.status.description\n    )\n\nprint(post_model_versions)\n',f='\x3c!--index.html file--\x3e\n\n<script>\n    ////////////////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, and details for incremental training.\n    // Change these strings to run your own example.\n    ////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n    const USER_ID = "YOUR_USER_ID_HERE";\n    // Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    const PAT = "YOUR_PAT_HERE";\n    const APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to incrementally train your own model\n    const MODEL_ID = "detection-test";\n    const MODEL_VERSION_ID = "5af1bd0fb79d47289ab82d5bb2325c81";\n    const CONCEPT_ID = "face";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    const raw = JSON.stringify({\n        "user_app_id": {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        "model_versions": [{\n            "train_info": {\n                "params": {\n                    "template": "MMDetection_SSD",\n                    "num_epochs": 1\n                },\n                "resume_from_model": {\n                    "id": MODEL_ID,\n                    "model_version": {\n                        "id": MODEL_VERSION_ID\n                    }\n                }\n            },\n            "output_info": {\n                "data": {\n                    "concepts": [\n                        {\n                            "id": CONCEPT_ID\n                        }\n                    ]\n                }\n            }\n        }]\n\n    });\n\n    const requestOptions = {\n        method: "POST",\n        headers: {\n            "Content-Type": "application/json",\n            "Authorization": "Key " + PAT\n        },\n        body: raw\n    };\n\n    fetch(`https://api.clarifai.com/v2/models/${MODEL_ID}/versions`, requestOptions)\n        .then(response => response.text())\n        .then(result => console.log(result))\n        .catch(error => console.log("error", error));\n\n<\/script>\n',g='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.status.StatusCode;\nimport com.google.protobuf.Struct;\nimport com.google.protobuf.Value;\n\npublic class ClarifaiExample {\n\n    //////////////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, and details for incremental training.\n    // Change these strings to run your own example.\n    //////////////////////////////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    // Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to incrementally train your own model\n    static final String MODEL_ID = "detection-test";\n    static final String MODEL_VERSION_ID = "5af1bd0fb79d47289ab82d5bb2325c81";\n    static final String CONCEPT_ID = "face";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\t\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n                .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        Struct.Builder params = Struct.newBuilder()\n                .putFields("template", Value.newBuilder().setStringValue("MMDetection_SSD").build())\n                .putFields("num_epochs", Value.newBuilder().setNumberValue(1).build());\n\n        SingleModelResponse postModelVersionsResponse = stub.postModelVersions(\n                PostModelVersionsRequest.newBuilder()\n                        .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n                        .setModelId(MODEL_ID)\n                        .addModelVersions(ModelVersion.newBuilder()\n                                .setTrainInfo(TrainInfo.newBuilder()\n                                        .setParams(params)\n                                        .setResumeFromModel(Model.newBuilder()\n                                                .setId(MODEL_ID)\n                                                .setModelVersion(ModelVersion.newBuilder()\n                                                        .setId(MODEL_VERSION_ID)\n                                                )\n                                        )\n                                )\n                                .setOutputInfo(OutputInfo.newBuilder()\n                                        .setData(Data.newBuilder()\n                                                .addConcepts(Concept.newBuilder()\n                                                        .setId(CONCEPT_ID)\n                                                )\n                                        )\n                                )\n                        )\n                        .build()\n        );\n\n        if (postModelVersionsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post model outputs failed, status: " + postModelVersionsResponse.getStatus());\n        }\n\n    }\n}\n',_='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models/detection-test/versions" \\\n-H "Authorization: Key YOUR_PAT_HERE" \\\n-H "Content-Type: application/json" \\\n-d \'{\n"model_versions": [{\n    "train_info": {\n        "params": {\n            "template": "MMDetection_SSD",\n            "num_epochs": 1\n        },\n        "resume_from_model": {\n            "id": "detection-test",\n            "model_version": {\n                "id": "5af1bd0fb79d47289ab82d5bb2325c81"\n            }\n        }\n    },\n    "output_info": {\n        "data": {\n            "concepts": [\n                {\n                    "id": "face"\n                }\n            ]\n        }\n    }\n}] \n}\'\n';var E=t(14795),b=t(95068);const x={description:"Learn how to fine-tune pre-trained models"},I="Deep Fine-Tuning",T={},D=[{value:"Why Choose Deep Fine-Tuning?",id:"why-choose-deep-fine-tuning",level:2},{value:"Types of Deep Fine-Tuned Models",id:"types-of-deep-fine-tuned-models",level:2},{value:"Number of Inputs",id:"number-of-inputs",level:2},{value:"Training Time Estimator",id:"training-time-estimator",level:2},{value:"How to Estimate Training Time",id:"how-to-estimate-training-time",level:3},{value:"Incrementally Train a Model",id:"incrementally-train-a-model",level:2}];function y(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"deep-fine-tuning",children:"Deep Fine-Tuning"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Learn how to fine-tune pre-trained models"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsx)(n.p,{children:'Fine-tuning is a deep learning technique that refers to taking a pre-trained model and further training it on a new dataset or task. The term "fine-tuning" implies making small adjustments or refinements to the already learned representations in the pre-trained model rather than training from scratch.'}),"\n",(0,a.jsx)(n.p,{children:"Fine-tuning leverages the power of pre-trained models to improve their performance on a new, related task. It involves taking a pre-trained model, which was previously trained on a vast dataset for a general-purpose task, and tailoring it to a more specific task."}),"\n",(0,a.jsx)(n.h2,{id:"why-choose-deep-fine-tuning",children:"Why Choose Deep Fine-Tuning?"}),"\n",(0,a.jsxs)(n.p,{children:["Clarifai offers a variety of pre-built models that are designed to help you create AI solutions quickly and efficiently. Clarifai models are the recommended starting point for many users because they offer incredibly fast training times, especially when you customize them using the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/model/model-types/transfer-learning",children:"transfer learning"})," model type."]}),"\n",(0,a.jsxs)(n.p,{children:["But there are some cases where accuracy and the ability to carefully target solutions takes priority over speed and ease of use. Additionally, you may need a model to learn new features not recognized by existing ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/model/clarifai-models#clarifai-models-1",children:"Clarifai models"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:['For such cases, it is possible to "deep fine-tune" your custom models and integrate them directly within your ',(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/workflows/working-with-workflows",children:"workflows"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"You might consider deep fine-tuning if:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"You have a custom tailored dataset. This will help you to tailor the model to a specific application or domain, such as customizing it with proprietary data from a private company."}),"\n",(0,a.jsx)(n.li,{children:"You have accurate labels. This provides a strong foundation for training your models, resulting in improved performance, reduced errors, and better alignment with the desired task or domain."}),"\n",(0,a.jsx)(n.li,{children:"You have the expertise and time to fine-tune models. So, you can modify the model's behavior to eliminate unwanted traits and instill desired ones."}),"\n",(0,a.jsx)(n.li,{children:"You want to reduce hallucinations, especially when presenting the model with questions or prompts it hasn't encountered during its initial training."}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"types-of-deep-fine-tuned-models",children:"Types of Deep Fine-Tuned Models"}),"\n",(0,a.jsxs)(n.p,{children:["To create a deep fine-tuned model using the Clarifai API, you need to specify the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/model/model-types/",children:"type of model"})," using the ",(0,a.jsx)(n.code,{children:"model_type_id"})," parameter\u2060."]}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:["You can use the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/create-manage/models/manage#list-model-types",children:(0,a.jsx)(n.code,{children:"ListModelTypes"})})," method to learn more about the available model types and their hyperparameters."]})}),"\n",(0,a.jsx)(n.p,{children:"Here some types of deep fine-tuned models you can create:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Visual classifier"})," (",(0,a.jsx)(n.code,{children:"visual-classifier"}),") \u2014 Create this model to classify images and video frames into a set of concepts."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Visual detector"})," (",(0,a.jsx)(n.code,{children:"visual-detector"}),") \u2014 Create this model to detect bounding box regions in images or video frames and then classify the detected images. You can also send the image regions to an image cropper model to create a new cropped image."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Visual embedder"})," (",(0,a.jsx)(n.code,{children:"visual-embedder"}),') \u2014 Create this model to transform images and video frames into "high level" vector representation understood by our AI models. These embeddings enable visual search and can be used as base models to train other models.']}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Visual segmenter"})," (",(0,a.jsx)(n.code,{children:"visual-segmenter"}),") \u2014 Create this model to segment a per-pixel mask in images where things are and then classify objects, descriptive words, or topics within the masks."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Visual anomaly heatmap"})," (",(0,a.jsx)(n.code,{children:"visual-anomaly-heatmap"}),") \u2014 Create this model to perform visual anomaly detection with image-level score and anomaly heatmap."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Text classifier"})," (",(0,a.jsx)(n.code,{children:"text-classifier"}),") \u2014 Create this model to classify text into a set of concepts."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Text generator"})," (",(0,a.jsx)(n.code,{children:"text-to-text"}),") \u2014 Create this model to generate or convert text based on the provided text input. For example, you can create it for prompt completion, translation, or summarization tasks."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"number-of-inputs",children:"Number of Inputs"}),"\n",(0,a.jsxs)(n.p,{children:["In general, deep fine-tuned models need more data than those trained using the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/model/model-types/transfer-learning/",children:"transfer learning technique"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"For most use cases, you\u2019ll need at least 1000 training inputs, but it could be much more than this depending on your specific scenario."}),"\n",(0,a.jsx)(n.h2,{id:"training-time-estimator",children:"Training Time Estimator"}),"\n",(0,a.jsx)(n.p,{children:"Before initiating the training of a deep fine-tuned model, you can estimate the anticipated duration of the training process. This offers transparency in expected training costs."}),"\n",(0,a.jsx)(n.p,{children:"We currently charge $4 per hour."}),"\n",(0,a.jsx)(n.p,{children:"The exact training time estimate depends on the following:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Model type;"}),"\n",(0,a.jsx)(n.li,{children:"Model configuration details;"}),"\n",(0,a.jsx)(n.li,{children:"Dataset statistics;"}),"\n",(0,a.jsx)(n.li,{children:"Hardware."}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Clarifai\u2019s Training Time Estimator is carefully designed to balance trade-offs between simplicity, generalization, and accuracy."}),"\n",(0,a.jsx)(n.p,{children:"Notably, some model configurations and dataset statistics affect training time much more than others. For example, the number of items in the dataset directly affects the number of training steps in most configs, while the learning rate has no impact."}),"\n",(0,a.jsx)(n.p,{children:"In addition, some parameters affect the time linearly (e.g. number of items), while others may be quadratic (e.g. image size), and others approximately linear, quadratic, or subquadratic\u2014depending on the model (e.g. number of tokens in each input)."}),"\n",(0,a.jsx)(n.p,{children:"The current version of the Training Time Estimator provides estimates only for each template\u2019s default parameter configuration, and we plan to include other parameter configurations in the upcoming releases."}),"\n",(0,a.jsx)(n.p,{children:"The exact calculation based on the current AWS A10 GPU is:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"training time = int(round(A * num_inputs * num_epochs + B)) \n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.em,{children:"Where A and B are parameter coefficients estimated specific to the template of each model type."})}),"\n",(0,a.jsx)(n.h3,{id:"how-to-estimate-training-time",children:"How to Estimate Training Time"}),"\n",(0,a.jsx)(n.admonition,{type:"info",children:(0,a.jsxs)(n.p,{children:["Before using the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/python-sdk",children:"Python SDK"}),", ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/nodejs-sdk",children:"Node.js SDK"}),", or any of our ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/grpc-clients",children:"gRPC clients"}),", ensure they are properly installed on your machine. Refer to their respective installation guides for instructions on how to install and initialize them."]})}),"\n","\n","\n","\n",(0,a.jsxs)(n.p,{children:["When training a deep fine-tuned model using the UI, the estimated duration for the training process will be ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/create-manage/models/deep-fine-tuning/visual-classifier#step-5-create-the-model",children:"displayed"}),", rounded down to the nearest hour with 15-minute increments."]}),"\n",(0,a.jsx)(n.p,{children:"Below is an example of how you can use the API to estimate the expected training time programmatically."}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:["Instead of providing an estimated input count, an alternative approach is to specify a dataset version ID in the ",(0,a.jsx)(n.code,{children:"train_info.params"})," of the request. Here is an example: ",(0,a.jsx)(n.code,{children:'params.update({"template":"MMDetection_FasterRCNN", "dataset_version_id":"dataset-version-1681974758238s"})'}),"."]})}),"\n",(0,a.jsxs)(s.A,{groupId:"code",children:[(0,a.jsx)(o.A,{value:"python",label:"Python (gRPC)",children:(0,a.jsx)(l.A,{className:"language-python",children:c})}),(0,a.jsx)(o.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,a.jsx)(l.A,{className:"language-javascript",children:d})}),(0,a.jsx)(o.A,{value:"java",label:"Java (gRPC)",children:(0,a.jsx)(l.A,{className:"language-java",children:u})}),(0,a.jsx)(o.A,{value:"curl",label:"cURL",children:(0,a.jsx)(l.A,{className:"language-bash",children:p})})]}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Raw Output Example"}),(0,a.jsx)(l.A,{className:"language-text",children:m})]}),"\n",(0,a.jsx)(n.h2,{id:"incrementally-train-a-model",children:"Incrementally Train a Model"}),"\n",(0,a.jsx)(n.p,{children:"You can update existing deep fine-tuned models with new data without retraining from scratch. After training a model version, a checkpoint file is automatically saved. And you can initiate incremental training from that previously trained version checkpoint."}),"\n",(0,a.jsx)(n.p,{children:"Below is an example of how you would perform incremental training from a specific version of a visual detector model."}),"\n",(0,a.jsxs)(s.A,{groupId:"code",children:[(0,a.jsx)(o.A,{value:"python",label:"Python (gRPC)",children:(0,a.jsx)(l.A,{className:"language-python",children:h})}),(0,a.jsx)(o.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,a.jsx)(l.A,{className:"language-javascript",children:f})}),(0,a.jsx)(o.A,{value:"java",label:"Java (gRPC)",children:(0,a.jsx)(l.A,{className:"language-java",children:g})}),(0,a.jsx)(o.A,{value:"curl",label:"cURL",children:(0,a.jsx)(l.A,{className:"language-bash",children:_})})]}),"\n","\n",(0,a.jsx)(E.A,{items:(0,b.$S)().items})]})}function v(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(y,{...e})}):y(e)}},95068:(e,n,t)=>{t.d(n,{$S:()=>i});t(44586);function i(...e){return t(48295).$S(...e)}}}]);