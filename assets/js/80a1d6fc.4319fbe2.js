"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[3974],{85162:(e,t,n)=>{n.d(t,{Z:()=>r});var a=n(67294),i=n(86010);const o={tabItem:"tabItem_Ymn6"};function r(e){let{children:t,hidden:n,className:r}=e;return a.createElement("div",{role:"tabpanel",className:(0,i.Z)(o.tabItem,r),hidden:n},t)}},74866:(e,t,n)=>{n.d(t,{Z:()=>w});var a=n(87462),i=n(67294),o=n(86010),r=n(12466),s=n(16550),l=n(91980),c=n(67392),u=n(50012);function d(e){return function(e){return i.Children.map(e,(e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:i}}=e;return{value:t,label:n,attributes:a,default:i}}))}function p(e){const{values:t,children:n}=e;return(0,i.useMemo)((()=>{const e=t??d(n);return function(e){const t=(0,c.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function m(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function h(e){let{queryString:t=!1,groupId:n}=e;const a=(0,s.k6)(),o=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,l._X)(o),(0,i.useCallback)((e=>{if(!o)return;const t=new URLSearchParams(a.location.search);t.set(o,e),a.replace({...a.location,search:t.toString()})}),[o,a])]}function f(e){const{defaultValue:t,queryString:n=!1,groupId:a}=e,o=p(e),[r,s]=(0,i.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!m({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:o}))),[l,c]=h({queryString:n,groupId:a}),[d,f]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[a,o]=(0,u.Nk)(n);return[a,(0,i.useCallback)((e=>{n&&o.set(e)}),[n,o])]}({groupId:a}),g=(()=>{const e=l??d;return m({value:e,tabValues:o})?e:null})();(0,i.useLayoutEffect)((()=>{g&&s(g)}),[g]);return{selectedValue:r,selectValue:(0,i.useCallback)((e=>{if(!m({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);s(e),c(e),f(e)}),[c,f,o]),tabValues:o}}var g=n(72389);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function k(e){let{className:t,block:n,selectedValue:s,selectValue:l,tabValues:c}=e;const u=[],{blockElementScrollPositionUntilNextRender:d}=(0,r.o5)(),p=e=>{const t=e.currentTarget,n=u.indexOf(t),a=c[n].value;a!==s&&(d(t),l(a))},m=e=>{let t=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{const n=u.indexOf(e.currentTarget)+1;t=u[n]??u[0];break}case"ArrowLeft":{const n=u.indexOf(e.currentTarget)-1;t=u[n]??u[u.length-1];break}}t?.focus()};return i.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":n},t)},c.map((e=>{let{value:t,label:n,attributes:r}=e;return i.createElement("li",(0,a.Z)({role:"tab",tabIndex:s===t?0:-1,"aria-selected":s===t,key:t,ref:e=>u.push(e),onKeyDown:m,onClick:p},r,{className:(0,o.Z)("tabs__item",b.tabItem,r?.className,{"tabs__item--active":s===t})}),n??t)})))}function y(e){let{lazy:t,children:n,selectedValue:a}=e;const o=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=o.find((e=>e.props.value===a));return e?(0,i.cloneElement)(e,{className:"margin-top--md"}):null}return i.createElement("div",{className:"margin-top--md"},o.map(((e,t)=>(0,i.cloneElement)(e,{key:t,hidden:e.props.value!==a}))))}function v(e){const t=f(e);return i.createElement("div",{className:(0,o.Z)("tabs-container",b.tabList)},i.createElement(k,(0,a.Z)({},e,t)),i.createElement(y,(0,a.Z)({},e,t)))}function w(e){const t=(0,g.Z)();return i.createElement(v,(0,a.Z)({key:String(t)},e))}},93500:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>u,default:()=>g,frontMatter:()=>c,metadata:()=>d,toc:()=>m});var a=n(87462),i=(n(67294),n(3905)),o=n(74866),r=n(85162),s=n(90814);const l="# Base Configuration File\n# This configuration file extends an existing YOLOF model configuration.\n\n_base_ = '/mmdetection/configs/yolof/yolof_r50_c5_8x8_1x_coco.py'\n\n# Model Configuration\nmodel = dict(\n    type='YOLOF',  # Specify the YOLOF model\n    pretrained='torchvision://resnet50',  # Pretrained model (if available)\n    backbone=dict(\n        type='ResNet',  # Specify the backbone network (e.g., 'ResNet')\n        depth=50  # Specify the depth of the backbone (e.g., ResNet-50)\n    ),\n    neck=dict(\n        type='YOLOFNeck',  # Specify the neck architecture (e.g., 'YOLOFNeck')\n        in_channels=[256, 512, 1024, 2048],  # Input channels from the backbone\n        out_channels=256,  # Output channels for the neck\n        num_csp_blocks=4  # Number of CSP blocks in the neck\n    ),\n    bbox_head=dict(\n        type='YOLOFHead',\n        num_classes=80,  # Number of object classes in your dataset. It must be included with any value, and it will be updated based on your dataset's number of classes\n        in_channels=256,  # Number of input channels from the neck\n        num_levels=5,  # Number of levels used in the detection head\n        reg_decoded_bbox=True,  # Whether to decode bounding box regression targets\n        loss_bbox=dict(type='CIoULoss', loss_weight=1.0),  # Specify the bounding box loss type\n        loss_conf=dict(type='CIoULoss', loss_weight=1.0)  # Specify the confidence loss type\n        roi_feat_size=7,  # RoI feature size\n        roi_out_channels=256,  # RoI feature output channels\n    )\n)\n\n# Data Configuration\n# This section should include 'train' and 'val' sections, each with 'ann_file', 'img_prefix', and 'classes' fields with empty strings as values\n# These values will be overwritten to be compatible with Clarifai's system, but must be included in the imported config\ndata = dict(\n    # Data Loader Configuration\n    samples_per_gpu=4,  # Number of samples processed on each GPU\n    workers_per_gpu=4,  # Number of data-loading workers per GPU\n    train=dict(\n        dataset=dict(            \n            ann_file='',  # Path to training dataset annotations\n            img_prefix='',  # Directory containing training images\n            classes=''  # List of class names in your dataset\n        ), \n    ),\n    val=dict(\n        dataset=dict(            \n            ann_file='',  # Path to validation dataset annotations\n            img_prefix='',  # Directory containing validation images\n            classes=''  # List of class names in your dataset\n        ),\n    ),\n    \n)\n\n# Optimizer Configuration\noptimizer = dict(\n    _delete_=True,  # Delete existing optimizer settings\n    type='Adam',  # Use the Adam optimizer\n    lr=0.0001,  # Set the learning rate\n    weight_decay=0.0001  # Weight decay for regularization\n)\n\n# Learning Rate Schedule Configuration\nlr_config = dict(\n    _delete_=True,  # Delete existing learning rate schedule settings\n    policy='CosineAnnealing',  # Learning rate schedule policy\n    warmup='linear',  # Warm-up strategy\n    warmup_iters=1000,  # Number of warm-up iterations\n    warmup_ratio=0.1,  # Ratio for warm-up learning rate\n    min_lr_ratio=1e-5  # Minimum learning rate ratio\n)\n\n# Runner Configuration\nrunner = dict(\n    _delete_=True,  # Delete existing runner settings\n    type='EpochBasedRunner',  # Training based on the number of epochs\n    max_epochs=1  # Maximum number of training epochs\n)\n",c={description:"Learn how to create your own custom deep trained template",sidebar_position:6},u="Create Your Own Template",d={unversionedId:"portal-guide/model/deep-training/custom-templates",id:"portal-guide/model/deep-training/custom-templates",title:"Create Your Own Template",description:"Learn how to create your own custom deep trained template",source:"@site/docs/portal-guide/model/deep-training/custom-templates.md",sourceDirName:"portal-guide/model/deep-training",slug:"/portal-guide/model/deep-training/custom-templates",permalink:"/portal-guide/model/deep-training/custom-templates",draft:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/portal-guide/model/deep-training/custom-templates.md",tags:[],version:"current",sidebarPosition:6,frontMatter:{description:"Learn how to create your own custom deep trained template",sidebar_position:6},sidebar:"tutorialSidebar",previous:{title:"Text Fine-Tuning Templates",permalink:"/portal-guide/model/deep-training/text-templates"},next:{title:"Import Models from Hugging Face",permalink:"/portal-guide/model/hf-model-importer"}},p={},m=[{value:"MMDetection Configurations",id:"mmdetection-configurations",level:2},{value:"Base Configuration",id:"base-configuration",level:3},{value:"Model",id:"model",level:3},{value:"Dataset",id:"dataset",level:3},{value:"Learning Rate Schedule",id:"learning-rate-schedule",level:3},{value:"Runtime",id:"runtime",level:3},{value:"Optimizer",id:"optimizer",level:3},{value:"Example",id:"example",level:2}],h={toc:m},f="wrapper";function g(e){let{components:t,...c}=e;return(0,i.kt)(f,(0,a.Z)({},h,c,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"create-your-own-template"},"Create Your Own Template"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Learn how to create your own custom deep trained template")),(0,i.kt)("hr",null),(0,i.kt)("p",null,"The Clarifai platform empowers advanced users to create their deep trained templates. You can customize your own templates to suit your specific needs and tasks. "),(0,i.kt)("p",null,"This flexibility allows you to leverage Clarifai's advanced machine learning capabilities and customize various template hyperparameters\u2014such as head, neck, backbone, and loss functions\u2014to influence \u201chow\u201d your model learns. "),(0,i.kt)("p",null,"If you select any of the following barebone templates:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"MMDetection"),";"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"MMClassification"),"; or,"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"MMSegmentation"),".")),(0,i.kt)("p",null,"Then, clicked the ",(0,i.kt)("strong",{parentName:"p"},"Show Training Settings (optional)")," button, a ",(0,i.kt)("strong",{parentName:"p"},"Custom config")," field will appear that allows you to provide a Python file that details the configurations of your template. "),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(67521).Z,width:"1741",height:"912"})),(0,i.kt)("br",null),(0,i.kt)("p",null,"If you click the pencil icon within the ",(0,i.kt)("strong",{parentName:"p"},"Custom Config")," field, a development environment will appear, enabling you to configure your template seamlessly without navigating away from the current screen. Additionally, you have the option to utilize the upload button, which allows you to upload a pre-configured Python file."),(0,i.kt)("admonition",{type:"info"},(0,i.kt)("p",{parentName:"admonition"},"Choosing non-barebone templates like ",(0,i.kt)("strong",{parentName:"p"},"MMDetection_YoloF"),", ",(0,i.kt)("strong",{parentName:"p"},"MMClassification_ResNet_50_RSB_A1"),", and ",(0,i.kt)("strong",{parentName:"p"},"MMSegmentation_SegFormer")," grants you access to pre-configured templates. These templates come with default settings, allowing you to use them as is or conveniently customize their settings on the UI to align with your specific use case.")),(0,i.kt)("p",null,"For this example, we\u2019ll demonstrate how you can create your own template using the MMDetection open source toolbox for ",(0,i.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/model/deep-training/visual-detection-templates/"},"visual detection")," tasks. "),(0,i.kt)("h2",{id:"mmdetection-configurations"},"MMDetection Configurations"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://mmdetection.readthedocs.io/en/latest/overview.html"},"MMDetection"),", developed by OpenMMLab, is a user-friendly toolbox based on PyTorch for object detection, instance segmentation, and panoptic segmentation tasks. It is designed to facilitate research and development in the field of object detection and instance segmentation. "),(0,i.kt)("p",null,"MMDetection provides a comprehensive collection of state-of-the-art models, datasets, and evaluation metrics, making it a valuable resource for both academic and industrial applications."),(0,i.kt)("p",null,"You can configure the MMDetection toolbox and create a unique model template with its own hyperparameters. By tweaking the various settings, you can tailor the template to match your specific tasks and improve its performance."),(0,i.kt)("p",null,"When configuring a MMDetection file, you need to set up the following basic component types under ",(0,i.kt)("inlineCode",{parentName:"p"},"config/_base_"),":"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Model"),(0,i.kt)("li",{parentName:"ul"},"Dataset"),(0,i.kt)("li",{parentName:"ul"},"Learning rate schedule"),(0,i.kt)("li",{parentName:"ul"},"Runtime")),(0,i.kt)("p",null,"Let\u2019s talk about each of them, and other associated components. "),(0,i.kt)("h3",{id:"base-configuration"},"Base Configuration"),(0,i.kt)("p",null,"To make the configuration as easy as possible, MMDetection provides base configurations for many models, which you can then customize. If used, the base config is specified by the ",(0,i.kt)("inlineCode",{parentName:"p"},"_base_")," variable, which points to a config file relative to the parent directory ",(0,i.kt)("inlineCode",{parentName:"p"},"/mmdetection/"),". "),(0,i.kt)("p",null,"You can find all available pre-build configs ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/open-mmlab/mmdetection/tree/v3.1.0/configs"},"here"),"."),(0,i.kt)("p",null,"Here is an example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"_base_ = '/mmdetection/configs/yolof/yolof_r50_c5_8x8_1x_coco.py'\n")),(0,i.kt)("p",null,"In the above example, the ",(0,i.kt)("inlineCode",{parentName:"p"},"_base_")," field indicates that this configuration file is based on another existing configuration file located at ",(0,i.kt)("inlineCode",{parentName:"p"},"/mmdetection/configs/yolof/yolof_r50_c5_8x8_1x_coco.py"),". "),(0,i.kt)("p",null,"This means that the current ",(0,i.kt)("a",{parentName:"p",href:"https://mmdetection.readthedocs.io/en/dev/tutorials/config.html"},"configuration file")," inherits settings and parameters from the base configuration file, and any modifications made in the current file will override or extend the base configuration. This base configuration file serves as a template or starting point, providing the fundamental settings and components for the detector model."),(0,i.kt)("p",null,"In this particular instance, the base configuration file defines the overall architecture of a YOLOv5 detector model, including the backbone network, neck, head, and other components."),(0,i.kt)("p",null,"By inheriting from this base configuration, the current file can leverage all these predefined settings and focus on modifying specific aspects of the model, such as hyperparameters, training settings, or inference options."),(0,i.kt)("h3",{id:"model"},"Model"),(0,i.kt)("p",null,"MMDetection contains high-quality codebases for many popular models and task-oriented modules. You can find a list of all pre-built models supported by MMDetection ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/open-mmlab/mmdetection/blob/main/docs/en/model_zoo.md"},"here"),"."),(0,i.kt)("p",null,"MMDetection lets you categorize model components into the following different parts."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Backbone"),"\u2014This is the part of the architecture that transforms the input images into raw feature maps. It is typically a pre-trained model, such as ResNet or MobileNet, that has been trained on a large dataset of images."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Neck"),"\u2014This is the component that connects the backbone with heads and performs reconfigurations and refinements on the raw feature maps so that heads can further process them. "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"DenseHead (AnchorHead/AnchorFreeHead)")," \u2014This part processes the dense locations of the feature maps fed by the neck."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"RoIExtractor"),"\u2014This part identifies the region of interest (RoI) and extracts RoI features from the feature maps."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"RoIHead (BBoxHead/MaskHead)")," \u2014This part takes RoI features as its input and makes predictions, such as bounding boxes classification or mask prediction as per the task assigned.  To adapt the number of classes for your dataset, consider modifying the ",(0,i.kt)("inlineCode",{parentName:"li"},"num_classes")," parameter within the ",(0,i.kt)("inlineCode",{parentName:"li"},"bbox_head"),"."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Loss"),"\u2014 This is the part in the head that measures the difference between the predictions of the model and the ground truth labels, such as GHMLoss, F1Loss, and FocalLoss. ")),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(64366).Z,width:"888",height:"406"})),(0,i.kt)("p",null,"The whole network is built as a series of pipelines so that end-to-end training is made simple with any kind of network. During training, the whole network is traversed in the forward and backward directions over iterations. "),(0,i.kt)("p",null,(0,i.kt)("img",{src:n(26173).Z,width:"888",height:"471"})),(0,i.kt)("h3",{id:"dataset"},"Dataset"),(0,i.kt)("p",null,"The data configuration section in an MMDetection file is meant to define how data is loaded and processed during training and validation. "),(0,i.kt)("p",null,"It specifies the number of samples processed per GPU, the number of data-loading workers, and the paths to annotation files, image directories, and class names for training and validation datasets. "),(0,i.kt)("h3",{id:"learning-rate-schedule"},"Learning Rate Schedule"),(0,i.kt)("p",null,"The learning rate schedule is specified in the ",(0,i.kt)("inlineCode",{parentName:"p"},"lr_config")," section of the MMDetection configuration file. It controls how the learning rate changes during the training process."),(0,i.kt)("p",null,"You need to set the ",(0,i.kt)("a",{parentName:"p",href:"https://mmclassification.readthedocs.io/en/latest/tutorials/schedule.html#learning-rate-decay"},"learning rate scheduling policy")," to use. "),(0,i.kt)("p",null,"For example, you can set it to ",(0,i.kt)("inlineCode",{parentName:"p"},"CosineAnnealing"),", which means the learning rate will follow a cosine annealing schedule. Cosine annealing is a popular learning rate schedule where the learning rate decreases and increases in a cosine-like manner over the course of training epochs. It is often used to help the model converge more effectively."),(0,i.kt)("p",null,"You can also incorporate a warmup strategy into the training process. This technique is used to stabilize training in the early stages. It gradually increases the learning rate from a minimal value to the desired target value, preventing large oscillations in the loss function and leading to more stable and reliable convergence. "),(0,i.kt)("h3",{id:"runtime"},"Runtime"),(0,i.kt)("p",null,"In the MMDetection configuration file, the ",(0,i.kt)("inlineCode",{parentName:"p"},"runner")," section defines runtime-related settings for the training process. "),(0,i.kt)("p",null,"It specifies how the training process is organized, including details about the type of runner used, number of training epochs, and other runtime-related parameters. "),(0,i.kt)("h3",{id:"optimizer"},"Optimizer"),(0,i.kt)("p",null,"In an MMDetection file, the optimizer settings are specified in the ",(0,i.kt)("inlineCode",{parentName:"p"},"optimizer")," section. The optimizer is a crucial component of training deep learning models, responsible for updating the model's weights during the training process. "),(0,i.kt)("p",null,"MMDetection already supports all the ",(0,i.kt)("a",{parentName:"p",href:"https://mmdetection.readthedocs.io/en/dev/tutorials/customize_runtime.html"},"optimizers implemented in PyTorch"),". So, you can conveniently adjust the optimizer choice, learning rate, and other hyperparameters in the ",(0,i.kt)("inlineCode",{parentName:"p"},"optimizer")," field."),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},"Sometimes it's necessary to delete all the existing keys in a dictionary and replace them with a new set of keys. In MMDetection, this can be achieved by setting the ",(0,i.kt)("inlineCode",{parentName:"p"},"_delete_=True")," flag in the target field. This flag instructs the configuration system to remove all keys in the dictionary except for the ones explicitly defined in the new configuration. If not used, the dict that is being defined is merged to the ",(0,i.kt)("inlineCode",{parentName:"p"},"_base_")," config, which might define an invalid configuration.")),(0,i.kt)("h2",{id:"example"},"Example"),(0,i.kt)("p",null,"Here is an example of a ",(0,i.kt)("inlineCode",{parentName:"p"},"config.py")," file for creating a custom deep-trained template using the MMDetection toolbox. "),(0,i.kt)(o.Z,{mdxType:"Tabs"},(0,i.kt)(r.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,i.kt)(s.Z,{className:"language-python",mdxType:"CodeBlock"},l))))}g.isMDXComponent=!0},67521:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/create_custom_template_1-28f8f9e3500edf001f2cff67e9cdd395.png"},64366:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/create_custom_template_2-fad126cffd6f4a48f4a009f3f0da1ac0.png"},26173:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/create_custom_template_3-8c38e96008fbc43c233dcbadfdf5a475.png"}}]);