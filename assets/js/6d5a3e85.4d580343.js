"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[844],{85162:(e,t,a)=>{a.d(t,{Z:()=>o});var n=a(67294),r=a(86010);const i={tabItem:"tabItem_Ymn6"};function o(e){let{children:t,hidden:a,className:o}=e;return n.createElement("div",{role:"tabpanel",className:(0,r.Z)(i.tabItem,o),hidden:a},t)}},74866:(e,t,a)=>{a.d(t,{Z:()=>T});var n=a(87462),r=a(67294),i=a(86010),o=a(12466),s=a(16550),l=a(91980),u=a(67392),p=a(50012);function c(e){return function(e){return r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:a,attributes:n,default:r}}=e;return{value:t,label:a,attributes:n,default:r}}))}function d(e){const{values:t,children:a}=e;return(0,r.useMemo)((()=>{const e=t??c(a);return function(e){const t=(0,u.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,a])}function f(e){let{value:t,tabValues:a}=e;return a.some((e=>e.value===t))}function m(e){let{queryString:t=!1,groupId:a}=e;const n=(0,s.k6)(),i=function(e){let{queryString:t=!1,groupId:a}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:t,groupId:a});return[(0,l._X)(i),(0,r.useCallback)((e=>{if(!i)return;const t=new URLSearchParams(n.location.search);t.set(i,e),n.replace({...n.location,search:t.toString()})}),[i,n])]}function h(e){const{defaultValue:t,queryString:a=!1,groupId:n}=e,i=d(e),[o,s]=(0,r.useState)((()=>function(e){let{defaultValue:t,tabValues:a}=e;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!f({value:t,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${a.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const n=a.find((e=>e.default))??a[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:i}))),[l,u]=m({queryString:a,groupId:n}),[c,h]=function(e){let{groupId:t}=e;const a=function(e){return e?`docusaurus.tab.${e}`:null}(t),[n,i]=(0,p.Nk)(a);return[n,(0,r.useCallback)((e=>{a&&i.set(e)}),[a,i])]}({groupId:n}),b=(()=>{const e=l??c;return f({value:e,tabValues:i})?e:null})();(0,r.useLayoutEffect)((()=>{b&&s(b)}),[b]);return{selectedValue:o,selectValue:(0,r.useCallback)((e=>{if(!f({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);s(e),u(e),h(e)}),[u,h,i]),tabValues:i}}var b=a(72389);const k={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function _(e){let{className:t,block:a,selectedValue:s,selectValue:l,tabValues:u}=e;const p=[],{blockElementScrollPositionUntilNextRender:c}=(0,o.o5)(),d=e=>{const t=e.currentTarget,a=p.indexOf(t),n=u[a].value;n!==s&&(c(t),l(n))},f=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const a=p.indexOf(e.currentTarget)+1;t=p[a]??p[0];break}case"ArrowLeft":{const a=p.indexOf(e.currentTarget)-1;t=p[a]??p[p.length-1];break}}t?.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.Z)("tabs",{"tabs--block":a},t)},u.map((e=>{let{value:t,label:a,attributes:o}=e;return r.createElement("li",(0,n.Z)({role:"tab",tabIndex:s===t?0:-1,"aria-selected":s===t,key:t,ref:e=>p.push(e),onKeyDown:f,onClick:d},o,{className:(0,i.Z)("tabs__item",k.tabItem,o?.className,{"tabs__item--active":s===t})}),a??t)})))}function y(e){let{lazy:t,children:a,selectedValue:n}=e;const i=(Array.isArray(a)?a:[a]).filter(Boolean);if(t){const e=i.find((e=>e.props.value===n));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},i.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==n}))))}function v(e){const t=h(e);return r.createElement("div",{className:(0,i.Z)("tabs-container",k.tabList)},r.createElement(_,(0,n.Z)({},e,t)),r.createElement(y,(0,n.Z)({},e,t)))}function T(e){const t=(0,b.Z)();return r.createElement(v,(0,n.Z)({key:String(t)},e))}},38040:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>m,contentTitle:()=>d,default:()=>_,frontMatter:()=>c,metadata:()=>f,toc:()=>h});var n=a(87462),r=(a(67294),a(3905)),i=a(74866),o=a(85162),s=a(90814);const l='#######################################################################################\n# In this section, we set the user authentication, user and app ID, and dataset ID.\n# Change these strings to run your own example.\n#######################################################################################\n\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "YOUR_USER_ID_HERE"\nAPP_ID = "YOUR_APP_ID_HERE"\nDATASET_ID = "YOUR_DATASET_ID_HERE"\n\n############################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n############################################################################\n\n# Import the required packages\nimport os\nfrom clarifaipyspark.client import ClarifaiPySpark\n\n# Set Clarifai PAT as environment variable\nos.environ["CLARIFAI_PAT"] = PAT\n# Create a Clarifai-PySpark client object to connect to your app on Clarifai\ncspark_obj = ClarifaiPySpark(user_id=USER_ID, app_id=APP_ID)\n# Specify the dataset\ndataset_obj = cspark_obj.dataset(dataset_id=DATASET_ID)\n\n#  Retrieve data files in JSON format\ninputs_response = list(\n    dataset_obj.list_inputs(\n        input_type="image"  # Or, specify as "video", "audio", or "text"\n    )\n)\nprint(inputs_response)\n',u='#######################################################################################\n# In this section, we set the user authentication, user and app ID, and dataset ID.\n# Change these strings to run your own example.\n######################################################################################\n\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "YOUR_USER_ID_HERE"\nAPP_ID = "YOUR_APP_ID_HERE"\nDATASET_ID = "YOUR_DATASET_ID_HERE"\n\n############################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n############################################################################\n\n# Import the required packages\nimport os\nfrom clarifaipyspark.client import ClarifaiPySpark\n\n# Set Clarifai PAT as environment variable\nos.environ["CLARIFAI_PAT"] = PAT\n# Create a Clarifai-PySpark client object to connect to your app on Clarifai\ncspark_obj = ClarifaiPySpark(user_id=USER_ID, app_id=APP_ID)\n# Specify the dataset\ndataset_obj = cspark_obj.dataset(dataset_id=DATASET_ID)\n\n# Retrieve data files as a dataframe\ninputs_df = dataset_obj.export_inputs_to_dataframe(\n          input_type="image" # Or, specify as "text"\n   )\nprint(inputs_df)\n',p='##################################################################################\n# In this section, we set the user authentication, user and app ID, dataset ID,\n# and destination volume path. Change these strings to run your own example.\n##################################################################################\n\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "YOUR_USER_ID_HERE"\nAPP_ID = "YOUR_APP_ID_HERE"\nDATASET_ID = "YOUR_DATASET_ID_HERE"\n# URL path of your Databricks volume \nDESTINATION_VOLUME_PATH = "YOUR_DATABRICKS_VOLUME_PATH_HERE"\n\n############################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n############################################################################\n\n# Import the required packages\nimport os\nfrom clarifaipyspark.client import ClarifaiPySpark\n# Set Clarifai PAT as environment variable\nos.environ["CLARIFAI_PAT"] = PAT\n# Create a Clarifai-PySpark client object to connect to your app on Clarifai\ncspark_obj = ClarifaiPySpark(user_id=USER_ID, app_id=APP_ID)\n# Specify the dataset\ndataset_obj = cspark_obj.dataset(dataset_id=DATASET_ID)\n\n#  Retrieve data files in JSON format\ninputs_response = list(\n    dataset_obj.list_inputs(\n        input_type="image"  # Or, specify as "text"\n    )\n)\n#For images\ndataset_obj.export_images_to_volume(path=DESTINATION_VOLUME_PATH, \n                                    input_response=inputs_response)\n#For text\n#dataset_obj.export_text_to_volume(path=DESTINATION_VOLUME_PATH, \n                                  #input_response=inputs_response)\n\n\n\n',c={description:"Seamlessly retrieve your data from Clarifai into Databricks",sidebar_position:2},d="Fetch Data",f={unversionedId:"integrations/databricks/fetch-data",id:"integrations/databricks/fetch-data",title:"Fetch Data",description:"Seamlessly retrieve your data from Clarifai into Databricks",source:"@site/docs/integrations/databricks/fetch-data.md",sourceDirName:"integrations/databricks",slug:"/integrations/databricks/fetch-data",permalink:"/integrations/databricks/fetch-data",draft:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/integrations/databricks/fetch-data.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{description:"Seamlessly retrieve your data from Clarifai into Databricks",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Upload Data",permalink:"/integrations/databricks/upload-data"},next:{title:"Fetch Annotations",permalink:"/integrations/databricks/fetch-annotations"}},m={},h=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Retrieve Data Files in JSON Format",id:"retrieve-data-files-in-json-format",level:2},{value:"Retrieve Data Files as a Dataframe",id:"retrieve-data-files-as-a-dataframe",level:2},{value:"Retrieve Data Files to Databricks Volume",id:"retrieve-data-files-to-databricks-volume",level:2}],b={toc:h},k="wrapper";function _(e){let{components:t,...a}=e;return(0,r.kt)(k,(0,n.Z)({},b,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"fetch-data"},"Fetch Data"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Seamlessly retrieve your data from Clarifai into Databricks")),(0,r.kt)("hr",null),(0,r.kt)("p",null,"You may use Clarifai for tasks like image recognition and analysis. Then, you may want to bring the results or the processed data into Databricks for more in-depth exploration, analysis, or integration with other data sources. "),(0,r.kt)("p",null,"Let\u2019s illustrate how you can effortlessly transfer data from Clarifai into the Databricks environment. "),(0,r.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Databricks notebook development environment. Also, ensure your Databricks workspace is enabled to work with ",(0,r.kt)("a",{parentName:"li",href:"https://docs.databricks.com/en/data-governance/unity-catalog/get-started.html"},"Unity Catalog")),(0,r.kt)("li",{parentName:"ul"},"Get your PAT (Personal Access Token) from the Clarifai\u2019s portal under the ",(0,r.kt)("a",{parentName:"li",href:"https://clarifai.com/settings/security"},"Settings/Security")," section"),(0,r.kt)("li",{parentName:"ul"},"Get your Clarifai user ID "),(0,r.kt)("li",{parentName:"ul"},"Get the ID of the Clarifai app where you want to fetch the data from"),(0,r.kt)("li",{parentName:"ul"},"Get the ID of the dataset having the data within your app"),(0,r.kt)("li",{parentName:"ul"},"Install the ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/Clarifai/clarifai-pyspark"},"Clarifai PySpark")," package by running ",(0,r.kt)("inlineCode",{parentName:"li"},"pip install clarifai-pyspark ")),(0,r.kt)("li",{parentName:"ul"},"Install Protocol Buffers by running ",(0,r.kt)("inlineCode",{parentName:"li"},"pip install protobuf==4.24.2 "),". It\u2019s a cross-platform, serialization protocol that describes the structure of the data to be sent ")),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"You can learn how to authenticate with the Clarifai platform ",(0,r.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/clarifai-basics/authentication/personal-access-tokens"},"here"),".")),(0,r.kt)("h2",{id:"retrieve-data-files-in-json-format"},"Retrieve Data Files in JSON Format"),(0,r.kt)("p",null,"You can retrieve detailed information about the input data in your Clarifai app\u2019s dataset. You\u2019ll get a JSON response containing comprehensive details about the dataset files. "),(0,r.kt)("p",null,"Ensure you use the ",(0,r.kt)("inlineCode",{parentName:"p"},"input_type"),' parameter for targeted retrieval based on the data file types. You can specify the desired type, such as "image", "video", "audio", or "text", to obtain specific details relevant to that file type. '),(0,r.kt)(i.Z,{mdxType:"Tabs"},(0,r.kt)(o.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)(s.Z,{className:"language-python",mdxType:"CodeBlock"},l))),(0,r.kt)("h2",{id:"retrieve-data-files-as-a-dataframe"},"Retrieve Data Files as a Dataframe"),(0,r.kt)("p",null,"You can retrieve detailed information about your data files in a structured dataframe format. The dataframe includes key columns like ",(0,r.kt)("inlineCode",{parentName:"p"},"input_id"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"image_url/text_url"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"image_info/text_info"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"input_created_at"),", and ",(0,r.kt)("inlineCode",{parentName:"p"},"input_modified_at"),"."),(0,r.kt)("p",null,"Ensure to specify the ",(0,r.kt)("inlineCode",{parentName:"p"},"input_type"),' parameter to tailor the results to a specific type, such as "image", or "text". '),(0,r.kt)("p",null,"Note that the JSON response may include additional attributes, offering comprehensive insights beyond the specified columns in the dataframe. "),(0,r.kt)(i.Z,{mdxType:"Tabs"},(0,r.kt)(o.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)(s.Z,{className:"language-python",mdxType:"CodeBlock"},u))),(0,r.kt)("h2",{id:"retrieve-data-files-to-databricks-volume"},"Retrieve Data Files to Databricks Volume"),(0,r.kt)("p",null,"You can effortlessly download image and text files from your Clarifai app\u2019s dataset to your Databricks volume. "),(0,r.kt)("p",null,"You need to specify the path where the retrieved data will be stored in the volume and utilize the response obtained from the ",(0,r.kt)("inlineCode",{parentName:"p"},"list_inputs()")," function as the parameter. "),(0,r.kt)(i.Z,{mdxType:"Tabs"},(0,r.kt)(o.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)(s.Z,{className:"language-python",mdxType:"CodeBlock"},p))),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"You can get examples for integrating Clarifai with Databricks ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/Clarifai/clarifai-pyspark/tree/main/examples"},"here"),".")))}_.isMDXComponent=!0}}]);