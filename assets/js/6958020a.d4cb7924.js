"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[9452],{8215:function(e,n,t){var a=t(7294);n.Z=function(e){var n=e.children,t=e.hidden,o=e.className;return a.createElement("div",{role:"tabpanel",hidden:t,className:o},n)}},6396:function(e,n,t){t.d(n,{Z:function(){return d}});var a=t(7462),o=t(7294),r=t(2389),i=t(9443);var s=function(){var e=(0,o.useContext)(i.Z);if(null==e)throw new Error('"useUserPreferencesContext" is used outside of "Layout" component.');return e},c=t(3616),l=t(6010),u="tabItem_vU9c";function p(e){var n,t,r,i=e.lazy,p=e.block,d=e.defaultValue,h=e.values,m=e.groupId,f=e.className,b=o.Children.map(e.children,(function(e){if((0,o.isValidElement)(e)&&void 0!==e.props.value)return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})),v=null!=h?h:b.map((function(e){var n=e.props;return{value:n.value,label:n.label,attributes:n.attributes}})),g=(0,c.lx)(v,(function(e,n){return e.value===n.value}));if(g.length>0)throw new Error('Docusaurus error: Duplicate values "'+g.map((function(e){return e.value})).join(", ")+'" found in <Tabs>. Every value needs to be unique.');var w=null===d?d:null!=(n=null!=d?d:null==(t=b.find((function(e){return e.props.default})))?void 0:t.props.value)?n:null==(r=b[0])?void 0:r.props.value;if(null!==w&&!v.some((function(e){return e.value===w})))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+w+'" but none of its children has the corresponding value. Available values are: '+v.map((function(e){return e.value})).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");var _=s(),k=_.tabGroupChoices,y=_.setTabGroupChoices,N=(0,o.useState)(w),S=N[0],T=N[1],C=[],E=(0,c.o5)().blockElementScrollPositionUntilNextRender;if(null!=m){var A=k[m];null!=A&&A!==S&&v.some((function(e){return e.value===A}))&&T(A)}var I=function(e){var n=e.currentTarget,t=C.indexOf(n),a=v[t].value;a!==S&&(E(n),T(a),null!=m&&y(m,a))},D=function(e){var n,t=null;switch(e.key){case"ArrowRight":var a=C.indexOf(e.currentTarget)+1;t=C[a]||C[0];break;case"ArrowLeft":var o=C.indexOf(e.currentTarget)-1;t=C[o]||C[C.length-1]}null==(n=t)||n.focus()};return o.createElement("div",{className:"tabs-container"},o.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.Z)("tabs",{"tabs--block":p},f)},v.map((function(e){var n=e.value,t=e.label,r=e.attributes;return o.createElement("li",(0,a.Z)({role:"tab",tabIndex:S===n?0:-1,"aria-selected":S===n,key:n,ref:function(e){return C.push(e)},onKeyDown:D,onFocus:I,onClick:I},r,{className:(0,l.Z)("tabs__item",u,null==r?void 0:r.className,{"tabs__item--active":S===n})}),null!=t?t:n)}))),i?(0,o.cloneElement)(b.filter((function(e){return e.props.value===S}))[0],{className:"margin-vert--md"}):o.createElement("div",{className:"margin-vert--md"},b.map((function(e,n){return(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==S})}))))}function d(e){var n=(0,r.Z)();return o.createElement(p,(0,a.Z)({key:String(n)},e))}},6392:function(e,n,t){t.r(n),t.d(n,{contentTitle:function(){return p},default:function(){return f},frontMatter:function(){return u},metadata:function(){return d},toc:function(){return h}});var a=t(7462),o=t(3366),r=(t(7294),t(3905)),i=t(6396),s=t(8215),c=t(9055),l=["components"],u={description:"Group or separate items in your dataset.",sidebar_position:2},p="Combine or Negate",d={unversionedId:"api-guide/search/combine-or-negate",id:"api-guide/search/combine-or-negate",title:"Combine or Negate",description:"Group or separate items in your dataset.",source:"@site/docs/api-guide/search/combine-or-negate.md",sourceDirName:"api-guide/search",slug:"/api-guide/search/combine-or-negate",permalink:"/docs-new/api-guide/search/combine-or-negate",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/api-guide/search/combine-or-negate.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{description:"Group or separate items in your dataset.",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Search Overview",permalink:"/docs-new/api-guide/search/rank-filter-combine-or-negate"},next:{title:"Filter",permalink:"/docs-new/api-guide/search/filter"}},h=[],m={toc:h};function f(e){var n=e.components,t=(0,o.Z)(e,l);return(0,r.kt)("wrapper",(0,a.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"combine-or-negate"},"Combine or Negate"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Group or separate items in your dataset")),(0,r.kt)("hr",null),(0,r.kt)("p",null,"You can also combine searches. Unlike our legacy search, in annotation search, ",(0,r.kt)("inlineCode",{parentName:"p"},"Filter")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Rank")," is a list of ",(0,r.kt)("inlineCode",{parentName:"p"},"Annotation")," objects. Filtered annotations will be ANDed. "),(0,r.kt)("p",null,"When you combine both ",(0,r.kt)("inlineCode",{parentName:"p"},"Filter")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Rank"),", filter will be applied before ranking annotations. This is important because limiting the result set on large applications can speedup the overall query drastically when doing a ranking."),(0,r.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"info")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"The initialization code used in the following example is outlined in detail on the ",(0,r.kt)("a",{parentName:"p",href:"../api-overview/api-clients#client-installation-instructions"},"client installation page.")))),(0,r.kt)(i.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)(c.Z,{className:"language-python",mdxType:"CodeBlock"},"################################################################################\n# In this section, we set the user authentication, app ID, and the concepts we  \n# we want to search by. Change these strings to run your own example.\n################################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to search by your own concepts\nCONCEPT_ID_1 = 'cat'\nCONCEPT_ID_2 = 'dog'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID) # The userDataObject is required when using a PAT\n\n# Here we search for images which we labeled with \"cat\" and for which the General prediction model does not find\n# a \"dog\" concept.\npost_annotations_searches_response = stub.PostAnnotationsSearches(\n    service_pb2.PostAnnotationsSearchesRequest(\n        user_app_id=userDataObject,  \n        searches = [\n            resources_pb2.Search(\n                query=resources_pb2.Query(\n                    filters=[\n                        resources_pb2.Filter(\n                            annotation=resources_pb2.Annotation(\n                                data=resources_pb2.Data(\n                                    concepts=[  # You can search by multiple concepts\n                                        resources_pb2.Concept(\n                                            id=CONCEPT_ID_1,  # You could search by concept Name as well\n                                            value=1  # Value of 0 will search for images that don't have the concept\n                                        )\n                                    ]\n                                )\n                            )\n                        )\n                    ],\n                    ranks=[\n                        resources_pb2.Rank(\n                            annotation=resources_pb2.Annotation(\n                                data=resources_pb2.Data(\n                                    concepts=[  # You can search by multiple concepts\n                                        resources_pb2.Concept(\n                                            id=CONCEPT_ID_2,  # You could search by concept Name as well\n                                            value=0  # Value of 0 will search for images that don't have the concept\n                                        )\n                                    ]\n                                )\n                            )\n                        )\n                    ]\n                )\n            )\n        ]\n    ),\n    metadata=metadata\n)\n\nif post_annotations_searches_response.status.code != status_code_pb2.SUCCESS:\n    print(post_annotations_searches_response.status)    \n    raise Exception(\"Post searches failed, status: \" + post_annotations_searches_response.status.description)\n\nprint(\"Search result:\")\nfor hit in post_annotations_searches_response.hits:\n    print(\"\\tScore %.2f for annotation: %s off input: %s\" % (hit.score, hit.annotation.id, hit.input.id))")),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'import com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.*;\n\n// Insert here the initialization code as outlined on this page:\n// https://docs.clarifai.com/api-guide/api-overview/api-clients#client-installation-instructions\n\n// Here we search for images which we labeled with "cat" and for which the General prediction model does not find\n// a "dog" concept.\nMultiSearchResponse postAnnotationsSearchesResponse = stub.postAnnotationsSearches(\n    PostAnnotationsSearchesRequest.newBuilder().addSearches(\n        Search.newBuilder().setQuery(\n            Query.newBuilder()\n                .addFilters(\n                    Filter.newBuilder().setAnnotation(\n                        Annotation.newBuilder().setData(\n                                Data.newBuilder().addConcepts(  // You can search by multiple concepts.\n                                Concept.newBuilder()\n                                    .setId("cat")  // You could search by concept Name as well.\n                                    .setValue(1f)  // Value of 0 will search for images that don\'t have the concept.\n                            )\n                        )\n                    )\n                )\n                .addRanks(\n                Rank.newBuilder().setAnnotation(\n                    Annotation.newBuilder().setData(\n                            Data.newBuilder().addConcepts(  // You can search by multiple concepts.\n                            Concept.newBuilder()\n                                .setId("dog")  // You could search by concept Name as well.\n                                .setValue(1f)  // Value of 0 will search for images that don\'t have the concept.\n                        )\n                    )\n                )\n            )\n        )    \n    )\n    .build()\n);\n\nif (postAnnotationsSearchesResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n  throw new RuntimeException("Post annotations searches failed, status: " + postAnnotationsSearchesResponse.getStatus());\n}\n\nSystem.out.println("Found inputs " + postAnnotationsSearchesResponse.getHitsCount() + ":");\nfor (Hit hit : postAnnotationsSearchesResponse.getHitsList()) {\n    System.out.printf("\\tScore %.2f for annotation % of input %s\\n", hit.getScore(), hit.getAnnotation().getId(), hit.getInput().getId())\n}\n'))),(0,r.kt)(s.Z,{value:"nodejs",label:"NodeJS",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'// Insert here the initialization code as outlined on this page:\n// https://docs.clarifai.com/api-guide/api-overview/api-clients#client-installation-instructions\n\n// Here we search for images which we labeled with "cat" and for which the General prediction model does not find\n// a "dog" concept.\nstub.PostAnnotationsSearches(\n    {\n        searches: [\n            {\n                query: {\n                    filters: [\n                        {\n                            annotation: {\n                                data: {\n                                    concepts: [  // You can search by multiple concepts.\n                                        {\n                                            id: "cat",  // You could search by concept Name as well.\n                                            value: 1  // Value of 0 will search for images that don\'t have the concept\n                                        }\n                                    ]\n                                }\n                            }\n                        }\n                    ],\n                    ranks: [\n                        {\n                            annotation: {\n                                data: {\n                                    concepts: [  // You can search by multiple concepts.\n                                        {\n                                            id: "dog",  // You could search by concept Name as well.\n                                            value: 0  // Value of 0 will search for images that don\'t have the concept\n                                        }\n                                    ]\n                                }\n                            }\n                        }\n                    ]             \n                }\n            }\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error("Post annotations searches failed, status: " + response.status.description);\n        }\n\n        console.log("Search result:");\n        for (const hit of response.hits) {\n            console.log("\\tScore " + hit.score + " for annotation: " + hit.annotation.id + " of input: ", hit.input.id);\n        }\n    }\n);\n'))),(0,r.kt)(s.Z,{value:"curl",label:"cURL",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'# Here we search for images which we labeled with "cat" and for which the General prediction model does not find\n# a "dog" concept.\n\ncurl -X POST \\\n  -H "Authorization: Key {api-key}" \\\n  -H "Content-Type: application/json" \\\n-d \'\n{\n    "searches": [\n      {\n        "query": {\n          "filters": [\n            {\n              "annotation": {\n                "data": {\n                  "concepts": [\n                    {\n                      "id":"people",\n                      "value": 1\n                    }\n                  ]\n                }\n              }\n            }\n          ],\n          "ranks": [\n            {\n              "annotation": {\n                "data": {\n                  "concepts": [\n                    {\n                      "id":"people",\n                      "value": 1\n                    }\n                  ]\n                }\n              }\n            }\n          ]\n        }\n      }\n    ]\n}\'\\\nhttps://api.clarifai.com/v2/searches\n'))),(0,r.kt)(s.Z,{value:"js_rest",label:"Javascript (REST)",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'const raw = JSON.stringify({\n  "user_app_id": {\n        "user_id": "{YOUR_USER_ID}",\n        "app_id": "{YOUR_APP_ID}"\n    },\n  "searches": [\n    {\n      "query": {\n        "filters": [\n          {\n            "annotation": {\n              "data": {\n                "concepts": [\n                  {\n                    "id":"people",\n                    "value": 1\n                  }\n                ]\n              }\n            }\n          }\n        ],\n        "ranks": [\n          {\n            "annotation": {\n              "data": {\n                "concepts": [\n                  {\n                    "id":"people",\n                    "value": 1\n                  }\n                ]\n              }\n            }\n          }\n        ]\n      }\n    }\n  ]\n});\n\nconst requestOptions = {\n  method: \'POST\',\n  headers: {\n    \'Accept\': \'application/json\',\n    \'Authorization\': \'Key {YOUR_PERSONAL_TOKEN}\'\n  },\n    body: raw\n};\n\nfetch(`https://api.clarifai.com/v2/searches`, requestOptions)\n  .then(response => response.text())\n  .then(result => console.log(result))\n  .catch(error => console.log(\'error\', error));\n')))))}f.isMDXComponent=!0}}]);