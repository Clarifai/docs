"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[998],{85073:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>H,contentTitle:()=>$,default:()=>M,frontMatter:()=>W,metadata:()=>F,toc:()=>B});var o=t(74848),r=t(28453),c=t(11470),s=t(19365),a=t(21432);const i='##############################################################################\n# In this section, we set the user authentication, app ID, workflow ID, and\n# image URL. Change these strings to run your own example.\n##############################################################################\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "clarifai"\nAPP_ID = "main"\n# Change these to make your own predictions\nWORKFLOW_ID = "Face-Sentiment"\nIMAGE_URL = "https://samples.clarifai.com/celebrity.jpeg"\n# Or, to use a local text file, assign the location variable\n# IMAGE_FILE_LOCATION = "YOUR_IMAGE_FILE_LOCATION_HERE"\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (("authorization", "Key " + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(\n    user_id=USER_ID, app_id=APP_ID\n)  # The userDataObject is required when using a PAT\n\n# To use a local text file, uncomment the following lines\n# with open(IMAGE_FILE_LOCATION, "rb") as f:\n#    file_bytes = f.read()\n\npost_workflow_results_response = stub.PostWorkflowResults(\n    service_pb2.PostWorkflowResultsRequest(\n        user_app_id=userDataObject,\n        workflow_id=WORKFLOW_ID,\n        inputs=[\n            resources_pb2.Input(\n                data=resources_pb2.Data(\n                    image=resources_pb2.Image(\n                        url=IMAGE_URL\n                      # base64=file_bytes\n                    )\n                )\n            )\n        ],\n    ),\n    metadata=metadata,\n)\nif post_workflow_results_response.status.code != status_code_pb2.SUCCESS:\n    print(post_workflow_results_response.status)\n    raise Exception(\n        "Post workflow results failed, status: "\n        + post_workflow_results_response.status.description\n    )\n\n# We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here one WorkflowResult\nresults = post_workflow_results_response.results[0]\n\n# Each model we have in the workflow will produce one output.\nfor output in results.outputs:\n    model = output.model\n\n    print("Predicted concepts for the model `%s`" % model.id)\n\n    for concept in output.data.regions:\n        for item in concept.data.concepts:\n            print("\\t%s %.2f" % (item.name, item.value))\n\n# Uncomment this line to print the raw output\n# print(results)\n',l='\x3c!--index.html file--\x3e\n\n<script>\n  ////////////////////////////////////////////////////////////////////////////////////////\n  //  In this section, we set the user authentication, app ID, workflow ID, and\n  // image URL. Change these strings to run your own example.\n  ///////////////////////////////////////////////////////////////////////////////////////\n\n  // Your PAT (Personal Access Token) can be found in the Account\'s Security section\n  const PAT = "YOUR_PAT_HERE";\n  const USER_ID = "clarifai";\n  const APP_ID = "main";\n  // Change these to make your own predictions\n  const WORKFLOW_ID = "Face-Sentiment";\n  const IMAGE_URL = "https://samples.clarifai.com/celebrity.jpeg";\n\n  ///////////////////////////////////////////////////////////////////////////////////\n  // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n  /////////////////////////////////////////////////////////////////////////////////// \n\n  const raw = JSON.stringify({\n    "user_app_id": {\n      "user_id": USER_ID,\n      "app_id": APP_ID\n    },\n    "inputs": [\n      {\n        "data": {\n          "image": {\n            "url": IMAGE_URL\n          }\n        }\n      }\n    ]\n  });\n\n  const requestOptions = {\n    method: \'POST\',\n    headers: {\n      \'Accept\': \'application/json\',\n      \'Authorization\': \'Key \' + PAT\n    },\n    body: raw\n  };\n\n  fetch(`https://api.clarifai.com/v2/workflows/${WORKFLOW_ID}/results`, requestOptions)\n    .then(response => response.text())\n    .then(result => console.log(result))\n    .catch(error => console.log(\'error\', error));\n<\/script>',v='//index.js file\n\n///////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, workflow ID, and\n// image URL. Change these strings to run your own example.\n///////////////////////////////////////////////////////////////////////////////////\n\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\nconst PAT = "YOUR_PAT_HERE";\n// Specify the correct user_id/app_id pairings\n// Since you\'re making inferences outside your app\'s scope\nconst USER_ID = "clarifai";\nconst APP_ID = "main";\n// Change these to make your own predictions\nconst WORKFLOW_ID = "Face-Sentiment";\nconst IMAGE_URL = "https://samples.clarifai.com/celebrity.jpeg";\n// Or, to use a local text file, assign the location variable\n// const IMAGE_FILE_LOCATION = "YOUR_IMAGE_FILE_LOCATION_HERE";\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\n// To use a local text file, uncomment the following lines\n// const fs = require("fs");\n// const imageBytes = fs.readFileSync(IMAGE_FILE_LOCATION);\n\nstub.PostWorkflowResults({\n        user_app_id: {\n            "user_id": USER_ID,\n            "app_id": APP_ID,\n        },\n        workflow_id: WORKFLOW_ID,\n        inputs: [{\n            data: {\n                image: {\n                    url: IMAGE_URL,\n                    // base64: imageBytes\n                }\n            }\n        }],\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error(\n                "Post workflow results failed, status: " + response.status.description\n            );\n        }\n\n        // We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here \n        // one WorkflowResult\n        const results = response.results[0];\n\n        // Each model we have in the workflow will produce one output.\n        for (const output of results.outputs) {\n            const model = output.model;\n\n            console.log(`Predicted concepts for the model \'${model.id}\'`);\n\n            for (const concept of output.data.regions) {\n                for (const item of concept.data.concepts) {\n                    console.log(`\\t${item.name} ${item.value.toFixed(2)}`);\n                }\n            }\n        }\n        // Uncomment this line to print the raw output\n        // console.log(results);\n    }\n);',u='package com.clarifai.example;\n\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\n\nimport com.google.protobuf.ByteString;\nimport java.io.File;\nimport java.io.IOException;\nimport java.nio.file.Files;\n\npublic class ClarifaiExample {\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, workflow ID, and\n    // image URL. Change these strings to run your own example.\n    ///////////////////////////////////////////////////////////////////////////////////\n    \n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String USER_ID = "clarifai";\n    static final String APP_ID = "main";\n    // Change these to make your own predictions\n    static final String WORKFLOW_ID = "Face-Sentiment";\n    static final String IMAGE_URL = "https://samples.clarifai.com/celebrity.jpeg";\n    // Or, to use a local text file, assign the location variable\n    // static final String IMAGE_FILE_LOCATION = "YOUR_IMAGE_FILE_LOCATION_HERE";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n    \n    public static void main(String[] args) throws IOException {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n                .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        PostWorkflowResultsResponse postWorkflowResultsResponse = stub.postWorkflowResults(\n                PostWorkflowResultsRequest.newBuilder()\n                        .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n                        .setWorkflowId(WORKFLOW_ID)\n                        .addInputs(\n                                Input.newBuilder().setData(\n                                        Data.newBuilder().setImage(\n                                                Image.newBuilder().setUrl(IMAGE_URL)\n                                                //  To use a local text file, uncomment the following lines\n                                                //Image.newBuilder().setBase64(ByteString.copyFrom(Files.readAllBytes(\n                                                       // new File(IMAGE_FILE_LOCATION).toPath()\n                                                //)))\n                                        )\n                                )\n                        )\n                        .build()\n        );\n\n        if (postWorkflowResultsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post workflow results failed, status: " + postWorkflowResultsResponse.getStatus());\n        }\n\n        // We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here\n        // one WorkflowResult\n        WorkflowResult results = postWorkflowResultsResponse.getResults(0);\n\n        // Each model we have in the workflow will produce its output       \n        for (Output output : results.getOutputsList()) {\n            Model model = output.getModel();\n\n            System.out.println("Predicted concepts for the model \'" + model.getId() + "\'");\n\n            for (Region concept : output.getData().getRegionsList()) {\n                for (Concept item : concept.getData().getConceptsList()) {\n                    System.out.printf("\\t%s %.2f%n", item.getName(), item.getValue());\n                }\n            }\n        }\n\n        // Uncomment this line to print the raw output\n        // System.out.println(results);\n    }\n\n}\n',d='curl -X POST "https://api.clarifai.com/v2/users/clarifai/apps/main/workflows/Face-Sentiment/results" \\\n  -H "authorization: Key YOUR_PAT_HERE" \\\n  -H "content-type: application/json" \\\n  -d \'{\n    "inputs": [\n        {\n          "data": {\n            "image": {\n              "url": "https://samples.clarifai.com/celebrity.jpeg"\n          }\n        }\n      }\n    ]\n}\'',p='<?php\n\nrequire __DIR__ . "/vendor/autoload.php";\n\n/////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, workflow ID, and\n// image URL. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////\n\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\n$PAT = "YOUR_PAT_HERE";\n$USER_ID = "clarifai";\n$APP_ID = "main";\n// Change these to make your own predictions\n$WORKFLOW_ID = "Face-Sentiment";\n$IMAGE_URL = "https://samples.clarifai.com/celebrity.jpeg";\n# Or, to use a local text file, assign the location variable\n// $IMAGE_BYTES_STRING = "YOUR_IMAGE_FILE_LOCATION_HERE";\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nuse Clarifai\\ClarifaiClient;\nuse Clarifai\\Api\\Data;\nuse Clarifai\\Api\\Image;\nuse Clarifai\\Api\\Input;\nuse Clarifai\\Api\\PostWorkflowResultsRequest;\nuse Clarifai\\Api\\Status\\StatusCode;\nuse Clarifai\\Api\\UserAppIDSet;\n\n$client = ClarifaiClient::grpc();\n\n$metadata = ["Authorization" => ["Key " . $PAT]];\n\n$userDataObject = new UserAppIDSet([\n    "user_id" => $USER_ID,\n    "app_id" => $APP_ID,\n]);\n\n// To use a local text file, uncomment the following lines\n// $imageData = file_get_contents($IMAGE_BYTES_STRING); \n\n// Let\'s make a RPC call to the Clarifai platform. It uses the opened gRPC client channel to communicate a\n// request and then wait for the response\n[$response, $status] = $client\n    ->PostWorkflowResults(\n        // The request object carries the request along with the request status and other metadata related to the request itself\n        new PostWorkflowResultsRequest([\n            "user_app_id" => $userDataObject,\n            "workflow_id" => $WORKFLOW_ID,\n            "inputs" => [\n                new Input([\n                    // The Input object wraps the Data object in order to meet the API specification\n                    "data" => new Data([\n                        // The Data object is constructed around the Image object. It offers a container that has additional image independent\n                        // metadata. In this particular use case, no other metadata is needed to be specified\n                        "image" => new Image([\n                            // In the Clarifai platform, an image is defined by a special Image object\n                           "url" => $IMAGE_URL,\n                            // "base64" => $imageData,\n                        ]),\n                    ]),\n                ]),\n            ],\n        ]),\n        $metadata\n    )\n    ->wait();\n\n// A response is returned and the first thing we do is check the status of it\n// A successful response will have a status code of 0; otherwise, there is some error\nif ($status->code !== 0) {\n    throw new Exception("Error: {$status->details}");\n}\n// In addition to the RPC response status, there is a Clarifai API status that reports if the operation was a success or failure\n// (not just that the communication was successful)\nif ($response->getStatus()->getCode() != StatusCode::SUCCESS) {\n    throw new Exception(\n        "Failure response: " .\n            $response->getStatus()->getDescription() .\n            " " .\n            $response->getStatus()->getDetails()\n    );\n}\n\n// We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here one WorkflowResult\n$results = $response->getResults()[0];\n\n// Each model we have in the workflow will produce one output\nforeach ($results->getOutputs() as $output) {\n    $model = $output->getModel();\n\n    echo "Predicted concepts for the model \'{$model->getId()}\'" . "\\n";\n\n    foreach ($output->getData()->getRegions() as $concept) {\n        foreach ($concept->getData()->getConcepts() as $item) {\n            echo "\\t{$item->getName()} {$item->getValue()}" . "\\n";\n        }\n    }\n}\n\n// Uncomment this line to print the raw output\n// print_r($results);\n\n?>',f="Predicted concepts for the model `face-detection`\n        BINARY_POSITIVE 1.00\nPredicted concepts for the model `margin-110-image-crop`\nPredicted concepts for the model `face-sentiment-recognition`\n        happiness 1.00\n        disgust 0.00\n        fear 0.00\n        sadness-contempt 0.00\n        surprise 0.00\n        anger 0.00\n        neutral 0.00",h='status {\n  code: SUCCESS\n  description: "Ok"\n}\ninput {\n  id: "5865e5d55a164beebc6f7a5682269cb4"\n  data {\n    image {\n      url: "https://samples.clarifai.com/celebrity.jpeg"\n    }\n  }\n}\noutputs {\n  id: "01e76acba82d4453a1d3c10b1777066e"\n  status {\n    code: SUCCESS\n    description: "Ok"\n  }\n  created_at {\n    seconds: 1700656970\n    nanos: 361613613\n  }\n  model {\n    id: "face-detection"\n    name: "Face"\n    created_at {\n      seconds: 1606323024\n      nanos: 453038000\n    }\n    modified_at {\n      seconds: 1665509418\n      nanos: 21257000\n    }\n    app_id: "main"\n    model_version {\n      id: "6dc7e46bc9124c5c8824be4822abe105"\n      created_at {\n        seconds: 1614879626\n        nanos: 81729000\n      }\n      status {\n        code: MODEL_TRAINED\n        description: "Model is trained and ready"\n      }\n      visibility {\n        gettable: PUBLIC\n      }\n      app_id: "main"\n      user_id: "clarifai"\n      metadata {\n      }\n    }\n    user_id: "clarifai"\n    model_type_id: "visual-detector"\n    visibility {\n      gettable: PUBLIC\n    }\n    workflow_recommended {\n    }\n  }\n  data {\n    regions {\n      id: "32b383f26ce26a4ff16642447f9317b8"\n      region_info {\n        bounding_box {\n          top_row: 0.151694223\n          left_col: 0.285768479\n          bottom_row: 0.614028037\n          right_col: 0.762517869\n        }\n      }\n      data {\n        concepts {\n          id: "ai_b1b1b1b1"\n          name: "BINARY_POSITIVE"\n          value: 0.999997377\n          app_id: "main"\n        }\n      }\n      value: 0.999997377\n    }\n  }\n}\noutputs {\n  id: "a521f59aeaf94d06901da76ab01fd0e0"\n  status {\n    code: SUCCESS\n    description: "Ok"\n  }\n  created_at {\n    seconds: 1700656970\n    nanos: 361621134\n  }\n  model {\n    id: "margin-110-image-crop"\n    name: "margin-110"\n    created_at {\n      seconds: 1590505298\n      nanos: 387731000\n    }\n    modified_at {\n      seconds: 1634716390\n      nanos: 69050000\n    }\n    app_id: "main"\n    model_version {\n      id: "b9987421b40a46649566826ef9325303"\n      created_at {\n        seconds: 1590505298\n        nanos: 387731000\n      }\n      status {\n        code: MODEL_TRAINED\n        description: "Model is trained and ready"\n      }\n      visibility {\n        gettable: PUBLIC\n      }\n      app_id: "main"\n      user_id: "clarifai"\n      metadata {\n      }\n    }\n    display_name: "margin-110-image-crop"\n    user_id: "clarifai"\n    model_type_id: "image-crop"\n    visibility {\n      gettable: PUBLIC\n    }\n    workflow_recommended {\n    }\n  }\n  data {\n    regions {\n      id: "6b5ea07bdaec9a8e48ff9424bf1f03b7"\n      region_info {\n        bounding_box {\n          top_row: 0.12857753\n          left_col: 0.261931\n          bottom_row: 0.637144744\n          right_col: 0.786355317\n        }\n      }\n      data {\n        image {\n          base64: "\\377\\330\\377\\340\\000\\020JFIF\\000\\001\\001\\000\\000\\001\\000\\001\\000\\000\\377\\333\\000C\\000\\010\\006\\006\\007\\006\\005\\010\\007\\007\\007\\t\\t\\010\\n\\014\\024\\r\\014\\013\\013\\014\\031\\022\\023\\017\\024\\035\\032\\037\\036\\035\\032\\034\\034 $.\\\' \\",#\\034\\034(7),01444\\037\\\'9=82<.342\\377\\333\\000C\\001\\t\\t\\t\\014\\013\\014\\030\\r\\r\\0302!\\034!22222222222222222222222222222222222222222222222222\\377\\300\\000\\021\\010\\000\\373\\000\\267\\003\\001\\"\\000\\002\\021\\001\\003\\021\\001\\377\\304\\000\\037\\000\\000\\001\\005\\001\\001\\001\\001\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\001\\002\\003\\004\\005\\006\\007\\010\\t\\n\\013\\377\\304\\000\\265\\020\\000\\002\\001\\003\\003\\002\\004\\003\\005\\005\\004\\004\\000\\000\\001}\\001\\002\\003\\000\\004\\021\\005\\022!1A\\006\\023Qa\\007\\"q\\0242\\201\\221\\241\\010#B\\261\\301\\025R\\321\\360$3br\\202\\t\\n\\026\\027\\030\\031\\032%&\\\'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\203\\204\\205\\206\\207\\210\\211\\212\\222\\223\\224\\225\\226\\227\\230\\231\\232\\242\\243\\244\\245\\246\\247\\250\\251\\252\\262\\263\\264\\265\\266\\267\\270\\271\\272\\302\\303\\304\\305\\306\\307\\310\\311\\312\\322\\323\\324\\325\\326\\327\\330\\331\\332\\341\\342\\343\\344\\345\\346\\347\\350\\351\\352\\361\\362\\363\\364\\365\\366\\367\\370\\371\\372\\377\\304\\000\\037\\001\\000\\003\\001\\001\\001\\001\\001\\001\\001\\001\\001\\000\\000\\000\\000\\000\\000\\001\\002\\003\\004\\005\\006\\007\\010\\t\\n\\013\\377\\304\\000\\265\\021\\000\\002\\001\\002\\004\\004\\003\\004\\007\\005\\004\\004\\000\\001\\002w\\000\\001\\002\\003\\021\\004\\005!1\\006\\022AQ\\007aq\\023\\"2\\201\\010\\024B\\221\\241\\261\\301\\t#3R\\360\\025br\\321\\n\\026$4\\341%\\361\\027\\030\\031\\032&\\\'()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\202\\203\\204\\205\\206\\207\\210\\211\\212\\222\\223\\224\\225\\226\\227\\230\\231\\232\\242\\243\\244\\245\\246\\247\\250\\251\\252\\262\\263\\264\\265\\266\\267\\270\\271\\272\\302\\303\\304\\305\\306\\307\\310\\311\\312\\322\\323\\324\\325\\326\\327\\330\\331\\332\\342\\343\\344\\345\\346\\347\\350\\351\\352\\362\\363\\364\\365\\366\\367\\370\\371\\372\\377\\332\\000\\014\\003\\001\\000\\002\\021\\003\\021\\000?\\000\\267\\343\\235r\\342\\037\\t\\333E\\013\\235\\363I\\2169\\030Q\\237\\347\\\\\\265\\215\\203jSGi\\031;\\374\\244s\\307^I\\374\\263Z^(\\267i\\264\\235.$\\004\\262\\242\\310A\\350s\\237\\360\\244\\360\\254e\\365\\213F3}\\236\\342%\\302\\223\\321\\306\\343\\3764\\001\\351\\332T\\253\\035\\252Z_),\\000\\344\\216\\234W-\\343\\035\\021\\217\\225%\\244\\212\\033\\177,8;{\\217\\344kw\\\\\\274\\362\\356\\360\\315\\203\\264d\\017\\245ajz\\221\\273\\323\\221\\320\\375\\322:\\367\\355@\\036s\\250xZ\\005i\\245\\211\\260\\n\\347\\216\\233\\272g\\333>\\225\\227\\006\\200\\310\\025\\267\\t\\037~\\000\\000\\355\\353\\324\\237\\351]\\253\\022f6\\345\\306\\030\\202\\247\\361\\310\\255\\333-\\r\\036\\305rw\\004l\\341G\\271\\377\\000\\032\\000\\363m?\\303\\327S\\3523\\302\\301v\\344\\202q\\216\\343\\374kN\\037\\006;\\224\\215\\260VF\\034\\036\\307\\034\\327\\253\\330\\370~<\\264\\221\\242\\251f\\335\\300\\357\\232\\261.\\206\\360\\344\\214\\026 \\250\\366\\316y\\240\\016\\"\\307B\\032\\177\\237:\\"\\220cs\\273\\035\\277\\310\\247Ec$\\020:\\020\\024\\2220\\007\\030\\256\\272{IJ\\371J\\277\\"\\205\\014{\\340\\036\\237\\245U\\276fX\\302\\210\\301y\\216\\336?\\204\\347\\257\\363\\240\\014\\030\\356e\\265\\272DV\\312\\217\\223\\036\\265\\\'\\372F\\307|1\\031\\013\\237\\344+F\\332\\311d\\236Id\\371QO\\310H\\357\\334\\377\\000:\\275\\025\\210r&e;\\006B(\\356Oz\\000\\347\\247\\232D\\266\\\\\\256\\013\\026\\177\\256zT6o<\\022<\\216>|\\371\\216\\007n0\\005uR\\351RN\\342F^\\177\\204zS\\323\\303\\341U\\211o\\235\\310$\\216\\302\\2009i/\\356\\r\\350\\220\\234mR\\t=NNO\\341\\305Nu\\2276R+g\\356\\005\\006\\266\\245\\360\\366\\340W\\037/Oz\\241q\\243,\\205c\\013\\373\\265\\345\\273~\\024\\001\\315\\245\\334\\205\\240NA\\003%\\207\\247\\245hG\\256I#\\3033\\266\\317(\\025\\367=\\305O>\\230\\322\\254\\202%\\332\\25200?J\\306\\271\\323\\347\\267u.\\273Q\\017\\034\\346\\200:\\353\\rN;\\253\\313\\270\\311\\300h9\\317J\\3263\\304\\342&\\016\\016r\\016\\017\\260\\2578\\266\\2756\\333\\211\\353\\214u\\353\\351Zv\\032\\226\\350\\330<\\234\\242\\234z\\002h\\003\\244\\273\\324\\0323\\264\\267\\312\\t\\340\\037j~\\241j\\232\\305\\206\\340\\271\\223\\030$\\236\\325\\312_j\\r$\\214K\\3416\\200=\\316k_N\\325\\231-d\\001\\263\\200[\\035\\370\\240\\016CP\\265kk\\247\\211\\307*v\\321Z\\272\\233\\303\\177p\\262\\2467\\225\\303\\003\\353E\\000u\\257\\341\\370u\\037\\rXN\\337,\\221B\\252\\304}3\\237\\314\\326\\236\\211\\242i\\255hM\\324)\\347!\\311n\\230\\367\\025\\223\\341\\335Y\\227G\\212)C\\035\\243\\033\\010\\350*\\245\\376\\245${\\326#\\264\\\'\\336\\301\\352(\\003/\\304\\372\\203C\\2513#\\356D\\316\\016y=\\205gAr\\346\\312x\\316?\\325\\356\\307\\247z\\212X^\\372\\340H\\352|\\265\\301,\\303\\001\\217`*\\255\\373\\0338\\2340\\313\\310v\\214~\\202\\200\\036\\203\\315\\273\\261d\\\\\\310X\\222\\276\\243\\322\\275kD\\264\\217\\354\\352\\0356\\260\\025\\346>\\036\\322\\346\\325<Ug\\032\\037\\335Y\\307\\346JG|\\364\\025\\354\\321F\\021@\\034z\\320\\004\\211\\032F\\273Tq\\232qU#\\007\\030\\244\\343<\\322|\\304\\216(\\001\\277g\\214\\251\\033G=j\\205\\336\\233\\033+2\\24785\\250\\240\\016i~\\\\r3@\\0306Z:\\340\\263\\216;\\003\\332\\265\\026\\326%P6\\214\\212\\263\\200\\017#\\360\\246\\266Nx\\240\\010X/L\\016;Ty\\300\\341A\\\'\\323\\245Y\\362\\301\\031\\301\\246\\371aE\\000SeG\\0075Vh\\"+\\200:v\\305h\\262\\214\\236*\\273 \\310\\376T\\001\\2155\\266\\341\\205L`\\366\\025\\205\\253X\\374\\247 \\202Eu\\323\\241*~`3\\336\\262.\\255\\325\\211\\016\\t\\343\\363\\240\\017>\\273\\260*\\300\\356\\3713\\220j \\202+g;\\260O\\312:\\364\\356k\\256\\222\\3364gP\\204\\203\\323w\\364\\254k\\210\\222&`\\352\\014x\\310R?\\255\\000b\\223\\373\\264g\\371\\202\\345\\261\\370\\325h\\365S\\000wn\\025br\\336\\331\\007\\217\\326\\254\\336L\\233\\260\\321\\252\\2560\\025{\\366\\305s\\372\\204M\\345\\262\\026t\\36306u\\300\\240\\013\\376\\036\\327\\343.^\\3458\\031\\000\\217\\322\\212\\311\\264\\267`\\256\\233F\\305\\352\\336\\2474P\\007\\277\\315e\\021\\214In\\361\\355\\003<\\014\\223X3\\350\\357p\\314\\315\\014\\222\\023\\317M\\240Um\\007Y\\221\\003yw,\\253\\350Fq\\3765\\253<wW\\270\\377\\000\\211\\204\\254\\247\\000\\202\\330^~\\224\\001\\314jWv\\372_\\311\\2729$\\350\\261\\203\\234\\037\\177LV\\034v\\363\\334\\317&\\243x\\017\\244Jz\\022z`Wc\\250h\\232.\\222\\206\\346\\376\\345e\\003\\222\\250r\\307\\330zVW\\205\\235\\274W\\2565\\371\\203\\311\\322l\\330\\210#\\376\\373z\\232\\000\\355<!\\242\\r#IS(\\037j\\233\\347\\224\\217~\\337\\205t\\200\\214\\340\\032\\256\\216U@\\343\\350*T9 c\\221@\\023\\237\\347M\\030\\335\\326\\202s\\212\\\\\\216\\224\\000\\345\\037\\205(\\004\\365\\241A\\3174\\376\\270\\240\\010\\302\\363\\311\\240\\376\\224\\363\\223\\326\\230\\001\\351\\332\\200\\024\\023A\\300\\240\\374\\275)\\t\\343\\332\\200\\030\\300c\\007\\255U\\220\\000j\\314\\215\\305T\\231\\266\\343\\034\\212\\000\\206^\\325R]\\205J\\262\\3765;\\261\\301\\006\\253JKpzP\\006\\035\\364,\\23709\\003\\277z\\240cYa\\"E\\030c\\234\\343\\245l\\314NJ\\2209\\252\\022\\241\\213\\250\\001\\033\\217\\245\\000sZ\\215\\202\\014\\200\\210\\007P\\007J\\345u\\013;\\250\\013\\375\\235\\304\\201\\316Hn\\253]\\305\\3623\\206\\034nO\\302\\271K\\331\\266F\\305\\230\\206\\355\\333\\360\\240\\014(%h\\243dh\\360\\304\\374\\300\\234QD\\227K.\\010\\3032\\365\\337E\\000oCt-\\333z\\034\\251\\3523Zp\\353~J\\022\\315\\2663\\334\\265r3j0\\305\\302\\262\\273\\001\\323\\251\\025\\231s\\252\\\\J\\305Ps\\330\\365\\305\\000t\\272\\275\\343k\\027\\221XB\\371y\\231Q\\025[$\\347\\2515\\354\\332.\\231o\\243i\\026\\266P(\\013\\032\\000}\\317rk\\310\\276\\030i?i\\325\\337Q\\234\\026\\021ga=Kz\\327\\262+\\226l\\364\\240\\013\\3611\\351\\351V\\324n\\301\\025\\235\\021\\310\\034\\326\\204O\\362\\216E\\000J\\026\\225z\\364\\244\\335\\307\\024\\354c\\221@\\013\\234\\323\\263\\232`<\\360)w{P\\002\\367\\034Q\\317^\\242\\202h\\317\\313@\\r9\\357HN3\\315) \\212\\211\\330\\347\\212\\000l\\234\\367\\346\\251J\\333z\\232\\264\\315\\200j\\235\\307Pq@\\025d`:\\032\\205\\232\\245\\224t8\\346\\241 \\234\\373\\320\\0059\\2241\\306MF\\310\\n\\225\\353\\237Z\\236^\\270\\3075\\024\\2146\\373\\032\\000\\311\\274\\2044{\\270\\035\\363\\374\\253\\216\\324\\204n\\\\\\224\\034\\251\\312\\221\\320\\327es4e\\nd\\025c\\264z\\203\\\\\\027\\210&{y\\231\\362IS\\363/\\257\\257\\351@\\034\\325\\355\\273\\t\\314\\260\\253\\025=\\207Ph\\246=\\314\\236yh\\231\\260\\334\\2145\\024\\000\\267\\260\\375\\214\\006p7\\036p:/\\370\\232\\312\\336\\323L\\002\\214\\0268\\000Qqy-\\323\\226\\221\\263\\316y\\251\\264\\225\\337\\252\\332\\217\\372h(\\003\\334\\274\\\'g\\016\\223\\241\\304\\230U\\302\\006v?\\255A7\\304M\\"\\033\\267\\201\\030\\220\\274o\\317\\004\\373W5\\250__j\\302=\\023M\\334A\\000\\\\88\\037\\356\\347\\371\\325\\330\\276\\027D\\360|\\316\\212\\344`\\220I\\240\\r1\\361KJV+\\363px\\000WI\\243\\370\\327L\\324\\231B\\316\\253\\273\\200\\254y5\\347\\223|4\\236\\021\\225\\270\\214c\\257\\313\\367\\253<\\370v\\357O\\271R\\244\\200\\2479\\006\\200=\\372;\\204\\221@G\\006\\245\\317C\\232\\363\\037\\013\\353\\363DV\\031\\3130^2s^\\203oy\\034\\3439\\340\\320\\005\\360h,\\000\\357P\\211\\007c\\305<\\236\\347\\232\\000p;\\273\\364\\2449\\307\\007\\245B\\322\\0055\\237\\250\\352\\253gn\\354\\010\\335\\320s@\\027\\345\\270H\\207\\316\\352\\276\\344\\342\\262o|I\\247\\331g\\316\\270E\\300\\317Z\\363m{_\\276\\232\\340\\204i\\030\\366\\332+\\232\\223G\\325\\365I\\204\\263\\006,\\307\\030c\\322\\200=B\\357\\342>\\215\\006vLd#\\262\\214\\326L\\337\\023\\364\\361!-\\033l\\355\\201\\315qi\\360\\373Q.\\t%\\201\\351\\216\\200\\326\\245\\207\\3039\\311\\3374\\215\\274t\\\'\\374(\\003\\252\\265\\361\\356\\215r\\312\\257r\\020\\236\\306\\272\\010\\256\\241\\236!,,\\035\\010\\340\\203^e}\\340\\023\\n\\223\\261\\213\\003\\367\\223\\255g\\332j\\272\\267\\206.>m\\363Z\\217\\225\\220\\366\\240\\017T\\270\\234\\003\\3375FK\\236\\240`Vu\\236\\265o\\252\\331\\245\\315\\273eXr;\\203U.\\3570\\335(\\000\\325.\\214E\\231c\\335\\225\\344\\017\\342\\025\\304\\370\\222\\364I\\n4l_\\003\\031\\376\\360\\367\\367\\025\\257{~\\300\\375\\354\\257S\\354k\\216\\326.\\243\\226]\\3216\\033\\270\\316CP\\006ls\\274O\\224\\3069\\371H\\310\\037\\235\\025\\017\\037\\375j(\\002\\032\\273\\246\\022\\267\\321\\262\\214\\260\\316\\337\\256*\\216kOB]\\372\\274\\003\\031\\031\\311\\372b\\200=\\223\\302\\332|\\032}\\212\\310\\374\\312\\377\\00037\\326\\272t\\272\\007\\201^r\\372\\371\\203dQ\\236\\247\\004\\3243\\370\\345-\\031QX7\\030f\\\'\\200\\177\\n\\000\\365 \\206\\3410z\\223Yz\\226\\215&\\326oQ\\315y\\342\\374C\\215o\\221\\336y\\314D\\r\\376_\\312\\007\\323\\275Y\\377\\000\\204\\372\\322\\346\\351\\201\\270\\274\\2113\\362\\026\\223\\250\\307\\241\\343\\326\\200.Ne\\261\\270\\310\\007\\000\\372WC\\242k\\245\\230)=;\\023X\\021_C\\254ea\\270[\\206\\003$\\343k/\\324w\\250|\\251-&\\334\\231\\340\\363\\305\\000z\\315\\235\\302\\314\\231\\004sW\\310!s\\236\\265\\315\\370js4+\\237\\316\\272Y~X\\375q@\\031\\327s\\210\\262A\\351\\\\\\236\\2538\\234\\341\\316@<\\001[Z\\224\\340\\006$\\376\\025\\306\\335\\\\\\031f(9\\240\\002\\025\\217\\314\\312\\307\\320\\365\\002\\266-\\"g#\\344\\343\\351Y\\261\\315\\r\\244`\\277\\007\\323\\031\\346\\2337\\211\\\'\\264\\031\\021C\\002u\\335p\\370\\375\\005\\000v\\020)E\\031^\\235\\252S0\\0305\\300\\311\\343k\\225\\212I~\\323dc\\214)%Q\\261\\317\\276j\\025\\361\\344>c+\\354r:\\264\\017\\237\\320\\320\\007\\241<\\210\\337\\210\\357Xz\\266\\231k{\\023#D\\231n\\370\\254\\253/\\024[_\\251he\\014\\243\\257\\265^\\376\\322\\216U\\371\\\\\\037\\306\\200<\\372\\346\\326_\\njd\\306\\316\\326\\222\\237\\233\\330\\325\\313\\213\\360\\321\\356V\\030<\\203Z\\372\\3641_\\332\\272\\267$\\202\\001\\035Eq\\0214\\220\\333\\233yO*p>\\224\\001WV\\272|\\374\\2140G\\"\\260\\035\\211bOS[\\2271\\006L\\267^\\325\\227<\\014\\024\\222=\\350\\002\\256h\\244\\242\\200\\021\\3431\\271Rs\\203[\\036\\031\\266\\226\\343Qo$\\002\\352\\204\\200{\\326k\\220\\343\\236\\243\\371Wc\\360\\336\\317\\355\\032\\274\\255\\214\\205Q@\\030\\372\\325\\304\\221H\\312\\021\\342byF\\0042\\236\\377\\000\\205c[[Kw:\\306\\210\\356I\\347h\\316\\005{\\256\\271\\243G\\251D\\366\\361X\\2031\\340J\\313\\362\\250\\365\\367\\247h^\\031]\\n\\315a\\206$bG\\317&\\316X\\320\\007\\221\\352>\\026\\274Ia6v\\256\\321\\310\\240\\000:\\206\\367\\253#\\300^\\"\\220+\\0356vR\\200)\\310\\340\\373\\347\\265{\\2641o\\330\\246\\331>NG\\313\\322\\264\\225.\\\'M\\245B\\363\\351@\\036Q\\\'\\201\\256t\\333{y\\364\\206\\232;\\270\\243\\006A\\267\\211\\030\\016\\303\\353]u\\235\\215\\305\\377\\000\\207\\342\\270\\276\\265\\362/TbU\\365\\367\\256\\276;R\\000\\334rEA\\250\\355\\216\\335\\300<\\343\\237z\\000\\316\\360\\314%\\006\\010\\357[\\367\\317\\262,\\017\\312\\251hv\\306(A\\365\\251\\2657\\371v\\320\\007+\\252\\273\\2630N\\265\\026\\217\\240\\033\\200\\322\\271\\307\\275Z\\232\\"\\362\\217C[\\272>\\321j` \\014\\346\\200<\\307\\304~$\\264\\323\\356Z\\316\\3126\\236\\355N\\001U\\310\\007\\353Qi\\337\\017\\365\\rv\\321\\365\\rN\\354\\215\\310\\305`L\\023\\234w&\\2756m\\006\\331\\030\\225\\265\\2079\\316\\340\\2035\\037\\331!R\\240\\240M\\277\\335\\342\\200>b!\\343\\027\\021\\3102W\\013\\206r\\n\\220};\\324R,\\221\\025\\334@\\334\\241\\206\\030\\036?\\n\\367\\253\\337\\006\\350W\\006`\\360\\306\\246^X\\205\\347>\\271\\256~\\177\\207\\332Kp\\234v8\\034\\375E\\000yu\\246\\253sf\\341\\342|0\\353\\236\\343\\320\\372\\327M\\242j\\315\\3441yX\\314\\355\\300=\\251u_\\207w\\360>\\3759^\\342>\\352F\\030\\177\\215Y\\321|7u\\001\\204\\311l\\353:\\311\\226\\363T\\200\\007\\265\\000t\\221\\244\\262\\333\\006*@\\"\\261.\\264\\360\\362\\226a\\217J\\364[]9V\\313.0q\\323\\025\\313\\353H\\250\\330\\000~\\024\\001\\305\\337\\300\\253\\036\\007P;U\\033\\273\\177*\\325$P\\013\\021\\223\\315j\\335:\\253\\355+\\222GAP\\334\\306\\222\\330\\034G\\363\\001\\307l\\320\\007\\"\\337x\\343\\326\\212V]\\254G\\241\\242\\200-\\317lcp\\303\\247Z\\364/\\205\\360\\005\\202\\346~\\357&\\321\\370\\n\\345\\257\\341X,\\313u%\\000\\317\\340k\\264\\370s\\031]\\0266\\035Y\\330\\376\\264\\001\\352\\326I\\033\\"\\356\\\\\\326\\232B\\244}\\321\\212\\315\\323\\301\\"\\266c\\031Z\\000\\214B\\243\\242\\216)J\\201V6\\344}*\\\'\\024\\001\\004\\207\\007\\247\\025\\203\\251\\312e\\224F\\243\\2775\\265t\\352\\220\\261$\\014\\016\\365\\207`\\246\\362\\351\\244# \\036(\\003r\\301Dv\\312=\\253;R\\220\\031\\017?\\205l\\010\\202F@\\364\\256gTvF>\\335(\\002\\263\\221\\346\\n\\323\\323\\376\\367N\\225\\315\\303xL\\300\\036y\\256\\237Le\\220\\016}\\350\\003]\\016\\341\\206\\024\\311-\\243q\\310\\372\\324\\301G\\245!\\\\s\\322\\2003\\246\\322\\255\\344\\004\\355\\025\\007\\366T\\013\\320sZ\\215\\320\\217J\\201\\370$\\320\\005Qf\\240\\0001\\365\\025\\024\\220\\242\\222@\\031\\251\\236}\\247\\031\\342\\250\\334\\335\\016I4\\001R\\376\\\\!\\031\\256\\023\\\\\\224e\\210\\346\\272}F\\360mc\\234`W\\237\\353w\\237+\\022\\324\\001\\211wq\\275\\213\\203\\323\\201\\212#\\235\\232\\035\\256\\273\\243+\\216:\\203Y\\023^\\035\\344g\\275Y\\264\\272\\362\\340U\\007\\234\\367\\035\\215\\000d\\\\\\200\\263\\270\\034\\340\\365\\365\\242\\226g\\01736\\321\\317j(\\003\\245\\361S\\254@F\\270\\034\\355\\037\\205v\\377\\000\\017v\\215\\026\\330\\036\\371?\\255y\\217\\210u\\024\\3245F1g\\312O\\225k\\321|\\007(\\032]\\262\\347\\267\\365\\240\\017]\\261\\n\\020`\\365\\255T\\340qXZl\\243n3\\316+\\\\J\\252\\271\\310\\034P\\005\\226uQ\\232\\315\\272\\324b\\213?0\\252\\367\\332\\200\\211\\033\\006\\261\\326\\316]E\\332G,\\023\\327\\326\\200\\027R\\325\\267\\302\\334\\341O\\025\\241\\240<-\\000!\\201\\317J\\362?\\031x\\212\\347A\\277\\223L(X\\201\\271\\030\\367\\006\\261t\\177\\210\\02762r\\314\\253\\237\\273\\234\\212\\000\\372VFA\\021\\344t\\2567[\\275\\267B\\353\\271Kt\\034\\327\\233]|S\\236H\\331\\025\\233$W%?\\214\\257f\\234\\310\\006\\356{\\232\\000\\365\\253u\\337.\\345\\025\\245m\\177\\366\\031\\201f\\342\\274\\237O\\361\\375\\305\\263\\001u\\006\\007\\250\\251\\365?\\034\\244\\361\\376\\340\\222O@(\\003\\336\\255\\265(\\247EepA\\025m$\\017\\320\\365\\257*\\360,\\272\\245\\376\\223\\366\\211I\\306\\357\\222\\272\\3305)\\355\\247\\362\\347R\\255\\333=\\350\\003\\253\\000\\021\\322\\252\\316\\241G\\2756\\332\\365fQ\\315\\023>T\\232\\000\\312\\271b\\271\\037\\344V\\035\\355\\307\\004V\\305\\353\\360Oz\\346\\257\\245\\000\\034\\342\\2002\\365+\\203\\214g\\250\\346\\270\\035n\\34030\\311\\300\\342\\272\\235Fs\\222Mp\\272\\264\\305\\230\\364\\240\\014\\263\\206#\\236\\264\\371\\\'\\371\\021A\\035\\016\\177:\\257\\223\\270\\232N\\364\\000\\346b\\3074U\\324\\261\\337\\246\\265\\321b\\010`\\000\\366\\242\\2003s\\236k\\321\\374\\027u\\215:\\334\\017\\341%O\\347^l+\\263\\360d\\245\\240\\226<\\375\\307\\007\\363\\377\\000\\365P\\007\\263\\351\\227\\300\\250\\311\\347\\025\\2515\\360Hr\\307\\363\\256KJ\\\'+\\357\\355[\\363\\333\\264\\266\\307\\035\\372\\032\\000\\316I\\344\\325u/%[\\367hr\\344\\036\\202\\272\\370\\212E\\010\\2165\\300\\003\\025\\205\\244\\330\\303\\246\\332\\223\\307\\230\\347s1\\352i\\367\\376\\"\\323\\264\\250\\032k\\313\\230\\341A\\375\\343\\311\\372P\\006W\\213\\374\\re\\342\\242\\222\\311#Cr\\203\\013*\\214\\361\\350}\\253\\313\\265\\317\\205\\332\\276\\225\\033On\\313w\\010\\376\\340\\303~U\\334\\\\\\374Z\\322\\225\\312[@\\362\\217\\357\\023\\2675=\\277\\304\\313I\\206^\\317\\344\\030\\316$\\024\\001\\343\\013\\246\\310\\271\\016\\245[\\241\\004r*h4\\271$\\177.$gs\\306\\024W\\264\\333\\352\\036\\016\\327\\245\\222Y\\255B\\314\\243s\\356^\\337\\205[\\267\\324\\274#\\246e\\255\\243Tb:\\210\\215\\000y}\\217\\303-f\\370y\\222\\005\\204\\036@s\\315ni\\337\\010\\245\\022\\253^^\\250\\214\\036V1\\311\\374\\353\\273\\377\\000\\204\\317CB\\000\\271\\333\\236r\\312kB\\327]\\323\\257\\0245\\275\\334NO`\\324\\001kK\\323\\340\\323l\\243\\265\\201\\002\\307\\030\\332\\242\\233\\252\\332\\307sl@\\0370\\345H\\353\\232\\177\\332\\224\\216\\032\\221\\245\\004u\\3104\\001\\211\\246\\337\\024c\\013\\237\\231N+`\\335\\202\\235A\\025\\316k6\\257mp\\267p)\\3018p)\\022\\361\\232.N\\r\\000]\\275\\272R\\017\\"\\271\\235J}\\303\\nFMK}t\\352\\016\\017\\342k\\032y\\031\\311$\\376T\\001\\233\\250\\022P\\201\\311\\355\\\\\\215\\362\\206\\007 dWYp\\254\\3753\\317j\\300\\324!\\332\\033\\201\\232\\000\\347[\\216)\\326\\320\\233\\211\\2261\\336\\222p\\025\\310\\024\\266\\263<\\022\\356NX\\214P\\007k\\243h\\277\\333Z\\315\\266\\211\\027\\372\\250\\3432\\316\\376\\234p?2(\\257@\\360\\026\\223\\026\\221\\2424\\316\\237\\351\\267{d\\225\\317Q\\334/\\345E\\000|\\376+\\245\\360e\\307\\225\\252I\\021<H\\237\\310\\3277\\232\\275\\244\\334\\375\\223T\\267\\233\\260p\\017\\320\\361@\\036\\353\\244\\220\\0311\\322\\273\\033xL\\221\\006\\035\\205q:K\\215\\250A\\353\\214W\\240iN\\257\\006\\334\\320\\0075\\254\\255\\3540H\\360F\\317\\267\\\'\\002\\276~\\361\\006\\257w\\253jr\\275\\303\\266\\325b\\252\\204\\375\\332\\372\\314\\304\\204\\036\\0075\\341\\337\\025<\\024\\260j\\203T\\323\\321Q\\\'\\037\\274\\214\\014\\r\\343\\277\\343@\\036qa\\241jZ\\225\\264\\327\\026\\226\\317$P\\214\\273\\016\\325\\320\\332|;\\361d\\206\\333\\313\\262u\\027+\\2712\\334c\\336\\272\\277\\205\\336#\\322\\364\\233;\\273MJx\\241/\\367\\226R\\007\\267z\\367\\013;\\273;\\264\\215\\255\\246\\212@\\027\\215\\214\\016\\007\\341@\\0374\\334x_\\304\\332\\r\\303%\\314\\027QH\\352q\\345|\\312\\376\\325V\\347\\303\\236/\\020\\255\\324\\232}\\312\\240\\030\\017\\267\\025\\365-\\305\\274S\\264~b\\253ml\\214\\323o\\0266\\265ulm\\307~\\224\\001\\362E\\325\\226\\275m\\t\\236\\342\\033\\225\\210pX\\216*\\240\\237R\\211D\\352fE^7\\250 \\017\\306\\276\\252\\327\\364\\353I\\364\\031\\255\\345\\2161\\031\\\\\\034\\201^{\\343\\213]#M\\360\\352i\\266\\220\\242\\3119X\\325\\207\\\\\\236\\246\\200<\\313K\\361\\366\\271\\247:\\206\\2717\\021\\016\\251\\\'\\247\\326\\275\\007E\\370\\211c\\250\\354\\216F0Jx*\\347\\277\\265y\\336\\263\\243Z\\330\\334\\332[\\2271\\202\\205\\234\\236\\244V~\\213\\241j\\032\\356\\244\\266\\332l.\\355\\273\\357\\364\\010=I\\240\\017\\240\\215\\3547P|\\254\\034\\021\\326\\251Kdb^\\001\\372\\325\\275\\037\\303?\\3316\\021D\\363\\031\\245\\n\\003\\261=O\\255^\\272\\211v\\355\\316q@\\034u\\364d\\251\\025\\232-\\t\\346\\272;\\270\\027q\\307j\\242\\361\\355R1@\\030\\023\\306\\0279\\256oU\\306\\327\\302\\223\\306q\\351]E\\351\\332H5\\305\\353W\\030,\\007Lc\\212\\000\\347\\347?\\274<\\346\\257\\370v\\320_k\\326\\220\\2666\\264\\203v};\\326[\\034\\234\\326\\327\\205\\031\\223^\\205\\301\\373\\240\\237\\322\\200=\\252\\363S\\216\\336U\\265\\214\\025M\\240\\223\\236\\364W%\\254\\335\\307\\r\\314/+\\223\\373\\275\\334t\\311\\242\\200<\\216\\224\\034RQ@\\036\\271\\340\\335T^\\351\\321\\2536dN\\010\\372W\\247\\350\\327\\253\\201\\333\\327\\025\\363\\237\\205\\365f\\323\\265\\025R\\330\\216N\\277Z\\366}\\022\\377\\000s#\\003\\303s@\\036\\220\\256\\031{r+\\220\\361\\325\\217\\333\\264Y\\325rdE.\\200z\\212\\350\\255&\\337\\030\\365\\252\\272\\242\\357\\211\\201\\031\\355@\\0372H\\366WW\\031\\2342\\311\\234\\0208\\255\\255;L\\236/\\336\\350\\272\\235\\345\\264\\354061\\371\\275\\270\\253\\3762\\360d\\242\\362K\\35557\\0079x\\307\\\\\\372\\212\\347t\\275GS\\321\\256A\\362\\244F^\\205\\201\\030\\240\\016\\204j\\177\\020t\\373\\230\\330jwnS;|\\307\\3349\\366j\\237P\\327\\274q\\251\\351\\362[_j\\350\\220H0\\352\\252\\001#\\352\\005^\\203\\306\\0272K\\r\\304\\3067eS\\234\\340\\326F\\275\\343\\031o\\025\\221\\2216\\360\\000E\\003\\247\\320P\\006n\\241\\252\\370\\210X\\233\\013\\255vy-\\3602\\214\\304\\344u\\353\\326\\2625\\035F\\366\\365\\340\\373f\\242\\363\\030T\\010\\311\\352\\005K\\366\\035GW`-\\355&r{\\355\\300\\307\\326\\272\\215\\017\\341\\314\\222:\\313\\2521\\307\\374\\363S\\374\\315\\000d\\350\\332E\\357\\212\\365$\\226R\\356\\027\\001\\344\\220q\\201\\330W\\271xoA\\264\\321\\254\\226+h\\202\\223\\367\\237\\034\\261\\252ZF\\223oa\\002G\\014A\\025G\\000\\016\\225\\321\\300\\307!E\\000X\\333\\234\\344t\\254\\333\\250\\302\\263\\036+Wn\\330\\311j\\310\\276\\225y\\307z\\000\\307\\225\\003\\312y\\342\\251^ U8\\0305x\\261\\031=\\253/Q\\272TS\\316O\\265\\000r\\372\\274\\253\\031c\\221\\221^u\\251]\\031\\245+\\236\\225\\324x\\233P*\\215\\317,{W\\022\\314Y\\211=\\350\\001\\246\\265\\264\\t\\326\\336\\361\\244l\\234\\251Q\\217z\\3115n\\300\\220de\\\'r\\000\\343\\352\\r\\000tZ\\315\\324\\227VV\\227\\n\\331\\300(\\331\\365\\242\\253\\3463\\031\\266\\220\\200\\214w\\251\\3169\\357E\\000r\\335h\\242\\2279\\000zP\\002\\202A\\004\\032\\364\\357\\005\\352\\222\\313\\014Ipp\\330\\312\\347\\270\\365\\2570\\357Z\\232V\\2555\\206\\241\\025\\301b@\\300#=\\250\\003\\351\\215.\\340<K\\223Z7\\021\\231a#\\326\\270\\215\\003WK\\210cpr\\010\\007\\212\\354\\255\\256<\\305\\344\\346\\2009\\313\\313&26\\006k\\"\\343D\\023\\022\\036\\020A\\366\\256\\342[q$\\231\\355O\\212\\321\\030\\014\\257\\343@\\036n\\336\\020\\261\\221\\376{Q\\317\\267Z\\277k\\341K\\030@\\333g\\027\\035\\366\\327\\241\\213\\010\\217%\\006}i>\\304\\2128\\035z\\320\\007/\\026\\233\\024*\\004q\\205\\307\\240\\253\\021\\332\\205#\\217\\306\\266\\315\\230\\335\\234S\\205\\242\\343$P\\006zC\\264\\021\\216\\225n\\004\\331\\320sS:\\004\\007\\212\\256\\323\\004\\3474\\000\\373\\231\\210C\\315a\\\\\\266\\362w\\034{\\232\\236\\366\\354\\355!M`\\335\\337\\252d\\356\\372P\\003\\357.B+\\021\\315q\\332\\346\\256\\261+\\020y\\366\\246\\353:\\350\\215\\030\\207\\300\\035\\253\\317\\265-VK\\331[\\007\\3444\\001\\026\\243z\\327\\227,\\354x\\317\\025N\\223\\245\\\'S@\\001\\253\\232`f\\273\\001:\\3438\\317Z\\246MZ\\323]\\322\\365\\nu\\351@\\032m\\021\\273s\\000\\307\\313\\363\\017\\306\\212\\275\\004\\r\\r\\364\\222\\205\\371\\037\\246}h\\240\\016B\\224\\243\\005\\016G\\004\\340SsZ\\006h\\344\\320\\026-\\243\\315\\206\\340\\266{\\225e\\377\\000\\021\\372\\320\\003\\277\\263\\310\\265\\016A\\004&\\366\\374z\\017\\313\\237\\306\\251\\306\\233\\330\\214\\200\\000\\\'&\\264\\236\\355M\\274\\212:\\030\\366\\203\\370\\017\\360\\254\\326p|\\302\\000\\344\\342\\200;\\217\\004kf<\\332H\\374\\251\\371F{W\\255i\\272\\232\\262\\257<\\032\\371\\306\\326yl\\256c\\231r\\247\\257=\\305z6\\221\\342%1\\241\\337\\236\\231\\240\\017d\\216\\355_\\201Z08\\003\\232\\363\\213=}p\\016\\377\\000\\326\\267m\\365\\356\\203w\\353@\\035\\242\\277Jv29\\256Z=pn\\004\\2605|k\\211\\264|\\302\\2005\\330\\016\\375\\2151\\346D\\007\\245bM\\256 \\\'\\347\\030\\254\\373\\215uUX\\226\\037\\215\\000l\\\\\\336\\204\\r\\310\\305b]j+\\264\\220\\337\\255s\\227\\376!BH\\337\\\\\\346\\241\\342%\\215Nd\\343\\0353@\\0355\\376\\250\\250\\255\\363r}\\372\\327\\025\\254x\\201c\\334<\\317\\326\\260\\265\\037\\022\\274\\233\\2226\\3115\\316K$\\263\\266\\347\\311\\240\\0137\\332\\203\\335\\310r\\307mT\\003\\214\\346\\236\\210;\\216i\\316\\000\\007\\024\\001\\r\\024\\231\\245\\024\\000\\204\\325\\213\\031\\204\\027q\\310T\\020\\017qU\\315[\\261\\212Gf\\"=\\351\\2140\\316(\\003\\253k\\241k:\\272\\223\\345\\3122\\271\\301\\000\\372QX\\261\\316m\\024Gp\\331\\210\\363\\033u\\307\\261\\242\\2009\\354\\322\\251 \\020\\016\\001\\340\\321\\212\\231,\\356d\\031H$a\\354\\246\\200\\"9S\\212\\003e\\271\\351\\232\\234[J\\3213\\224#a\\332s\\353H\\266\\2638\\312!a\\3543@\\014\\232f\\232M\\314z\\000\\007\\260\\253\\026\\327OnA\\004\\200j\\365\\247\\206\\257n`i\\014l\\230\\344\\002:\\325\\033\\253I-d1\\310\\2440\\365\\240\\016\\202\\327Y\\221\\025K7\\312z\\232\\334\\265\\327N\\321\\206 W\\007\\003\\272\\020\\001\\343\\371\\326\\305\\263\\0020T\\202{\\251\\240\\016\\3115\\351U\\211/\\322\\244\\036\\"v\\377\\000\\226\\2035\\310\\0377\\202\\254\\307\\352*2.2:\\343\\324\\320\\007b\\376 \\220\\003\\227\\254\\273\\317\\021q\\203&\\177\\032\\347\\245Y\\316>r\\rW6N\\355\\363\\261\\317\\326\\200-]\\353\\354\\344\\204\\344\\326\\\\\\255ux\\3376pj\\362X\\242\\002B\\375j\\302\\306\\241@\\003\\247S@\\031\\261X\\004\\033\\237\\222(h\\325[\\247\\036\\225\\240\\370\\031\\007\\223Te<\\344\\363\\217z\\000\\211\\276^\\265ZF\\353\\374\\252G\\221\\216y5]\\271&\\200\\033J))h\\000\\247\\3073\\307\\235\\214@\\356=i\\206\\222\\2004\\"\\324\\314h\\020\\304\\254\\203\\370I\\310\\242\\263\\350\\240\\017y\\321\\376\\033\\350\\332n\\014\\361y\\362c\\253t\\256\\217\\376\\021\\335?f\\324\\201\\000\\372U\\370\\376\\351\\2531\\216\\007\\322\\200<\\263\\304\\336\\010\\363\\\'qk\\204I>\\366\\007\\353\\365\\251t\\237\\r\\332\\331\\230\\266\\303\\227\\214`q^\\207x\\212I\\310\\025V\\030\\243\\005\\210A\\232\\000\\307M8ua\\222{b\\270\\317\\032\\370dKm\\366\\270\\023\\014\\234\\266\\007Q^\\240\\31288\\355Yz\\252+\\332\\312\\030\\002\\n\\320\\007\\201G\\010\\316;\\326\\235\\254d\\036\\237\\235Gv\\252\\232\\224\\310\\243\\n\\034\\360*\\344\\003\\030\\305\\000ZX\\307\\007oZR\\213\\323\\212U<\\023A\\352h\\002\\002\\243\\323\\212\\0361\\216;\\366\\024\\366\\357H\\334\\n\\000\\210\\306v\\001\\330\\324\\022\\355^\\230\\253c\\221\\315U\\237\\225\\003\\265\\000R\\235\\200\\310\\007\\267Z\\250\\303 zU\\211G\\312\\247\\275Vj\\000\\202C\\200x\\252\\335\\352i\\017\\312j\\032\\000\\005\\024\\n;P\\002\\036\\264R\\236\\264P\\001E\\\'\\255\\024\\001\\377\\331"\n          image_info {\n            width: 183\n            height: 251\n            format: "JPEG"\n            color_mode: "UnknownColorMode"\n          }\n        }\n      }\n    }\n  }\n}\noutputs {\n  id: "7ab40bb98cad4133b490d7183095d9b5"\n  status {\n    code: SUCCESS\n    description: "Ok"\n  }\n  created_at {\n    seconds: 1700656970\n    nanos: 361626613\n  }\n  model {\n    id: "face-sentiment-recognition"\n    name: "face-sentiment"\n    created_at {\n      seconds: 1620837542\n      nanos: 718331000\n    }\n    modified_at {\n      seconds: 1652994708\n      nanos: 222496000\n    }\n    app_id: "main"\n    model_version {\n      id: "a5d7776f0c064a41b48c3ce039049f65"\n      created_at {\n        seconds: 1620837542\n        nanos: 812738000\n      }\n      status {\n        code: MODEL_TRAINED\n        description: "Model is trained and ready"\n      }\n      visibility {\n        gettable: PUBLIC\n      }\n      app_id: "main"\n      user_id: "clarifai"\n      metadata {\n      }\n    }\n    user_id: "clarifai"\n    model_type_id: "visual-classifier"\n    visibility {\n      gettable: PUBLIC\n    }\n    workflow_recommended {\n    }\n  }\n  data {\n    regions {\n      id: "6b5ea07bdaec9a8e48ff9424bf1f03b7"\n      region_info {\n        bounding_box {\n          top_row: 0.12857753\n          left_col: 0.261931\n          bottom_row: 0.637144744\n          right_col: 0.786355317\n        }\n      }\n      data {\n        concepts {\n          id: "ai_CrBPDCM6"\n          name: "happiness"\n          value: 0.999999821\n          app_id: "main"\n        }\n        concepts {\n          id: "ai_5fbLSP06"\n          name: "disgust"\n          value: 3.61372668e-006\n          app_id: "main"\n        }\n        concepts {\n          id: "ai_8PZvz0N1"\n          name: "fear"\n          value: 1.39605234e-007\n          app_id: "main"\n        }\n        concepts {\n          id: "ai_KdS5fmgb"\n          name: "sadness-contempt"\n          value: 4.07719938e-008\n          app_id: "main"\n        }\n        concepts {\n          id: "ai_59ZvTKz7"\n          name: "surprise"\n          value: 1.09932232e-008\n          app_id: "main"\n        }\n        concepts {\n          id: "ai_96KLdq72"\n          name: "anger"\n          value: 6.72241196e-009\n          app_id: "main"\n        }\n        concepts {\n          id: "ai_MqGSWdbN"\n          name: "neutral"\n          value: 4.21860102e-009\n          app_id: "main"\n        }\n      }\n    }\n  }\n}',_='######################################################################################################\n# In this section, we set the user authentication, user and app ID, workflow ID, and the text \n# we want as an input. Change these strings to run your own example.\n######################################################################################################\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "clarifai"\nAPP_ID = "main"\n# Change these to make your own predictions\nWORKFLOW_ID = "Language-Understanding"\nRAW_TEXT = "This is a test text for testing"\n# To use a hosted text file, assign the URL variable\n# TEXT_FILE_URL = "https://samples.clarifai.com/negative_sentence_12.txt"\n# Or, to use a local text file, assign the location variable\n# TEXT_FILE_LOCATION = "YOUR_TEXT_FILE_LOCATION_HERE"\n\n############################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n############################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (("authorization", "Key " + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\n# To use a local text file, uncomment the following lines\n# with open(TEXT_FILE_LOCATION, "rb") as f:\n#    file_bytes = f.read()\n\npost_workflow_results_response = stub.PostWorkflowResults(\n    service_pb2.PostWorkflowResultsRequest(\n        user_app_id=userDataObject,\n        workflow_id=WORKFLOW_ID,\n        inputs=[\n            resources_pb2.Input(\n                data=resources_pb2.Data(\n                    text=resources_pb2.Text(\n                        raw=RAW_TEXT\n                        # url=TEXT_FILE_URL\n                        # raw=file_bytes\n                    )\n                )\n            )\n        ],\n    ),\n    metadata=metadata,\n)\nif post_workflow_results_response.status.code != status_code_pb2.SUCCESS:\n    print(post_workflow_results_response.status)\n    raise Exception(\n        "Post workflow results failed, status: "\n        + post_workflow_results_response.status.description\n    )\n\n# We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here one WorkflowResult\nresults = post_workflow_results_response.results[0]\n\n# Each model we have in the workflow will produce one output.\nfor output in results.outputs:\n    model = output.model\n\n    print("Predicted concepts for the model `%s`" % model.id)\n    print(output.data)\n\n# Uncomment this line to print the raw output\n# print(results)\n',m='\x3c!--index.html file--\x3e\n\n<script>\n  ////////////////////////////////////////////////////////////////////////////////////////////////////\n  // In this section, we set the user authentication, user and app ID, workflow ID, and the text \n  // we want as an input. Change these strings to run your own example.\n  ///////////////////////////////////////////////////////////////////////////////////////////////////\n\n  // Your PAT (Personal Access Token) can be found in the Account\'s Security section\n  const PAT = "YOUR_PAT_HERE";\n  const USER_ID = "clarifai";\n  const APP_ID = "main";\n  // Change these to make your own predictions\n  const WORKFLOW_ID = "Language-Understanding";\n  const RAW_TEXT = "This is a test text for testing";\n  // To use a hosted text file, assign the URL variable\n  // const TEXT_FILE_URL = "https://samples.clarifai.com/negative_sentence_12.txt";\n\n  ///////////////////////////////////////////////////////////////////////////////////\n  // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n  /////////////////////////////////////////////////////////////////////////////////// \n\n  const raw = JSON.stringify({\n    "user_app_id": {\n      "user_id": USER_ID,\n      "app_id": APP_ID\n    },\n    "inputs": [\n      {\n        "data": {\n          "text": {\n            "raw": RAW_TEXT\n            // "url": TEXT_FILE_URL\n          }\n        }\n      }\n    ]\n  });\n\n  const requestOptions = {\n    method: "POST",\n    headers: {\n      "Accept": "application/json",\n      "Authorization": "Key " + PAT\n    },\n    body: raw\n  };\n\n  fetch(`https://api.clarifai.com/v2/workflows/${WORKFLOW_ID}/results`, requestOptions)\n    .then(response => response.text())\n    .then(result => console.log(result))\n    .catch(error => console.log("error", error));\n\n<\/script>',w='//index.js file\n\n//////////////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, user and app ID, workflow ID, and the text \n// we want as an input. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////////////////\n\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\nconst PAT = "YOUR_PAT_HERE";\nconst USER_ID = "clarifai";\nconst APP_ID = "main";\n// Change these to make your own predictions\nconst WORKFLOW_ID = "Language-Understanding";\nconst RAW_TEXT = "This is a test text for testing";\n// To use a hosted text file, assign the URL variable\n// const TEXT_FILE_URL = "https://samples.clarifai.com/negative_sentence_12.txt"\n// Or, to use a local text file, assign the location variable\n// TEXT_FILE_LOCATION = "YOUR_TEXT_FILE_LOCATION_HERE"\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\n// To use a local text file, uncomment the following lines\n// const fs = require("fs");\n// const fileBytes = fs.readFileSync(TEXT_FILE_LOCATION);\n\nstub.PostWorkflowResults({\n    user_app_id: {\n        "user_id": USER_ID,\n        "app_id": APP_ID,\n    },\n    workflow_id: WORKFLOW_ID,\n    inputs: [{\n        data: {\n            text: {\n                raw: RAW_TEXT\n                // url: TEXT_FILE_URL,\n                // raw: fileBytes\n            }\n        }\n    }],\n},\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error(\n                "Post workflow results failed, status: " + response.status.description\n            );\n        }\n\n        // We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here \n        // one WorkflowResult\n        const results = response.results[0];\n\n        // Each model we have in the workflow will produce one output.\n        for (const output of results.outputs) {\n            const model = output.model;\n\n            console.log(`Predicted concepts for the model \'${model.id}\'`);\n            console.log(output.data);\n\n        }\n        // Uncomment this line to print the raw output\n        // console.log(results);\n    }\n);',g='package com.clarifai.example;\n\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\n\nimport com.google.protobuf.ByteString;\nimport java.io.File;\nimport java.io.IOException;\nimport java.nio.file.Files;\n\npublic class ClarifaiExample {\n\n    /////////////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, user and app ID, workflow ID, and the text \n    // we want as an input. Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////////////////////////////\n    \n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String USER_ID = "clarifai";\n    static final String APP_ID = "main";\n    // Change these to make your own predictions\n    static final String WORKFLOW_ID = "Language-Understanding";\n    static final String RAW_TEXT = "This is a test text for testing";    \n    // To use a hosted text file, assign the URL variable\n    // static final String TEXT_FILE_URL = "https://samples.clarifai.com/negative_sentence_12.txt";\n    // Or, to use a local text file, assign the location variable\n    // static final String TEXT_FILE_LOCATION = "YOUR_TEXT_FILE_LOCATION_HERE";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n    \n    public static void main(String[] args) throws IOException {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n                .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        PostWorkflowResultsResponse postWorkflowResultsResponse = stub.postWorkflowResults(\n                PostWorkflowResultsRequest.newBuilder()\n                        .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n                        .setWorkflowId(WORKFLOW_ID)\n                        .addInputs(\n                                Input.newBuilder().setData(\n                                        Data.newBuilder().setText(\n                                                Text.newBuilder().setRaw(RAW_TEXT)\n                                                // Text.newBuilder().setUrl(TEXT_FILE_URL)\n                                                // Text.newBuilder().setRawBytes(ByteString.copyFrom(Files.readAllBytes(\n                                                       // new File(TEXT_FILE_LOCATION).toPath()\n                                                //)))\n                                        )\n                                )\n                        )\n                        .build()\n        );\n\n        if (postWorkflowResultsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post workflow results failed, status: " + postWorkflowResultsResponse.getStatus());\n        }\n\n        // We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here\n        // one WorkflowResult\n        WorkflowResult results = postWorkflowResultsResponse.getResults(0);\n\n        // Each model we have in the workflow will produce its output       \n        for (Output output : results.getOutputsList()) {\n            Model model = output.getModel();\n\n            System.out.println("Predicted concepts for the model \'" + model.getId() + "\'");\n            \n            System.out.println(output.getData());\n \n        }\n\n        // Uncomment this line to print the raw output\n        // System.out.println(results);\n    }\n\n}\n',I='curl -X POST "https://api.clarifai.com/v2/users/clarifai/apps/main/workflows/Language-Understanding/results" \\\n  -H "authorization: Key YOUR_PAT_HERE" \\\n  -H "content-type: application/json" \\\n  -d \'{\n    "inputs": [\n        {\n          "data": {\n            "text": {\n              "raw": "This is a test text for testing"\n          }\n        }\n      }\n    ]\n}\'',E='<?php\n\nrequire __DIR__ . "/vendor/autoload.php";\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, user and app ID, workflow ID, and the text \n// we want as an input. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////////////////\n\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\n$PAT = "YOUR_PAT_HERE";\n$USER_ID = "clarifai";\n$APP_ID = "main";\n// Change these to make your own predictions\n$WORKFLOW_ID = "Language-Understanding";\n$RAW_TEXT = "This is a test text for testing";\n// To use a hosted text file, assign the URL variable\n// $TEXT_FILE_URL = "https://samples.clarifai.com/negative_sentence_12.txt";\n// Or, to use a local text file, assign the location variable\n// $TEXT_FILE_LOCATION = "YOUR_TEXT_FILE_LOCATION_HERE";\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nuse Clarifai\\ClarifaiClient;\nuse Clarifai\\Api\\Data;\nuse Clarifai\\Api\\Text;\nuse Clarifai\\Api\\Input;\nuse Clarifai\\Api\\PostWorkflowResultsRequest;\nuse Clarifai\\Api\\Status\\StatusCode;\nuse Clarifai\\Api\\UserAppIDSet;\n\n$client = ClarifaiClient::grpc();\n\n$metadata = ["Authorization" => ["Key " . $PAT]];\n\n$userDataObject = new UserAppIDSet([\n    "user_id" => $USER_ID,\n    "app_id" => $APP_ID,\n]);\n\n// To use a local text file, uncomment the following lines\n// $textData = file_get_contents($TEXT_FILE_LOCATION); \n\n// Let\'s make a RPC call to the Clarifai platform. It uses the opened gRPC client channel to communicate a\n// request and then wait for the response\n[$response, $status] = $client\n    ->PostWorkflowResults(\n        // The request object carries the request along with the request status and other metadata related to the request itself\n        new PostWorkflowResultsRequest([\n            "user_app_id" => $userDataObject,\n            "workflow_id" => $WORKFLOW_ID,\n            "inputs" => [\n                new Input([\n                    // The Input object wraps the Data object in order to meet the API specification\n                    "data" => new Data([\n                        // The Data object is constructed around the Image object. It offers a container that has additional image independent\n                        // metadata. In this particular use case, no other metadata is needed to be specified\n                        "text" => new Text([\n                            // In the Clarifai platform, a text is defined by a special Text object\n                            "raw" => $RAW_TEXT\n                            // "url" => $TEXT_FILE_URL \n                            // "raw" => $textData \n                        ]),\n                    ]),\n                ]),\n            ],\n        ]),\n        $metadata\n    )\n    ->wait();\n\n// A response is returned and the first thing we do is check the status of it\n// A successful response will have a status code of 0; otherwise, there is some error\nif ($status->code !== 0) {\n    throw new Exception("Error: {$status->details}");\n}\n// In addition to the RPC response status, there is a Clarifai API status that reports if the operation was a success or failure\n// (not just that the communication was successful)\nif ($response->getStatus()->getCode() != StatusCode::SUCCESS) {\n    throw new Exception(\n        "Failure response: " .\n            $response->getStatus()->getDescription() .\n            " " .\n            $response->getStatus()->getDetails()\n    );\n}\n\n// We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here one WorkflowResult\n$results = $response->getResults()[0];\n\n// Each model we have in the workflow will produce one output\nforeach ($results->getOutputs() as $output) {\n    $model = $output->getModel();\n\n    echo "Predicted concepts for the model \'{$model->getId()}\'" . "\\n";\n\n    $convertDataToJSONString = $output->getData()->serializeToJsonString();\n\n    echo  $convertDataToJSONString . "\\n";\n}\n\n// Uncomment this line to print the raw output\n// print_r($results);\n\n?>',A='Predicted concepts for the model `multilingual-text-embedding`\nembeddings {\n  vector: 0.0255603846\n  vector: 0.0256410129\n  vector: 0.0107929539\n  vector: 0.030718796\n  vector: 0.0150386961\n  vector: -0.0226166341\n  vector: -0.0263089519\n  vector: 0.00326520158\n  vector: 0.0102104917\n  vector: -0.044386141\n  vector: -0.0195556302\n  vector: 0.00893216766\n  vector: 0.015003683\n  vector: -0.0130465208\n  vector: -0.0104514267\n  vector: 0.0217112433\n  vector: -0.0362542719\n  vector: -0.00232617464\n  vector: 0.0566842183\n  vector: -0.0483675748\n  vector: -0.010495048\n  vector: 0.0236451961\n  vector: -0.0139718978\n  vector: -0.0204272885\n  vector: 0.00862451177\n  vector: 0.0366721936\n  vector: 0.0400005206\n  vector: -0.0113559328\n  vector: -0.0424929187\n  vector: -0.0034513874\n  vector: -0.0322748311\n  vector: -0.00985202659\n  vector: -0.012448323\n  vector: -0.0394972041\n  vector: 0.0184240248\n  vector: 0.000438908\n  vector: -0.0020233281\n  vector: 0.0129011944\n  vector: 0.0250889361\n  vector: -0.0152506949\n  vector: 0.0270063598\n  vector: -0.0264613442\n  vector: 0.0258420501\n  vector: -0.0289224759\n  vector: -0.0264949258\n  vector: 0.0334232263\n  vector: -0.0338085629\n  vector: 0.0334763639\n  vector: -0.03762725\n  vector: 0.00782276411\n  vector: -0.00409373501\n  vector: 0.0120968325\n  vector: -0.0106019555\n  vector: -0.0269890483\n  vector: -0.072263509\n  vector: -0.012660739\n  vector: 0.0308089778\n  vector: 0.0298142675\n  vector: -0.0146902641\n  vector: 0.0218613446\n  vector: 0.0323576666\n  vector: -0.0436149947\n  vector: -0.0174307581\n  vector: 0.084372744\n  vector: 0.0181334354\n  vector: -0.0199910812\n  vector: 0.0123974094\n  vector: -0.0193333048\n  vector: 0.0339736864\n  vector: -0.0253562946\n  vector: 0.00288021402\n  vector: 0.0169731714\n  vector: -0.0200157464\n  vector: -0.0637308881\n  vector: 7.40556279e-005\n  vector: 0.00873292703\n  vector: -0.0170422606\n  vector: 0.0415907614\n  vector: -0.00372848427\n  vector: 0.0341904387\n  vector: 0.0267014429\n  vector: -0.0209374689\n  vector: -0.0327630155\n  vector: -0.0457439\n  vector: 0.00402727\n  vector: -0.00840501208\n  vector: 0.0180109739\n  vector: -0.00936154835\n  vector: -0.0110226534\n  vector: -0.00436874479\n  vector: 0.0163043\n  vector: 0.0262424368\n  vector: 0.0101943593\n  vector: -0.0400694683\n  vector: -0.00884656888\n  vector: -0.0427878574\n  vector: -0.0641586557\n  vector: -0.0212010648\n  vector: -0.00159631309\n  vector: 0.0310680382\n  vector: -0.0647975504\n  vector: -0.023672644\n  vector: 0.0459937714\n  vector: -0.00774210179\n  vector: 0.000529117067\n  vector: -0.0292916577\n  vector: -0.0145822288\n  vector: 0.00338335894\n  vector: -0.0156141864\n  vector: -0.00935915578\n  vector: 0.0299793016\n  vector: -0.00355648622\n  vector: 0.0202946737\n  vector: 0.0302724876\n  vector: 0.00297537982\n  vector: 0.0380662605\n  vector: 0.0350826\n  vector: 0.0141671756\n  vector: 0.0307802558\n  vector: 0.0251820423\n  vector: -0.04314005\n  vector: 0.0967362\n  vector: 0.0179795\n  vector: -0.0144064706\n  vector: 0.0614442118\n  vector: 0.0418301858\n  vector: 0.0298902467\n  vector: -0.00762633048\n  vector: 0.00442519924\n  vector: 0.000885691727\n  vector: -0.0406515226\n  vector: -0.0188011918\n  vector: 0.0137273492\n  vector: 0.00622383412\n  vector: 0.0335491821\n  vector: 0.00737484824\n  vector: 0.0139906872\n  vector: 0.0109717203\n  vector: 0.010755497\n  vector: 0.0112457387\n  vector: -0.00598319899\n  vector: 0.0259225015\n  vector: -0.000439705298\n  vector: -0.017860774\n  vector: -0.0371661447\n  vector: -0.0182125829\n  vector: -0.000586743816\n  vector: 0.0030561774\n  vector: 0.00668949727\n  vector: -0.0123718204\n  vector: -0.0365500264\n  vector: 0.0134482831\n  vector: -0.0129413838\n  vector: -0.00557328854\n  vector: 0.0504806265\n  vector: 0.0707531124\n  vector: 0.0188564844\n  vector: 0.0097397631\n  vector: -0.0409301817\n  vector: 0.00957701914\n  vector: -0.0113784261\n  vector: 0.0362381637\n  vector: 0.00238611782\n  vector: -0.0190066174\n  vector: -0.0160514135\n  vector: -0.0437530763\n  vector: -0.00567471469\n  vector: -0.0242700893\n  vector: 0.0125929378\n  vector: -0.00250009913\n  vector: -0.0128744598\n  vector: -0.0602364838\n  vector: -0.0363118686\n  vector: 0.0310818329\n  vector: -0.0280554648\n  vector: 0.00686237263\n  vector: 0.051632829\n  vector: -0.0259241946\n  vector: 0.000656295859\n  vector: -0.0104174372\n  vector: 0.0143860672\n  vector: -0.0219465848\n  vector: -0.0635990351\n  vector: 0.00397105515\n  vector: -0.0171896238\n  vector: -0.000487698242\n  vector: 0.0557192415\n  vector: 0.0290173776\n  vector: -0.0216272268\n  vector: 0.0197027903\n  vector: 0.00293333107\n  vector: -0.0256508272\n  vector: 0.0145954657\n  vector: 0.0147802\n  vector: 0.0199410208\n  vector: 0.0362814479\n  vector: 0.0114512853\n  vector: 0.0516074747\n  vector: -0.00228457758\n  vector: -0.0247946437\n  vector: 0.0531231686\n  vector: 0.0412405729\n  vector: -0.00312332762\n  vector: -0.0384900719\n  vector: 0.0265060011\n  vector: 0.0188652594\n  vector: 0.0254785381\n  vector: -0.0120410575\n  vector: -0.055106923\n  vector: -0.041226916\n  vector: -0.0110674649\n  vector: -0.00518939504\n  vector: 0.0258076955\n  vector: -4.47058883e-005\n  vector: 0.00584268896\n  vector: 0.0291903764\n  vector: 0.0544795282\n  vector: -0.0141743645\n  vector: 0.0383740328\n  vector: -0.0609933324\n  vector: 0.0196725428\n  vector: -0.0131683592\n  vector: 0.0928284079\n  vector: 0.0304285903\n  vector: -0.0431602523\n  vector: -0.000314288016\n  vector: 0.0481073223\n  vector: -0.03109896\n  vector: 0.0305516273\n  vector: -0.0531298704\n  vector: -0.0364271179\n  vector: 0.0249502454\n  vector: -0.035180334\n  vector: -0.00412273454\n  vector: 0.0286418777\n  vector: 0.00197291095\n  vector: -0.0143354721\n  vector: 0.0143140703\n  vector: 0.044354897\n  vector: 0.0567986146\n  vector: 0.0701035857\n  vector: 0.010885776\n  vector: -0.00677968934\n  vector: -0.0355549529\n  vector: 0.0214009341\n  vector: -0.0396741442\n  vector: 0.0010890587\n  vector: 0.0230288804\n  vector: 0.0160423983\n  vector: 0.00770209916\n  vector: -0.00134117063\n  vector: 0.00584157603\n  vector: -0.0506436527\n  vector: 0.0167286471\n  vector: -0.0331318229\n  vector: 0.0315938741\n  vector: -0.0301273353\n  vector: 0.00558987679\n  vector: 0.00451010419\n  vector: -0.0279915575\n  vector: -0.0209878609\n  vector: -0.0199963469\n  vector: -0.000246938725\n  vector: -0.0405185111\n  vector: 0.00242121704\n  vector: 0.00407472113\n  vector: -0.00968741067\n  vector: -0.038693171\n  vector: -0.0187584516\n  vector: 0.0341708027\n  vector: -0.0132718869\n  vector: 0.00288945087\n  vector: 0.0163044799\n  vector: -0.0546093583\n  vector: -0.0190316942\n  vector: 0.0211417172\n  vector: 0.0336544812\n  vector: -0.00693607656\n  vector: 0.0127230892\n  vector: 0.0135776838\n  vector: -0.0617968142\n  vector: -0.00195178052\n  vector: 0.0471284464\n  vector: -0.0395634659\n  vector: 0.0295374077\n  vector: -0.0362583138\n  vector: 0.0599530078\n  vector: -0.0492380969\n  vector: 0.0120025882\n  vector: -0.0152681777\n  vector: 0.00973533373\n  vector: 0.0677181706\n  vector: 0.0222762376\n  vector: -0.0271166284\n  vector: 0.0360873379\n  vector: -0.0109270047\n  vector: 0.00856078602\n  vector: 0.0292164441\n  vector: -0.0243707\n  vector: -0.0110178702\n  vector: 0.0125099961\n  vector: -0.000995316426\n  vector: 0.00649002707\n  vector: -0.0221561305\n  vector: 0.0468515716\n  vector: 0.00950729568\n  vector: -0.0216504335\n  vector: -0.0135809742\n  vector: -0.587396502\n  vector: -0.0500078537\n  vector: 0.0219854936\n  vector: -0.01205255\n  vector: 0.0175891258\n  vector: -0.0113249039\n  vector: 0.0286584757\n  vector: 0.00650032377\n  vector: -0.00326811569\n  vector: 0.022440603\n  vector: -0.0182182249\n  vector: 0.0761179253\n  vector: -0.0167741235\n  vector: 0.0361539535\n  vector: -0.0113675604\n  vector: -0.00895621907\n  vector: -0.0258418024\n  vector: 0.0181844737\n  vector: 0.0115667935\n  vector: 0.0318501815\n  vector: 0.00093767792\n  vector: 0.00287587265\n  vector: 0.0216217488\n  vector: 0.0230962206\n  vector: -0.0256820396\n  vector: 0.0218300279\n  vector: -0.0249342\n  vector: 0.0561292693\n  vector: -0.0231751911\n  vector: 0.016221609\n  vector: 0.00636604\n  vector: -0.0150087075\n  vector: -0.00729617896\n  vector: 0.031151155\n  vector: -0.0164434742\n  vector: -0.00316140847\n  vector: 0.0480747186\n  vector: -0.00684076874\n  vector: -0.0348987654\n  vector: 0.0300664771\n  vector: -0.0080304658\n  vector: -0.00318912556\n  vector: 0.0232989155\n  vector: -0.0248846486\n  vector: -0.074139826\n  vector: -0.017566992\n  vector: 0.00341211492\n  vector: -0.00683950912\n  vector: 0.0451601073\n  vector: -0.0306811985\n  vector: -0.0506822355\n  vector: 0.0148111014\n  vector: -0.0168116689\n  vector: 0.0245187134\n  vector: -0.0385940857\n  vector: -0.00666388543\n  vector: 0.00905002933\n  vector: 0.0306002442\n  vector: 0.0104561793\n  vector: -0.0616600476\n  vector: -0.000910751347\n  vector: -0.0383770578\n  vector: -0.0319519192\n  vector: -0.0191159304\n  vector: 0.00798001699\n  vector: 0.0162921902\n  vector: -0.00722851697\n  vector: -0.00984974951\n  vector: 0.00443824846\n  vector: 0.0458599813\n  vector: 0.00428895839\n  vector: -0.016468009\n  vector: 0.00984302443\n  vector: -0.0848148167\n  vector: 0.0138867963\n  vector: -0.0347199\n  vector: -0.012926463\n  vector: -0.0195842963\n  vector: 0.00821305159\n  vector: 0.0116449213\n  vector: -0.0596969128\n  vector: 0.0139209842\n  vector: 0.0124949655\n  vector: 0.0564839914\n  vector: 0.073116228\n  vector: 0.0054912949\n  vector: 0.008373552\n  vector: 0.049428314\n  vector: 0.00387572078\n  vector: 0.00328427833\n  vector: 0.0574303158\n  vector: -0.0401720814\n  vector: 0.00543978252\n  vector: 0.0125507237\n  vector: -0.0223911144\n  vector: 0.0530512854\n  vector: -0.0193119962\n  vector: -0.056736242\n  vector: 0.028417591\n  vector: 0.0039758184\n  vector: 0.0603403524\n  vector: 0.00940856431\n  vector: -0.00775589608\n  vector: -0.00202059839\n  vector: -0.0325067\n  vector: 0.00763982581\n  vector: -0.0420214422\n  vector: -0.0248172414\n  vector: 0.0121375453\n  vector: -0.0279675424\n  vector: -0.0139899682\n  vector: 0.0103907259\n  vector: 0.00846104417\n  vector: 0.000477065099\n  vector: -0.0172488894\n  vector: 0.0307512395\n  vector: -0.0159618128\n  vector: -0.0448177345\n  vector: -0.0378222652\n  vector: -0.00430452963\n  vector: -0.0221919119\n  vector: -0.0052908631\n  vector: -0.0408164859\n  vector: -0.0093395263\n  vector: -0.0526061207\n  vector: -0.0033937979\n  vector: -0.0111951698\n  vector: -0.018287722\n  vector: 0.0332923383\n  vector: 0.0202295\n  vector: -0.0026297241\n  vector: -0.0169538446\n  vector: -0.000453287736\n  vector: 0.0429562218\n  vector: -0.000680702738\n  vector: 0.0273506679\n  vector: -0.0683761761\n  vector: 0.0667696\n  vector: 0.0106630186\n  vector: -0.0298528746\n  vector: -0.000488598191\n  vector: -0.0440973416\n  vector: 0.0534471236\n  vector: -0.0181944631\n  vector: -0.00166536344\n  vector: -0.0655773953\n  vector: 0.0274203978\n  vector: 0.00751716364\n  vector: 0.012719023\n  vector: -0.0299365614\n  vector: 0.0668713\n  vector: 0.0176321361\n  vector: 0.00121316453\n  vector: 0.0211630538\n  vector: -0.0457814448\n  vector: 0.0290366914\n  vector: 0.0472914241\n  vector: 1.481e-005\n  vector: -0.0201600771\n  vector: 0.0741583481\n  vector: -0.0177378468\n  vector: -0.018208934\n  vector: -0.0424425118\n  vector: -0.0322192535\n  vector: 0.0212140493\n  vector: -0.0333384909\n  vector: -0.0089503089\n  vector: 0.00865053944\n  vector: -0.0114420308\n  vector: -0.0323484875\n  vector: -0.0319988914\n  vector: -0.0404753834\n  vector: -0.0135618644\n  vector: 0.0243302248\n  vector: -0.00248846621\n  vector: -0.00764315343\n  vector: 0.0407035202\n  vector: 0.0072440342\n  vector: -0.00446285773\n  vector: -0.00628219312\n  vector: 0.00204555667\n  vector: -0.0171564016\n  vector: 0.00325665134\n  vector: -0.0169214662\n  vector: -0.00940683484\n  vector: 0.0141208908\n  vector: 0.00711128581\n  vector: -0.0218882859\n  vector: -0.0365912281\n  vector: -0.0138345128\n  vector: 0.028417252\n  vector: -0.0632902831\n  vector: 0.0563294031\n  vector: -0.0139016444\n  vector: 0.0173191428\n  vector: 0.0109188249\n  vector: -0.00881743524\n  vector: 0.0335570648\n  vector: 0.0302902944\n  vector: 0.00306223263\n  vector: 0.0300811697\n  vector: 0.0165142342\n  vector: -0.0220398791\n  vector: -0.0190337524\n  vector: -0.0218247\n  vector: -0.00892979838\n  vector: 0.00296077109\n  vector: -0.00667882059\n  vector: 0.0369906649\n  vector: 0.00189560978\n  vector: 0.0496911258\n  vector: -0.0371349975\n  vector: -0.0232151151\n  vector: 0.0153016197\n  vector: -0.00322092674\n  vector: -0.0189977195\n  vector: -0.0241388399\n  vector: -0.0209848098\n  vector: -0.00240087532\n  vector: -0.0097488109\n  vector: 0.0277912915\n  vector: 0.0129486732\n  vector: -0.0418183915\n  vector: -0.0172175094\n  vector: 0.014063701\n  vector: 0.0179245677\n  vector: 0.0329503492\n  vector: -0.0451413542\n  vector: 0.0375629142\n  vector: -0.00336613436\n  vector: 0.0837872624\n  vector: 0.0155244442\n  vector: -0.0319327973\n  vector: 0.0177341402\n  vector: -0.0694914684\n  vector: -0.0230065882\n  vector: -0.0349770822\n  vector: -0.000637284247\n  vector: -0.0171240233\n  vector: -0.000385974447\n  vector: -0.0154445628\n  vector: -0.00813626312\n  vector: -0.0018971978\n  vector: -0.0101503106\n  vector: -0.0577919446\n  vector: 0.00862083118\n  vector: 0.0169755798\n  vector: -0.0585522167\n  vector: -0.0303873625\n  vector: 0.0278049447\n  vector: 0.000132163666\n  vector: 0.0184809174\n  vector: 0.0111429971\n  vector: 0.0186991747\n  vector: 0.0336764\n  vector: 0.00854624715\n  vector: 0.0118956529\n  vector: 5.09967458e-006\n  vector: -0.0374510773\n  vector: 0.0125189032\n  vector: 0.0146504\n  vector: 0.0372200981\n  vector: -0.0323317759\n  vector: 0.0184809044\n  vector: -0.0637908429\n  vector: 0.00348871434\n  vector: 0.0116535509\n  vector: -0.0170193538\n  vector: -0.00596837653\n  vector: 0.00763026299\n  vector: -0.0396812037\n  vector: 0.00393839693\n  vector: 0.0243215691\n  vector: 0.0736935437\n  vector: 0.0649354607\n  vector: -0.0693660229\n  vector: -0.0173935127\n  vector: 0.0645925924\n  vector: 0.0218239073\n  vector: 0.0443394184\n  vector: 0.00201784237\n  vector: 0.000589759089\n  vector: 0.0140056768\n  vector: 0.0208582152\n  vector: -0.0178501364\n  vector: 0.0198773723\n  vector: 0.0119620683\n  vector: -0.00607993035\n  vector: 0.0137936343\n  vector: 0.015486001\n  vector: 0.0217939913\n  vector: 0.000516918313\n  vector: -0.0155286901\n  vector: -0.0236418\n  vector: 0.00602063863\n  vector: -0.0117947338\n  vector: -0.0382487215\n  vector: -0.0253913198\n  vector: 0.0540902093\n  vector: -0.00069479784\n  vector: -0.0030842768\n  vector: 0.00678593758\n  vector: -0.0158268567\n  vector: -0.0301091801\n  vector: -0.047721222\n  vector: 0.0486889854\n  vector: -0.0031820375\n  vector: -0.00780140189\n  vector: -0.0473188572\n  vector: -0.0377694\n  vector: 0.00300174044\n  vector: 0.00725157047\n  vector: 0.0334912054\n  vector: -0.0190392211\n  vector: -0.00786152\n  vector: -0.00393901\n  vector: 0.0346906558\n  vector: -0.0048984047\n  vector: -0.0289619621\n  vector: -0.0132993627\n  vector: -0.0260517057\n  vector: -0.0194860194\n  vector: -0.00903460104\n  vector: -0.0720684156\n  vector: -0.0326718502\n  vector: -0.0178757478\n  vector: 0.0116493832\n  vector: -0.0249003451\n  vector: -0.012765849\n  vector: -0.0367143154\n  vector: 0.0253556\n  vector: -0.000750295934\n  vector: 0.00800141\n  vector: -0.0399938263\n  vector: -0.0156591497\n  vector: 0.00355092739\n  vector: 0.00527952937\n  vector: -0.00371489814\n  vector: 0.00979584455\n  vector: 0.0128817623\n  vector: -0.0257944819\n  vector: 0.00532698631\n  vector: -0.0054745716\n  vector: -0.0402425155\n  vector: 0.0023749\n  vector: -0.0191466119\n  vector: -0.000185457975\n  vector: 0.0123729743\n  vector: -0.0285796933\n  vector: 0.027248418\n  vector: -0.00682593649\n  vector: -0.027824128\n  vector: -0.0483085215\n  vector: 0.0509723\n  vector: 0.0150561249\n  vector: -0.0671003759\n  vector: -0.0302604195\n  vector: 0.0335228\n  vector: -0.00811030716\n  vector: -0.0476540774\n  vector: -0.0483691692\n  vector: 0.0257905629\n  vector: 0.0216702223\n  vector: 0.0756625161\n  vector: -0.0114407977\n  vector: 0.0250642728\n  vector: 0.0492128\n  vector: 0.0104585467\n  vector: 0.0354731493\n  vector: 0.0342974328\n  vector: -0.0315436497\n  vector: -0.0416372307\n  vector: 0.0251945127\n  vector: 0.0550534874\n  vector: -0.00769103458\n  vector: -0.0269156434\n  vector: 0.0629401803\n  vector: 0.00849406514\n  vector: 0.0277529527\n  vector: 0.00905152876\n  vector: -0.0214481559\n  vector: -0.0336390026\n  vector: 0.0172805414\n  vector: -0.0254873466\n  vector: 0.00181326456\n  vector: -0.00262851967\n  vector: 0.00212677\n  vector: 0.021096956\n  vector: -0.0310921967\n  vector: 0.0090319775\n  vector: -0.0244406015\n  vector: -0.00450366875\n  vector: 0.0024087145\n  vector: -0.021715302\n  vector: -0.0187266618\n  vector: 0.00639256975\n  vector: 0.00592296245\n  vector: -0.0126604829\n  vector: -0.00361264497\n  vector: 0.018905757\n  vector: 0.0180640183\n  vector: -0.0142810205\n  vector: 0.0201476328\n  vector: -0.0371763296\n  vector: -0.016901549\n  vector: 0.0173841435\n  vector: 0.0144714024\n  vector: 0.0371279158\n  vector: -0.0259519368\n  vector: -0.0135354148\n  vector: 0.0480304547\n  vector: 0.0241338\n  vector: 0.00995781645\n  vector: -0.0145506114\n  vector: -0.0132244434\n  vector: 0.0104087936\n  vector: -0.0019786309\n  vector: -0.010059624\n  vector: 0.0418220572\n  vector: 0.00906385668\n  vector: -0.0608912781\n  vector: 0.0269323979\n  vector: 0.0267148074\n  vector: 0.0114678359\n  vector: -0.00542484596\n  vector: 0.0605565161\n  vector: 0.00729974685\n  vector: 0.0284503475\n  vector: 0.000257256615\n  vector: -0.029183466\n  vector: 0.029569421\n  vector: 0.000915852608\n  vector: 0.0109864781\n  vector: 0.0160177927\n  vector: -0.0311278421\n  vector: -0.00568914367\n  vector: -0.045658119\n  vector: -0.0380534567\n  vector: 0.00769931311\n  vector: -0.0169286355\n  vector: -0.0414473452\n  vector: 0.0346236937\n  vector: 0.00468268059\n  vector: -0.000171230145\n  vector: -0.0555126853\n  vector: -0.0213408619\n  vector: -0.00562082976\n  vector: -0.042139709\n  vector: 0.00932554808\n  vector: 0.0544001274\n  vector: 0.0186972376\n  vector: 0.0127014797\n  vector: 0.0039651487\n  vector: 0.0317394622\n  vector: 0.00775914779\n  vector: -0.0223883521\n  vector: -0.0120635182\n  vector: 0.0196055751\n  vector: 0.0291586574\n  vector: 0.0337944\n  num_dimensions: 768\n}\n\nPredicted concepts for the model `multilingual-text-clustering`\nclusters {\n  id: "9_17"\n  projection: 0.210836634\n  projection: -0.248410583\n}\n',O='status {\n  code: SUCCESS\n  description: "Ok"\n}\ninput {\n  id: "f58574ce6a304c39ba298ecb4f4eef5e"\n  data {\n    text {\n      raw: "This is a test text for testing"\n      url: "https://samples.clarifai.com/placeholder.gif"\n    }\n  }\n}\noutputs {\n  id: "0ff24540c786470e912984865c03efc0"\n  status {\n    code: SUCCESS\n    description: "Ok"\n  }\n  created_at {\n    seconds: 1700723375\n    nanos: 640229252\n  }\n  model {\n    id: "multilingual-text-embedding"\n    name: "multilingual-text-embedding"\n    created_at {\n      seconds: 1581694729\n      nanos: 522174000\n    }\n    modified_at {\n      seconds: 1655211303\n      nanos: 454205000\n    }\n    app_id: "main"\n    model_version {\n      id: "9b33adf15280465b857163ddaaacdcb1"\n      created_at {\n        seconds: 1606747915\n        nanos: 848030000\n      }\n      status {\n        code: MODEL_TRAINED\n        description: "Model is trained and ready"\n      }\n      visibility {\n        gettable: PUBLIC\n      }\n      app_id: "main"\n      user_id: "clarifai"\n      metadata {\n      }\n    }\n    user_id: "clarifai"\n    model_type_id: "text-embedder"\n    visibility {\n      gettable: PUBLIC\n    }\n    workflow_recommended {\n    }\n  }\n  data {\n    embeddings {\n      vector: 0.0255603846\n      vector: 0.0256410129\n      vector: 0.0107929539\n      vector: 0.030718796\n      vector: 0.0150386961\n      vector: -0.0226166341\n      vector: -0.0263089519\n      vector: 0.00326520158\n      vector: 0.0102104917\n      vector: -0.044386141\n      vector: -0.0195556302\n      vector: 0.00893216766\n      vector: 0.015003683\n      vector: -0.0130465208\n      vector: -0.0104514267\n      vector: 0.0217112433\n      vector: -0.0362542719\n      vector: -0.00232617464\n      vector: 0.0566842183\n      vector: -0.0483675748\n      vector: -0.010495048\n      vector: 0.0236451961\n      vector: -0.0139718978\n      vector: -0.0204272885\n      vector: 0.00862451177\n      vector: 0.0366721936\n      vector: 0.0400005206\n      vector: -0.0113559328\n      vector: -0.0424929187\n      vector: -0.0034513874\n      vector: -0.0322748311\n      vector: -0.00985202659\n      vector: -0.012448323\n      vector: -0.0394972041\n      vector: 0.0184240248\n      vector: 0.000438908\n      vector: -0.0020233281\n      vector: 0.0129011944\n      vector: 0.0250889361\n      vector: -0.0152506949\n      vector: 0.0270063598\n      vector: -0.0264613442\n      vector: 0.0258420501\n      vector: -0.0289224759\n      vector: -0.0264949258\n      vector: 0.0334232263\n      vector: -0.0338085629\n      vector: 0.0334763639\n      vector: -0.03762725\n      vector: 0.00782276411\n      vector: -0.00409373501\n      vector: 0.0120968325\n      vector: -0.0106019555\n      vector: -0.0269890483\n      vector: -0.072263509\n      vector: -0.012660739\n      vector: 0.0308089778\n      vector: 0.0298142675\n      vector: -0.0146902641\n      vector: 0.0218613446\n      vector: 0.0323576666\n      vector: -0.0436149947\n      vector: -0.0174307581\n      vector: 0.084372744\n      vector: 0.0181334354\n      vector: -0.0199910812\n      vector: 0.0123974094\n      vector: -0.0193333048\n      vector: 0.0339736864\n      vector: -0.0253562946\n      vector: 0.00288021402\n      vector: 0.0169731714\n      vector: -0.0200157464\n      vector: -0.0637308881\n      vector: 7.40556279e-005\n      vector: 0.00873292703\n      vector: -0.0170422606\n      vector: 0.0415907614\n      vector: -0.00372848427\n      vector: 0.0341904387\n      vector: 0.0267014429\n      vector: -0.0209374689\n      vector: -0.0327630155\n      vector: -0.0457439\n      vector: 0.00402727\n      vector: -0.00840501208\n      vector: 0.0180109739\n      vector: -0.00936154835\n      vector: -0.0110226534\n      vector: -0.00436874479\n      vector: 0.0163043\n      vector: 0.0262424368\n      vector: 0.0101943593\n      vector: -0.0400694683\n      vector: -0.00884656888\n      vector: -0.0427878574\n      vector: -0.0641586557\n      vector: -0.0212010648\n      vector: -0.00159631309\n      vector: 0.0310680382\n      vector: -0.0647975504\n      vector: -0.023672644\n      vector: 0.0459937714\n      vector: -0.00774210179\n      vector: 0.000529117067\n      vector: -0.0292916577\n      vector: -0.0145822288\n      vector: 0.00338335894\n      vector: -0.0156141864\n      vector: -0.00935915578\n      vector: 0.0299793016\n      vector: -0.00355648622\n      vector: 0.0202946737\n      vector: 0.0302724876\n      vector: 0.00297537982\n      vector: 0.0380662605\n      vector: 0.0350826\n      vector: 0.0141671756\n      vector: 0.0307802558\n      vector: 0.0251820423\n      vector: -0.04314005\n      vector: 0.0967362\n      vector: 0.0179795\n      vector: -0.0144064706\n      vector: 0.0614442118\n      vector: 0.0418301858\n      vector: 0.0298902467\n      vector: -0.00762633048\n      vector: 0.00442519924\n      vector: 0.000885691727\n      vector: -0.0406515226\n      vector: -0.0188011918\n      vector: 0.0137273492\n      vector: 0.00622383412\n      vector: 0.0335491821\n      vector: 0.00737484824\n      vector: 0.0139906872\n      vector: 0.0109717203\n      vector: 0.010755497\n      vector: 0.0112457387\n      vector: -0.00598319899\n      vector: 0.0259225015\n      vector: -0.000439705298\n      vector: -0.017860774\n      vector: -0.0371661447\n      vector: -0.0182125829\n      vector: -0.000586743816\n      vector: 0.0030561774\n      vector: 0.00668949727\n      vector: -0.0123718204\n      vector: -0.0365500264\n      vector: 0.0134482831\n      vector: -0.0129413838\n      vector: -0.00557328854\n      vector: 0.0504806265\n      vector: 0.0707531124\n      vector: 0.0188564844\n      vector: 0.0097397631\n      vector: -0.0409301817\n      vector: 0.00957701914\n      vector: -0.0113784261\n      vector: 0.0362381637\n      vector: 0.00238611782\n      vector: -0.0190066174\n      vector: -0.0160514135\n      vector: -0.0437530763\n      vector: -0.00567471469\n      vector: -0.0242700893\n      vector: 0.0125929378\n      vector: -0.00250009913\n      vector: -0.0128744598\n      vector: -0.0602364838\n      vector: -0.0363118686\n      vector: 0.0310818329\n      vector: -0.0280554648\n      vector: 0.00686237263\n      vector: 0.051632829\n      vector: -0.0259241946\n      vector: 0.000656295859\n      vector: -0.0104174372\n      vector: 0.0143860672\n      vector: -0.0219465848\n      vector: -0.0635990351\n      vector: 0.00397105515\n      vector: -0.0171896238\n      vector: -0.000487698242\n      vector: 0.0557192415\n      vector: 0.0290173776\n      vector: -0.0216272268\n      vector: 0.0197027903\n      vector: 0.00293333107\n      vector: -0.0256508272\n      vector: 0.0145954657\n      vector: 0.0147802\n      vector: 0.0199410208\n      vector: 0.0362814479\n      vector: 0.0114512853\n      vector: 0.0516074747\n      vector: -0.00228457758\n      vector: -0.0247946437\n      vector: 0.0531231686\n      vector: 0.0412405729\n      vector: -0.00312332762\n      vector: -0.0384900719\n      vector: 0.0265060011\n      vector: 0.0188652594\n      vector: 0.0254785381\n      vector: -0.0120410575\n      vector: -0.055106923\n      vector: -0.041226916\n      vector: -0.0110674649\n      vector: -0.00518939504\n      vector: 0.0258076955\n      vector: -4.47058883e-005\n      vector: 0.00584268896\n      vector: 0.0291903764\n      vector: 0.0544795282\n      vector: -0.0141743645\n      vector: 0.0383740328\n      vector: -0.0609933324\n      vector: 0.0196725428\n      vector: -0.0131683592\n      vector: 0.0928284079\n      vector: 0.0304285903\n      vector: -0.0431602523\n      vector: -0.000314288016\n      vector: 0.0481073223\n      vector: -0.03109896\n      vector: 0.0305516273\n      vector: -0.0531298704\n      vector: -0.0364271179\n      vector: 0.0249502454\n      vector: -0.035180334\n      vector: -0.00412273454\n      vector: 0.0286418777\n      vector: 0.00197291095\n      vector: -0.0143354721\n      vector: 0.0143140703\n      vector: 0.044354897\n      vector: 0.0567986146\n      vector: 0.0701035857\n      vector: 0.010885776\n      vector: -0.00677968934\n      vector: -0.0355549529\n      vector: 0.0214009341\n      vector: -0.0396741442\n      vector: 0.0010890587\n      vector: 0.0230288804\n      vector: 0.0160423983\n      vector: 0.00770209916\n      vector: -0.00134117063\n      vector: 0.00584157603\n      vector: -0.0506436527\n      vector: 0.0167286471\n      vector: -0.0331318229\n      vector: 0.0315938741\n      vector: -0.0301273353\n      vector: 0.00558987679\n      vector: 0.00451010419\n      vector: -0.0279915575\n      vector: -0.0209878609\n      vector: -0.0199963469\n      vector: -0.000246938725\n      vector: -0.0405185111\n      vector: 0.00242121704\n      vector: 0.00407472113\n      vector: -0.00968741067\n      vector: -0.038693171\n      vector: -0.0187584516\n      vector: 0.0341708027\n      vector: -0.0132718869\n      vector: 0.00288945087\n      vector: 0.0163044799\n      vector: -0.0546093583\n      vector: -0.0190316942\n      vector: 0.0211417172\n      vector: 0.0336544812\n      vector: -0.00693607656\n      vector: 0.0127230892\n      vector: 0.0135776838\n      vector: -0.0617968142\n      vector: -0.00195178052\n      vector: 0.0471284464\n      vector: -0.0395634659\n      vector: 0.0295374077\n      vector: -0.0362583138\n      vector: 0.0599530078\n      vector: -0.0492380969\n      vector: 0.0120025882\n      vector: -0.0152681777\n      vector: 0.00973533373\n      vector: 0.0677181706\n      vector: 0.0222762376\n      vector: -0.0271166284\n      vector: 0.0360873379\n      vector: -0.0109270047\n      vector: 0.00856078602\n      vector: 0.0292164441\n      vector: -0.0243707\n      vector: -0.0110178702\n      vector: 0.0125099961\n      vector: -0.000995316426\n      vector: 0.00649002707\n      vector: -0.0221561305\n      vector: 0.0468515716\n      vector: 0.00950729568\n      vector: -0.0216504335\n      vector: -0.0135809742\n      vector: -0.587396502\n      vector: -0.0500078537\n      vector: 0.0219854936\n      vector: -0.01205255\n      vector: 0.0175891258\n      vector: -0.0113249039\n      vector: 0.0286584757\n      vector: 0.00650032377\n      vector: -0.00326811569\n      vector: 0.022440603\n      vector: -0.0182182249\n      vector: 0.0761179253\n      vector: -0.0167741235\n      vector: 0.0361539535\n      vector: -0.0113675604\n      vector: -0.00895621907\n      vector: -0.0258418024\n      vector: 0.0181844737\n      vector: 0.0115667935\n      vector: 0.0318501815\n      vector: 0.00093767792\n      vector: 0.00287587265\n      vector: 0.0216217488\n      vector: 0.0230962206\n      vector: -0.0256820396\n      vector: 0.0218300279\n      vector: -0.0249342\n      vector: 0.0561292693\n      vector: -0.0231751911\n      vector: 0.016221609\n      vector: 0.00636604\n      vector: -0.0150087075\n      vector: -0.00729617896\n      vector: 0.031151155\n      vector: -0.0164434742\n      vector: -0.00316140847\n      vector: 0.0480747186\n      vector: -0.00684076874\n      vector: -0.0348987654\n      vector: 0.0300664771\n      vector: -0.0080304658\n      vector: -0.00318912556\n      vector: 0.0232989155\n      vector: -0.0248846486\n      vector: -0.074139826\n      vector: -0.017566992\n      vector: 0.00341211492\n      vector: -0.00683950912\n      vector: 0.0451601073\n      vector: -0.0306811985\n      vector: -0.0506822355\n      vector: 0.0148111014\n      vector: -0.0168116689\n      vector: 0.0245187134\n      vector: -0.0385940857\n      vector: -0.00666388543\n      vector: 0.00905002933\n      vector: 0.0306002442\n      vector: 0.0104561793\n      vector: -0.0616600476\n      vector: -0.000910751347\n      vector: -0.0383770578\n      vector: -0.0319519192\n      vector: -0.0191159304\n      vector: 0.00798001699\n      vector: 0.0162921902\n      vector: -0.00722851697\n      vector: -0.00984974951\n      vector: 0.00443824846\n      vector: 0.0458599813\n      vector: 0.00428895839\n      vector: -0.016468009\n      vector: 0.00984302443\n      vector: -0.0848148167\n      vector: 0.0138867963\n      vector: -0.0347199\n      vector: -0.012926463\n      vector: -0.0195842963\n      vector: 0.00821305159\n      vector: 0.0116449213\n      vector: -0.0596969128\n      vector: 0.0139209842\n      vector: 0.0124949655\n      vector: 0.0564839914\n      vector: 0.073116228\n      vector: 0.0054912949\n      vector: 0.008373552\n      vector: 0.049428314\n      vector: 0.00387572078\n      vector: 0.00328427833\n      vector: 0.0574303158\n      vector: -0.0401720814\n      vector: 0.00543978252\n      vector: 0.0125507237\n      vector: -0.0223911144\n      vector: 0.0530512854\n      vector: -0.0193119962\n      vector: -0.056736242\n      vector: 0.028417591\n      vector: 0.0039758184\n      vector: 0.0603403524\n      vector: 0.00940856431\n      vector: -0.00775589608\n      vector: -0.00202059839\n      vector: -0.0325067\n      vector: 0.00763982581\n      vector: -0.0420214422\n      vector: -0.0248172414\n      vector: 0.0121375453\n      vector: -0.0279675424\n      vector: -0.0139899682\n      vector: 0.0103907259\n      vector: 0.00846104417\n      vector: 0.000477065099\n      vector: -0.0172488894\n      vector: 0.0307512395\n      vector: -0.0159618128\n      vector: -0.0448177345\n      vector: -0.0378222652\n      vector: -0.00430452963\n      vector: -0.0221919119\n      vector: -0.0052908631\n      vector: -0.0408164859\n      vector: -0.0093395263\n      vector: -0.0526061207\n      vector: -0.0033937979\n      vector: -0.0111951698\n      vector: -0.018287722\n      vector: 0.0332923383\n      vector: 0.0202295\n      vector: -0.0026297241\n      vector: -0.0169538446\n      vector: -0.000453287736\n      vector: 0.0429562218\n      vector: -0.000680702738\n      vector: 0.0273506679\n      vector: -0.0683761761\n      vector: 0.0667696\n      vector: 0.0106630186\n      vector: -0.0298528746\n      vector: -0.000488598191\n      vector: -0.0440973416\n      vector: 0.0534471236\n      vector: -0.0181944631\n      vector: -0.00166536344\n      vector: -0.0655773953\n      vector: 0.0274203978\n      vector: 0.00751716364\n      vector: 0.012719023\n      vector: -0.0299365614\n      vector: 0.0668713\n      vector: 0.0176321361\n      vector: 0.00121316453\n      vector: 0.0211630538\n      vector: -0.0457814448\n      vector: 0.0290366914\n      vector: 0.0472914241\n      vector: 1.481e-005\n      vector: -0.0201600771\n      vector: 0.0741583481\n      vector: -0.0177378468\n      vector: -0.018208934\n      vector: -0.0424425118\n      vector: -0.0322192535\n      vector: 0.0212140493\n      vector: -0.0333384909\n      vector: -0.0089503089\n      vector: 0.00865053944\n      vector: -0.0114420308\n      vector: -0.0323484875\n      vector: -0.0319988914\n      vector: -0.0404753834\n      vector: -0.0135618644\n      vector: 0.0243302248\n      vector: -0.00248846621\n      vector: -0.00764315343\n      vector: 0.0407035202\n      vector: 0.0072440342\n      vector: -0.00446285773\n      vector: -0.00628219312\n      vector: 0.00204555667\n      vector: -0.0171564016\n      vector: 0.00325665134\n      vector: -0.0169214662\n      vector: -0.00940683484\n      vector: 0.0141208908\n      vector: 0.00711128581\n      vector: -0.0218882859\n      vector: -0.0365912281\n      vector: -0.0138345128\n      vector: 0.028417252\n      vector: -0.0632902831\n      vector: 0.0563294031\n      vector: -0.0139016444\n      vector: 0.0173191428\n      vector: 0.0109188249\n      vector: -0.00881743524\n      vector: 0.0335570648\n      vector: 0.0302902944\n      vector: 0.00306223263\n      vector: 0.0300811697\n      vector: 0.0165142342\n      vector: -0.0220398791\n      vector: -0.0190337524\n      vector: -0.0218247\n      vector: -0.00892979838\n      vector: 0.00296077109\n      vector: -0.00667882059\n      vector: 0.0369906649\n      vector: 0.00189560978\n      vector: 0.0496911258\n      vector: -0.0371349975\n      vector: -0.0232151151\n      vector: 0.0153016197\n      vector: -0.00322092674\n      vector: -0.0189977195\n      vector: -0.0241388399\n      vector: -0.0209848098\n      vector: -0.00240087532\n      vector: -0.0097488109\n      vector: 0.0277912915\n      vector: 0.0129486732\n      vector: -0.0418183915\n      vector: -0.0172175094\n      vector: 0.014063701\n      vector: 0.0179245677\n      vector: 0.0329503492\n      vector: -0.0451413542\n      vector: 0.0375629142\n      vector: -0.00336613436\n      vector: 0.0837872624\n      vector: 0.0155244442\n      vector: -0.0319327973\n      vector: 0.0177341402\n      vector: -0.0694914684\n      vector: -0.0230065882\n      vector: -0.0349770822\n      vector: -0.000637284247\n      vector: -0.0171240233\n      vector: -0.000385974447\n      vector: -0.0154445628\n      vector: -0.00813626312\n      vector: -0.0018971978\n      vector: -0.0101503106\n      vector: -0.0577919446\n      vector: 0.00862083118\n      vector: 0.0169755798\n      vector: -0.0585522167\n      vector: -0.0303873625\n      vector: 0.0278049447\n      vector: 0.000132163666\n      vector: 0.0184809174\n      vector: 0.0111429971\n      vector: 0.0186991747\n      vector: 0.0336764\n      vector: 0.00854624715\n      vector: 0.0118956529\n      vector: 5.09967458e-006\n      vector: -0.0374510773\n      vector: 0.0125189032\n      vector: 0.0146504\n      vector: 0.0372200981\n      vector: -0.0323317759\n      vector: 0.0184809044\n      vector: -0.0637908429\n      vector: 0.00348871434\n      vector: 0.0116535509\n      vector: -0.0170193538\n      vector: -0.00596837653\n      vector: 0.00763026299\n      vector: -0.0396812037\n      vector: 0.00393839693\n      vector: 0.0243215691\n      vector: 0.0736935437\n      vector: 0.0649354607\n      vector: -0.0693660229\n      vector: -0.0173935127\n      vector: 0.0645925924\n      vector: 0.0218239073\n      vector: 0.0443394184\n      vector: 0.00201784237\n      vector: 0.000589759089\n      vector: 0.0140056768\n      vector: 0.0208582152\n      vector: -0.0178501364\n      vector: 0.0198773723\n      vector: 0.0119620683\n      vector: -0.00607993035\n      vector: 0.0137936343\n      vector: 0.015486001\n      vector: 0.0217939913\n      vector: 0.000516918313\n      vector: -0.0155286901\n      vector: -0.0236418\n      vector: 0.00602063863\n      vector: -0.0117947338\n      vector: -0.0382487215\n      vector: -0.0253913198\n      vector: 0.0540902093\n      vector: -0.00069479784\n      vector: -0.0030842768\n      vector: 0.00678593758\n      vector: -0.0158268567\n      vector: -0.0301091801\n      vector: -0.047721222\n      vector: 0.0486889854\n      vector: -0.0031820375\n      vector: -0.00780140189\n      vector: -0.0473188572\n      vector: -0.0377694\n      vector: 0.00300174044\n      vector: 0.00725157047\n      vector: 0.0334912054\n      vector: -0.0190392211\n      vector: -0.00786152\n      vector: -0.00393901\n      vector: 0.0346906558\n      vector: -0.0048984047\n      vector: -0.0289619621\n      vector: -0.0132993627\n      vector: -0.0260517057\n      vector: -0.0194860194\n      vector: -0.00903460104\n      vector: -0.0720684156\n      vector: -0.0326718502\n      vector: -0.0178757478\n      vector: 0.0116493832\n      vector: -0.0249003451\n      vector: -0.012765849\n      vector: -0.0367143154\n      vector: 0.0253556\n      vector: -0.000750295934\n      vector: 0.00800141\n      vector: -0.0399938263\n      vector: -0.0156591497\n      vector: 0.00355092739\n      vector: 0.00527952937\n      vector: -0.00371489814\n      vector: 0.00979584455\n      vector: 0.0128817623\n      vector: -0.0257944819\n      vector: 0.00532698631\n      vector: -0.0054745716\n      vector: -0.0402425155\n      vector: 0.0023749\n      vector: -0.0191466119\n      vector: -0.000185457975\n      vector: 0.0123729743\n      vector: -0.0285796933\n      vector: 0.027248418\n      vector: -0.00682593649\n      vector: -0.027824128\n      vector: -0.0483085215\n      vector: 0.0509723\n      vector: 0.0150561249\n      vector: -0.0671003759\n      vector: -0.0302604195\n      vector: 0.0335228\n      vector: -0.00811030716\n      vector: -0.0476540774\n      vector: -0.0483691692\n      vector: 0.0257905629\n      vector: 0.0216702223\n      vector: 0.0756625161\n      vector: -0.0114407977\n      vector: 0.0250642728\n      vector: 0.0492128\n      vector: 0.0104585467\n      vector: 0.0354731493\n      vector: 0.0342974328\n      vector: -0.0315436497\n      vector: -0.0416372307\n      vector: 0.0251945127\n      vector: 0.0550534874\n      vector: -0.00769103458\n      vector: -0.0269156434\n      vector: 0.0629401803\n      vector: 0.00849406514\n      vector: 0.0277529527\n      vector: 0.00905152876\n      vector: -0.0214481559\n      vector: -0.0336390026\n      vector: 0.0172805414\n      vector: -0.0254873466\n      vector: 0.00181326456\n      vector: -0.00262851967\n      vector: 0.00212677\n      vector: 0.021096956\n      vector: -0.0310921967\n      vector: 0.0090319775\n      vector: -0.0244406015\n      vector: -0.00450366875\n      vector: 0.0024087145\n      vector: -0.021715302\n      vector: -0.0187266618\n      vector: 0.00639256975\n      vector: 0.00592296245\n      vector: -0.0126604829\n      vector: -0.00361264497\n      vector: 0.018905757\n      vector: 0.0180640183\n      vector: -0.0142810205\n      vector: 0.0201476328\n      vector: -0.0371763296\n      vector: -0.016901549\n      vector: 0.0173841435\n      vector: 0.0144714024\n      vector: 0.0371279158\n      vector: -0.0259519368\n      vector: -0.0135354148\n      vector: 0.0480304547\n      vector: 0.0241338\n      vector: 0.00995781645\n      vector: -0.0145506114\n      vector: -0.0132244434\n      vector: 0.0104087936\n      vector: -0.0019786309\n      vector: -0.010059624\n      vector: 0.0418220572\n      vector: 0.00906385668\n      vector: -0.0608912781\n      vector: 0.0269323979\n      vector: 0.0267148074\n      vector: 0.0114678359\n      vector: -0.00542484596\n      vector: 0.0605565161\n      vector: 0.00729974685\n      vector: 0.0284503475\n      vector: 0.000257256615\n      vector: -0.029183466\n      vector: 0.029569421\n      vector: 0.000915852608\n      vector: 0.0109864781\n      vector: 0.0160177927\n      vector: -0.0311278421\n      vector: -0.00568914367\n      vector: -0.045658119\n      vector: -0.0380534567\n      vector: 0.00769931311\n      vector: -0.0169286355\n      vector: -0.0414473452\n      vector: 0.0346236937\n      vector: 0.00468268059\n      vector: -0.000171230145\n      vector: -0.0555126853\n      vector: -0.0213408619\n      vector: -0.00562082976\n      vector: -0.042139709\n      vector: 0.00932554808\n      vector: 0.0544001274\n      vector: 0.0186972376\n      vector: 0.0127014797\n      vector: 0.0039651487\n      vector: 0.0317394622\n      vector: 0.00775914779\n      vector: -0.0223883521\n      vector: -0.0120635182\n      vector: 0.0196055751\n      vector: 0.0291586574\n      vector: 0.0337944\n      num_dimensions: 768\n    }\n  }\n}\noutputs {\n  id: "ce36cd3d9aa645338238341bfbdfcf45"\n  status {\n    code: SUCCESS\n    description: "Ok"\n  }\n  created_at {\n    seconds: 1700723375\n    nanos: 640238148\n  }\n  model {\n    id: "multilingual-text-clustering"\n    name: "multilingual-text-clustering"\n    created_at {\n      seconds: 1607379316\n      nanos: 936028000\n    }\n    modified_at {\n      seconds: 1657111032\n      nanos: 332505000\n    }\n    app_id: "main"\n    model_version {\n      id: "f3f0dbe5e9ec4072ae4aa2794021982b"\n      created_at {\n        seconds: 1607365607\n        nanos: 249885000\n      }\n      status {\n        code: MODEL_TRAINED\n        description: "Model is trained and ready"\n      }\n      visibility {\n        gettable: PUBLIC\n      }\n      app_id: "main"\n      user_id: "clarifai"\n      metadata {\n      }\n    }\n    user_id: "clarifai"\n    model_type_id: "clusterer"\n    visibility {\n      gettable: PUBLIC\n    }\n    workflow_recommended {\n    }\n  }\n  data {\n    clusters {\n      id: "9_17"\n      projection: 0.210836634\n      projection: -0.248410583\n    }\n  }\n}\n',b='######################################################################################################\n# In this section, we set the user authentication, user and app ID, workflow ID, video input,\n# and sample_ms. Change these strings to run your own example.\n######################################################################################################\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "YOUR_USER_ID_HERE"\nAPP_ID = "YOUR_APP_ID_HERE"\n# Change these to make your own predictions\nWORKFLOW_ID = "YOUR_WORKFLOW_ID_HERE"\nVIDEO_URL = "https://samples.clarifai.com/beer.mp4"\n# Or, to use a local video file, assign the location variable\n# VIDEO_FILE_LOCATION = "YOUR_VIDEO_FILE_LOCATION_HERE"\n# Change this to configure the FPS rate (If it\'s not configured, it defaults to 1 FPS) \nSAMPLE_MS = 500\n\n############################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n############################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (("authorization", "Key " + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\n# To use a local video file, uncomment the following lines\n# with open(VIDEO_FILE_LOCATION, "rb") as f:\n   # file_bytes = f.read()\n\npost_workflow_results_response = stub.PostWorkflowResults(\n    service_pb2.PostWorkflowResultsRequest(\n        user_app_id=userDataObject,\n        workflow_id=WORKFLOW_ID,\n        inputs=[\n            resources_pb2.Input(\n                data=resources_pb2.Data(\n                    video=resources_pb2.Video(\n                        url=VIDEO_URL,\n                        # base64=file_bytes\n                    )\n                )\n            )\n        ],\n        output_config=resources_pb2.OutputConfig(\n            sample_ms=SAMPLE_MS\n        )\n    ),\n    metadata=metadata,\n)\nif post_workflow_results_response.status.code != status_code_pb2.SUCCESS:\n    print(post_workflow_results_response.status)\n    raise Exception(\n        "Post workflow results failed, status: "\n        + post_workflow_results_response.status.description\n    )\n\n# We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here one WorkflowResult\nresults = post_workflow_results_response.results[0]\n\n# Uncomment this line to print the raw output\nprint(results)\n',R='\x3c!--index.html file--\x3e\n\n<script>\n  ////////////////////////////////////////////////////////////////////////////////////////////////////\n  // In this section, we set the user authentication, user and app ID, workflow ID, video input,\n  // and sample_ms. Change these strings to run your own example.\n  ///////////////////////////////////////////////////////////////////////////////////////////////////\n\n  // Your PAT (Personal Access Token) can be found in the Account\'s Security section\n  const PAT = "YOUR_PAT_HERE";\n  const USER_ID = "YOUR_USER_ID_HERE";\n  const APP_ID = "YOUR_APP_ID_HERE";\n  // Change these to make your own predictions\n  const WORKFLOW_ID = "YOUR_WORKFLOW_ID_HERE";\n  const VIDEO_URL = "https://samples.clarifai.com/beer.mp4";\n  // Change this to configure the FPS rate (If it\'s not configured, it defaults to 1 FPS) \n  const SAMPLE_MS = 500;\n\n  ///////////////////////////////////////////////////////////////////////////////////\n  // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n  /////////////////////////////////////////////////////////////////////////////////// \n\n  const raw = JSON.stringify({\n    "user_app_id": {\n      "user_id": USER_ID,\n      "app_id": APP_ID\n    },\n    "inputs": [\n      {\n        "data": {\n          "video": {            \n            "url": VIDEO_URL\n          }\n        }\n      }\n    ],\n    "output_config": {\n      "sample_ms": SAMPLE_MS\n    }\n  });\n\n  const requestOptions = {\n    method: "POST",\n    headers: {\n      "Accept": "application/json",\n      "Authorization": "Key " + PAT\n    },\n    body: raw\n  };\n\n  fetch(`https://api.clarifai.com/v2/workflows/${WORKFLOW_ID}/results`, requestOptions)\n    .then(response => response.text())\n    .then(result => console.log(result))\n    .catch(error => console.log("error", error));\n\n<\/script>',T='//index.js file\n\n//////////////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, user and app ID, workflow ID, video input,\n// and sample_ms. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////////////////\n\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\nconst PAT = "YOUR_PAT_HERE";\nconst USER_ID = "YOUR_USER_ID_HERE";\nconst APP_ID = "YOUR_APP_ID_HERE";\n// Change these to make your own predictions\nconst WORKFLOW_ID = "YOUR_WORKFLOW_ID_HERE";\nconst VIDEO_URL = "https://samples.clarifai.com/beer.mp4";\n// Or, to use a local video file, assign the location variable\n// const VIDEO_FILE_LOCATION = "YOUR_VIDEO_FILE_LOCATION_HERE"\n// Change this to configure the FPS rate (If it\'s not configured, it defaults to 1 FPS) \nconst SAMPLE_MS = 500;\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\n// To use a local text file, uncomment the following lines\n// const fs = require("fs");\n// const videoBytes = fs.readFileSync(VIDEO_FILE_LOCATION);\n\nstub.PostWorkflowResults({\n    user_app_id: {\n        "user_id": USER_ID,\n        "app_id": APP_ID,\n    },\n    workflow_id: WORKFLOW_ID,\n    inputs: [{\n        data: {\n            video: {\n                url: VIDEO_URL,\n                // base64: videoBytes\n            }\n        }\n    }],\n    output_config: {\n        sample_ms: SAMPLE_MS\n      }  \n},\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error(\n                "Post workflow results failed, status: " + response.status.description\n            );\n        }\n\n        // We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here \n        // one WorkflowResult\n        const results = response.results[0];\n\n        // Uncomment this line to print the raw output\n        console.log(results);\n    }\n);\n',S='package com.clarifai.example;\n\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\n\nimport com.google.protobuf.ByteString;\nimport java.io.File;\nimport java.io.IOException;\nimport java.nio.file.Files;\n\npublic class ClarifaiExample {\n\n    /////////////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, user and app ID, workflow ID, video input,\n    // and sample_ms. Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////////////////////////////\n\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to make your own predictions\n    static final String WORKFLOW_ID = "YOUR_WORKFLOW_ID_HERE";\n    static final String VIDEO_URL = "https://samples.clarifai.com/beer.mp4";\n    // Or, to use a local video file, assign the location variable\n    // static final String VIDEO_FILE_LOCATION = "YOUR_VIDEO_FILE_LOCATION_HERE";\n    // Change this to configure the FPS rate (If it\'s not configured, it defaults to 1 FPS) \n    static final int SAMPLE_MS = 500;\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    public static void main(String[] args) throws IOException {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n                .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        PostWorkflowResultsResponse postWorkflowResultsResponse = stub.postWorkflowResults(\n                PostWorkflowResultsRequest.newBuilder()\n                        .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n                        .setWorkflowId(WORKFLOW_ID)\n                        .addInputs(\n                                Input.newBuilder().setData(\n                                        Data.newBuilder().setVideo(\n                                                Video.newBuilder().setUrl(VIDEO_URL)\n                                        // Video.newBuilder().setBase64(ByteString.copyFrom(Files.readAllBytes(\n                                        // new File(VIDEO_FILE_LOCATION).toPath()\n                                        //)))\n                                        )\n                                )\n                        )\n                        .setOutputConfig(OutputConfig.newBuilder()\n                        \t.setSampleMs(SAMPLE_MS)                        \t\t\n                        )\n                        .build()\n        );\n\n        if (postWorkflowResultsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post workflow results failed, status: " + postWorkflowResultsResponse.getStatus());\n        }\n\n        // We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here\n        // one WorkflowResult\n        WorkflowResult results = postWorkflowResultsResponse.getResults(0);\n\n        // Uncomment this line to print the raw output\n        System.out.println(results);\n    }\n\n}\n',P='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/workflows/YOUR_WORKFLOW_ID_HERE/results" \\\n  -H "authorization: Key YOUR_PAT_HERE" \\\n  -H "content-type: application/json" \\\n  -d \'{\n    "inputs": [\n        {\n          "data": {\n            "video": {\n              "url": "https://samples.clarifai.com/beer.mp4"\n          }\n        }\n      }\n    ],\n    "output_config": {\n        "sample_ms": 500\n    }\n}\'',D='<?php\n\nrequire __DIR__ . "/vendor/autoload.php";\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, user and app ID, workflow ID, video input,\n// and sample_ms. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////////////////\n\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\n$PAT = "YOUR_PAT_HERE";\n$USER_ID = "YOUR_USER_ID_HERE";\n$APP_ID = "YOUR_APP_ID_HERE";\n// Change these to make your own predictions\n$WORKFLOW_ID = "YOUR_WORKFLOW_ID_HERE";\n$VIDEO_URL = "https://samples.clarifai.com/beer.mp4";\n# Or, to use a local video file, assign the location variable\n# $VIDEO_FILE_LOCATION = "YOUR_VIDEO_FILE_LOCATION_HERE";\n# Change this to configure the FPS rate (If it\'s not configured, it defaults to 1 FPS) \n$SAMPLE_MS = 500;\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nuse Clarifai\\ClarifaiClient;\nuse Clarifai\\Api\\Data;\nuse Clarifai\\Api\\Video;\nuse Clarifai\\Api\\Input;\nuse Clarifai\\Api\\PostWorkflowResultsRequest;\nuse Clarifai\\Api\\Status\\StatusCode;\nuse Clarifai\\Api\\UserAppIDSet;\nuse Clarifai\\Api\\OutputConfig;\n\n$client = ClarifaiClient::grpc();\n\n$metadata = ["Authorization" => ["Key " . $PAT]];\n\n$userDataObject = new UserAppIDSet([\n    "user_id" => $USER_ID,\n    "app_id" => $APP_ID,\n]);\n\n// To use a local text file, uncomment the following lines\n// $videoData = file_get_contents($VIDEO_FILE_LOCATION); \n\n// Let\'s make a RPC call to the Clarifai platform. It uses the opened gRPC client channel to communicate a\n// request and then wait for the response\n[$response, $status] = $client\n    ->PostWorkflowResults(\n        // The request object carries the request along with the request status and other metadata related to the request itself\n        new PostWorkflowResultsRequest([\n            "user_app_id" => $userDataObject,\n            "workflow_id" => $WORKFLOW_ID,\n            "inputs" => [\n                new Input([\n                    // The Input object wraps the Data object in order to meet the API specification\n                    "data" => new Data([\n                        // The Data object is constructed around the Video object. It offers a container that has additional independent\n                        // metadata. In this particular use case, no other metadata is needed to be specified\n                        "video" => new Video([\n                            // In the Clarifai platform, a Video is defined by a special Video object                            \n                            "url" => $VIDEO_URL\n                            // "base64" => $videoData \n                        ]),\n                    ]),\n                ]),\n            ],\n            "output_config" => new OutputConfig([\n                "sample_ms" => $SAMPLE_MS\n            ])\n        ]),\n        $metadata\n    )\n    ->wait();\n\n// A response is returned and the first thing we do is check the status of it\n// A successful response will have a status code of 0; otherwise, there is some error\nif ($status->code !== 0) {\n    throw new Exception("Error: {$status->details}");\n}\n// In addition to the RPC response status, there is a Clarifai API status that reports if the operation was a success or failure\n// (not just that the communication was successful)\nif ($response->getStatus()->getCode() != StatusCode::SUCCESS) {\n    throw new Exception(\n        "Failure response: " .\n            $response->getStatus()->getDescription() .\n            " " .\n            $response->getStatus()->getDetails()\n    );\n}\n\n// We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here one WorkflowResult\n$results = $response->getResults()[0];\n\n// Uncomment this line to print the raw output\nprint_r($results);\n\n?>',C='###########################################################################################\n# In this section, we set the user authentication, user and app ID, workflow ID, and\n# audio URL. Change these strings to run your own example.\n##########################################################################################\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nUSER_ID = "clarifai"\nAPP_ID = "main"\n# Change these to make your own predictions\nWORKFLOW_ID = "asr-sentiment"\nAUDIO_URL = "https://samples.clarifai.com/negative_sentence_1.wav"\n# Or, to use a local audio file, assign the location variable\n# AUDIO_FILE_LOCATION = "YOUR_AUDIO_FILE_LOCATION_HERE"\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (("authorization", "Key " + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(\n    user_id=USER_ID, app_id=APP_ID\n)  # The userDataObject is required when using a PAT\n\n# To use a local video file, uncomment the following lines\n# with open(AUDIO_FILE_LOCATION, "rb") as f:\n# audio_bytes = f.read()\n\npost_workflow_results_response = stub.PostWorkflowResults(\n    service_pb2.PostWorkflowResultsRequest(\n        user_app_id=userDataObject,\n        workflow_id=WORKFLOW_ID,\n        inputs=[\n            resources_pb2.Input(\n                data=resources_pb2.Data(\n                    audio=resources_pb2.Audio(\n                        url=AUDIO_URL,\n                        # base64=audio_bytes\n                    )\n                )\n            )\n        ],\n    ),\n    metadata=metadata,\n)\nif post_workflow_results_response.status.code != status_code_pb2.SUCCESS:\n    print(post_workflow_results_response.status)\n    raise Exception(\n        "Post workflow results failed, status: "\n        + post_workflow_results_response.status.description\n    )\n\n# We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here one WorkflowResult\nresults = post_workflow_results_response.results[0]\n\n# Each model we have in the workflow will produce its output\nfor output in results.outputs:\n    model = output.model\n    print("Output for the model: `%s`" % model.id)\n    for concept in output.data.concepts:\n        print("\\t%s %.2f" % (concept.name, concept.value))\n    print(output.data.text.raw)\n\n# Uncomment this line to print the raw output\n# print(results)\n',L='\x3c!--index.html file--\x3e\n\n<script>\n  ////////////////////////////////////////////////////////////////////////////////////////////////////\n  // In this section, we set the user authentication, user and app ID, workflow ID, and\n  // audio URL. Change these strings to run your own example.\n  ///////////////////////////////////////////////////////////////////////////////////////////////////\n\n  // Your PAT (Personal Access Token) can be found in the Account\'s Security section\n  const PAT = "YOUR_PAT_HERE";\n  const USER_ID = "clarifai";\n  const APP_ID = "main";\n  // Change these to make your own predictions\n  const WORKFLOW_ID = "asr-sentiment";\n  const AUDIO_URL = "https://samples.clarifai.com/negative_sentence_1.wav";\n\n  ///////////////////////////////////////////////////////////////////////////////////\n  // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n  /////////////////////////////////////////////////////////////////////////////////// \n\n  const raw = JSON.stringify({\n    "user_app_id": {\n      "user_id": USER_ID,\n      "app_id": APP_ID\n    },\n    "inputs": [\n      {\n        "data": {\n          "audio": {            \n            "url": AUDIO_URL\n          }\n        }\n      }\n    ]\n  });\n\n  const requestOptions = {\n    method: "POST",\n    headers: {\n      "Accept": "application/json",\n      "Authorization": "Key " + PAT\n    },\n    body: raw\n  };\n\n  fetch(`https://api.clarifai.com/v2/workflows/${WORKFLOW_ID}/results`, requestOptions)\n    .then(response => response.text())\n    .then(result => console.log(result))\n    .catch(error => console.log("error", error));\n\n<\/script>',k='\n//index.js file\n\n//////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, user and app ID, workflow ID, and\n// audio URL. Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////\n\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\nconst PAT = "YOUR_PAT_HERE";\nconst USER_ID = "clarifai";\nconst APP_ID = "main";\n// Change these to make your own predictions\nconst WORKFLOW_ID = "asr-sentiment";\nconst AUDIO_URL = "https://samples.clarifai.com/negative_sentence_1.wav";\n// Or, to use a local audio file, assign the location variable\n// const AUDIO_FILE_LOCATION = "YOUR_AUDIO_FILE_LOCATION_HERE";\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\n// To use a local text file, uncomment the following lines\n// const fs = require("fs");\n// const audioBytes = fs.readFileSync(AUDIO_FILE_LOCATION);\n\nstub.PostWorkflowResults(\n    {\n        user_app_id: {\n            "user_id": USER_ID,\n            "app_id": APP_ID,\n        },\n        workflow_id: WORKFLOW_ID,\n        inputs: [{\n            data: {\n                audio: {\n                    url: AUDIO_URL,\n                    // base64: audioBytes\n                }\n            }\n        }],\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error(\n                "Post workflow results failed, status: " + response.status.description\n            );\n        }\n\n        // We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here \n        // one WorkflowResult\n        const results = response.results[0];\n\n        // Each model we have in the workflow will produce its output   \n        for (const output of results.outputs) {\n            const model = output.model;\n            console.log("Output for the model: `" + model.id + "`");\n            for (const concept of output.data.concepts) {\n                console.log("\\t" + concept.name + " " + concept.value);\n            }\n            if (output.data.text) {\n                console.log(output.data.text.raw);\n            }\n        }\n    }\n);\n',x='package com.clarifai.example;\n\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\n\nimport com.google.protobuf.ByteString;\nimport java.io.File;\nimport java.io.IOException;\nimport java.nio.file.Files;\n\npublic class ClarifaiExample {\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, workflow ID, and\n    // audio URL. Change these strings to run your own example.\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String USER_ID = "clarifai";\n    static final String APP_ID = "main";\n    // Change these to make your own predictions\n    static final String WORKFLOW_ID = "asr-sentiment";\n    static final String AUDIO_URL = "https://samples.clarifai.com/negative_sentence_1.wav";\n    // Or, to use a local audio file, assign the location variable\n    // static final String AUDIO_FILE_LOCATION = "YOUR_IMAGE_FILE_LOCATION_HERE";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    public static void main(String[] args) throws IOException {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n                .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        PostWorkflowResultsResponse postWorkflowResultsResponse = stub.postWorkflowResults(\n                PostWorkflowResultsRequest.newBuilder()\n                        .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n                        .setWorkflowId(WORKFLOW_ID)\n                        .addInputs(\n                                Input.newBuilder().setData(\n                                        Data.newBuilder().setAudio(\n                                                Audio.newBuilder().setUrl(AUDIO_URL)\n                                        //  To use a local text file, uncomment the following lines\n                                        //Audio.newBuilder().setBase64(ByteString.copyFrom(Files.readAllBytes(\n                                        // new File(AUDIO_FILE_LOCATION).toPath()\n                                        //)))\n                                        )\n                                )\n                        )\n                        .build()\n        );\n\n        if (postWorkflowResultsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post workflow results failed, status: " + postWorkflowResultsResponse.getStatus());\n        }\n\n        // We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here\n        // one WorkflowResult\n        WorkflowResult results = postWorkflowResultsResponse.getResults(0);\n\n        // Each model we have in the workflow will produce its output\n        for (Output output : results.getOutputsList()) {\n            Model model = output.getModel();\n            System.out.println("Output for the model: `" + model.getId() + "`");\n            for (Concept concept : output.getData().getConceptsList()) {\n                System.out.printf("%s %.2f%n", concept.getName(), concept.getValue());\n            }\n            System.out.println(output.getData().getText().getRaw());\n        }\n\n    }\n\n}\n',U='curl -X POST "https://api.clarifai.com/v2/users/clarifai/apps/main/workflows/asr-sentiment/results" \\\n  -H "authorization: Key YOUR_PAT_HERE" \\\n  -H "content-type: application/json" \\\n  -d \'{\n    "inputs": [\n        {\n          "data": {\n            "audio": {\n              "url": "https://samples.clarifai.com/negative_sentence_1.wav"\n          }\n        }\n      }\n    ]\n}\'',y='<?php\n\nrequire __DIR__ . "/vendor/autoload.php";\n\n///////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, user and app ID, workflow ID, and\n// audio URL. Change these strings to run your own example.\n////////////////////////////////////////////////////////////////////////////////////////////\n\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\n$PAT = "YOUR_PAT_HERE";\n$USER_ID = "clarifai";\n$APP_ID = "main";\n// Change these to make your own predictions\n$WORKFLOW_ID = "asr-sentiment";\n$AUDIO_URL = "https://samples.clarifai.com/negative_sentence_1.wav";\n# Or, to use a local audio file, assign the location variable\n# $AUDIO_FILE_LOCATION = "YOUR_AUDIO_FILE_LOCATION_HERE";\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nuse Clarifai\\ClarifaiClient;\nuse Clarifai\\Api\\Data;\nuse Clarifai\\Api\\Audio;\nuse Clarifai\\Api\\Input;\nuse Clarifai\\Api\\PostWorkflowResultsRequest;\nuse Clarifai\\Api\\Status\\StatusCode;\nuse Clarifai\\Api\\UserAppIDSet;\n\n$client = ClarifaiClient::grpc();\n\n$metadata = ["Authorization" => ["Key " . $PAT]];\n\n$userDataObject = new UserAppIDSet([\n    "user_id" => $USER_ID,\n    "app_id" => $APP_ID,\n]);\n\n// To use a local text file, uncomment the following lines\n//$audioData = file_get_contents($AUDIO_FILE_LOCATION);\n\n// Let\'s make a RPC call to the Clarifai platform. It uses the opened gRPC client channel to communicate a\n// request and then wait for the response\n[$response, $status] = $client\n    ->PostWorkflowResults(\n        // The request object carries the request along with the request status and other metadata related to the request itself\n        new PostWorkflowResultsRequest([\n            "user_app_id" => $userDataObject,\n            "workflow_id" => $WORKFLOW_ID,\n            "inputs" => [\n                new Input([\n                    // The Input object wraps the Data object in order to meet the API specification\n                    "data" => new Data([\n                        // The Data object is constructed around the Audio object. It offers a container that has additional independent\n                        // metadata. In this particular use case, no other metadata is needed to be specified\n                        "audio" => new Audio([\n                            // In the Clarifai platform, a audio is defined by a special Audio object\n                            "url" => $AUDIO_URL,\n                            //"base64" => $audioData\n                        ]),\n                    ]),\n                ]),\n            ],\n        ]),\n        $metadata\n    )\n    ->wait();\n\n// A response is returned and the first thing we do is check the status of it\n// A successful response will have a status code of 0; otherwise, there is some error\nif ($status->code !== 0) {\n    throw new Exception("Error: {$status->details}");\n}\n// In addition to the RPC response status, there is a Clarifai API status that reports if the operation was a success or failure\n// (not just that the communication was successful)\nif ($response->getStatus()->getCode() != StatusCode::SUCCESS) {\n    throw new Exception(\n        "Failure response: " .\n            $response->getStatus()->getDescription() .\n            " " .\n            $response->getStatus()->getDetails()\n    );\n}\n\n// We\'ll get one WorkflowResult for each input we used above. Because of one input, we have here one WorkflowResult\n$results = $response->getResults()[0];\n\n// Each model we have in the workflow will produce its output\nforeach ($results->getOutputs() as $output) {\n    $model = $output->getModel();\n    echo "Output for the model: `" . $model->getId() . "`" . "<br>";\n    foreach ($output->getData()->getConcepts() as $concept) {\n        echo $concept->getName() .\n            " " .\n            number_format($concept->getValue(), 2) .\n            "<br>";\n    }\n    $textData = $output->getData()->getText();\n\n    if ($textData !== null) {\n        echo $textData->getRaw() . "<br>";\n    }\n}\n\n// Uncomment this line to print the raw output\n// echo $results->serializeToJsonString();\n',N="Output for the model: `asr-wav2vec2-large-robust-ft-swbd-300h-english`\nI AM NOT FLYING TO ENGLAND\nOutput for the model: `sentiment-analysis-twitter-roberta-base`\n        LABEL_0 0.92\n        LABEL_1 0.07\n        LABEL_2 0.01",j='status {\n  code: SUCCESS\n  description: "Ok"\n}\ninput {\n  id: "c7b258c785614694bc1d9982e847e327"\n  data {\n    audio {\n      url: "https://samples.clarifai.com/negative_sentence_1.wav"\n    }\n  }\n}\noutputs {\n  id: "b562c938bb4545199a6908eabd8f6295"\n  status {\n    code: SUCCESS\n    description: "Ok"\n  }\n  created_at {\n    seconds: 1700762370\n    nanos: 800729365\n  }\n  model {\n    id: "asr-wav2vec2-large-robust-ft-swbd-300h-english"\n    name: "wav2vec2-large-robust-ft-swbd-300"\n    created_at {\n      seconds: 1636021464\n      nanos: 884891000\n    }\n    modified_at {\n      seconds: 1659644487\n      nanos: 107647000\n    }\n    app_id: "asr"\n    model_version {\n      id: "7adce5efc90744ed986fbd0bdc40000f"\n      created_at {\n        seconds: 1638786626\n        nanos: 104602000\n      }\n      status {\n        code: MODEL_TRAINED\n        description: "Model is trained and ready"\n      }\n      visibility {\n        gettable: PUBLIC\n      }\n      app_id: "asr"\n      user_id: "facebook"\n      metadata {\n      }\n      license: "Apache-2.0"\n    }\n    user_id: "facebook"\n    model_type_id: "audio-to-text"\n    visibility {\n      gettable: PUBLIC\n    }\n    workflow_recommended {\n    }\n  }\n  data {\n    text {\n      raw: "I AM NOT FLYING TO ENGLAND"\n      text_info {\n        encoding: "UnknownTextEnc"\n      }\n    }\n  }\n}\noutputs {\n  id: "1a3815e9c46b425e8247a4c491cfa0f2"\n  status {\n    code: SUCCESS\n    description: "Ok"\n  }\n  created_at {\n    seconds: 1700762370\n    nanos: 800742640\n  }\n  model {\n    id: "sentiment-analysis-twitter-roberta-base"\n    name: "sentiment-analysis-twitter-roberta-base"\n    created_at {\n      seconds: 1656525158\n      nanos: 299847000\n    }\n    modified_at {\n      seconds: 1659564125\n      nanos: 82152000\n    }\n    app_id: "text-classification"\n    model_version {\n      id: "f7f3df02b79d4080a0233ec1fb6404bd"\n      created_at {\n        seconds: 1656525158\n        nanos: 310142000\n      }\n      status {\n        code: MODEL_TRAINED\n        description: "Model is trained and ready"\n      }\n      visibility {\n        gettable: PUBLIC\n      }\n      app_id: "text-classification"\n      user_id: "erfan"\n      metadata {\n        fields {\n          key: "Model version logs zipped"\n          value {\n            string_value: "https://s3.amazonaws.com/clarifai-temp/prod/f7f3df02b79d4080a0233ec1fb6404bd.zip"\n          }\n        }\n      }\n    }\n    user_id: "erfan"\n    model_type_id: "text-classifier"\n    task: "text-classification"\n    visibility {\n      gettable: PUBLIC\n    }\n    workflow_recommended {\n    }\n  }\n  data {\n    concepts {\n      id: "LABEL_0"\n      name: "LABEL_0"\n      value: 0.91823113\n      app_id: "text-classification"\n    }\n    concepts {\n      id: "LABEL_1"\n      name: "LABEL_1"\n      value: 0.0743510351\n      app_id: "text-classification"\n    }\n    concepts {\n      id: "LABEL_2"\n      name: "LABEL_2"\n      value: 0.00741776684\n      app_id: "text-classification"\n    }\n  }\n}',W={description:"Make predictions with your workflows.",sidebar_position:3},$="Workflow Predict",F={id:"api-guide/workflows/workflow-predict",title:"Workflow Predict",description:"Make predictions with your workflows.",source:"@site/docs/api-guide/workflows/workflow-predict.md",sourceDirName:"api-guide/workflows",slug:"/api-guide/workflows/workflow-predict",permalink:"/api-guide/workflows/workflow-predict",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/api-guide/workflows/workflow-predict.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{description:"Make predictions with your workflows.",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Create, Get, Update, Delete",permalink:"/api-guide/workflows/create-get-update-delete"},next:{title:"Common Workflows Examples",permalink:"/api-guide/workflows/common-workflows/"}},H={},B=[{value:"Images",id:"images",level:2},{value:"Videos",id:"videos",level:2},{value:"Text",id:"text",level:2},{value:"Audio",id:"audio",level:2}];function Y(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"workflow-predict",children:"Workflow Predict"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Make predictions with your workflows"})}),"\n",(0,o.jsx)("hr",{}),"\n",(0,o.jsx)(n.p,{children:"The Workflow Predict API allows you make predictions using one or more models, whether they are Clarifai's pre-built models or custom creations \u2014 all in a single API call."}),"\n",(0,o.jsx)(n.p,{children:"The maximum number of inputs that can be processed at once with any given workflow is 32."}),"\n",(0,o.jsxs)(n.p,{children:["After you're set up, you can initiate predictions under a specific workflow by utilizing the ",(0,o.jsx)(n.code,{children:"POST /v2/workflows/WORKFLOW_ID_HERE/results"})," endpoint, where ",(0,o.jsx)(n.code,{children:"WORKFLOW_ID_HERE"})," corresponds to the unique ID you assigned to your workflow."]}),"\n",(0,o.jsxs)(n.p,{children:["When crafting the request body, its layout remains consistent with the usual approach for making a prediction call. The response body will include a ",(0,o.jsx)(n.code,{children:"results"})," object, with each sub-object representing a response from the models, maintaining the same order as specified in the workflow you configured."]}),"\n",(0,o.jsxs)(n.p,{children:["You can also use the ",(0,o.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/workflows/working-with-workflows",children:"Workflow Builder"})," in the Clarifai Portal to build your workflows and see the results of their predictions on a given input."]}),"\n",(0,o.jsx)(n.admonition,{type:"info",children:(0,o.jsxs)(n.p,{children:["The initialization code used in the following example is outlined in detail on the ",(0,o.jsx)(n.a,{href:"https://docs.clarifai.com/api-guide/api-overview/api-clients/#client-installation-instructions",children:"client installation page."})]})}),"\n","\n","\n","\n","\n","\n","\n","\n","\n",(0,o.jsx)(n.admonition,{type:"tip",children:(0,o.jsxs)(n.p,{children:["If you want to make a predict call with an external workflow that is outside the scope of your app, you need to use a PAT while specifying the ",(0,o.jsx)(n.code,{children:"app_id"})," and the ",(0,o.jsx)(n.code,{children:"user_id"})," associated with the workflow you want to use."]})}),"\n",(0,o.jsx)(n.h2,{id:"images",children:"Images"}),"\n",(0,o.jsxs)(n.p,{children:["Let's illustrate how you would get predictions from image inputs using Clarifai's ",(0,o.jsx)(n.a,{href:"https://clarifai.com/clarifai/main/workflows/Face-Sentiment",children:"Face-Sentiment"})," workflow. The workflow combines these three models:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"A visual detector model that detects bounding box regions in an image;"}),"\n",(0,o.jsx)(n.li,{children:"An image cropper model that extracts the specific region of interest from an image;"}),"\n",(0,o.jsx)(n.li,{children:"A visual classifier model that classifies an image into a set of concepts."}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["Note that the ",(0,o.jsx)(n.code,{children:"base64"})," output representation of the image in bytes is already in binary format. It is not encoded, so you do not need to decode it for further downstream tasks."]}),"\n",(0,o.jsxs)(c.A,{children:[(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(a.A,{className:"language-python",children:i})}),(0,o.jsx)(s.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,o.jsx)(a.A,{className:"language-javascript",children:l})}),(0,o.jsx)(s.A,{value:"nodejs",label:"NodeJS",children:(0,o.jsx)(a.A,{className:"language-javascript",children:v})}),(0,o.jsx)(s.A,{value:"java",label:"Java",children:(0,o.jsx)(a.A,{className:"language-java",children:u})}),(0,o.jsx)(s.A,{value:"php",label:"PHP",children:(0,o.jsx)(a.A,{className:"language-php",children:p})}),(0,o.jsx)(s.A,{value:"curl",label:"cURL",children:(0,o.jsx)(a.A,{className:"language-bash",children:d})})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Text Output Example"}),(0,o.jsx)(a.A,{className:"language-text",children:f})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Raw Output Example"}),(0,o.jsx)(a.A,{className:"language-javascript",children:h})]}),"\n",(0,o.jsx)(n.h2,{id:"videos",children:"Videos"}),"\n",(0,o.jsx)(n.p,{children:"When you input a video into the Workflow Predict API, the response includes a list of predicted concepts for each frame of the video. By default, the video is processed at 1 frame per second (FPS), but this rate can be customized in the predict request. This means you\u2019ll receive a set of concepts for every second (1000 milliseconds) of your video."}),"\n",(0,o.jsxs)(n.p,{children:["To adjust the FPS rate, use the ",(0,o.jsx)(n.code,{children:"sample_ms"})," parameter in your predict request. The ",(0,o.jsx)(n.code,{children:"sample_ms"})," value specifies the time interval (in milliseconds) between frames selected for inference, determining how frequently frames are processed."]}),"\n",(0,o.jsxs)(n.p,{children:["The valid range for ",(0,o.jsx)(n.code,{children:"sample_ms"})," is between 100 and 60,000 milliseconds."]}),"\n",(0,o.jsxs)(n.admonition,{type:"tip",children:[(0,o.jsx)(n.mdxAdmonitionTitle,{}),(0,o.jsx)(n.p,{children:"FPS is calculated as: FPS = 1000 / sample_ms"})]}),"\n",(0,o.jsxs)(n.p,{children:["For example, if ",(0,o.jsx)(n.code,{children:"sample_ms"})," is set to 1000, the FPS rate will be 1 (the default value)."]}),"\n",(0,o.jsx)(n.p,{children:"The Workflow Predict API has size and duration limitations for video inputs:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Videos uploaded via URL can be up to 100 MB in size or 10 minutes in length."}),"\n",(0,o.jsx)(n.li,{children:"Videos sent as byte data are limited to 10 MB in size."}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["If your video exceeds these limits, you can refer to ",(0,o.jsx)(n.a,{href:"https://www.clarifai.com/blog/splitting-video-into-smaller-pieces",children:"this tutorial"})," on splitting large videos into smaller segments for processing. Exceeding these limits may cause the process to time out and result in an error response."]}),"\n",(0,o.jsxs)(c.A,{children:[(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(a.A,{className:"language-python",children:b})}),(0,o.jsx)(s.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,o.jsx)(a.A,{className:"language-javascript",children:R})}),(0,o.jsx)(s.A,{value:"nodejs",label:"NodeJS",children:(0,o.jsx)(a.A,{className:"language-javascript",children:T})}),(0,o.jsx)(s.A,{value:"java",label:"Java",children:(0,o.jsx)(a.A,{className:"language-java",children:S})}),(0,o.jsx)(s.A,{value:"php",label:"PHP",children:(0,o.jsx)(a.A,{className:"language-php",children:D})}),(0,o.jsx)(s.A,{value:"curl",label:"cURL",children:(0,o.jsx)(a.A,{className:"language-bash",children:P})})]}),"\n",(0,o.jsx)(n.h2,{id:"text",children:"Text"}),"\n",(0,o.jsxs)(n.p,{children:["Let's illustrate how you would produce embeddings and clusters from text inputs using Clarifai's ",(0,o.jsx)(n.a,{href:"https://clarifai.com/clarifai/main/workflows/Language-Understanding",children:"Language-Understanding"})," text workflow."]}),"\n",(0,o.jsxs)(c.A,{children:[(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(a.A,{className:"language-python",children:_})}),(0,o.jsx)(s.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,o.jsx)(a.A,{className:"language-javascript",children:m})}),(0,o.jsx)(s.A,{value:"nodejs",label:"NodeJS",children:(0,o.jsx)(a.A,{className:"language-javascript",children:w})}),(0,o.jsx)(s.A,{value:"java",label:"Java",children:(0,o.jsx)(a.A,{className:"language-java",children:g})}),(0,o.jsx)(s.A,{value:"php",label:"PHP",children:(0,o.jsx)(a.A,{className:"language-php",children:E})}),(0,o.jsx)(s.A,{value:"curl",label:"cURL",children:(0,o.jsx)(a.A,{className:"language-bash",children:I})})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Text Output Example"}),(0,o.jsx)(a.A,{className:"language-text",children:A})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Raw Output Example"}),(0,o.jsx)(a.A,{className:"language-javascript",children:O})]}),"\n",(0,o.jsx)(n.h2,{id:"audio",children:"Audio"}),"\n",(0,o.jsxs)(n.p,{children:["Let's illustrate how you would get the sentiment of an audio input using Clarifai's ",(0,o.jsx)(n.a,{href:"https://clarifai.com/clarifai/main/workflows/asr-sentiment",children:"asr-sentiment"})," workflow."]}),"\n",(0,o.jsxs)(c.A,{children:[(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(a.A,{className:"language-python",children:C})}),(0,o.jsx)(s.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,o.jsx)(a.A,{className:"language-javascript",children:L})}),(0,o.jsx)(s.A,{value:"nodejs",label:"NodeJS",children:(0,o.jsx)(a.A,{className:"language-javascript",children:k})}),(0,o.jsx)(s.A,{value:"java",label:"Java",children:(0,o.jsx)(a.A,{className:"language-java",children:x})}),(0,o.jsx)(s.A,{value:"php",label:"PHP",children:(0,o.jsx)(a.A,{className:"language-php",children:y})}),(0,o.jsx)(s.A,{value:"curl",label:"cURL",children:(0,o.jsx)(a.A,{className:"language-bash",children:U})})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Text Output Example"}),(0,o.jsx)(a.A,{className:"language-text",children:N})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Raw Output Example"}),(0,o.jsx)(a.A,{className:"language-javascript",children:j})]})]})}function M(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(Y,{...e})}):Y(e)}},19365:(e,n,t)=>{t.d(n,{A:()=>s});t(96540);var o=t(18215);const r={tabItem:"tabItem_Ymn6"};var c=t(74848);function s(e){let{children:n,hidden:t,className:s}=e;return(0,c.jsx)("div",{role:"tabpanel",className:(0,o.A)(r.tabItem,s),hidden:t,children:n})}},11470:(e,n,t)=>{t.d(n,{A:()=>A});var o=t(96540),r=t(18215),c=t(23104),s=t(56347),a=t(205),i=t(57485),l=t(31682),v=t(70679);function u(e){return o.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function d(e){const{values:n,children:t}=e;return(0,o.useMemo)((()=>{const e=n??function(e){return u(e).map((e=>{let{props:{value:n,label:t,attributes:o,default:r}}=e;return{value:n,label:t,attributes:o,default:r}}))}(t);return function(e){const n=(0,l.X)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function p(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function f(e){let{queryString:n=!1,groupId:t}=e;const r=(0,s.W6)(),c=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,i.aZ)(c),(0,o.useCallback)((e=>{if(!c)return;const n=new URLSearchParams(r.location.search);n.set(c,e),r.replace({...r.location,search:n.toString()})}),[c,r])]}function h(e){const{defaultValue:n,queryString:t=!1,groupId:r}=e,c=d(e),[s,i]=(0,o.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!p({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const o=t.find((e=>e.default))??t[0];if(!o)throw new Error("Unexpected error: 0 tabValues");return o.value}({defaultValue:n,tabValues:c}))),[l,u]=f({queryString:t,groupId:r}),[h,_]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[r,c]=(0,v.Dv)(t);return[r,(0,o.useCallback)((e=>{t&&c.set(e)}),[t,c])]}({groupId:r}),m=(()=>{const e=l??h;return p({value:e,tabValues:c})?e:null})();(0,a.A)((()=>{m&&i(m)}),[m]);return{selectedValue:s,selectValue:(0,o.useCallback)((e=>{if(!p({value:e,tabValues:c}))throw new Error(`Can't select invalid tab value=${e}`);i(e),u(e),_(e)}),[u,_,c]),tabValues:c}}var _=t(92303);const m={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var w=t(74848);function g(e){let{className:n,block:t,selectedValue:o,selectValue:s,tabValues:a}=e;const i=[],{blockElementScrollPositionUntilNextRender:l}=(0,c.a_)(),v=e=>{const n=e.currentTarget,t=i.indexOf(n),r=a[t].value;r!==o&&(l(n),s(r))},u=e=>{let n=null;switch(e.key){case"Enter":v(e);break;case"ArrowRight":{const t=i.indexOf(e.currentTarget)+1;n=i[t]??i[0];break}case"ArrowLeft":{const t=i.indexOf(e.currentTarget)-1;n=i[t]??i[i.length-1];break}}n?.focus()};return(0,w.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":t},n),children:a.map((e=>{let{value:n,label:t,attributes:c}=e;return(0,w.jsx)("li",{role:"tab",tabIndex:o===n?0:-1,"aria-selected":o===n,ref:e=>i.push(e),onKeyDown:u,onClick:v,...c,className:(0,r.A)("tabs__item",m.tabItem,c?.className,{"tabs__item--active":o===n}),children:t??n},n)}))})}function I(e){let{lazy:n,children:t,selectedValue:r}=e;const c=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=c.find((e=>e.props.value===r));return e?(0,o.cloneElement)(e,{className:"margin-top--md"}):null}return(0,w.jsx)("div",{className:"margin-top--md",children:c.map(((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==r})))})}function E(e){const n=h(e);return(0,w.jsxs)("div",{className:(0,r.A)("tabs-container",m.tabList),children:[(0,w.jsx)(g,{...n,...e}),(0,w.jsx)(I,{...n,...e})]})}function A(e){const n=(0,_.A)();return(0,w.jsx)(E,{...e,children:u(e.children)},String(n))}}}]);