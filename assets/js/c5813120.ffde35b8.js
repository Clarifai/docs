"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[2988],{19365:(e,t,n)=>{n.d(t,{A:()=>i});var o=n(96540),a=n(20053);const r={tabItem:"tabItem_Ymn6"};function i(e){let{children:t,hidden:n,className:i}=e;return o.createElement("div",{role:"tabpanel",className:(0,a.A)(r.tabItem,i),hidden:n},t)}},11470:(e,t,n)=>{n.d(t,{A:()=>A});var o=n(58168),a=n(96540),r=n(20053),i=n(23104),s=n(56347),l=n(57485),u=n(31682),c=n(89466);function d(e){return function(e){return a.Children.map(e,(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:n,attributes:o,default:a}}=e;return{value:t,label:n,attributes:o,default:a}}))}function p(e){const{values:t,children:n}=e;return(0,a.useMemo)((()=>{const e=t??d(n);return function(e){const t=(0,u.X)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function m(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function f(e){let{queryString:t=!1,groupId:n}=e;const o=(0,s.W6)(),r=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,l.aZ)(r),(0,a.useCallback)((e=>{if(!r)return;const t=new URLSearchParams(o.location.search);t.set(r,e),o.replace({...o.location,search:t.toString()})}),[r,o])]}function h(e){const{defaultValue:t,queryString:n=!1,groupId:o}=e,r=p(e),[i,s]=(0,a.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!m({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const o=n.find((e=>e.default))??n[0];if(!o)throw new Error("Unexpected error: 0 tabValues");return o.value}({defaultValue:t,tabValues:r}))),[l,u]=f({queryString:n,groupId:o}),[d,h]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[o,r]=(0,c.Dv)(n);return[o,(0,a.useCallback)((e=>{n&&r.set(e)}),[n,r])]}({groupId:o}),g=(()=>{const e=l??d;return m({value:e,tabValues:r})?e:null})();(0,a.useLayoutEffect)((()=>{g&&s(g)}),[g]);return{selectedValue:i,selectValue:(0,a.useCallback)((e=>{if(!m({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);s(e),u(e),h(e)}),[u,h,r]),tabValues:r}}var g=n(92303);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function y(e){let{className:t,block:n,selectedValue:s,selectValue:l,tabValues:u}=e;const c=[],{blockElementScrollPositionUntilNextRender:d}=(0,i.a_)(),p=e=>{const t=e.currentTarget,n=c.indexOf(t),o=u[n].value;o!==s&&(d(t),l(o))},m=e=>{let t=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{const n=c.indexOf(e.currentTarget)+1;t=c[n]??c[0];break}case"ArrowLeft":{const n=c.indexOf(e.currentTarget)-1;t=c[n]??c[c.length-1];break}}t?.focus()};return a.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},t)},u.map((e=>{let{value:t,label:n,attributes:i}=e;return a.createElement("li",(0,o.A)({role:"tab",tabIndex:s===t?0:-1,"aria-selected":s===t,key:t,ref:e=>c.push(e),onKeyDown:m,onClick:p},i,{className:(0,r.A)("tabs__item",b.tabItem,i?.className,{"tabs__item--active":s===t})}),n??t)})))}function I(e){let{lazy:t,children:n,selectedValue:o}=e;const r=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=r.find((e=>e.props.value===o));return e?(0,a.cloneElement)(e,{className:"margin-top--md"}):null}return a.createElement("div",{className:"margin-top--md"},r.map(((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==o}))))}function v(e){const t=h(e);return a.createElement("div",{className:(0,r.A)("tabs-container",b.tabList)},a.createElement(y,(0,o.A)({},e,t)),a.createElement(I,(0,o.A)({},e,t)))}function A(e){const t=(0,g.A)();return a.createElement(v,(0,o.A)({key:String(t)},e))}},96966:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>f,contentTitle:()=>p,default:()=>y,frontMatter:()=>d,metadata:()=>m,toc:()=>h});var o=n(58168),a=(n(96540),n(15680)),r=n(11470),i=n(19365),s=n(77964);const l='from clarifai.client.model import Model\n\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\n# Specify the correct user_id/app_id pairings\n# Since you\'re making inferences outside your app\'s scope\n#USER_ID = "facebook"\n#APP_ID = "asr"\n\n# You can set the model using model URL or model ID.\n# Change these to whatever model you want to use\n# eg : MODEL_ID = \'asr-wav2vec2-base-960h-english\'\n# You can also set a particular model version by specifying the  version ID\n# eg: MODEL_VERSION_ID = \'model_version\'\n#  Model class objects can be inititalised by providing its URL or also by defining respective user_id, app_id and model_id\n\n# eg : model = Model(user_id="clarifai", app_id="main", model_id=MODEL_ID)\n\naudio_url = "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav"\n\n# The predict API gives the flexibility to generate predictions for data provided through URL, Filepath and bytes format.\n\n# Example for prediction through Bytes:\n# model_prediction = model.predict_by_bytes(audio_bytes, input_type="audio")\n\n\n# Example for prediction through Filepath:\n# model_prediction = Model(model_url).predict_by_filepath(audio_filepath, input_type="audio")\n\nmodel_url = "https://clarifai.com/facebook/asr/models/asr-wav2vec2-large-robust-ft-swbd-300h-english"\n\nmodel_prediction = Model(url=model_url, pat="YOUR_PAT").predict_by_url(\n    audio_url, "audio"\n)\n\n# Print the output\nprint(model_prediction.outputs[0].data.text.raw)\n\n',u='import { Model } from "clarifai-nodejs";\n\n/**\n    Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    Specify the correct userId/appId pairings\n    Since you\'re making inferences outside your app\'s scope\n    USER_ID = "facebook"\n    APP_ID = "asr"\n\n    You can set the model using model URL or model ID.\n    Change these to whatever model you want to use\n    eg : MODEL_ID = \'asr-wav2vec2-base-960h-english\'\n    You can also set a particular model version by specifying the  version ID\n    eg: MODEL_VERSION_ID = "model_version"\n    Model class objects can be initialised by providing its URL or also by defining respective userId, appId and modelId\n\n    eg : \n    const model = new Model({\n        authConfig: {\n            userId: "clarifai",\n            appId: "main",\n            pat: process.env.CLARIFAI_PAT,\n        },\n        modelId: MODEL_ID,\n    });\n\n*/\n\nconst audioUrl =\n  "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav";\n\n/**\n        The predict API gives flexibility to generate predictions for data provided through URL, Filepath and bytes format.\n\n\n        Example for prediction through Bytes:\n        const modelPrediction = await model.predictByBytes({\n                                    inputBytes,\n                                    inputType\n                                });\n\n\n        Example for prediction through Filepath:\n        const modelPrediction = await model.predictByFilepath({\n                                    filepath, \n                                    inputType\n                                });\n    */\n\nconst modelUrl =\n  "https://clarifai.com/facebook/asr/models/asr-wav2vec2-large-robust-ft-swbd-300h-english";\n\n\nconst model = new Model({\n  url: modelUrl,\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n  },\n});\nconst modelPrediction = await model.predictByUrl({\n  url: audioUrl,\n  inputType: "audio",\n});\n\n// Print the output\nconsole.log(modelPrediction?.[0]?.data?.text?.raw);\n',c="GOOD MORNING I THINK THIS IS GOING TO BE A GREAT PRESENTATION",d={sidebar_position:3},p="Audio as Input",m={unversionedId:"sdk/Inference-from-AI-Models/Audio-as-Input",id:"sdk/Inference-from-AI-Models/Audio-as-Input",title:"Audio as Input",description:"Learn how to perform inference with audio as input using Clarifai Python SDK",source:"@site/docs/sdk/Inference-from-AI-Models/Audio-as-Input.md",sourceDirName:"sdk/Inference-from-AI-Models",slug:"/sdk/Inference-from-AI-Models/Audio-as-Input",permalink:"/sdk/Inference-from-AI-Models/Audio-as-Input",draft:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/sdk/Inference-from-AI-Models/Audio-as-Input.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Text as Input",permalink:"/sdk/Inference-from-AI-Models/Text-as-Input"},next:{title:"MultiModal as Input",permalink:"/sdk/Inference-from-AI-Models/Multimodal-as-Input"}},f={},h=[{value:"Audio to Text",id:"audio-to-text",level:2}],g={toc:h},b="wrapper";function y(e){let{components:t,...n}=e;return(0,a.yg)(b,(0,o.A)({},g,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"audio-as-input"},"Audio as Input"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Learn how to perform inference with audio as input using Clarifai Python SDK")),(0,a.yg)("hr",null),(0,a.yg)("p",null,"The Clarifai Python SDK for Audio Processing provides a comprehensive set of tools and functionalities, enabling you to process audio inputs with unparalleled ease and efficiency. Whether you're working on applications related to voice recognition, sound classification, or speech-to-text conversion, our SDK streamlines the development process, allowing you to focus on building cutting-edge functionalities."),(0,a.yg)("h2",{id:"audio-to-text"},"Audio to Text"),(0,a.yg)("p",null,"Harness the power of the Predict API to seamlessly transform audio files into text-based formats using our advanced Automatic Speech Recognition (ASR) ",(0,a.yg)("a",{parentName:"p",href:"https://clarifai.com/explore/models?page=1&perPage=24&filterData=%5B%7B%22field%22%3A%22model_type_id%22%2C%22value%22%3A%5B%22audio-to-text%22%5D%7D%5D"},"model"),". With this functionality, you can effortlessly transcribe spoken words from audio, opening up possibilities for diverse applications such as transcription services, voice command processing, and more."),(0,a.yg)(r.A,{mdxType:"Tabs"},(0,a.yg)(i.A,{value:"python",label:"Python",mdxType:"TabItem"},(0,a.yg)(s.A,{className:"language-python",mdxType:"CodeBlock"},l),(0,a.yg)("details",null,(0,a.yg)("summary",null,"Output"),(0,a.yg)(s.A,{className:"language-text",mdxType:"CodeBlock"},c))),(0,a.yg)(i.A,{value:"typescript",label:"Typescript",mdxType:"TabItem"},(0,a.yg)(s.A,{className:"language-typescript",mdxType:"CodeBlock"},u))))}y.isMDXComponent=!0}}]);