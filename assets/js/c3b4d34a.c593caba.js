"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[3413],{10972:(e,t,r)=>{r.d(t,{A:()=>a});const a=r.p+"assets/images/rag-prompter-2-069d5d935f1cf3ab78632d2dca6eed97.png"},28453:(e,t,r)=>{r.d(t,{R:()=>o,x:()=>s});var a=r(96540);const n={},i=a.createContext(n);function o(e){const t=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:o(e.components),a.createElement(i.Provider,{value:t},e.children)}},28485:(e,t,r)=>{r.d(t,{A:()=>a});const a=r.p+"assets/images/rag-prompter-3-d62dd10d594c8101ec505d34eaf8cada.png"},38980:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>d,contentTitle:()=>s,default:()=>h,frontMatter:()=>o,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"portal-guide/agent-system-operators/rag-prompter","title":"RAG Prompter","description":"Learn how to enhance the quality and relevance of LLM-generated text","source":"@site/docs/portal-guide/agent-system-operators/rag-prompter.md","sourceDirName":"portal-guide/agent-system-operators","slug":"/portal-guide/agent-system-operators/rag-prompter","permalink":"/portal-guide/agent-system-operators/rag-prompter","draft":false,"unlisted":false,"editUrl":"https://github.com/Clarifai/docs/blob/main/docs/portal-guide/agent-system-operators/rag-prompter.md","tags":[],"version":"current","sidebarPosition":1.1,"frontMatter":{"description":"Learn how to enhance the quality and relevance of LLM-generated text","sidebar_position":1.1},"sidebar":"tutorialSidebar","previous":{"title":"Prompter","permalink":"/portal-guide/agent-system-operators/prompter"},"next":{"title":"Filter","permalink":"/portal-guide/agent-system-operators/filter"}}');var n=r(74848),i=r(28453);const o={description:"Learn how to enhance the quality and relevance of LLM-generated text",sidebar_position:1.1},s="RAG Prompter",d={},l=[{value:"How RAG Works",id:"how-rag-works",level:2},{value:"How to Create a RAG Prompter",id:"how-to-create-a-rag-prompter",level:2},{value:"Step 1: Create an Application",id:"step-1-create-an-application",level:3},{value:"Step 2: Upload Data",id:"step-2-upload-data",level:3},{value:"Step 3: Create a Workflow",id:"step-3-create-a-workflow",level:3},{value:"Step 4: Use the Workflow",id:"step-4-use-the-workflow",level:3},{value:"How to Edit a RAG Prompter",id:"how-to-edit-a-rag-prompter",level:2}];function c(e){const t={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"rag-prompter",children:"RAG Prompter"})}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:"Learn how to enhance the quality and relevance of LLM-generated text"})}),"\n",(0,n.jsx)("hr",{}),"\n",(0,n.jsxs)(t.p,{children:["The RAG Prompter is a prompt template operator that leverages the ",(0,n.jsx)(t.a,{href:"https://www.clarifai.com/blog/what-is-rag-retrieval-augmented-generation",children:"Retrieval-Augmented Generation (RAG)"})," technique to improve the performance of Large Language Models (LLMs)."]}),"\n",(0,n.jsx)(t.p,{children:"LLMs have revolutionized natural language understanding across various applications and industries. These models have introduced a new era of quick problem-solving and AI-powered interactions."}),"\n",(0,n.jsx)(t.p,{children:"However, LLMs are often plagued by these two main limitations:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"Most traditional LLMs have a static knowledge base that is limited to a specific period; for example, as of this writing, ChatGPT's knowledge cut-off is in October 2023. This makes them outdated and unable to respond accurately to recent events."}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:'Most traditional LLMs are trained on an extensive, generalized collection of data, which may not be applicable to your specific use case. Whenever LLMs confront voids in their training data, they might generate seemingly plausible yet erroneous information, a phenomenon referred to as "hallucination."'}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"RAG helps solve these issues by incorporating your data into the existing dataset that is accessible to LLMs. With the RAG AI framework, you can retrieve facts from an external knowledge base, thereby anchoring LLMs with the most precise and current information available."}),"\n",(0,n.jsx)(t.p,{children:"Additionally, RAG reduces the necessity for users to continuously train a model on new data and update its parameters to accommodate evolving circumstances. RAG allows users to do much cheaper in-context learning and reduces the need for expensive LLM fine-tuning."}),"\n",(0,n.jsx)(t.admonition,{type:"note",children:(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["The RAG Prompter model type should not be set as an app\u2019s ",(0,n.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/workflows/base-workflows/",children:"base workflow"}),"; otherwise, it would cause a dependency cycle."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsx)(t.p,{children:"This model generates search billable events."}),"\n"]}),"\n"]})}),"\n",(0,n.jsx)(t.h2,{id:"how-rag-works",children:"How RAG Works"}),"\n",(0,n.jsx)(t.p,{children:"As its name implies, RAG works through two phases: retrieval and content generation."}),"\n",(0,n.jsx)(t.p,{children:"When a user uploads external data to be used for RAG purposes into a Clarifai application, the data is first chunked into bite-sized pieces. The chunks are then passed through an embedding model, which transforms the data into indexed vectors and stores them in a vector database."}),"\n",(0,n.jsx)(t.admonition,{type:"info",children:(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.a,{href:"https://docs.clarifai.com/api-guide/predict/embeddings",children:"Embedding models"})," are the type of models usually used to convert data into numerical vectors, while preserving meaningful relationships between them. These vectors are like condensed summaries of the data, capturing its important aspects in a way that machine learning models can understand. By using these vectors, the models can now reason about the data, compare different pieces of information, and perform tasks like similarity search."]})}),"\n",(0,n.jsxs)(t.p,{children:["When an LLM is asked a question, the prompt will first pass through an embedding model and also be converted into a vector. Algorithms will search the Clarifai vector store to ",(0,n.jsx)(t.em,{children:"retrieve"})," the chunks most relevant to that provided user\u2019s prompt."]}),"\n",(0,n.jsx)(t.p,{children:"The most relevant chunks are then appended to the user\u2019s query and served as context \u2013 extending the prompt to the LLM with a lot of background information."}),"\n",(0,n.jsxs)(t.p,{children:["Next, in the generative phase, the LLM leverages the ",(0,n.jsx)(t.em,{children:"augmented"})," prompt along with its internal representation of training data to craft a compelling response tailored to the user's query at that moment."]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{src:"https://www.clarifai.com/hs-fs/hubfs/rag-query-drawio%20(1)-png-2.png?width=2056&height=1334&name=rag-query-drawio%20(1)-png-2.png",alt:""})}),"\n",(0,n.jsxs)(t.p,{children:["Image source: ",(0,n.jsx)(t.a,{href:"https://www.clarifai.com/hs-fs/hubfs/rag-query-drawio%20(1)-png-2.png?width=2056&height=1334&name=rag-query-drawio%20(1)-png-2.png",children:"Clarifai portal"})]}),"\n",(0,n.jsx)(t.h2,{id:"how-to-create-a-rag-prompter",children:"How to Create a RAG Prompter"}),"\n",(0,n.jsx)(t.p,{children:"Let\u2019s demonstrate how you can create a RAG Prompter model on the Clarifai platform."}),"\n",(0,n.jsx)(t.admonition,{title:"objective",type:"note",children:(0,n.jsx)(t.p,{children:"Our intention is to search an app containing textual data for relevant information related to a provided text query. We extract the top k most relevant results from the app, and augment these results into the prompt we provide to the model. By leveraging the additional context, the model should be able to generate a more informative response to the question."})}),"\n",(0,n.jsx)(t.h3,{id:"step-1-create-an-application",children:"Step 1: Create an Application"}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.a,{href:"https://docs.clarifai.com/clarifai-basics/applications/create-an-application/#create-an-application-on-the-portal",children:"Click here"})," to learn how to create an application on the Clarifai portal."]}),"\n",(0,n.jsx)(t.admonition,{title:"Base Workflow",type:"info",children:(0,n.jsxs)(t.p,{children:["When creating the application, select the ",(0,n.jsx)(t.strong,{children:"Text/Document"})," option as the primary input type. And in the collapsible ",(0,n.jsx)(t.strong,{children:"Advanced Settings"})," field, select an embeddings workflow, such as the ",(0,n.jsx)(t.a,{href:"https://clarifai.com/clarifai/main/workflows/baai-general-embedding-base-en",children:"baai-general-embedding-base-en"})," as the ",(0,n.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/workflows/base-workflows/",children:"base workflow"}),". The base workflow will convert the uploaded data into indexed vectors, which makes them searchable \u2013 as explained earlier."]})}),"\n",(0,n.jsx)(t.h3,{id:"step-2-upload-data",children:"Step 2: Upload Data"}),"\n",(0,n.jsxs)(t.p,{children:["Next, upload the external data you want to use to optimize the output of a large language model. ",(0,n.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/inputs-manager/upload-inputs",children:"Click here"})," to learn how you can upload data to your application."]}),"\n",(0,n.jsxs)(t.p,{children:["You can also ",(0,n.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete/#create-datasets",children:"create a dataset"})," and add your inputs to it, then specify the dataset ID when configuring the RAG Prompter. This ensures the RAG Prompter performs context-based searches within the specified dataset, which leads to more accurate and relevant outputs."]}),"\n",(0,n.jsx)(t.p,{children:"If a dataset ID is not specified, the RAG Prompter will search across all inputs in your app, spanning all datasets. This can result in mixed context searches and less precise outputs due to jumbled context hits from unrelated datasets."}),"\n",(0,n.jsx)(t.p,{children:"Similarly, you can attach JSON metadata to your inputs when uploading them to the Clarifai platform. Metadata serve as additional information associated with your inputs and, like dataset IDs, can be used to narrow down search results. By specifying metadata, you can filter search results to match specific conditions, which further improves the relevance and accuracy of the context provided by the RAG Prompter."}),"\n",(0,n.jsx)(t.admonition,{title:"RAG in four lines of code",type:"warning",children:(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.a,{href:"https://www.clarifai.com/blog/retrieval-augmented-generation-rag-in-4-lines-of-code",children:"Click here"})," to learn how to build a RAG system in four lines of code. You\u2019ll also learn how to upload documents seamlessly to your Clarifai application."]})}),"\n",(0,n.jsx)(t.p,{children:"For this example, let's add the following inputs to a dataset in our app:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"The audit findings indicate that $460,000 was expended on machinery repairs during the previous twelve months. \n"})}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"The total expenditure allocated to machinery repairs in the 2022 fiscal year amounted to $500,000. \n"})}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"The expenses for machinery repairs in the year 2021 totaled $550,000, reflecting increased maintenance requirements.\n"})}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"The financial records indicate that $480,000 was disbursed for machinery repairs during 2020 calendar year.\n"})}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"During the 2019 fiscal year, the organization disbursed $475,000 on machinery repairs to ensure operational efficiency. \n"})}),"\n",(0,n.jsx)(t.h3,{id:"step-3-create-a-workflow",children:"Step 3: Create a Workflow"}),"\n",(0,n.jsxs)(t.p,{children:["Go to the ",(0,n.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/workflows/workflow-builder/",children:"workflow builder"}),"."]}),"\n",(0,n.jsxs)(t.p,{children:["Then, search for the ",(0,n.jsx)(t.strong,{children:"rag-prompter"})," node in the left-hand sidebar and drag it onto the empty workspace."]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{src:r(99703).A+"",width:"1916",height:"818"})}),"\n",(0,n.jsx)(t.p,{children:"Use the pop-up that appears on the right-hand sidebar to set up the template text as a single-line statement. For this example, let's use this prompt template text:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"Context information is below: {data.hits} Given the context information and not prior knowledge, answer the query.Query: {data.text.raw} Answer: \n"})}),"\n",(0,n.jsx)(t.admonition,{type:"tip",children:(0,n.jsxs)(t.p,{children:["Your prompt template must include at least one instance of each of these placeholders: ",(0,n.jsx)(t.code,{children:"{data.text.raw}"})," and ",(0,n.jsx)(t.code,{children:"{data.hits}"}),". During inference, all instances of ",(0,n.jsx)(t.code,{children:"{data.text.raw}"})," within the template will be substituted with the user query provided. Similarly, ",(0,n.jsx)(t.code,{children:"{data.hits}"})," will represent a newline-separated list of search results retrieved from your app\u2019s data and ordered by similarity."]})}),"\n",(0,n.jsx)(t.p,{children:"To customize your search experience, you can:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["Adjust the ",(0,n.jsx)(t.code,{children:"min_score"})," parameter if you desire a minimum threshold for search result scores."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["Modify ",(0,n.jsx)(t.code,{children:"max_results"})," to specify the maximum number of relevant search results included in the prompt."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["Provide a comma-separated list of ",(0,n.jsx)(t.code,{children:"dataset_ids"})," or a single dataset ID for the RAG Prompter to search within. This ensures the search results are confined to specific datasets, which improves relevance and precision, as earlier explained."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["Define the ",(0,n.jsx)(t.code,{children:"metadata"})," in JSON format to filter the search results further. Just like specifying a dataset ID, using ",(0,n.jsx)(t.a,{href:"https://docs.clarifai.com/portal-guide/psearch/pfilter/#filter-by-metadata",children:"metadata"})," enhances context generation and boosts the accuracy of the results."]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(t.p,{children:["To finalize creating your workflow, connect the ",(0,n.jsx)(t.strong,{children:"rag-prompter"})," to a text-to-text node, and choose a text-to-text LLM from the Clarifai Community, such as ",(0,n.jsx)(t.a,{href:"https://clarifai.com/openai/chat-completion/models/gpt-4-turbo",children:"GPT-4 Turbo"}),"."]}),"\n",(0,n.jsxs)(t.p,{children:["Then, click the ",(0,n.jsx)(t.strong,{children:"Save Workflow"})," button to save your workflow."]}),"\n",(0,n.jsx)(t.h3,{id:"step-4-use-the-workflow",children:"Step 4: Use the Workflow"}),"\n",(0,n.jsx)(t.p,{children:"After saving the workflow, you\u2019ll be directed to its individual page, where you can start using it."}),"\n",(0,n.jsxs)(t.p,{children:["Click the ",(0,n.jsx)(t.strong,{children:"+"})," button to provide your query text."]}),"\n",(0,n.jsx)(t.p,{children:"For example, you could provide the following as your input text:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"How much was spent on machinery repairs in 2020?\n"})}),"\n",(0,n.jsxs)(t.p,{children:["Click the ",(0,n.jsx)(t.strong,{children:"Submit"})," button."]}),"\n",(0,n.jsx)(t.p,{children:"Once the workflow has completed processing your input, you'll see the results, starting with the earlier template text, now adapted to your input."}),"\n",(0,n.jsx)(t.p,{children:"As you can see below, the LLM model leveraged the additional context to generate an accurate response to the question."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{src:r(10972).A+"",width:"1802",height:"885"})}),"\n",(0,n.jsx)(t.h2,{id:"how-to-edit-a-rag-prompter",children:"How to Edit a RAG Prompter"}),"\n",(0,n.jsxs)(t.p,{children:["After creating your RAG Prompter, you can edit it by navigating to its individual page and clicking the ",(0,n.jsx)(t.strong,{children:"Edit workflow"})," button in the upper-right section."]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{src:r(28485).A+"",width:"1793",height:"691"})}),"\n",(0,n.jsx)(t.p,{children:"You'll be redirected to the workflow editor page, where you can make any changes needed, such as updating the prompt template text or other parameters."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{src:r(43818).A+"",width:"1912",height:"838"})}),"\n",(0,n.jsxs)(t.p,{children:["Once you've made your changes, click the ",(0,n.jsx)(t.strong,{children:"Save as new version"})," button to save the updated RAG Prompter under a new version \u2014 without exiting the workflow editor."]}),"\n",(0,n.jsx)(t.admonition,{type:"note",children:(0,n.jsx)(t.p,{children:"You can easily switch between different versions of the RAG Prompter by selecting the respective version ID from the left sidebar in the workflow editor."})}),"\n",(0,n.jsxs)(t.p,{children:["Note that clicking the ",(0,n.jsx)(t.strong,{children:"Update Workflow"})," button creates a new version of your RAG Prompter and exits the workflow editor, redirecting you to its main page."]}),"\n",(0,n.jsx)(t.p,{children:"You can then select the version to use for inferencing."}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{src:r(94579).A+"",width:"1794",height:"677"})})]})}function h(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}},43818:(e,t,r)=>{r.d(t,{A:()=>a});const a=r.p+"assets/images/rag-prompter-4-0d8b973b8e9c018277763ea8a98d17fb.png"},94579:(e,t,r)=>{r.d(t,{A:()=>a});const a=r.p+"assets/images/rag-prompter-5-421950a5915a143f61fd3e88ca85cd8c.png"},99703:(e,t,r)=>{r.d(t,{A:()=>a});const a=r.p+"assets/images/rag-prompter-1-2d37ac598d78688d9b4db474510fc25c.png"}}]);