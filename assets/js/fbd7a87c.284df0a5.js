"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[1361],{14924:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>b,contentTitle:()=>f,default:()=>v,frontMatter:()=>m,metadata:()=>g,toc:()=>y});var a=n(74848),i=n(28453),s=n(11470),r=n(19365),o=n(21432);const l='from clarifai.client.model import Model\n\nprompt = "What is the future of AI?"\n\nmodel_url="https://clarifai.com/meta/Llama-3/models/Llama-3_2-3B-Instruct"\n\n# Model Predict\nmodel_prediction = Model(url=model_url, pat="YOUR_PAT_HERE").predict_by_bytes(prompt.encode(), input_type="text")\n\nprint(model_prediction.outputs[0].data.text.raw)',c='//Use the CLI to log in to the Clarifai platform first: https://docs.clarifai.com/getting-started/api-overview/cli\n\nclarifai model predict --model_url https://clarifai.com/meta/Llama-3/models/Llama-3_2-3B-Instruct --bytes "What is the future of AI?" --input_type text',u='curl -X POST "https://api.clarifai.com/v2/users/meta/apps/Llama-3/models/Llama-3_2-3B-Instruct/versions/52528868e11d431fa0450f00b22af18c/outputs" \\\n    -H "Authorization: Key YOUR_PAT_HERE" \\\n    -H "Content-Type: application/json" \\\n    -d \'{\n      "inputs": [\n        {\n          "data": {\n            "text": {\n              "raw": "What is the future of AI?"\n            }\n          }\n        }\n      ]\n    }\'\n   \n',d="\x3c!--index.html file--\x3e\n\n<script>        \n    ////////////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, user and app ID, model details, and the raw\n    // text we want as a prompt. Change these strings to run your own example.\n    ///////////////////////////////////////////////////////////////////////////////////////////////////\n\n    // Your PAT (Personal Access Token) can be found in the Account's Security section\n    const PAT = 'YOUR_PAT_HERE';\n    // Specify the correct user_id/app_id pairings\n    // Since you're making inferences outside your app's scope\n    const USER_ID = 'meta';    \n    const APP_ID = 'Llama-3';\n    // Change these to whatever model and text you want to use  \n    const MODEL_ID = 'Llama-3_2-3B-Instruct';\n    const MODEL_VERSION_ID = '52528868e11d431fa0450f00b22af18c';    \n    const RAW_TEXT = 'What is the future of AI?';\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    const raw = JSON.stringify({\n        \"user_app_id\": {\n            \"user_id\": USER_ID,\n            \"app_id\": APP_ID\n        },\n        \"inputs\": [\n            {\n                \"data\": {\n                    \"text\": {\n                        \"raw\": RAW_TEXT\n                    }\n                }\n            }\n        ]\n    });\n\n    const requestOptions = {\n        method: 'POST',\n        headers: {\n            'Accept': 'application/json',\n            'Authorization': 'Key ' + PAT\n        },\n        body: raw\n    };\n\n    // NOTE: MODEL_VERSION_ID is optional, you can also call prediction with the MODEL_ID only\n    // https://api.clarifai.com/v2/models/{YOUR_MODEL_ID}/outputs\n    // this will default to the latest version_id\n\n    fetch(\"https://api.clarifai.com/v2/models/\" + MODEL_ID + \"/versions/\" + MODEL_VERSION_ID + \"/outputs\", requestOptions)\n        .then((response) => {\n            return response.json();\n        })\n        .then((data) => {\n            if(data.status.code != 10000) console.log(data.status);\n            else console.log(data['outputs'][0]['data']['text']['raw']);\n        }).catch(error => console.log('error', error));\n\n<\/script>",p="######################################################################################################\n# In this section, we set the user authentication, user and app ID, model details, and the raw\n# text we want as a prompt. Change these strings to run your own example.\n######################################################################################################\n\n# Your PAT (Personal Access Token) can be found in the Account's Security section\nPAT = 'YOUR_PAT_HERE'\n# Specify the correct user_id/app_id pairings\n# Since you're making inferences outside your app's scope\nUSER_ID = 'meta'\nAPP_ID = 'Llama-3'\n# Change these to whatever model and text you want to use\nMODEL_ID = 'Llama-3_2-3B-Instruct'\nMODEL_VERSION_ID = '52528868e11d431fa0450f00b22af18c'\nRAW_TEXT = 'What is the futute of AI?'\n\n############################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n############################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\npost_model_outputs_response = stub.PostModelOutputs(\n    service_pb2.PostModelOutputsRequest(\n        user_app_id=userDataObject,  # The userDataObject is created in the overview and is required when using a PAT\n        model_id=MODEL_ID,\n        version_id=MODEL_VERSION_ID,  # This is optional. Defaults to the latest model version\n        inputs=[\n            resources_pb2.Input(\n                data=resources_pb2.Data(\n                    text=resources_pb2.Text(\n                        raw=RAW_TEXT\n                    )\n                )\n            )\n        ]\n    ),\n    metadata=metadata\n)\nif post_model_outputs_response.status.code != status_code_pb2.SUCCESS:\n    print(post_model_outputs_response.status)\n    raise Exception(f\"Post model outputs failed, status: {post_model_outputs_response.status.description}\")\n\n# Since we have one input, one output will exist here\noutput = post_model_outputs_response.outputs[0]\n\nprint(\"Completion:\\n\")\nprint(output.data.text.raw)",h="The future of AI is a topic of much debate and speculation. While it's difficult to predict exactly what the future holds, here are some potential trends and developments that could shape the future of AI:\n\n1. **Increased Integration with Other Technologies**: AI is likely to become even more integrated with other technologies such as blockchain, the Internet of Things (IoT), and 5G networks. This could lead to new applications and use cases that we cannot yet imagine.\n\n2. **Advances in Explainability and Transparency**: As AI becomes more pervasive, there will be a growing need for explainability and transparency. This could involve the development of new techniques for interpreting and understanding AI decision-making processes.\n\n3. **Rise of Edge AI**: Edge AI refers to the processing of AI tasks at the edge of the network, rather than in a centralized cloud. This could enable faster and more efficient AI processing, particularly in applications such as autonomous vehicles and smart cities.\n\n4. **Increased Focus on Ethics and Fairness**: As AI becomes more influential, there will be a growing need to address issues of ethics and fairness. This could involve the development of new AI systems that are designed to be more transparent, explainable, and equitable.\n\n5. **Potential for AI to Disrupt Traditional Industries**: AI has the potential to disrupt traditional industries such as healthcare, finance, and education. This could lead to significant job displacement and the need for workers to adapt to new roles and responsibilities.\n\n6. **Advances in Natural Language Processing (NLP)**: NLP is a key area of research in AI, and it's likely that we'll see significant advances in this area over the coming years. This could enable AI systems to better understand and respond to human language, leading to more natural and intuitive interfaces.\n\n7. **Increased Use of Reinforcement Learning**: Reinforcement learning is a type of machine learning that involves training AI systems through trial and error. This could enable AI systems to learn more efficiently and effectively, particularly in applications such as robotics and game playing.\n\n8. **Potential for AI to Enhance Human Capabilities**: AI has the potential to enhance human capabilities, particularly in areas such as cognitive abilities and physical abilities. This could lead to significant improvements in productivity and quality of life.\n\nSome potential timelines for these developments include:\n\n* **2025**: Edge AI becomes more widespread, enabling faster and more efficient AI processing.\n* **2030**: AI systems become more integrated with other technologies such as blockchain and IoT.\n* **2035**: Advances in NLP lead\n",m={description:"Get started quickly with Clarifai in a few simple steps",sidebar_position:1},f="Quick Start",g={id:"getting-started/quickstart",title:"Quick Start",description:"Get started quickly with Clarifai in a few simple steps",source:"@site/docs/getting-started/quickstart.md",sourceDirName:"getting-started",slug:"/getting-started/quickstart",permalink:"/getting-started/quickstart",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/getting-started/quickstart.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{description:"Get started quickly with Clarifai in a few simple steps",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Welcome",permalink:"/"},next:{title:"Deploy Your First Model",permalink:"/getting-started/first-deployment"}},b={},y=[{value:"Try Out Our Community Models",id:"try-out-our-community-models",level:2},{value:"Step 1: Find a Model",id:"step-1-find-a-model",level:3},{value:"Step 2: Run Your Inference",id:"step-2-run-your-inference",level:3},{value:"Call Your First Model With Our API",id:"call-your-first-model-with-our-api",level:2},{value:"Step 1: Get a PAT Key",id:"step-1-get-a-pat-key",level:3},{value:"Step 2: Install Your Preferred Client",id:"step-2-install-your-preferred-client",level:3},{value:"Step 3: Send an API Request",id:"step-3-send-an-api-request",level:3}];function x(e){const t={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:m}=t;return m||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.h1,{id:"quick-start",children:"Quick Start"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.strong,{children:"Get started quickly with Clarifai in a few simple steps"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsx)(t.p,{children:"Clarifai provides an intuitive interface and a robust API designed to get you up and running quickly. In just a few simple steps or a few lines of code, you can bring your AI projects to life within minutes."}),"\n",(0,a.jsx)(t.admonition,{title:"Set up Your Account or Log in",type:"tip",children:(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"https://clarifai.com/signup",children:"Create"})," a new Clarifai account or ",(0,a.jsx)(t.a,{href:"https://clarifai.com/login",children:"log in to"})," your existing one to start accessing the platform's powerful AI capabilities."]})}),"\n","\n","\n","\n",(0,a.jsx)(t.h2,{id:"try-out-our-community-models",children:"Try Out Our Community Models"}),"\n",(0,a.jsxs)(t.p,{children:["We offer a diverse collection of ",(0,a.jsx)(t.a,{href:"https://clarifai.com/explore",children:"Community"})," models that you can browse, test, and integrate into your projects."]}),"\n",(0,a.jsx)(t.h3,{id:"step-1-find-a-model",children:"Step 1: Find a Model"}),"\n",(0,a.jsxs)(t.p,{children:["You can easily find a model to use by heading to the homepage and exploring the ",(0,a.jsx)(t.strong,{children:"Trending AI models"})," section, which showcases popular and ready-to-use options."]}),"\n",(0,a.jsxs)(t.p,{children:["After finding the model, click the ",(0,a.jsx)(t.strong,{children:"TEST IN PLAYGROUND"})," button in the bottom left corner of its information card."]}),"\n",(0,a.jsxs)(t.p,{children:["For this example, we'll use the ",(0,a.jsx)(t.a,{href:"https://clarifai.com/meta/Llama-3/models/Llama-3_2-3B-Instruct",children:"Llama-3.2-3B-Instruct"})," model."]}),"\n",(0,a.jsxs)(t.blockquote,{children:["\n",(0,a.jsx)(t.p,{children:(0,a.jsxs)(t.em,{children:["Alternatively, you can select the ",(0,a.jsx)(t.strong,{children:"Playground"})," option in the top navigation bar."]})}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{src:n(15174).A+"",width:"1866",height:"856"})}),"\n",(0,a.jsx)(t.h3,{id:"step-2-run-your-inference",children:"Step 2: Run Your Inference"}),"\n",(0,a.jsx)(t.p,{children:"You'll be taken to the Playground interface, which is a pre-authenticated testing environment that allows you to quickly interact with Clarifai's AI models without additional setup or authentication."}),"\n",(0,a.jsx)(t.p,{children:"In the chat interface at the bottom of the Playground, enter your desired prompt to generate text with the selected model. Note that if the model supports image inputs as prompts, you can also upload images directly into the interface."}),"\n",(0,a.jsxs)(t.blockquote,{children:["\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.em,{children:"Alternatively, in the upper-left section of the Playground, you can choose the model you'd like to use for inference."})}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"Then, click the arrow icon to submit your request."}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{src:n(54191).A+"",width:"1908",height:"895"})}),"\n",(0,a.jsx)(t.p,{children:"The results will be streamed directly in the interface, allowing you to see the output in real time."}),"\n",(0,a.jsxs)(t.admonition,{type:"info",children:[(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsxs)(t.p,{children:["For this example, we're using the default settings for deployment (",(0,a.jsx)(t.code,{children:"Clarifai Shared"}),"), inference parameters, and others. You can customize these settings as needed for more advanced use cases."]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"You can toggle the button in the upper-left section of the Playground to display ready-to-use API code snippets in various programming languages. Simply copy and use them in your project."}),"\n"]}),"\n"]}),(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{src:n(58320).A+"",width:"1910",height:"903"})})]}),"\n",(0,a.jsx)(t.h2,{id:"call-your-first-model-with-our-api",children:"Call Your First Model With Our API"}),"\n",(0,a.jsx)(t.p,{children:"You can access the Clarifai API effortlessly using your preferred method:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"SDKs \u2013 Quick integration with official client libraries."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"CLI (Command Line Interface) \u2013 Manage tasks directly from the command line."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"HTTP Requests \u2013 Use any programming language with REST API calls."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"gRPC Clients \u2013 High-performance support for popular languages."}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"step-1-get-a-pat-key",children:"Step 1: Get a PAT Key"}),"\n",(0,a.jsxs)(t.p,{children:["You need a PAT (Personal Access Token) key to authenticate your connection to the Clarifai platform. You can generate the PAT key in your personal settings page by navigating to the ",(0,a.jsx)(t.a,{href:"https://clarifai.com/settings/security",children:"Security section"}),"."]}),"\n",(0,a.jsx)(t.h3,{id:"step-2-install-your-preferred-client",children:"Step 2: Install Your Preferred Client"}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(r.A,{value:"python1",label:"Python SDK",children:(0,a.jsx)(o.A,{className:"language-python",children:"pip install --upgrade clarifai"})}),(0,a.jsx)(r.A,{value:"cli",label:"CLI",children:(0,a.jsx)(o.A,{className:"language-javascript",children:"pip install --upgrade clarifai"})}),(0,a.jsx)(r.A,{value:"python2",label:"Python (gRPC)",children:(0,a.jsx)(o.A,{className:"language-php",children:"python -m pip install clarifai-grpc"})})]}),"\n",(0,a.jsx)(t.h3,{id:"step-3-send-an-api-request",children:"Step 3: Send an API Request"}),"\n",(0,a.jsx)(t.p,{children:"For this example, let's use the Llama-3.2-3B-Instruct model to generate text based on a given prompt."}),"\n",(0,a.jsxs)(s.A,{children:[(0,a.jsx)(r.A,{value:"python11",label:"Python SDK",children:(0,a.jsx)(o.A,{className:"language-python",children:l})}),(0,a.jsx)(r.A,{value:"cli1",label:"CLI",children:(0,a.jsx)(o.A,{className:"language-bash",children:c})}),(0,a.jsx)(r.A,{value:"js11",label:"cURL",children:(0,a.jsx)(o.A,{className:"language-javascript",children:u})}),(0,a.jsx)(r.A,{value:"javascript11",label:"JavaScript (REST)",children:(0,a.jsx)(o.A,{className:"language-javascript",children:d})}),(0,a.jsx)(r.A,{value:"python21",label:"Python (gRPC)",children:(0,a.jsx)(o.A,{className:"language-python",children:p})})]}),"\n",(0,a.jsxs)(m,{children:[(0,a.jsx)("summary",{children:"Output Example"}),(0,a.jsx)(o.A,{className:"language-text",children:h})]}),"\n",(0,a.jsx)("br",{}),"\n",(0,a.jsx)("br",{}),"\n",(0,a.jsx)(t.p,{children:"Congratulations \u2014 you've just get started with the Clarifai platform!"})]})}function v(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(x,{...e})}):x(e)}},19365:(e,t,n)=>{n.d(t,{A:()=>r});n(96540);var a=n(18215);const i={tabItem:"tabItem_Ymn6"};var s=n(74848);function r(e){let{children:t,hidden:n,className:r}=e;return(0,s.jsx)("div",{role:"tabpanel",className:(0,a.A)(i.tabItem,r),hidden:n,children:t})}},11470:(e,t,n)=>{n.d(t,{A:()=>I});var a=n(96540),i=n(18215),s=n(23104),r=n(56347),o=n(205),l=n(57485),c=n(31682),u=n(70679);function d(e){return a.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(e){const{values:t,children:n}=e;return(0,a.useMemo)((()=>{const e=t??function(e){return d(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:i}}=e;return{value:t,label:n,attributes:a,default:i}}))}(n);return function(e){const t=(0,c.X)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function h(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function m(e){let{queryString:t=!1,groupId:n}=e;const i=(0,r.W6)(),s=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,l.aZ)(s),(0,a.useCallback)((e=>{if(!s)return;const t=new URLSearchParams(i.location.search);t.set(s,e),i.replace({...i.location,search:t.toString()})}),[s,i])]}function f(e){const{defaultValue:t,queryString:n=!1,groupId:i}=e,s=p(e),[r,l]=(0,a.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!h({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:s}))),[c,d]=m({queryString:n,groupId:i}),[f,g]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[i,s]=(0,u.Dv)(n);return[i,(0,a.useCallback)((e=>{n&&s.set(e)}),[n,s])]}({groupId:i}),b=(()=>{const e=c??f;return h({value:e,tabValues:s})?e:null})();(0,o.A)((()=>{b&&l(b)}),[b]);return{selectedValue:r,selectValue:(0,a.useCallback)((e=>{if(!h({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);l(e),d(e),g(e)}),[d,g,s]),tabValues:s}}var g=n(92303);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var y=n(74848);function x(e){let{className:t,block:n,selectedValue:a,selectValue:r,tabValues:o}=e;const l=[],{blockElementScrollPositionUntilNextRender:c}=(0,s.a_)(),u=e=>{const t=e.currentTarget,n=l.indexOf(t),i=o[n].value;i!==a&&(c(t),r(i))},d=e=>{let t=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const n=l.indexOf(e.currentTarget)+1;t=l[n]??l[0];break}case"ArrowLeft":{const n=l.indexOf(e.currentTarget)-1;t=l[n]??l[l.length-1];break}}t?.focus()};return(0,y.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":n},t),children:o.map((e=>{let{value:t,label:n,attributes:s}=e;return(0,y.jsx)("li",{role:"tab",tabIndex:a===t?0:-1,"aria-selected":a===t,ref:e=>l.push(e),onKeyDown:d,onClick:u,...s,className:(0,i.A)("tabs__item",b.tabItem,s?.className,{"tabs__item--active":a===t}),children:n??t},t)}))})}function v(e){let{lazy:t,children:n,selectedValue:i}=e;const s=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=s.find((e=>e.props.value===i));return e?(0,a.cloneElement)(e,{className:"margin-top--md"}):null}return(0,y.jsx)("div",{className:"margin-top--md",children:s.map(((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==i})))})}function A(e){const t=f(e);return(0,y.jsxs)("div",{className:(0,i.A)("tabs-container",b.tabList),children:[(0,y.jsx)(x,{...t,...e}),(0,y.jsx)(v,{...t,...e})]})}function I(e){const t=(0,g.A)();return(0,y.jsx)(A,{...e,children:d(e.children)},String(t))}},15174:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/playground-2-46fad25b0f57db5948200d7a7d98486b.png"},54191:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/playground-3-b3067e624667a1519d5b652b95d3d599.png"},58320:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/playground-4-7b8a13deebdb32a7a39b57f718b3b37a.png"}}]);