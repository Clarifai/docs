"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[5629],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>h});var o=a(67294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,o)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,o,n=function(e,t){if(null==e)return{};var a,o,n={},i=Object.keys(e);for(o=0;o<i.length;o++)a=i[o],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)a=i[o],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var r=o.createContext({}),u=function(e){var t=o.useContext(r),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},c=function(e){var t=u(e.components);return o.createElement(r.Provider,{value:t},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},g=o.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,r=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=u(a),g=n,h=p["".concat(r,".").concat(g)]||p[g]||d[g]||i;return a?o.createElement(h,l(l({ref:t},c),{},{components:a})):o.createElement(h,l({ref:t},c))}));function h(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,l=new Array(i);l[0]=g;var s={};for(var r in t)hasOwnProperty.call(t,r)&&(s[r]=t[r]);s.originalType=e,s[p]="string"==typeof e?e:n,l[1]=s;for(var u=2;u<i;u++)l[u]=a[u];return o.createElement.apply(null,l)}return o.createElement.apply(null,a)}g.displayName="MDXCreateElement"},7269:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>r,contentTitle:()=>l,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>u});var o=a(87462),n=(a(67294),a(3905));const i={description:"Learn about the labeling tools that are available to you in Scribe.",sidebar_position:4},l="Labeling Tools",s={unversionedId:"portal-guide/annotate/labeling-tools",id:"portal-guide/annotate/labeling-tools",title:"Labeling Tools",description:"Learn about the labeling tools that are available to you in Scribe.",source:"@site/docs/portal-guide/annotate/labeling-tools.md",sourceDirName:"portal-guide/annotate",slug:"/portal-guide/annotate/labeling-tools",permalink:"/portal-guide/annotate/labeling-tools",draft:!1,tags:[],version:"current",sidebarPosition:4,frontMatter:{description:"Learn about the labeling tools that are available to you in Scribe.",sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Label Types",permalink:"/portal-guide/annotate/label-types"},next:{title:"AI-Assisted Labeling",permalink:"/portal-guide/annotate/ai-assist"}},r={},u=[{value:"Labeling Tools",id:"labeling-tools-1",level:2},{value:"View metadata",id:"view-metadata",level:3},{value:"Brightness",id:"brightness",level:3},{value:"Saturation",id:"saturation",level:3},{value:"Invert color",id:"invert-color",level:3},{value:"Zoom",id:"zoom",level:3},{value:"Pan",id:"pan",level:3},{value:"Show hotkeys",id:"show-hotkeys",level:3},{value:"Labeling Image Inputs",id:"labeling-image-inputs",level:2},{value:"Classification labeling",id:"classification-labeling",level:3},{value:"Bounding box (detection labeling task)",id:"bounding-box-detection-labeling-task",level:3},{value:"Segmentation labeling using polygons",id:"segmentation-labeling-using-polygons",level:3},{value:"Quick-mask tool",id:"quick-mask-tool",level:4},{value:"Labeling Video Inputs",id:"labeling-video-inputs",level:2},{value:"Keyframes",id:"keyframes",level:3},{value:"Frames and time segments",id:"frames-and-time-segments",level:3},{value:"Interpolation",id:"interpolation",level:3},{value:"Track suggestions for AI-Assist",id:"track-suggestions-for-ai-assist",level:3},{value:"Video keyboard shortcuts",id:"video-keyboard-shortcuts",level:3},{value:"Labeling Text Inputs",id:"labeling-text-inputs",level:2}],c={toc:u},p="wrapper";function d(e){let{components:t,...i}=e;return(0,n.kt)(p,(0,o.Z)({},c,i,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"labeling-tools"},"Labeling Tools"),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Learn about the labeling tools that are available to you in Scribe")),(0,n.kt)("hr",null),(0,n.kt)("div",{style:{position:"relative",width:"100%",overflow:"hidden","padding-top":"56.25%"}},(0,n.kt)("iframe",{width:"900",height:"500",style:{position:"absolute",top:"0",left:"0",bottom:"0",right:"0",width:"100%",height:"100%"},src:"https://www.youtube.com/embed/KLoziNCUKFQ",title:"11 - Detection labeling task",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowfullscreen:!0})),(0,n.kt)("br",null),(0,n.kt)("br",null),(0,n.kt)("p",null,"The Scribe labeler provides special tools for working with images, videos, and texts for classification, detection, and segmentation labeling tasks. With the tools, you can annotate your inputs faster and more conveniently. "),(0,n.kt)("p",null,"After successfully ",(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/annotate/create-a-task"},"creating a labeling task"),", it will appear on the ",(0,n.kt)("strong",{parentName:"p"},"Tasks")," listing page. To begin working on the task, click the blue ",(0,n.kt)("strong",{parentName:"p"},"LABEL")," button. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"label button",src:a(39810).Z,width:"1889",height:"735"})),(0,n.kt)("p",null,"You\u2019ll be redirected to the ",(0,n.kt)("strong",{parentName:"p"},"Labeling Tasks")," screen, where you can begin annotating your inputs. At the upper-right section of the screen, you'll find a variety of tools you can use to simplify the annotation process."),(0,n.kt)("p",null,"On the right sidebar, you can find a list of the ",(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/concepts/create-get-update-delete"},"concepts")," you specified when you created a new labeling task. You can use them to label your inputs. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"labeling tools",src:a(334).Z,width:"1895",height:"845"})),(0,n.kt)("h2",{id:"labeling-tools-1"},"Labeling Tools"),(0,n.kt)("p",null,"Let's talk about each of the tools. "),(0,n.kt)("admonition",{type:"tip"},(0,n.kt)("ul",{parentName:"admonition"},(0,n.kt)("li",{parentName:"ul"},"After selecting a labeling tool and using the slider that pops up to adjust your input, you can simply click the ",(0,n.kt)("strong",{parentName:"li"},"Reset")," button to revert to its initial version."),(0,n.kt)("li",{parentName:"ul"},"You can combine multiple tools as appropriate to make adjustments to your input."),(0,n.kt)("li",{parentName:"ul"},"Clicking a button for the second time will deactivate or remove the highlight effect associated with that button. "))),(0,n.kt)("h3",{id:"view-metadata"},"View metadata"),(0,n.kt)("p",null,"The metadata button allows you to toggle and view the metadata available in your inputs. "),(0,n.kt)("h3",{id:"brightness"},"Brightness"),(0,n.kt)("p",null,"The brightness button allows you to adjust the visibility of your inputs. "),(0,n.kt)("h3",{id:"saturation"},"Saturation"),(0,n.kt)("p",null,"The saturation button allows you to adjust the hue or saturation intensity of your inputs."),(0,n.kt)("h3",{id:"invert-color"},"Invert color"),(0,n.kt)("p",null,"The invert color button allows you to apply a transformation to your inputs. When clicked, it reverses the colors within the input, turning light areas dark, and vice versa. "),(0,n.kt)("h3",{id:"zoom"},"Zoom"),(0,n.kt)("p",null,"The zoom button allows you to change the level of magnification or the size of the view for your inputs. "),(0,n.kt)("h3",{id:"pan"},"Pan"),(0,n.kt)("p",null,"The pan button allows you to move the visible areas of your inputs so that you can inspect specific regions closely."),(0,n.kt)("h3",{id:"show-hotkeys"},"Show hotkeys"),(0,n.kt)("p",null,"The show hotkeys button allows you to display the keyboard shortcuts available for each annotation tool. "),(0,n.kt)("p",null,"These are the hotkeys you can use:"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"display hotkeys",src:a(6475).Z,width:"1911",height:"837"})),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"B"),"\u2014brightness"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"S"),"\u2014saturation"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"I"),"\u2014invert color"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"P"),"\u2014pan"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"/"),"\u2014filter concepts"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Enter"),"\u2014submit a label")),(0,n.kt)("p",null,"These are other general keyboard shortcuts:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Left arrow\u2014previous input"),(0,n.kt)("li",{parentName:"ul"},"Right arrow\u2014next input")),(0,n.kt)("h2",{id:"labeling-image-inputs"},"Labeling Image Inputs"),(0,n.kt)("h3",{id:"classification-labeling"},"Classification labeling"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/annotate/label-types#classification-label-type"},"Click here")," to learn more on how to annotate images for classification tasks. "),(0,n.kt)("h3",{id:"bounding-box-detection-labeling-task"},"Bounding box (detection labeling task)"),(0,n.kt)("p",null,"To begin labeling, click the plus (",(0,n.kt)("strong",{parentName:"p"},"+"),") button next to the concept you want to use. This action will highlight the button in blue, enabling you to begin drawing a bounding box around the image. "),(0,n.kt)("p",null,'You also have the option to use keyboard shortcuts provided alongside the concepts. For example, in the image below, pressing the number "2" on the keyboard will highlight the "vehicle" concept.'),(0,n.kt)("p",null,"Once you've highlighted a concept, position your cursor over the input and draw a bounding box as closely as possible around it. Next, release your mouse, and you'll see the annotation appearing under the selected concept."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"draw bounding box",src:a(81655).Z,width:"1908",height:"825"})),(0,n.kt)("admonition",{type:"info"},(0,n.kt)("p",{parentName:"admonition"},'You can easily resize, move, or relabel existing bounding boxes. Just click inside the bounding box you wish to modify, then drag to move or resize. If you need to change the label, just click the "edit" icon located next to the existing label in the right sidebar.')),(0,n.kt)("h3",{id:"segmentation-labeling-using-polygons"},"Segmentation labeling using polygons"),(0,n.kt)("p",null,"Bounding boxes are effective for many labeling tasks, but in scenarios requiring more precise object annotation, polygon labels offer a more accurate solution. With polygon labels, you can pinpoint and annotate the exact pixels in your image that define the object you're labeling."),(0,n.kt)("p",null,"Polygon labels generate a sequence of x and y coordinates that define each point forming the polygon."),(0,n.kt)("admonition",{type:"note"},(0,n.kt)("p",{parentName:"admonition"},'To use polygon labels, you\'ll need to specify "segmentation" as the ',(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/annotate/label-types#how-to-choose-a-label-type"},"label type")," when setting up your labeling task. ")),(0,n.kt)("p",null,'While labeling your images, you can create multi-point shapes to precisely outline the pixels of the object you intend to label. Remember that you\'ll need to "connect the dots" by linking the last point in your polygon with the initial point to form a complete shape.'),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Outline your image and be sure to connect the first and last nodes of your polygon",src:a(33114).Z,width:"640",height:"360"})),(0,n.kt)("h4",{id:"quick-mask-tool"},"Quick-mask tool"),(0,n.kt)("p",null,"The Quick-mask tool makes it easy to select image masks when creating polygon annotations. "),(0,n.kt)("p",null,"The tool allows you to select a region of an image and then automatically generate an image mask for the detected object in the image. You can also fine-tune the selection once a mask has been created."),(0,n.kt)("h2",{id:"labeling-video-inputs"},"Labeling Video Inputs"),(0,n.kt)("p",null,"Scribe provides powerful tools for labeling videos. When working with video, you can leverage video interpolation tools to label thousands of individual frames of video quickly. "),(0,n.kt)("p",null,"This rapid labeling technique makes video an excellent source of training data, even if you want your model to primarily analyze still images. "),(0,n.kt)("h3",{id:"keyframes"},"Keyframes"),(0,n.kt)("p",null,"Keyframes define the starting and ending points of interpolated transitions. When you adjust the positions of bounding points around your object, new keyframe markers are added to the timeline of your video."),(0,n.kt)("p",null,"Keyframes allow you to adjust for the changing shape, speed, and trajectory of a given object in your video."),(0,n.kt)("h3",{id:"frames-and-time-segments"},"Frames and time segments"),(0,n.kt)("p",null,"When labeling video, you can label and train video at the frame level or the video level. Labeling video at the frame level means that you are labeling individual video frames as separate images. Labeling video at the video level means that you are labeling an entire video or a segment of time from a video."),(0,n.kt)("p",null,"When creating your labeling project, you can label a video using time segments by selecting a concept task type. Just click the plus icon in the labeling view, and you can adjust the time segment selected by using the slider bars below the video."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"label time segment",src:a(8156).Z,width:"1920",height:"1080"})),(0,n.kt)("p",null,"Note that you can label an entire video with a concept by holding down the option key when clicking the plus icon to add a concept to a video. "),(0,n.kt)("p",null,"You can also click the cancel button next to the time segment display, and the concept will be applied to the whole video (if you want to remove the entire concept, click the trash can icon instead)."),(0,n.kt)("h3",{id:"interpolation"},"Interpolation"),(0,n.kt)("p",null,"Interpolation allows you to label multiple frames of video with the same concept quickly. Select the interpolation icon and draw a bounding box or polygon around the object you would like to label. "),(0,n.kt)("p",null,"Then, scrub the video player to a new point in the video and move and adjust the bounding box to the object's new location. Interpolation will automatically draw a series of bounding boxes between them. A keyframe marker will identify the point in the video where a new interpolation begins."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Label multiple frames of video with video interpolation",src:a(97726).Z,width:"1920",height:"1080"})),(0,n.kt)("h3",{id:"track-suggestions-for-ai-assist"},"Track suggestions for AI-Assist"),(0,n.kt)("p",null,'AI-Assist can automatically track objects across multiple frames of video. Just be sure to include a "centroid-tracker" in the workflow that you are using for AI-assist. '),(0,n.kt)("p",null,"Separate instances of a given concept will be detected and versioned for labeling. You can even use the timeline editor to scrub back and forth between different frames of video."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Automatically track objects",src:a(52634).Z,width:"1000",height:"562"})),(0,n.kt)("h3",{id:"video-keyboard-shortcuts"},"Video keyboard shortcuts"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Q - Start of video"),(0,n.kt)("li",{parentName:"ul"},"W - Scrub backward"),(0,n.kt)("li",{parentName:"ul"},"E - Scrub forward"),(0,n.kt)("li",{parentName:"ul"},"R - End of video")),(0,n.kt)("h2",{id:"labeling-text-inputs"},"Labeling Text Inputs"),(0,n.kt)("p",null,"Scribe makes it easy to label your text data. You can review text inputs in the same view that you would review images for classification tasks."),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Label text data in Scribe",src:a(14942).Z,width:"1000",height:"548"})))}d.isMDXComponent=!0},39810:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/labeling_tools_1-ed1857aec42006897c4370141c2589cf.png"},334:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/labeling_tools_2-0df2a2ccec9f9ee036a79f9ea459b4d5.png"},6475:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/labeling_tools_3-292f364dc8894949523ea6f02d5a83e1.png"},81655:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/labeling_tools_4-1314e3341216bb59a3e6a1b4cc205a76.png"},52634:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/detect-tracks-scribe-0f1804f712e84b94b077092a11f24e2a.jpeg"},14942:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/label-text-da3dc44e87bf5c5589afc11531546eff.jpg"},33114:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/polygon-label-393b335449dd529fd114e248732e7f27.gif"},8156:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/time-segment-1f67adf573ce435379d122fff01d2dc1.jpg"},97726:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/video-timeline-81e1884ecec39de5034955efe5d309ab.jpeg"}}]);