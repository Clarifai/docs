"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[7756],{28453:(e,s,t)=>{t.d(s,{R:()=>r,x:()=>o});var i=t(96540);const a={},n=i.createContext(a);function r(e){const s=i.useContext(n);return i.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(n.Provider,{value:s},e.children)}},32402:(e,s,t)=>{t.d(s,{A:()=>i});const i=t.p+"assets/images/evaluate_1-4f9d70b887d2a1960b4f0fae6f9d034a.png"},51979:(e,s,t)=>{t.d(s,{A:()=>i});const i=t.p+"assets/images/cross_validation-cfadf56b2e40cbff4a4709169d1b5640.jpg"},66509:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"portal-guide/evaluate/transfer-learn","title":"Transfer Learn Models","description":"Evaluate visual or text classifiers trained using transfer learning","source":"@site/docs/portal-guide/evaluate/transfer-learn.md","sourceDirName":"portal-guide/evaluate","slug":"/portal-guide/evaluate/transfer-learn","permalink":"/portal-guide/evaluate/transfer-learn","draft":false,"unlisted":false,"editUrl":"https://github.com/Clarifai/docs/blob/main/docs/portal-guide/evaluate/transfer-learn.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"Evaluate visual or text classifiers trained using transfer learning","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Evaluating Models","permalink":"/portal-guide/evaluate/"},"next":{"title":"Classification Models","permalink":"/portal-guide/evaluate/interpreting-evaluations"}}');var a=t(74848),n=t(28453);const r={description:"Evaluate visual or text classifiers trained using transfer learning",sidebar_position:1},o="Transfer Learn Models",l={},c=[{value:"Performing Evaluation",id:"performing-evaluation",level:2},{value:"Cross-Validation",id:"cross-validation",level:2},{value:"Evaluation Metrics",id:"evaluation-metrics",level:2}];function d(e){const s={a:"a",admonition:"admonition",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,n.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(s.header,{children:(0,a.jsx)(s.h1,{id:"transfer-learn-models",children:"Transfer Learn Models"})}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.strong,{children:"Evaluate visual or text classifiers trained using transfer learning"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.a,{href:"https://docs.clarifai.com/portal-guide/model/model-types/transfer-learning",children:"Transfer learning"})," models are machine learning models that leverage knowledge gained from training on one task (often with a large, general dataset) to improve performance on a different, often related task."]}),"\n",(0,a.jsx)(s.p,{children:"Evaluating transfer learning models for visual or text classification tasks involves assessing how well the transferred knowledge generalizes to the new task."}),"\n",(0,a.jsx)(s.h2,{id:"performing-evaluation",children:"Performing Evaluation"}),"\n",(0,a.jsx)(s.p,{children:"You can evaluate a specific version of your custom transfer learn model to assess its performance on a designated dataset. To do so, navigate to the versions table of your model and locate the version of the model you want to evaluate."}),"\n",(0,a.jsxs)(s.p,{children:["In the ",(0,a.jsx)(s.strong,{children:"Evaluation Dataset"})," column, click the field to open a drop-down list displaying available ",(0,a.jsx)(s.a,{href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete",children:"datasets"}),". Then, choose a dataset to use to assess the model\u2019s performance."]}),"\n",(0,a.jsx)(s.p,{children:"You can select a dataset within your application or from another application under your ownership. This cross-application evaluation enables you to test your model\u2019s robustness across various contexts and use cases."}),"\n",(0,a.jsx)(s.admonition,{title:"Prepare the Evaluation Dataset",type:"tip",children:(0,a.jsx)(s.p,{children:"Use a separate, high-quality evaluation dataset with accurate labels that reflect real-world conditions and include challenging edge cases. This ensures an unbiased assessment of the model\u2019s generalization and performance."})}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{src:t(32402).A+"",width:"1794",height:"855"})}),"\n",(0,a.jsxs)(s.p,{children:["If the desired dataset isn\u2019t in the drop-down list, click the ",(0,a.jsx)(s.strong,{children:"Evaluate with a new Dataset"})," button. A window will appear, allowing you to choose a new dataset and its version for evaluation."]}),"\n",(0,a.jsx)(s.p,{children:"Note that if you do not select a specific dataset version, the latest version will be used."}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{src:t(97545).A+"",width:"1820",height:"839"})}),"\n",(0,a.jsxs)(s.p,{children:["After selecting the dataset, click the ",(0,a.jsx)(s.strong,{children:"Calculate"})," button to initiate the evaluation process, which could take some time."]}),"\n",(0,a.jsxs)(s.p,{children:["Once complete, the ",(0,a.jsx)(s.strong,{children:"Calculate"})," button will become a ",(0,a.jsx)(s.strong,{children:"View Results"})," button, and the value for the ROC metric will be displayed."]}),"\n",(0,a.jsx)(s.h2,{id:"cross-validation",children:"Cross-Validation"}),"\n",(0,a.jsxs)(s.p,{children:["Evaluating transfer learning classifier models is typically done using ",(0,a.jsx)(s.strong,{children:"K-fold cross-validation"})," on the provided test data. This method ensures robust evaluation by leveraging different splits of the dataset, helping to mitigate biases caused by uneven data splits."]}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{alt:"cross validation",src:t(51979).A+"",width:"962",height:"946"})}),"\n",(0,a.jsx)(s.p,{children:"Here\u2019s how the cross-validation process works:"}),"\n",(0,a.jsxs)(s.ol,{children:["\n",(0,a.jsxs)(s.li,{children:["\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Data splitting"})," \u2014 The evaluation dataset is divided into K-equal subsets. For each iteration, one subset is set aside as the test set, while the remaining K-1 subsets are used for training."]}),"\n"]}),"\n",(0,a.jsxs)(s.li,{children:["\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Model training"})," \u2014 A new model is trained on the K-1 training subsets during each iteration."]}),"\n"]}),"\n",(0,a.jsxs)(s.li,{children:["\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Prediction"})," \u2014 The trained model is used to make predictions on the test set (the subset set aside for that iteration)."]}),"\n"]}),"\n",(0,a.jsxs)(s.li,{children:["\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Comparison"})," \u2014 The predictions are compared with the actual labels in the test set to calculate performance metrics (such as accuracy, F1-score, or precision)."]}),"\n"]}),"\n",(0,a.jsxs)(s.li,{children:["\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Repetition and aggregation"})," \u2014 Steps 1 to 4 are repeated K times, with a different subset serving as the test set in each iteration. The final performance is obtained by averaging the metrics across all splits, providing a more reliable evaluation."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(s.h2,{id:"evaluation-metrics",children:"Evaluation Metrics"}),"\n",(0,a.jsxs)(s.p,{children:["Once the evaluation process is complete, you can click the ",(0,a.jsx)(s.strong,{children:"View Results"})," button."]}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{src:t(90695).A+"",width:"1777",height:"519"})}),"\n",(0,a.jsxs)(s.p,{children:["You will be redirected to the ",(0,a.jsx)(s.strong,{children:"Evaluation results"})," page, where you can analyze the outcomes of the evaluation process."]}),"\n",(0,a.jsx)(s.p,{children:(0,a.jsx)(s.img,{src:t(72382).A+"",width:"1787",height:"821"})}),"\n",(0,a.jsx)(s.p,{children:"These are some of the metrics you can assess to understand a model\u2019s classification performance:"}),"\n",(0,a.jsxs)(s.ul,{children:["\n",(0,a.jsxs)(s.li,{children:["\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"ROC/AUC"})," \u2014 It evaluates a model\u2019s ability to differentiate between classes by plotting the true positive rate against the false positive rate at various classification thresholds. The resulting curve provides insights into the model's performance, with the Area Under the Curve (AUC) summarizing its effectiveness; a value closer to 1 indicates excellent discrimination between classes."]}),"\n"]}),"\n",(0,a.jsxs)(s.li,{children:["\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"F1 Score"})," \u2014 It combines precision and recall into a single metric by calculating their harmonic mean. It is particularly useful for imbalanced datasets, as it considers both false positives and false negatives, providing a balanced measure of a model\u2019s accuracy in predicting positive instances."]}),"\n"]}),"\n",(0,a.jsxs)(s.li,{children:["\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Precision"})," \u2014 It focuses on the accuracy of positive predictions by calculating the proportion of correctly identified positives out of all instances classified as positive. This metric is crucial in scenarios where false positives carry significant consequences, such as fraud detection or medical diagnoses."]}),"\n"]}),"\n",(0,a.jsxs)(s.li,{children:["\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.strong,{children:"Recall"})," \u2014 On the other hand, it emphasizes the model\u2019s ability to capture all actual positive instances by calculating the proportion of true positives out of the total actual positives. It is particularly important for tasks where positive cases are missing, such as identifying diseases or security threats, which could have severe repercussions."]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(s.p,{children:[(0,a.jsx)(s.a,{href:"https://docs.clarifai.com/portal-guide/evaluate/interpreting-evaluations#evaluation-metrics",children:"Click here"})," to learn more about the evaluation metrics."]})]})}function h(e={}){const{wrapper:s}={...(0,n.R)(),...e.components};return s?(0,a.jsx)(s,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},72382:(e,s,t)=>{t.d(s,{A:()=>i});const i=t.p+"assets/images/evaluate_16-0b7a9d785d0d3190b73dd0e780715852.png"},90695:(e,s,t)=>{t.d(s,{A:()=>i});const i=t.p+"assets/images/evaluate_17-fa29adcbbd563a5c65e61b7dc7905908.png"},97545:(e,s,t)=>{t.d(s,{A:()=>i});const i=t.p+"assets/images/evaluate_2-0c0aae5d0370a61cbd67e75aab5fe5b7.png"}}]);