"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[1333],{91188:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>p,frontMatter:()=>s,metadata:()=>a,toc:()=>l});var n=i(74848),o=i(28453);const s={description:"(Beta) Track people and objects in video",pagination_next:null,sidebar_position:5},r="Object Tracking",a={id:"portal-guide/input-viewer/object-tracking",title:"Object Tracking",description:"(Beta) Track people and objects in video",source:"@site/docs/portal-guide/input-viewer/object-tracking.md",sourceDirName:"portal-guide/input-viewer",slug:"/portal-guide/input-viewer/object-tracking",permalink:"/portal-guide/input-viewer/object-tracking",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/portal-guide/input-viewer/object-tracking.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{description:"(Beta) Track people and objects in video",pagination_next:null,sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"AI-Assisted Labeling",permalink:"/portal-guide/input-viewer/ai-assist"}},c={},l=[{value:"Track people and objects across multiple frames",id:"track-people-and-objects-across-multiple-frames",level:2},{value:"Build an object tracking workflow",id:"build-an-object-tracking-workflow",level:2},{value:"Limitations",id:"limitations",level:2}];function d(e){const t={h1:"h1",h2:"h2",img:"img",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,o.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h1,{id:"object-tracking",children:"Object Tracking"}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.strong,{children:"(Beta) Track people and objects in video"})}),"\n",(0,n.jsx)("hr",{}),"\n",(0,n.jsx)(t.h2,{id:"track-people-and-objects-across-multiple-frames",children:"Track people and objects across multiple frames"}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{src:i(96451).A+"",width:"1000",height:"562"})}),"\n",(0,n.jsx)(t.p,{children:"Videos are actually made up of a sequence of still images. Detection models can identify individual people and objects in still images, but they are not able to maintain these identities across frames. That is, they are not able to say that the person in one frame video is the same as the person in the next frame of video."}),"\n",(0,n.jsx)(t.p,{children:"This is where object tracking comes in. Clarifai offers convenient, pre-built object tracking workflows that help you identify and track objects and people across multiple frames of video."}),"\n",(0,n.jsx)(t.h2,{id:"build-an-object-tracking-workflow",children:"Build an object tracking workflow"}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{src:i(24621).A+"",width:"1000",height:"562"})}),"\n",(0,n.jsx)(t.p,{children:"To build an object tracking workflow, just visit model mode and click the create workflow button in the upper righthand corner of the screen. From here you will need to add two models to your workflow:"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"Model"}),(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"ID"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"efficient person detector"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"5750faf62ed9d514b9ee9d2d163f172e"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Person Tracker"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"c9d65bb4f86c487b848e9400725168d4"})]})]})]}),"\n",(0,n.jsx)(t.p,{children:"Just add these two models to your workflow and connect the efficient person detector to the input node on the Person Tracker."}),"\n",(0,n.jsx)(t.h2,{id:"limitations",children:"Limitations"}),"\n",(0,n.jsx)(t.p,{children:"Please keep in mind that video support is in Beta. Any video of 100MBs or less that is less than 1 minute can be processed at 10 FPS for any workflow. Download is 20 second limit per job assuming 5MB/sec."})]})}function p(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},96451:(e,t,i)=>{i.d(t,{A:()=>n});const n=i.p+"assets/images/object-tracker-a1c692b973631c7637c3b96410cf76d1.jpg"},24621:(e,t,i)=>{i.d(t,{A:()=>n});const n=i.p+"assets/images/person-tracker-wkflw-fb877c3a2d933183737a8a7aa06ecd49.jpg"},28453:(e,t,i)=>{i.d(t,{R:()=>r,x:()=>a});var n=i(96540);const o={},s=n.createContext(o);function r(e){const t=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),n.createElement(s.Provider,{value:t},e.children)}}}]);