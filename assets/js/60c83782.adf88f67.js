"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[6308],{14475:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/my-deep-training-6-599040ca59c7f997c2db49ebfe2e2812.png"},40293:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/my-deep-training-8-834952ebd56f6e3cf09a86c1a44892ec.png"},41529:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/my-deep-training-4-7da8da64158aa1030e5fe5ce9a4e6f97.png"},48454:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/my-deep-training-3-c6220d9888e4f30a8cb1dcfcdfc7d546.png"},60976:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/my-deep-training-5-44e09c1379347bba587c82caf293ee35.png"},63788:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>B,contentTitle:()=>V,default:()=>G,frontMatter:()=>H,metadata:()=>a,toc:()=>q});const a=JSON.parse('{"id":"create/models/deep-fine-tuning/visual-classifier","title":"Visual Classifier","description":"Learn how to create and train a visual classifier model","source":"@site/docs/create/models/deep-fine-tuning/visual-classifier.md","sourceDirName":"create/models/deep-fine-tuning","slug":"/create/models/deep-fine-tuning/visual-classifier","permalink":"/create/models/deep-fine-tuning/visual-classifier","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"description":"Learn how to create and train a visual classifier model","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Deep Fine-Tuning","permalink":"/create/models/deep-fine-tuning/"},"next":{"title":"Visual Detector","permalink":"/create/models/deep-fine-tuning/visual-detector"}}');var s=t(74848),i=t(28453),r=t(65537),o=t(79329),l=t(58069);const d='from clarifai.client.user import User\n#replace your "user_id"\nclient = User(user_id="user_id")\napp = client.create_app(app_id="demo_train", base_workflow="Universal")',c="#importing load_module_dataloader for calling the dataloader object in dataset.py in the local data folder\nfrom clarifai.datasets.upload.utils import load_module_dataloader\n\n\n# Construct the path to the dataset folder\nmodule_path = os.path.join(os.getcwd().split('/models/model_train')[0], 'datasets/upload/image_classification/food-101')\n\n# Load the dataloader module using the provided function from your module\nfood101_dataloader = load_module_dataloader(module_path)\n\n# Create a Clarifai dataset with the specified dataset_id (\"image_dataset\")\ndataset = app.create_dataset(dataset_id=\"image_dataset\")\n\n# Upload the dataset using the provided dataloader and get the upload status\ndataset.upload_dataset(dataloader=food101_dataloader, get_upload_status=True)\n",p="print(app.list_trainable_model_types())",u='MODEL_ID = "model_classifier"\nMODEL_TYPE_ID = "visual-classifier"\n# Create a model by passing the model name and model type as parameter\nmodel = app.create_model(model_id=MODEL_ID, model_type_id=MODEL_TYPE_ID)',h="print(model.list_training_templates())",m="import yaml\nYAML_FILE = 'mmclassification_efficientnet.yaml'\nmodel_params = model.get_params(template='MMClassification_EfficientNet', save_to=YAML_FILE)\n# Preview YAML content\nfile = open(YAML_FILE)\ndata = yaml.safe_load(file)\nprint(data)\n",g="file = open('models/model_train/saved_mmclassification_efficientnet.yaml')\ndata = yaml.safe_load(file)\nprint(data)\n",f="#Starting the training\nmodel_version_id = model.train(yaml_file='models/model_train/saved_mmclassification_efficientnet.yaml')\n#Checking the status of training\n#To store training logs in a file, fix training_logs param as True\nstatus = model.training_status(version_id=model_version_id,training_logs=False)\n",_="import cv2\nimport matplotlib.pyplot as plt\n\nIMAGE_PATH = os.path.join(os.getcwd().split('/models')[0],'datasets/upload/image_classification/food-101/images/hamburger/139558.jpg')\nmodel_prediction = model.predict_by_filepath(IMAGE_PATH, input_type=\"image\")\n\n#Display the model predictions\nimg = plt.imread(IMAGE_PATH)\nplt.axis('off')\nplt.imshow(img)\nfor concept in model_prediction.outputs[0].data.concepts:\n    print(concept.id,':',round(concept.value,2))",x="# Evaluate the model using the specified dataset ID and evaluation ID.\nmodel.evaluate(dataset_id='image_dataset', eval_id='one')\n\n\n# Retrieve the evaluation results using the specified evaluation ID and store it in the variable 'result'.\nresult = model.get_eval_by_id(eval_id=\"one\")\n\n# Print a summary of the evaluation results stored in the variable 'result'.\nprint(result.summary)\n",j="# Load the dataloader module using the provided function from your module\nPATH=os.path.join(os.getcwd().split('/models/model_train')[0],'datasets/upload/data/images_test')\nfood101_dataloader = load_module_dataloader(PATH)\n\n# Create a Clarifai dataset with the specified dataset_id (\"image_dataset\")\ntest_dataset = app.create_dataset(dataset_id=\"image_dataset2\")\n\n# Upload the dataset using the provided dataloader and get the upload status\ntest_dataset.upload_dataset(dataloader=food101_dataloader, get_upload_status=True)\n\n# Evaluate the model using the specified dataset ID and evaluation ID.\nmodel.evaluate(dataset_id='image_dataset2',eval_id='two')\n\n\n# Retrieve the evaluation results using the specified evaluation ID and store it in the variable 'result'.\nresult=model.get_eval_by_id(\"two\")\n\nprint(result.summary)",v="from clarifai.utils.evaluation import EvalResultCompare\n\n# Initializing an object of the EvalResultCompare class\n# with specified models and datasets\neval_result = EvalResultCompare(models=[model], datasets=[dataset, test_dataset])\n\nprint(eval_result.detailed_summary())",y="['visual-classifier',\n 'visual-detector',\n 'visual-segmenter',\n 'visual-anomaly-heatmap',\n 'visual-embedder',\n 'clusterer',\n 'text-classifier',\n 'embedding-classifier',\n 'text-to-text']",b="['classification_inception_general_v1_3_transfer_embednorm',\n 'classification_basemodel_v1',\n 'classification_cifar10_v1',\n 'Clarifai_InceptionTransferEmbedNorm',\n 'Clarifai_ResNext',\n 'Clarifai_InceptionV2',\n 'Clarifai_InceptionBatchNorm',\n 'MMClassification',\n 'MMClassification_EfficientNet',\n 'MMClassification_ResNet_50_RSB_A1',\n 'MMClassification_ResNet_50']",A="{'dataset_id': '',\n 'dataset_version_id': '',\n 'concepts': [],\n 'train_params': {'invalid_data_tolerance_percent': 5.0,\n  'template': 'MMClassification_EfficientNet',\n  'seed': -1.0,\n  'num_gpus': 1.0,\n  'image_size': 336.0,\n  'batch_size': 4.0,\n  'num_epochs': 30.0,\n  'per_item_lrate': 0.000390625,\n  'weight_decay': 0.0001,\n  'momentum': 0.9,\n  'pretrained_weights': 'ImageNet-1k',\n  'flip_probability': 0.5,\n  'flip_direction': 'horizontal',\n  'concepts_mutually_exclusive': False},\n 'inference_params': {'select_concepts': []}}\n",I="{'dataset_id': 'image_dataset',\n 'dataset_version_id': '',\n 'concepts': ['id-ramen', 'id-prime_rib', 'id-hamburger', 'id-beignets'],\n 'train_params': {'invalid_data_tolerance_percent': 5.0,\n  'template': 'MMClassification_EfficientNet',\n  'seed': -1.0,\n  'num_gpus': 1.0,\n  'image_size': 336.0,\n  'batch_size': 4.0,\n  'num_epochs': 10.0,\n  'per_item_lrate': 0.000390625,\n  'weight_decay': 0.0001,\n  'momentum': 0.9,\n  'pretrained_weights': 'ImageNet-1k',\n  'flip_probability': 0.5,\n  'flip_direction': 'horizontal',\n  'concepts_mutually_exclusive': False},\n 'inference_params': {'select_concepts': []}}",E='code: MODEL_TRAINED\ndescription: "Model is trained and ready"',D="id-hamburger : 0.64\n\nid-ramen : 0.45\n\nid-prime_rib : 0.44\n\nid-beignets : 0.42",w="macro_avg_roc_auc: 0.9200000166893005\nmacro_std_roc_auc: 0.03399345278739929\nmacro_avg_f1_score: 0.6682435274124146\nmacro_std_f1_score: 0.08137183636426926\nmacro_avg_precision: 0.53125\nmacro_avg_recall: 0.949999988079071",C="macro_avg_roc_auc: 1.0\nmacro_avg_f1_score: 0.7916666865348816\nmacro_std_f1_score: 0.21650634706020355\nmacro_avg_precision: 0.7083333134651184\nmacro_avg_recall: 1.0",P="INFO:clarifai.utils.evaluation.helpers:Model visual_classifier_eval2/model_classifier/48ed4: retrieving {'binary_metrics': True} metrics of dataset: image_dataset2\n(        Concept  Accuracy (ROC AUC)  Total Labeled  Total Predicted  \\\n 0      id-ramen               0.933              5               12   \n 0  id-prime_rib               0.960              5                5   \n 0  id-hamburger               0.920              5                8   \n 0   id-beignets               0.867              5               12   \n 0      id-ramen               1.000              1                3   \n 0  id-prime_rib               1.000              1                1   \n 0  id-hamburger               1.000              1                1   \n 0   id-beignets               1.000              1                1   \n \n    True Positives  False Negatives  False Positives  Recall  Precision  \\\n 0               5                0                7     1.0     0.4167   \n 0               4                1                1     0.8     0.6667   \n 0               5                0                3     1.0     0.6250   \n 0               5                0                7     1.0     0.4167   \n 0               1                0                2     1.0     0.3333   \n 0               1                0                0     1.0     1.0000   \n 0               1                0                0     1.0     1.0000   \n 0               1                0                0     1.0     0.5000   \n \n          F1         Dataset  \n 0  0.588269  image_dataset3  \n 0  0.727293  image_dataset3  \n 0  0.769231  image_dataset3  \n 0  0.588269  image_dataset3  \n 0  0.499962  image_dataset2  \n 0  1.000000  image_dataset2  \n 0  1.000000  image_dataset2  \n 0  0.666667  image_dataset2  ,\n             Total Concept  Accuracy (ROC AUC)  Total Labeled  Total Predicted  \\\n 0  Dataset:image_dataset3                0.92             20               37   \n 0  Dataset:image_dataset2                1.00              4                6   \n \n    True Positives  False Negatives  False Positives  Recall  Precision  \\\n 0              19                1               18    0.95   0.531275   \n 0               4                0                2    1.00   0.708325   \n \n          F1  \n 0  0.681455  \n 0  0.829263  )",S="##########################################################################################\n# In this section, we set the user authentication, app ID, model ID, and model type ID.\n# Change these strings to run your own example.\n#########################################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the Account's Security section\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to create your own model\nMODEL_ID = 'petsID'\nMODEL_TYPE_ID = 'visual-classifier'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\npost_models_response = stub.PostModels(\n    service_pb2.PostModelsRequest(\n        user_app_id=userDataObject,\n        models=[\n            resources_pb2.Model(\n                id=MODEL_ID,\n                model_type_id=MODEL_TYPE_ID             \n            )\n        ]\n    ),\n    metadata=metadata\n)\n\nif post_models_response.status.code != status_code_pb2.SUCCESS:\n    print(post_models_response.status)\n    raise Exception(\"Post models failed, status: \" + post_models_response.status.description)\n",T="\x3c!--index.html file--\x3e\n\n<script>\n    ///////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and model type ID.\n    // Change these strings to run your own example.\n    //////////////////////////////////////////////////////////////////////////////////////////\n\n    const USER_ID = 'YOUR_USER_ID_HERE';\n    // Your PAT (Personal Access Token) can be found in the Account's Security section\n    const PAT = 'YOUR_PAT_HERE';\n    const APP_ID = 'YOUR_APP_ID_HERE';\n    // Change these to create your own model\n    const MODEL_ID = 'petsID';\n    const MODEL_TYPE_ID = 'visual-classifier';\n    \n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    const raw = JSON.stringify({\n        \"user_app_id\": {\n            \"user_id\": USER_ID,\n            \"app_id\": APP_ID\n        },\n        \"model\": {\n            \"id\": MODEL_ID,\n            \"model_type_id\": MODEL_TYPE_ID         \n        }\n    });\n\n    const requestOptions = {\n        method: 'POST',\n        headers: {\n            'Accept': 'application/json',\n            'Authorization': 'Key ' + PAT\n        },\n        body: raw\n    };\n\n    fetch(\"https://api.clarifai.com/v2/models\", requestOptions)\n        .then(response => response.text())\n        .then(result => console.log(result))\n        .catch(error => console.log('error', error));\n\n<\/script>",O='//index.js file\n\n////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, model ID, and model type ID.\n// Change these strings to run your own example.\n///////////////////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = \'YOUR_USER_ID_HERE\';\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\nconst PAT = \'YOUR_PAT_HERE\';\nconst APP_ID = \'YOUR_APP_ID_HERE\';\n// Change these to create your own model\nconst MODEL_ID = \'petsID\';\nconst MODEL_TYPE_ID = \'visual-classifier\';\n\n/////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n/////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require("clarifai-nodejs-grpc");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set("authorization", "Key " + PAT);\n\nstub.PostModels(\n    {\n        user_app_id: {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        models: [\n            {\n                id: MODEL_ID,\n                model_type_id: MODEL_TYPE_ID               \n            }\n        ]\n    },\n    metadata,\n    (err, response) => {\n        if (err) {\n            throw new Error(err);\n        }\n\n        if (response.status.code !== 10000) {\n            throw new Error("Post models failed, status: " + response.status.description);\n        }\n    }\n);',R='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.status.StatusCode;\n\npublic class ClarifaiExample {\n\n    ////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and model type ID.\n    // Change these strings to run your own example.\n    ///////////////////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to create your own model    \n    static final String MODEL_ID = "petsID";\n    static final String MODEL_TYPE_ID = "visual-classifier";\n    \n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\t\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n            .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        SingleModelResponse postModelsResponse = stub.postModels(\n            PostModelsRequest.newBuilder()\n            .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n            .addModels(\n                Model.newBuilder()\n                .setId(MODEL_ID)\n                .setModelTypeId(MODEL_TYPE_ID)              \n            ).build()\n        );\n\n        if (postModelsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post models failed, status: " + postModelsResponse.getStatus());\n        }\n\n    }\n\n}',N='<?php\n\nrequire __DIR__ . "/vendor/autoload.php";\n\n/////////////////////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, model ID, and model type ID.\n// Change these strings to run your own example.\n/////////////////////////////////////////////////////////////////////////////////////////////////\n\n$USER_ID = "YOUR_USER_ID_HERE";\n// Your PAT (Personal Access Token) can be found in the Account\'s Security section\n$PAT = "YOUR_PAT_HERE";\n$APP_ID = "YOUR_APP_ID_HERE";\n// Change these to create your own model\n$MODEL_ID = "petsID";\n$MODEL_TYPE_ID = "visual-classifier";\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nuse Clarifai\\ClarifaiClient;\nuse Clarifai\\Api\\Model;\nuse Clarifai\\Api\\PostModelsRequest;\nuse Clarifai\\Api\\Status\\StatusCode;\nuse Clarifai\\Api\\UserAppIDSet;\n\n$client = ClarifaiClient::grpc();\n\n$metadata = ["Authorization" => ["Key " . $PAT]];\n\n$userDataObject = new UserAppIDSet([\n    "user_id" => $USER_ID,\n    "app_id" => $APP_ID,\n]);\n\n// Let\'s make a RPC call to the Clarifai platform. It uses the opened gRPC client channel to communicate a\n// request and then wait for the response\n[$response, $status] = $client->PostModels(\n        // The request object carries the request along with the request status and other metadata related to the request itself\n        new PostModelsRequest([\n            "user_app_id" => $userDataObject,\n            "models" => [\n                new Model([                    \n                    "id" => $MODEL_ID,\n                    "model_type_id" => $MODEL_TYPE_ID,\n                ]),\n            ],\n        ]),\n        $metadata\n    )->wait();\n\n// A response is returned and the first thing we do is check the status of it\n// A successful response will have a status code of 0; otherwise, there is some error\nif ($status->code !== 0) {\n    throw new Exception("Error: {$status->details}");\n}\n// In addition to the RPC response status, there is a Clarifai API status that reports if the operation was a success or failure\n// (not just that the communication was successful)\nif ($response->getStatus()->getCode() != StatusCode::SUCCESS) {\n    throw new Exception("Failure response: " . $response->getStatus()->getDescription() . " " . $response->getStatus()->getDetails());\n}\n\n?>',M='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models" \\\n  -H "Authorization: Key YOUR_PAT_HERE" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "model": {\n      "id": "petsID",\n      "model_type_id": "visual-classifier"\n    }\n  }\'',U='########################################################################################\n# In this section, we set the user authentication, app ID, model ID, and concept IDs.\n# Change these strings to run your own example.\n########################################################################################\n\nUSER_ID = "YOUR_USER_ID_HERE"\n# Your PAT (Personal Access Token) can be found in the Account\'s Security section\nPAT = "YOUR_PAT_HERE"\nAPP_ID = "YOUR_APP_ID_HERE"\n# Change these to train your own model\nMODEL_ID = "petsID"\nCONCEPT_ID_1 = "ferrari23"\nCONCEPT_ID_2 = "outdoors23"\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\nfrom google.protobuf.struct_pb2 import Struct\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nparams = Struct()\nparams.update(\n    {\n        "template": "MMClassification_ResNet_50_RSB_A1", \n        "num_epochs": 2\n    }\n    )\n\nmetadata = (("authorization", "Key " + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\npost_model_versions = stub.PostModelVersions(\n    service_pb2.PostModelVersionsRequest(\n        user_app_id=userDataObject,\n        model_id=MODEL_ID,\n        model_versions=[\n            resources_pb2.ModelVersion(\n                train_info=resources_pb2.TrainInfo(\n                    params=params,\n                ),\n                output_info=resources_pb2.OutputInfo(\n                    data=resources_pb2.Data(\n                        concepts=[\n                            resources_pb2.Concept(id=CONCEPT_ID_1),\n                            resources_pb2.Concept(id=CONCEPT_ID_2)\n                            ]\n                    ),\n                ),\n            )\n        ],\n    ),\n    metadata=metadata,\n)\n\nif post_model_versions.status.code != status_code_pb2.SUCCESS:\n    print(post_model_versions.status)\n    raise Exception("Post models versions failed, status: " + post_model_versions.status.description)\n',Y='\x3c!--index.html file--\x3e\n\n<script>\n    //////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and concept IDs.\n    // Change these strings to run your own example.\n    /////////////////////////////////////////////////////////////////////////////////////////\n\n    const USER_ID = "YOUR_USER_ID_HERE";\n    // Your PAT (Personal Access Token) can be found in the Account\'s Security section\n    const PAT = "YOUR_PAT_HERE";\n    const APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to train your own model\n    const MODEL_ID = "petsID";\n    const CONCEPT_ID_1 = "ferrari23";\n    const CONCEPT_ID_2 = "outdoors23";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    const raw = JSON.stringify({\n        "user_app_id": {\n            "user_id": USER_ID,\n            "app_id": APP_ID\n        },\n        "model_versions": [{\n            "train_info": {\n                "params": {\n                    "template": "MMClassification_ResNet_50_RSB_A1",\n                    "num_epochs": 2\n                }\n            },\n            "output_info": {\n                "data": {\n                    "concepts": [\n                        {\n                            "id": CONCEPT_ID_1\n                        },\n                        {\n                            "id": CONCEPT_ID_2\n                        }\n                    ]\n                }\n            }\n        }]\n\n    });\n\n    const requestOptions = {\n        method: "POST",\n        headers: {\n            "Content-Type": "application/json",\n            "Authorization": "Key " + PAT\n        },\n        body: raw\n    };\n\n    fetch(`https://api.clarifai.com/v2/models/${MODEL_ID}/versions`, requestOptions)\n        .then(response => response.text())\n        .then(result => console.log(result))\n        .catch(error => console.log("error", error));\n\n<\/script>',L='package com.clarifai.example;\n\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.status.StatusCode;\nimport com.google.protobuf.Struct;\nimport com.google.protobuf.Value;\n\npublic class ClarifaiExample {\n\n    //////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, model ID, and concept IDs.\n    // Change these strings to run your own example.\n    //////////////////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    // Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to train your own model\n    static final String MODEL_ID = "petsID";\n    static final String CONCEPT_ID_1 = "ferrari23";\n    static final String CONCEPT_ID_2 = "outdoors23";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\t\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n                .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        Struct.Builder params = Struct.newBuilder()\n                .putFields("template", Value.newBuilder().setStringValue("MMClassification_ResNet_50_RSB_A1").build())\n                .putFields("num_epochs", Value.newBuilder().setNumberValue(2).build());\n\n        SingleModelResponse postModelVersionsResponse = stub.postModelVersions(\n                PostModelVersionsRequest.newBuilder()\n                        .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n                        .setModelId(MODEL_ID)\n                        .addModelVersions(ModelVersion.newBuilder()\n                                .setTrainInfo(TrainInfo.newBuilder()\n                                        .setParams(params)\n                                )\n                                .setOutputInfo(OutputInfo.newBuilder()\n                                        .setData(Data.newBuilder()\n                                                .addConcepts(Concept.newBuilder()\n                                                        .setId(CONCEPT_ID_1)\n                                                )\n                                                .addConcepts(Concept.newBuilder()\n                                                        .setId(CONCEPT_ID_2)\n                                                )\n                                        )\n                                )\n                        )\n                        .build()\n        );\n\n        if (postModelVersionsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Post model outputs failed, status: " + postModelVersionsResponse.getStatus());\n        }\n\n    }\n}\n',k='curl -X POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models/YOUR_MODEL_ID_HERE/versions" \\\n  -H "Authorization: Key YOUR_PAT_HERE" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n        "model_versions": [{\n            "train_info": {\n                "params": {\n                    "template": "MMClassification_ResNet_50_RSB_A1",\n                    "num_epochs": 2\n                }\n            },\n            "output_info": {\n                "data": {\n                    "concepts": [\n                        {\n                            "id": "ferrari23"\n                        },\n                        {\n                            "id": "outdoors23"\n                        }\n                    ]\n                }\n            }\n        }] \n  }\'',H={description:"Learn how to create and train a visual classifier model",sidebar_position:2},V="Visual Classifier",B={},q=[{value:"Example Use Case",id:"example-use-case",level:2},{value:"<strong>Via the UI</strong>",id:"via-the-ui",level:2},{value:"Step 1: Prepare Training Data",id:"step-1-prepare-training-data",level:3},{value:"Step 2: Create an App",id:"step-2-create-an-app",level:3},{value:"Step 3: Add and Annotate Inputs",id:"step-3-add-and-annotate-inputs",level:3},{value:"Step 4: Choose a Model Type",id:"step-4-choose-a-model-type",level:3},{value:"Step 5: Create the Model",id:"step-5-create-the-model",level:3},{value:"Step 6: Train the Model\u200b",id:"step-6-train-the-model",level:3},{value:"Step 7: Use the Model\u200b",id:"step-7-use-the-model",level:3},{value:"<strong>Via the API</strong>",id:"via-the-api",level:2},{value:"Step 1: App Creation",id:"step-1-app-creation",level:3},{value:"Step 2: Dataset Upload",id:"step-2-dataset-upload",level:3},{value:"Step 3: Model Creation",id:"step-3-model-creation",level:3},{value:"Step 4: Template Selection",id:"step-4-template-selection",level:3},{value:"Step 5: Set Up Model Parameters",id:"step-5-set-up-model-parameters",level:3},{value:"Step 6: Initiate Model Training",id:"step-6-initiate-model-training",level:3},{value:"Step 7: Model Prediction",id:"step-7-model-prediction",level:3},{value:"Step 8: Model Evaluation",id:"step-8-model-evaluation",level:3}];function $(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:a}=n;return a||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"visual-classifier",children:"Visual Classifier"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Learn how to create and train a visual classifier model"})}),"\n",(0,s.jsx)("hr",{}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input"}),": Images and videos"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Output"}),": ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/concepts",children:"Concepts"})]}),"\n",(0,s.jsx)(n.p,{children:'Visual classifier is a type of deep fine-tuned model that allows you to classify images and video frames into a set of concepts. It helps you answer the question "What" or "Who" is in your data.'}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{src:t(66832).A+"",width:"822",height:"462"}),"\n",(0,s.jsx)("center",{children:"Image classification example"})]}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["The visual classifier model type also comes with various ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/model/deep-training/visual-classification-templates/",children:"templates"})," that give you the control to choose the specific architecture used by your neural network, as well as define a set of hyperparameters you can use to fine-tune the way your model learns."]})}),"\n",(0,s.jsx)(n.p,{children:"Visual classifiers are commonly used for various computer vision tasks, such as:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Image classification"}),': Categorizing images into different concepts, such as "cat", "dog", "car", or "person".']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Object detection"}),": Finding and identifying objects in images, such as faces, cars, or traffic signs."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scene recognition"}),": Identifying the scene in an image, such as a beach, a forest, or a city."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Video analysis"}),": Tracking objects and events in videos."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"You may choose a visual classifier model type in cases where:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Accuracy and the ability to carefully target solutions take priority over speed and ease of use."}),"\n",(0,s.jsxs)(n.li,{children:['You need a classification model to learn new features not recognized by the existing Clarifai models. In that case, you may need to "deep fine-tune" your custom model and integrate it directly within your ',(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/workflows/",children:"workflows"}),"."]}),"\n",(0,s.jsx)(n.li,{children:"You have a custom-tailored dataset, accurate labels, and the expertise and time to fine-tune models."}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"example-use-case",children:"Example Use Case"}),"\n",(0,s.jsx)(n.p,{children:"A large retailer is looking to find and remove listings for illegal objects and substances across thousands of listings that include user-generated data. A classification model allows the retailer to quickly find listings that violate their community rules, and remove them from the site."}),"\n",(0,s.jsx)(n.h2,{id:"via-the-ui",children:(0,s.jsx)(n.strong,{children:"Via the UI"})}),"\n",(0,s.jsx)(n.p,{children:"Let's demonstrate how to create and train a visual classifier model using the UI. We intend to create a model that can distinguish between images of cats and dogs."}),"\n",(0,s.jsx)(n.h3,{id:"step-1-prepare-training-data",children:"Step 1: Prepare Training Data"}),"\n",(0,s.jsx)(n.p,{children:"Preparing data for fine-tuning ensures that the custom model learns effectively from the new task or domain, generalizes well to unseen data, and produces reliable predictions."}),"\n",(0,s.jsx)(n.p,{children:"Ensure that you collect high-quality, well-prepared data that will help achieve optimized performance in your model."}),"\n",(0,s.jsxs)(n.p,{children:["You can prepare your data using your preferred spreadsheet software.\n",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/advanced-topics/csv-and-tsv",children:"Click here"})," to download a CSV template you can use to prepare your data."]}),"\n",(0,s.jsxs)(n.p,{children:["To illustrate how fine-tuning works, we'll prepare the following simple dataset consisting of images of dogs and cats. Note that for your model to perform well, you need to provide it with enough diverse data to learn meaningful patterns. ",(0,s.jsx)(n.a,{href:"https://www.clarifai.com/blog/using-ai-to-create-applications-downloading-images-easily",children:"Click here"})," to learn how you can get images to enrich your dataset."]}),"\n",(0,s.jsxs)(a,{children:[(0,s.jsx)("summary",{children:"Sample Dataset"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"https://samples.clarifai.com/dog1.jpeg\nhttps://samples.clarifai.com/dog2.jpeg\nhttps://samples.clarifai.com/dog3.jpeg\nhttps://samples.clarifai.com/dog2_tiny.jpeg\nhttps://samples.clarifai.com/dog.tiff\nhttps://samples.clarifai.com/cat1.jpeg\nhttps://samples.clarifai.com/cat2.jpeg\nhttps://samples.clarifai.com/cat3.jpeg\nhttps://samples.clarifai.com/featured-models/blip-flying-cat.jpg\nhttps://samples.clarifai.com/featured-models/social-media-cat-laying-down.jpg\n"})})]}),"\n",(0,s.jsx)(n.h3,{id:"step-2-create-an-app",children:"Step 2: Create an App"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/clarifai-basics/applications/create-an-application/#create-an-application-on-the-portal",children:"Click here"})," to learn how to create an application on the Clarifai portal."]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["When creating the application, go with the default Image/Video option as the primary input type. And in the collapsible ",(0,s.jsx)(n.strong,{children:"Advanced Settings"})," field, also go with the default ",(0,s.jsx)(n.strong,{children:"Universal"})," as the ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/workflows/base-workflows/",children:"base workflow"}),"."]})}),"\n",(0,s.jsx)(n.h3,{id:"step-3-add-and-annotate-inputs",children:"Step 3: Add and Annotate Inputs"}),"\n",(0,s.jsxs)(n.p,{children:["Select the ",(0,s.jsx)(n.strong,{children:"Inputs"})," option on your app\u2019s collapsible left sidebar. Next, use the inputs uploader pop-up window to ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete#add-inputs",children:"upload"})," the images of dogs you prepared to a ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete",children:"dataset"})," within your application."]}),"\n",(0,s.jsxs)(n.p,{children:["Also, ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/annotate/create-get-update-delete",children:"label"}),' the images with the "dog" concept.']}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:t(68564).A+"",width:"1905",height:"889"})}),"\n",(0,s.jsxs)(n.p,{children:["Click the ",(0,s.jsx)(n.strong,{children:"Upload inputs"})," button to add the annotated images of dogs to your app."]}),"\n",(0,s.jsx)(n.p,{children:"Similarly, use the inputs uploader pop-up window to upload the images of cats you prepared to the same dataset."}),"\n",(0,s.jsx)(n.p,{children:'Also, label the images with the "cat" concept.'}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:t(87471).A+"",width:"1911",height:"906"})}),"\n",(0,s.jsxs)(n.p,{children:["Click the ",(0,s.jsx)(n.strong,{children:"Upload inputs"})," button to add the annotated images of cats to your app."]}),"\n",(0,s.jsx)(n.h3,{id:"step-4-choose-a-model-type",children:"Step 4: Choose a Model Type"}),"\n",(0,s.jsxs)(n.p,{children:["Select the ",(0,s.jsx)(n.strong,{children:"Models"})," option on your app\u2019s collapsible left sidebar."]}),"\n",(0,s.jsxs)(n.p,{children:["Click the ",(0,s.jsx)(n.strong,{children:"Add Model"})," button on the upper-right corner of the page. On the window that pops up, select the ",(0,s.jsx)(n.strong,{children:"Build a Custom Model"})," option and click the ",(0,s.jsx)(n.strong,{children:"Continue"})," button."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:t(48454).A+"",width:"1897",height:"862"})}),"\n",(0,s.jsx)(n.p,{children:"You\u2019ll be redirected to a page where you can choose the type of model you want to create and fine-tune."}),"\n",(0,s.jsxs)(n.p,{children:["Select the ",(0,s.jsx)(n.strong,{children:"Visual Classifier"})," option."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:t(41529).A+"",width:"1804",height:"836"})}),"\n",(0,s.jsx)(n.h3,{id:"step-5-create-the-model",children:"Step 5: Create the Model"}),"\n",(0,s.jsx)(n.p,{children:"The ensuing page allows you to create and fine-tune a visual classifier model that categorizes images into a set of predefined concepts."}),"\n",(0,s.jsxs)(n.p,{children:["Provide a unique ID and click the ",(0,s.jsx)(n.strong,{children:"Continue to Configure model"})," button to create your model."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:t(60976).A+"",width:"1840",height:"742"})}),"\n",(0,s.jsx)(n.p,{children:"After creating the model, set it up for training."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:t(14475).A+"",width:"1723",height:"896"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Dataset"})," \u2014 Select the dataset you previously created that has the images of the dogs and cats. You can also select ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete#update-a-dataset-version",children:"a specific version"})," for it."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Concepts"}),' \u2014 Select the list of concepts you want the model to predict from the existing concepts in your app. For this example, let\'s select "cat" and "dog."']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Invalid Data Tolerance Percent"})," \u2014 Optionally, you can set a tolerance threshold (0 to 100) for the percentage of invalid inputs during training, and if this threshold is exceeded, training is stopped with an error."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Template"})," \u2014 Select a pre-configured model template you want to use to fine-tune your model. When you choose a deep training template, you will see the hyperparameters that are available within that template populated with default values. You can adjust these values as desired. For this example, we\u2019ll go with the recommended template: ",(0,s.jsx)(n.code,{children:"MMClassification_ResNet_50_RSB_A1"}),". ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/model/deep-training/visual-classification-templates",children:"Click here"})," to learn more about the visual classification templates."]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["Notice that the estimated duration for the training process is displayed for you. This ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/create-manage/models/deep-fine-tuning/#training-time-estimator",children:"Training Time Estimator"})," feature offers transparency in expected training costs."]})}),"\n",(0,s.jsx)(n.h3,{id:"step-6-train-the-model",children:"Step 6: Train the Model\u200b"}),"\n",(0,s.jsxs)(n.p,{children:["After configuring the training settings, click the ",(0,s.jsx)(n.strong,{children:"Train Model"})," button to initiate training your model."]}),"\n",(0,s.jsx)(n.p,{children:"You'll be redirected to the individual page of your model."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:t(93346).A+"",width:"1790",height:"736"})}),"\n",(0,s.jsxs)(n.p,{children:["If you check the ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/model-versions/#model-versions-table",children:"model's versions table"}),", you\u2019ll notice that the model is still being trained."]}),"\n",(0,s.jsxs)(n.p,{children:["Many hours may be required to deep train models with large numbers of inputs and complex taxonomies. You can cancel a deep fine-tuning job at any time by clicking the ",(0,s.jsx)(n.strong,{children:"Cancel training"})," button."]}),"\n",(0,s.jsx)(n.admonition,{type:"caution",children:(0,s.jsxs)(n.p,{children:["Deep fine-tuning is billed at an hourly rate, and for canceled jobs, you will be charged for the time you've used to train your model. You can learn more about deep fine-tuning pricing ",(0,s.jsx)(n.a,{href:"https://www.clarifai.com/pricing",children:"here"}),"."]})}),"\n",(0,s.jsxs)(n.p,{children:["You can check the training progress by clicking the ",(0,s.jsx)(n.strong,{children:"View Training Log"})," button. If you click the button, a small sidebar will appear with details of the training exercise.\nYou can also download the training log data by clicking the ",(0,s.jsx)(n.strong,{children:"download"})," button."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:t(71696).A+"",width:"1632",height:"627"})}),"\n",(0,s.jsx)(n.h3,{id:"step-7-use-the-model",children:"Step 7: Use the Model\u200b"}),"\n",(0,s.jsxs)(n.p,{children:["After the model has been trained, the status will change to ",(0,s.jsx)(n.strong,{children:"Model Trained"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.strong,{children:"Actions"})," column, you can carry out the following:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Copy the model version ID"}),"\n",(0,s.jsxs)(n.li,{children:["View the model in the ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/evaluate/leaderboard/",children:"leaderboard"})]}),"\n",(0,s.jsxs)(n.li,{children:["View the ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/model-versions/",children:"model version details"})]}),"\n",(0,s.jsx)(n.li,{children:"Download the training log data"}),"\n",(0,s.jsx)(n.li,{children:"Delete the model version"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:t(40293).A+"",width:"1596",height:"770"})}),"\n",(0,s.jsxs)(n.p,{children:["Once you've created and trained your new model, you can put it to work. It will be ready to be ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/evaluate/",children:"evaluated"}),", combined with other models and ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/model/agent-system-operators/",children:"agent operators"})," in a workflow, or used to serve ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/ppredict",children:"inference"})," requests as it is."]}),"\n",(0,s.jsx)(n.p,{children:"That's it!"}),"\n",(0,s.jsx)(n.h2,{id:"via-the-api",children:(0,s.jsx)(n.strong,{children:"Via the API"})}),"\n",(0,s.jsx)(n.p,{children:"Let's demonstrate how to create and train a visual classifier model using our API."}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["Before using the ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/python-sdk",children:"Python SDK"}),", ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/nodejs-sdk",children:"Node.js SDK"}),", or any of our ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/grpc-clients",children:"gRPC clients"}),", ensure they are properly installed on your machine. Refer to their respective installation guides for instructions on how to install and initialize them."]})}),"\n","\n","\n","\n","\n","\n",(0,s.jsx)(n.h3,{id:"step-1-app-creation",children:"Step 1: App Creation"}),"\n",(0,s.jsxs)(n.p,{children:["Let's start by creating an ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/create-manage/applications/create",children:"app"}),"."]}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,s.jsx)(l.A,{className:"language-python",children:d})})}),"\n",(0,s.jsx)(n.h3,{id:"step-2-dataset-upload",children:"Step 2: Dataset Upload"}),"\n",(0,s.jsxs)(n.p,{children:["Next, let\u2019s upload the ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/create-manage/datasets/upload",children:"dataset"})," that will be used to train the model to the app."]}),"\n",(0,s.jsxs)(n.p,{children:["You can find the dataset we used ",(0,s.jsx)(n.a,{href:"https://github.com/Clarifai/examples/tree/main/datasets/upload/image_classification",children:"here"}),"."]}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,s.jsx)(l.A,{className:"language-python",children:c})})}),"\n",(0,s.jsx)(n.h3,{id:"step-3-model-creation",children:"Step 3: Model Creation"}),"\n",(0,s.jsx)(n.p,{children:"Let's list all the available trainable model types in the Clarifai platform."}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,s.jsx)(l.A,{className:"language-python",children:p})})}),"\n",(0,s.jsxs)(a,{children:[(0,s.jsx)("summary",{children:"Output"}),(0,s.jsx)(l.A,{className:"language-text",children:y})]}),"\n",(0,s.jsxs)(n.p,{children:["Next, let's select the ",(0,s.jsx)(n.code,{children:"visual-classifier"})," model type and use it to create a model."]}),"\n",(0,s.jsxs)(r.A,{groupId:"code",children:[(0,s.jsx)(o.A,{value:"python",label:"Python SDK",children:(0,s.jsx)(l.A,{className:"language-python",children:u})}),(0,s.jsx)(o.A,{value:"python2",label:"Python (gRPC)",children:(0,s.jsx)(l.A,{className:"language-python",children:S})}),(0,s.jsx)(o.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,s.jsx)(l.A,{className:"language-javascript",children:T})}),(0,s.jsx)(o.A,{value:"nodejs",label:"Node.js (gRPC)",children:(0,s.jsx)(l.A,{className:"language-javascript",children:O})}),(0,s.jsx)(o.A,{value:"java",label:"Java (gRPC)",children:(0,s.jsx)(l.A,{className:"language-java",children:R})}),(0,s.jsx)(o.A,{value:"php",label:"PHP (gRPC)",children:(0,s.jsx)(l.A,{className:"language-php",children:N})}),(0,s.jsx)(o.A,{value:"curl",label:"cURL",children:(0,s.jsx)(l.A,{className:"language-bash",children:M})})]}),"\n",(0,s.jsx)(n.h3,{id:"step-4-template-selection",children:"Step 4: Template Selection"}),"\n",(0,s.jsx)(n.p,{children:"Let's list all the available training templates in the Clarifai platform."}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(o.A,{value:"python",label:"Python",children:(0,s.jsx)(l.A,{className:"language-python",children:h})})}),"\n",(0,s.jsxs)(a,{children:[(0,s.jsx)("summary",{children:"Output"}),(0,s.jsx)(l.A,{className:"language-text",children:b})]}),"\n",(0,s.jsxs)(n.p,{children:["Next, let's choose the ",(0,s.jsx)(n.code,{children:"'MMClassification_EfficientNet' "})," template to use for training our model, as demonstrated below."]}),"\n",(0,s.jsx)(n.h3,{id:"step-5-set-up-model-parameters",children:"Step 5: Set Up Model Parameters"}),"\n",(0,s.jsx)(n.p,{children:"You can save the model parameters in a YAML file, which can then be passed to the model when initiating training."}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(o.A,{value:"python",label:"Python",children:(0,s.jsx)(l.A,{className:"language-python",children:m})})}),"\n",(0,s.jsxs)(a,{children:[(0,s.jsx)("summary",{children:"Output"}),(0,s.jsx)(l.A,{className:"language-text",children:A})]}),"\n",(0,s.jsx)(n.p,{children:"You can customize the YAML file according to your requirements and then reload it for model training."}),"\n",(0,s.jsx)(n.p,{children:"Below is an example of the modifications made to the YAML file:"}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(o.A,{value:"python",label:"Python",children:(0,s.jsx)(l.A,{className:"language-python",children:g})})}),"\n",(0,s.jsxs)(a,{children:[(0,s.jsx)("summary",{children:"Output"}),(0,s.jsx)(l.A,{className:"language-text",children:I})]}),"\n",(0,s.jsx)(n.h3,{id:"step-6-initiate-model-training",children:"Step 6: Initiate Model Training"}),"\n",(0,s.jsxs)(n.p,{children:["You can initiate model training by passing the YAML configuration file as a parameter to ",(0,s.jsx)(n.code,{children:"model.train()"}),". The Clarifai API also provides features for monitoring training status and saving training logs to a local file."]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["If the status code is ",(0,s.jsx)(n.code,{children:"MODEL-TRAINED"}),", it indicates that the model has been successfully trained and is ready for use."]})}),"\n",(0,s.jsxs)(r.A,{groupId:"code",children:[(0,s.jsx)(o.A,{value:"python",label:"Python",children:(0,s.jsx)(l.A,{className:"language-python",children:f})}),(0,s.jsx)(o.A,{value:"python2",label:"Python (gRPC)",children:(0,s.jsx)(l.A,{className:"language-python",children:U})}),(0,s.jsx)(o.A,{value:"js_rest",label:"JavaScript (REST)",children:(0,s.jsx)(l.A,{className:"language-javascript",children:Y})}),(0,s.jsx)(o.A,{value:"java",label:"Java (gRPC)",children:(0,s.jsx)(l.A,{className:"language-java",children:L})}),(0,s.jsx)(o.A,{value:"curl",label:"cURL",children:(0,s.jsx)(l.A,{className:"language-bash",children:k})})]}),"\n",(0,s.jsxs)(a,{children:[(0,s.jsx)("summary",{children:"Output"}),(0,s.jsx)(l.A,{className:"language-text",children:E})]}),"\n",(0,s.jsx)(n.h3,{id:"step-7-model-prediction",children:"Step 7: Model Prediction"}),"\n",(0,s.jsx)(n.p,{children:"After the model is trained and ready to use, you can run some predictions with it."}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(o.A,{value:"python",label:"Python",children:(0,s.jsx)(l.A,{className:"language-python",children:_})})}),"\n",(0,s.jsxs)(a,{children:[(0,s.jsx)("summary",{children:"Output"}),(0,s.jsx)(l.A,{className:"language-text",children:D}),(0,s.jsx)("img",{src:"/img/python-sdk/vc_mp.png"})]}),"\n",(0,s.jsx)(n.h3,{id:"step-8-model-evaluation",children:"Step 8: Model Evaluation"}),"\n",(0,s.jsx)(n.p,{children:"Let\u2019s evaluate the model using both the training and test datasets. We\u2019ll start by reviewing the evaluation metrics for the training dataset."}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(o.A,{value:"python",label:"Python",children:(0,s.jsx)(l.A,{className:"language-python",children:x})})}),"\n",(0,s.jsxs)(a,{children:[(0,s.jsx)("summary",{children:"Output"}),(0,s.jsx)(l.A,{className:"language-text",children:w})]}),"\n",(0,s.jsx)(n.p,{children:"Before evaluating the model on the test dataset, ensure it is uploaded using the data loader. Once uploaded, proceed with the evaluation."}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(o.A,{value:"python",label:"Python",children:(0,s.jsx)(l.A,{className:"language-python",children:j})})}),"\n",(0,s.jsxs)(a,{children:[(0,s.jsx)("summary",{children:"Output"}),(0,s.jsx)(l.A,{className:"language-text",children:C})]}),"\n",(0,s.jsxs)(n.p,{children:["Finally, to gain deeper insights into the model\u2019s performance, use the ",(0,s.jsx)(n.code,{children:"EvalResultCompare"})," method to compare results across multiple datasets."]}),"\n",(0,s.jsx)(r.A,{groupId:"code",children:(0,s.jsx)(o.A,{value:"python",label:"Python",children:(0,s.jsx)(l.A,{className:"language-python",children:v})})}),"\n",(0,s.jsxs)(a,{children:[(0,s.jsx)("summary",{children:"Output"}),(0,s.jsx)(l.A,{className:"language-text",children:P})]})]})}function G(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)($,{...e})}):$(e)}},65537:(e,n,t)=>{t.d(n,{A:()=>b});var a=t(96540),s=t(18215),i=t(65627),r=t(56347),o=t(50372),l=t(30604),d=t(11861),c=t(78749);function p(e){return a.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function u(e){const{values:n,children:t}=e;return(0,a.useMemo)((()=>{const e=n??function(e){return p(e).map((e=>{let{props:{value:n,label:t,attributes:a,default:s}}=e;return{value:n,label:t,attributes:a,default:s}}))}(t);return function(e){const n=(0,d.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function h(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function m(e){let{queryString:n=!1,groupId:t}=e;const s=(0,r.W6)(),i=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,l.aZ)(i),(0,a.useCallback)((e=>{if(!i)return;const n=new URLSearchParams(s.location.search);n.set(i,e),s.replace({...s.location,search:n.toString()})}),[i,s])]}function g(e){const{defaultValue:n,queryString:t=!1,groupId:s}=e,i=u(e),[r,l]=(0,a.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!h({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const a=t.find((e=>e.default))??t[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:n,tabValues:i}))),[d,p]=m({queryString:t,groupId:s}),[g,f]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[s,i]=(0,c.Dv)(t);return[s,(0,a.useCallback)((e=>{t&&i.set(e)}),[t,i])]}({groupId:s}),_=(()=>{const e=d??g;return h({value:e,tabValues:i})?e:null})();(0,o.A)((()=>{_&&l(_)}),[_]);return{selectedValue:r,selectValue:(0,a.useCallback)((e=>{if(!h({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);l(e),p(e),f(e)}),[p,f,i]),tabValues:i}}var f=t(9136);const _={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=t(74848);function j(e){let{className:n,block:t,selectedValue:a,selectValue:r,tabValues:o}=e;const l=[],{blockElementScrollPositionUntilNextRender:d}=(0,i.a_)(),c=e=>{const n=e.currentTarget,t=l.indexOf(n),s=o[t].value;s!==a&&(d(n),r(s))},p=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":t},n),children:o.map((e=>{let{value:n,label:t,attributes:i}=e;return(0,x.jsx)("li",{role:"tab",tabIndex:a===n?0:-1,"aria-selected":a===n,ref:e=>{l.push(e)},onKeyDown:p,onClick:c,...i,className:(0,s.A)("tabs__item",_.tabItem,i?.className,{"tabs__item--active":a===n}),children:t??n},n)}))})}function v(e){let{lazy:n,children:t,selectedValue:i}=e;const r=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=r.find((e=>e.props.value===i));return e?(0,a.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:r.map(((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==i})))})}function y(e){const n=g(e);return(0,x.jsxs)("div",{className:(0,s.A)("tabs-container",_.tabList),children:[(0,x.jsx)(j,{...n,...e}),(0,x.jsx)(v,{...n,...e})]})}function b(e){const n=(0,f.A)();return(0,x.jsx)(y,{...e,children:p(e.children)},String(n))}},66832:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/image_classification_example-ed5ff532bd9491162ef2aa247052cc75.webp"},68564:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/my-deep-training-1-c153237957e0db7deb8527ad4621f587.png"},71696:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/my-deep-training-7-1-2da46f71d174190524213e2cebabdaa6.png"},79329:(e,n,t)=>{t.d(n,{A:()=>r});t(96540);var a=t(18215);const s={tabItem:"tabItem_Ymn6"};var i=t(74848);function r(e){let{children:n,hidden:t,className:r}=e;return(0,i.jsx)("div",{role:"tabpanel",className:(0,a.A)(s.tabItem,r),hidden:t,children:n})}},87471:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/my-deep-training-2-dc1bf180fa3345138283225ab311578b.png"},93346:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/my-deep-training-7-87fbe351c3e1c454c2ff189a42bcaeb6.png"}}]);