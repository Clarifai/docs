"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[3837],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>h});var o=a(67294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,o)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,o,n=function(e,t){if(null==e)return{};var a,o,n={},r=Object.keys(e);for(o=0;o<r.length;o++)a=r[o],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)a=r[o],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var s=o.createContext({}),p=function(e){var t=o.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=p(e.components);return o.createElement(s.Provider,{value:t},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},m=o.forwardRef((function(e,t){var a=e.components,n=e.mdxType,r=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=p(a),m=n,h=u["".concat(s,".").concat(m)]||u[m]||c[m]||r;return a?o.createElement(h,i(i({ref:t},d),{},{components:a})):o.createElement(h,i({ref:t},d))}));function h(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var r=a.length,i=new Array(r);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:n,i[1]=l;for(var p=2;p<r;p++)i[p]=a[p];return o.createElement.apply(null,i)}return o.createElement.apply(null,a)}m.displayName="MDXCreateElement"},75681:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>c,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var o=a(87462),n=(a(67294),a(3905));const r={description:"Learn about our text-to-text model type and understand its fine-tuning process",sidebar_position:9},i="Text-To-Text",l={unversionedId:"portal-guide/model/model-types/text-to-text",id:"portal-guide/model/model-types/text-to-text",title:"Text-To-Text",description:"Learn about our text-to-text model type and understand its fine-tuning process",source:"@site/docs/portal-guide/model/model-types/text-to-text.md",sourceDirName:"portal-guide/model/model-types",slug:"/portal-guide/model/model-types/text-to-text",permalink:"/portal-guide/model/model-types/text-to-text",draft:!1,tags:[],version:"current",sidebarPosition:9,frontMatter:{description:"Learn about our text-to-text model type and understand its fine-tuning process",sidebar_position:9},sidebar:"tutorialSidebar",previous:{title:"Text Classifier",permalink:"/portal-guide/model/model-types/text-classifier"},next:{title:"Deep Fine-Tuning Templates",permalink:"/portal-guide/model/deep-training/"}},s={},p=[{value:"How to Fine-Tune Text-to-Text Models",id:"how-to-fine-tune-text-to-text-models",level:2},{value:"1. Prepare your data",id:"1-prepare-your-data",level:3},{value:"2. Create an app",id:"2-create-an-app",level:3},{value:"3. Choose a model",id:"3-choose-a-model",level:3},{value:"4. Create the model",id:"4-create-the-model",level:3}],d={toc:p},u="wrapper";function c(e){let{components:t,...r}=e;return(0,n.kt)(u,(0,o.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"text-to-text"},"Text-To-Text"),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Learn about our text-to-text model type and understand its fine-tuning process")),(0,n.kt)("hr",null),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Input"),": Text"),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Output"),": Text"),(0,n.kt)("p",null,"Text-to-text is a general-purpose type of deep fine-tuned model that operates on a text-completion principle, specifically utilizing next-token prediction.\nIn the field of natural language processing (NLP), a language model is a computational model that is trained on a large dataset of text and learns to predict the probability distribution of the next word or token given the preceding context."),(0,n.kt)("p",null,"In the case of a text-to-text model, the approach is a bit more flexible than traditional language models. Instead of being restricted to generating text in a sequential manner, where the output builds upon the previous tokens, text-to-text models treat both the input and output as sequences of tokens. This means that the model can be used for various tasks beyond just predicting the next token."),(0,n.kt)("p",null,'The general idea behind text-to-text models is to frame a wide range of NLP tasks, including both generation and comprehension tasks, as a text-to-text problem. This approach provides a unified framework for solving various NLP tasks. The model is trained to take an input sequence (the "text") and generate an output sequence (also "text") that corresponds to the desired task.'),(0,n.kt)("admonition",{type:"info"},(0,n.kt)("p",{parentName:"admonition"},"The text-to-text model type also comes with various ",(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/model/deep-training/text-templates"},"templates")," that give you the control to choose the specific architecture used by your neural network, as well as define a set of hyperparameters you can use to fine-tune the way your model learns.")),(0,n.kt)("p",null,"The text-to-text model type can be used in a wide range of applications, including:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Text completion"),": The model is given a prompt, such as a sentence or a paragraph, and it generates the next sentence. This can be used to create creative text formats, such as poems, code, scripts, musical pieces, emails, letters, etc."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Text classification"),": The model can assign a label or category to a given piece of text. This can be used to organize, structure, and categorize text data. For example, it can categorize customer reviews, identify spam emails, or detect hate speech."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Translation"),": The model can convert text from one language to another. "),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Pre-encoded knowledge QA"),": The model can be used as a question-answering system where it answers questions from a knowledge base that has been pre-encoded with information. "),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Close-book QA"),": The model can be used as a question-answering system where it is provided with a set of questions and a corresponding set of passages or documents that it should use as reference material to generate answers. In contrast, open-book QA allows the model to access external sources, such as the Internet, to find answers beyond the provided passages."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Other tasks"),": The model can also be used for text summarization, extraction of specific texts from a given passage, removal of  personally identifying information from documents, and more. ")),(0,n.kt)("p",null,"You may choose a text-to-text model type in cases where:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"You need a model that can effectively learn patterns and structures from training data, and use this learned knowledge to generate text that is coherent and contextually relevant based on the input it receives. "),(0,n.kt)("li",{parentName:"ul"},'You need a text-to-text model to learn new features not recognized by the existing Clarifai models. In that case, you may need to "deep fine-tune" your custom model and integrate it directly within your ',(0,n.kt)("a",{parentName:"li",href:"https://docs.clarifai.com/portal-guide/workflows/"},"workflows"),"."),(0,n.kt)("li",{parentName:"ul"},"You have a custom-tailored dataset, accurate labels, and the expertise and time to fine-tune models.")),(0,n.kt)("h2",{id:"how-to-fine-tune-text-to-text-models"},"How to Fine-Tune Text-to-Text Models"),(0,n.kt)("p",null,"Fine-tuning allows you to adapt text-to-text models to specific tasks or domains, making them more suitable for particular applications. By training on task-specific data, you can improve model performance on those tasks."),(0,n.kt)("p",null,"With fine-tuning, you can take advantage of ",(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/model/model-types/transfer-learning/"},"transfer learning")," and utilize the knowledge gained from a pre-trained text model to facilitate the learning process of a new model for a related problem. "),(0,n.kt)("p",null,"You can follow the following steps to fine-tune a text-to-text model. "),(0,n.kt)("admonition",{type:"info"},(0,n.kt)("p",{parentName:"admonition"},"We currently only support fine-tuning text-to-text models using the ",(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/model/deep-training/text-templates#gpt-neo-lora"},"GPT-Neo LoRA template"),". ")),(0,n.kt)("h3",{id:"1-prepare-your-data"},"1. Prepare your data"),(0,n.kt)("p",null,"If you want to upload bulk text data from a file to the Clarifai platform, you need to convert the data into a format Clarifai accepts. "),(0,n.kt)("p",null,"You can download a CSV file template ",(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/advanced-topics/csv-and-tsv#csv-templates"},"here"),", and follow the prescribed format to prepare your text data, alongside the concepts you want to fine-tune for."),(0,n.kt)("h3",{id:"2-create-an-app"},"2. Create an app"),(0,n.kt)("p",null,"After preparing your dataset, the next step is to ",(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/clarifai-basics/applications/create-an-application/#create-an-application-on-the-portal"},"create an application"),"."),(0,n.kt)("admonition",{type:"tip"},(0,n.kt)("p",{parentName:"admonition"},"When creating an application, choose the ",(0,n.kt)("strong",{parentName:"p"},"Text/Document")," option as the primary input type. The base workflow will be automatically selected for you.")),(0,n.kt)("p",null,"Then, select the ",(0,n.kt)("strong",{parentName:"p"},"Inputs")," option on the collapsible left sidebar, and use the inputs uploader pop-up window to ",(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete#add-inputs"},"upload")," the text data you prepared to a ",(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/datasets/create-get-update-delete"},"dataset")," within your application.  "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"model types",src:a(18733).Z,width:"1915",height:"929"})),(0,n.kt)("h3",{id:"3-choose-a-model"},"3. Choose a model"),(0,n.kt)("p",null,"Next, choose the ",(0,n.kt)("strong",{parentName:"p"},"Models")," option on the collapsible left sidebar. Click the ",(0,n.kt)("strong",{parentName:"p"},"Add Model")," button on the upper-right corner of the page. "),(0,n.kt)("p",null,"On the window that pops up, select the ",(0,n.kt)("strong",{parentName:"p"},"Build a Custom Model")," option and click the ",(0,n.kt)("strong",{parentName:"p"},"Continue")," button. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"model types",src:a(97133).Z,width:"1917",height:"923"})),(0,n.kt)("p",null,"You\u2019ll be redirected to a page where you can choose the type of model you want to fine-tune."),(0,n.kt)("p",null,"Select the ",(0,n.kt)("strong",{parentName:"p"},"Text to Text")," option. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"model types",src:a(89306).Z,width:"1862",height:"917"})),(0,n.kt)("h3",{id:"4-create-the-model"},"4. Create the model"),(0,n.kt)("p",null,"The ensuing page allows you to create a text-to-text model. "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"model types",src:a(3497).Z,width:"1188",height:"1232"})),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Model Id"),"\u2014Provide an ID for your model."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Dataset"),"\u2014Select the dataset you want to use for fine-tuning the model."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Version"),"\u2014Select the version of your dataset."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Invalid data_tolerance_percent"),"\u2014Optionally, you can set a tolerance threshold (0 to 100) for the percentage of invalid inputs during training, and if this threshold is exceeded, training is stopped with an error."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Template"),"\u2014Select the pre-configured model template you want to use to train on your data. You can choose a template for either the 125 million parameters version or the 2.7 billion parameters version of the GPT-Neo model. For this example, let\u2019s choose the former. You have the option to configure the training settings, but we won't configure them\u2014we\u2019ll proceed with the default settings. ")),(0,n.kt)("p",null,"Finally, click the ",(0,n.kt)("strong",{parentName:"p"},"Train")," button. "),(0,n.kt)("p",null,"After the model has been trained, you can start using it to make text-to-text ",(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/ppredict"},"predictions"),". "),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"model types",src:a(51286).Z,width:"1917",height:"851"})),(0,n.kt)("p",null,"You can also evaluate the performance of the model. To do so, under the ",(0,n.kt)("strong",{parentName:"p"},"ROC")," column, click the ",(0,n.kt)("strong",{parentName:"p"},"Calculate")," button, which will initiate the evaluation process. "),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/evaluate/"},"Click here")," to learn more on how to evaluate a model\u2019s performance. "),(0,n.kt)("admonition",{type:"tip"},(0,n.kt)("p",{parentName:"admonition"},"You can further explore the step-by-step tutorial on fine-tuning the GPT-Neo LoRA template for text classification tasks ",(0,n.kt)("a",{parentName:"p",href:"https://www.clarifai.com/blog/fine-tuning-gpt-neo-for-text-classification"},"here"),".")))}c.isMDXComponent=!0},18733:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/fine-tune-1-6c2e052c7c42259ad78b271951bcdd7f.png"},97133:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/fine-tune-2-5c5725ddc68a5404da0577683abde1a1.png"},89306:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/fine-tune-3-25f2320d3b3e3865f04818827c3b793d.png"},3497:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/fine-tune-4-ebda59aa237cfe30d471fbd1310cfd6d.png"},51286:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/fine-tune-5-a295060aebe089c24a5721e2ef7d6217.png"}}]);