"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[4412],{38271:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>d});var t=i(74848),s=i(28453);const r={description:"Learn about our edit operators",sidebar_position:3},o="Edit",a={id:"portal-guide/agent-system-operators/edit",title:"Edit",description:"Learn about our edit operators",source:"@site/docs/portal-guide/agent-system-operators/edit.md",sourceDirName:"portal-guide/agent-system-operators",slug:"/portal-guide/agent-system-operators/edit",permalink:"/portal-guide/agent-system-operators/edit",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/portal-guide/agent-system-operators/edit.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{description:"Learn about our edit operators",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Filter",permalink:"/portal-guide/agent-system-operators/filter"},next:{title:"Push",permalink:"/portal-guide/agent-system-operators/push"}},l={},d=[{value:"Common Characteristics",id:"common-characteristics",level:3},{value:"Image Cropper",id:"image-cropper",level:2},{value:"Workflow Integration and Setup",id:"workflow-integration-and-setup",level:3},{value:"Image Tiler",id:"image-tiler",level:2},{value:"Workflow Integration and Setup",id:"workflow-integration-and-setup-1",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"edit",children:"Edit"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Learn about our edit operators"})}),"\n",(0,t.jsx)("hr",{}),"\n",(0,t.jsx)(n.p,{children:"Edit operators are specific type of agent system operators that are specialized for data transformation tasks. These operators are responsible for modifying and/or augmenting your data as it passes through the workflow."}),"\n",(0,t.jsx)(n.p,{children:"They can be used to crop out regions of an image, align an image based on the pose of a face, or even map predictions from one model to another."}),"\n",(0,t.jsx)(n.h3,{id:"common-characteristics",children:"Common Characteristics"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Purpose"}),": Designed to manipulate and prepare images for enhanced analysis or visual presentation."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Configurability"}),": Users can configure each operator with specific parameters to adjust the image processing according to the needs of their application, making these tools versatile across different scenarios."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Enhanced Workflow Efficiency"}),": By modifying images as per specified requirements early in the process, these operators streamline the workflow, reducing the workload and computational requirements of downstream processes."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsxs)(n.p,{children:['Since the transform operators can be "chained" together with models to automate tasks in a workflow, you can learn how to create workflows ',(0,t.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/workflows/input-nodes#create-your-workflow",children:"here"}),"."]})}),"\n",(0,t.jsx)(n.h2,{id:"image-cropper",children:"Image Cropper"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Input:"})," ",(0,t.jsx)(n.code,{children:"image"}),", ",(0,t.jsx)(n.code,{children:"regions"})]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Output:"})," ",(0,t.jsx)(n.code,{children:"regions[...].data.image"})]}),"\n",(0,t.jsx)(n.p,{children:"The Image Cropper model crops input images based on regions specified either in the workflow or detected by a preceding model, making it particularly useful in workflows where precise image manipulation is required."}),"\n",(0,t.jsx)(n.p,{children:"This model works seamlessly across different types of visual inputs. It is designed to ensure that only the specified regions of an image are retained for further processing, enhancing both the accuracy and relevance of the results. The cropper can look back along the workflow to find the input image if the preceding model does not output an image itself, allowing for a streamlined process in image-based workflows."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Example Scenario:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Region of Interest:"}),' "Face"']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Margin Setting:"})," 10 pixels"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Operation:"})," If a face is detected in an image, the cropper will extract this region with a 10-pixel margin around it. If no face is detected, the image may either be passed as is or not included in the output, depending on configuration."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"workflow-integration-and-setup",children:"Workflow Integration and Setup"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Go to the workflow builder page. Search for the visual-detector option in the left-hand sidebar and drag it onto the empty workspace. This model will detect the regions to be cropped."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Search for the Image Cropper option in the left-hand sidebar and drag it onto the workspace. Use the pop-up that appears on the right-hand sidebar to configure the margin and other settings."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Set up its output configuration on the below-given parameter:"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Margin:"})," Adjust the slider to set the desired margin around the cropped areas."]}),"\n"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Connect the region detection model (such as a face detector or general object detector) with the Image Cropper operator and configure the workflow."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Image Cropper Setup",src:i(22904).A+"",width:"3024",height:"1432"})}),"\n",(0,t.jsx)(n.p,{children:"To see it in action, upload the inputs from your local device or use the inputs in the app. As soon as you upload inputs where regions are detected, the workflow will execute and output the cropped images based on the configurations done."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"alt text",src:i(86920).A+"",width:"3024",height:"1484"})}),"\n",(0,t.jsx)(n.h2,{id:"image-tiler",children:"Image Tiler"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Input:"})," ",(0,t.jsx)(n.code,{children:"image"})]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Output:"})," ",(0,t.jsx)(n.code,{children:"regions[...].data.image"}),", ",(0,t.jsx)(n.code,{children:"regions|[...].region_info.bounding_box"})]}),"\n",(0,t.jsx)(n.p,{children:"The Image Tiler model divides input images into multiple equal-sized tiles. This operator is essential in workflows where large images need to be broken down into smaller, more manageable segments for detailed analysis or parallel processing."}),"\n",(0,t.jsx)(n.p,{children:"This model effectively handles visual inputs by splitting them into uniformly sized tiles. It ensures that detailed analyses can be performed on each segment without the computational burden of processing large images in their entirety. The tiler is configurable to adapt to various sizes and formats of images, making it versatile for different application needs."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Example Scenario:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Tile Size:"})," 512x512 pixels"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Max Object Size:"})," 120 pixels"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Operation:"})," An aerial photograph will be tiled into 512x512 pixel segments, ensuring that any object smaller than 120 pixels remains within a single tile to facilitate accurate analysis."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"workflow-integration-and-setup-1",children:"Workflow Integration and Setup"}),"\n",(0,t.jsx)(n.p,{children:"Workflow Integration and Setup"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Go to the workflow builder page. From the tool palette on the left-hand sidebar, select the Image Tiler option."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Drag the Image Tiler onto the workspace and use the configuration options in the right-hand sidebar to set the tile size and max object size."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Set up its output configuration on the below-given parameters:"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Tile Size:"})," Specify the size for each tile."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Max Object Size:"})," Set the maximum size for objects that should not be split across tiles."]}),"\n"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Save your workflow. No need to connect it to other models unless specific regions within tiles need further analysis or processing."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"alt text",src:i(39141).A+"",width:"3024",height:"1432"})}),"\n",(0,t.jsx)(n.p,{children:"To see it in action, upload the inputs from your local device or use the inputs in the app. As soon as you upload inputs, the workflow will execute, and you will see the images split into the specified tile sizes. This tiling is crucial for handling large-scale images efficiently."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"alt text",src:i(72683).A+"",width:"3024",height:"1432"})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},86920:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/Image Cropper Output-95fa2b7af66f753a472c52bc9bd45b09.png"},22904:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/Image Cropper Setup-4e6e6981b31aad26a8c10eb3f85497d1.png"},39141:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/Image TIler Setup-fa659a29d1ea519dfca6c06094a213f5.png"},72683:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/Image Tiler Output-00536e9e20f27bff2ac61b583632fb37.png"},28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var t=i(96540);const s={},r=t.createContext(s);function o(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);