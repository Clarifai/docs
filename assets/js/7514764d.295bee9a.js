"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[7671],{272:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/ai_assist_1-1daab33b5657671383edb7bf67eded2e.png"},2018:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/ai_assist_3-81e4fa12235a6917d485761f84878bb2.png"},10109:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/ai_assist_2-1-4378469421880f1afcd7bfc9c17581f4.png"},11165:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/ai_assist_4-23fc30701f8e55d4e6b65b87b6b874a0.png"},12495:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/ai_assist_6-3be86666510ffec961bc7a98f5d26eb1.png"},27398:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/ai_assist_7-d90eb058e181c2831a7325d120283619.png"},28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>l});var t=i(96540);const s={},a=t.createContext(s);function o(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(a.Provider,{value:n},e.children)}},39045:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/ai_assist_1-2-44057d14904b0b7813120b1a33d8a8c9.png"},52796:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>r,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"create/labeling/ui/ai-assist","title":"AI-Assisted Labeling","description":"Automatically generate annotations on Input-Viewer page","source":"@site/docs/create/labeling/ui/ai-assist.md","sourceDirName":"create/labeling/ui","slug":"/create/labeling/ui/ai-assist","permalink":"/create/labeling/ui/ai-assist","draft":false,"unlisted":false,"editUrl":"https://github.com/Clarifai/docs/blob/main/docs/create/labeling/ui/ai-assist.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"description":"Automatically generate annotations on Input-Viewer page","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Bulk Labeling","permalink":"/create/labeling/ui/bulk"},"next":{"title":"Labeling Tasks","permalink":"/create/labeling/ui/tasks/"}}');var s=i(74848),a=i(28453);const o={description:"Automatically generate annotations on Input-Viewer page",sidebar_position:3},l="AI-Assisted Labeling",r={},c=[{value:"1. Activate AI-Assist Settings",id:"1-activate-ai-assist-settings",level:2},{value:"2. Choose a Model or Workflow",id:"2-choose-a-model-or-workflow",level:2},{value:"Classifications Labeling",id:"classifications-labeling",level:3},{value:"Objects Labeling",id:"objects-labeling",level:3},{value:"3. Generate Annotations",id:"3-generate-annotations",level:2},{value:"Classifications Labeling",id:"classifications-labeling-1",level:3},{value:"Objects Labeling",id:"objects-labeling-1",level:3},{value:"4. Review and Accept Predictions",id:"4-review-and-accept-predictions",level:2},{value:"Classifications Labeling",id:"classifications-labeling-2",level:3},{value:"Objects Labeling",id:"objects-labeling-2",level:3}];function d(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"ai-assisted-labeling",children:"AI-Assisted Labeling"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Automatically generate annotations on Input-Viewer page"})}),"\n",(0,s.jsx)("hr",{}),"\n",(0,s.jsx)("div",{style:{position:"relative",width:"100%",overflow:"hidden","padding-top":"56.25%"},children:(0,s.jsx)("iframe",{width:"900",height:"500",style:{position:"absolute",top:"0",left:"0",bottom:"0",right:"0",width:"100%",height:"100%"},src:"https://www.youtube.com/embed/x4lC5sz-Oqs",frameborder:"0",allow:"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0})}),"\n",(0,s.jsx)("br",{}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.em,{children:"Note that our UI has been updated since the release of the above video. However, the AI-assist functionality described in the video remains fully compatible with the new interface."})}),"\n"]}),"\n",(0,s.jsx)("br",{}),"\n",(0,s.jsx)(n.p,{children:"AI-assisted labeling is an innovative Clarifai feature that leverages artificial intelligence technology to assist and optimize the process of annotating data."}),"\n",(0,s.jsx)(n.p,{children:"You can request predictions from any model or workflow available to you on a particular input, and then review, correct, or validate them before converting them into annotations."}),"\n",(0,s.jsx)(n.p,{children:"AI-Assist provides you with several benefits, including:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:i(58916).A+"",width:"1918",height:"959"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Significantly accelerate the labeling process, reducing the time required to create labeled datasets;"}),"\n",(0,s.jsx)(n.li,{children:"Automation can reduce the labor costs associated with manual labeling;"}),"\n",(0,s.jsx)(n.li,{children:"AI models can provide consistent labeling, minimizing human errors;"}),"\n",(0,s.jsx)(n.li,{children:"It allows for the efficient and scalable handling of large datasets or rapidly changing data."}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{title:"feature availability",type:"caution",children:(0,s.jsxs)(n.p,{children:["This AI-assist feature is only available to users on our ",(0,s.jsx)(n.a,{href:"https://www.clarifai.com/pricing",children:"paid plans"}),"."]})}),"\n",(0,s.jsxs)(n.p,{children:["Let\u2019s demonstrate how you can perform AI-assisted labeling using the ",(0,s.jsx)(n.strong,{children:"Annotate"})," mode of the Input-Viewer screen."]}),"\n",(0,s.jsx)(n.h2,{id:"1-activate-ai-assist-settings",children:"1. Activate AI-Assist Settings"}),"\n",(0,s.jsxs)(n.p,{children:["On the Input-Viewer, click the ",(0,s.jsx)(n.strong,{children:"Edit"})," button located in the upper-right corner of the page."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:i(39045).A+"",width:"1915",height:"893"})}),"\n",(0,s.jsxs)(n.p,{children:["You'll be redirected to the AI-assist sidebar that enables you to choose a model or workflow for using in labeling your inputs. Ensure the ",(0,s.jsx)(n.strong,{children:"AI Assist"})," toggle is switched on."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"navigate to input-viewer screen",src:i(272).A+"",width:"1919",height:"897"})}),"\n",(0,s.jsx)(n.h2,{id:"2-choose-a-model-or-workflow",children:"2. Choose a Model or Workflow"}),"\n",(0,s.jsxs)(n.p,{children:["Use the ",(0,s.jsx)(n.strong,{children:"Select Model or Workflow"})," search box to choose a model or workflow to generate predictions and assist with annotations. You can choose your own customized model or workflow, or look for a public one from the Community platform."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"choose a model or workflow",src:i(65675).A+"",width:"1901",height:"883"})}),"\n",(0,s.jsxs)(n.p,{children:["To select a public model or workflow from the Community, click the ",(0,s.jsx)(n.strong,{children:"Explore Community Models / Workflows"})," button. In the pop-up window, use the search bar to find the desired model or workflow."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:i(10109).A+"",width:"1911",height:"894"})}),"\n",(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsx)(n.p,{children:"When working with image inputs, you need to choose a model or workflow that outputs concepts or objects (bounding box regions). This ensures the generation and display of annotation suggestions."})}),"\n",(0,s.jsx)(n.admonition,{title:"Objective",type:"note",children:(0,s.jsxs)(n.p,{children:["In this example, we'll illustrate how to generate annotations using a ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/model/model-types/visual-classifier",children:"visual classification"})," model and a ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/model/model-types/visual-detector",children:"visual detection"})," workflow."]})}),"\n",(0,s.jsx)(n.h3,{id:"classifications-labeling",children:"Classifications Labeling"}),"\n",(0,s.jsxs)(n.p,{children:["First, let\u2019s choose the Community\u2019s ",(0,s.jsx)(n.a,{href:"https://clarifai.com/clarifai/main/models/general-image-recognition",children:"general-image-recognition"})," model, which is a visual classification model that identifies a variety of concepts in images."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:" general-image-recognition model",src:i(2018).A+"",width:"1900",height:"898"})}),"\n",(0,s.jsx)(n.h3,{id:"objects-labeling",children:"Objects Labeling"}),"\n",(0,s.jsxs)(n.p,{children:["Similarly, let\u2019s select another input on the Input-Viewer screen. And on the ",(0,s.jsx)(n.strong,{children:"AI Assist"})," sidebar, let\u2019s choose the Community\u2019s ",(0,s.jsx)(n.a,{href:"https://clarifai.com/clarifai/main/workflows/General-Detection",children:"General-Detection"})," workflow, which identifies a variety of common objects in images."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"General-Detection workflow",src:i(11165).A+"",width:"1889",height:"888"})}),"\n",(0,s.jsx)(n.h2,{id:"3-generate-annotations",children:"3. Generate Annotations"}),"\n",(0,s.jsx)(n.p,{children:"After choosing a model or workflow, it could take a few moments to automatically generate the annotations. The generated labels are sorted in descending order based on their concept probability values."}),"\n",(0,s.jsx)(n.h3,{id:"classifications-labeling-1",children:"Classifications Labeling"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Classifications"})," pane lists the concepts generated by the classification model, alongside their probability values."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"generate classification annotations",src:i(90036).A+"",width:"1894",height:"906"})}),"\n",(0,s.jsx)(n.h3,{id:"objects-labeling-1",children:"Objects Labeling"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Objects"})," pane displays the bounding boxes identified by the detection workflow, alongside their probability values."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"generate bounding box annotations",src:i(12495).A+"",width:"1900",height:"900"})}),"\n",(0,s.jsx)(n.admonition,{title:"Manually Generate annotations",type:"note",children:(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Select or add concepts"})," field in either the ",(0,s.jsx)(n.strong,{children:"Classifications"})," or ",(0,s.jsx)(n.strong,{children:"Objects"})," pane lets you choose existing concepts in your app for annotating your inputs. You can also add new concepts for the annotation."]})}),"\n",(0,s.jsx)(n.h2,{id:"4-review-and-accept-predictions",children:"4. Review and Accept Predictions"}),"\n",(0,s.jsx)(n.p,{children:"Finally, you can review the model or workflow prediction suggestions and accept them as needed."}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"AI assist probability threshold"})," section in the right sidebar allows you to filter predictions by probability values. Use the slider control to display only the predictions that fall within your selected probability range."]}),"\n",(0,s.jsxs)(n.p,{children:["To accept all AI-assisted suggestions for annotating your input(s) with the selected threshold, simply click the ",(0,s.jsx)(n.strong,{children:"Accept all AI assist predictions"})," button."]}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["When you accept an AI-assisted prediction suggestion, it will be added to your application as a ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/inputs-manager/concepts",children:"concept"})," and automatically applied as a label to your input."]})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Search concepts"})," field allows you to find specific concepts and display their annotations on the page."]}),"\n",(0,s.jsx)(n.h3,{id:"classifications-labeling-2",children:"Classifications Labeling"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Classifications"})," pane allows you to review and accept classification predictions."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"review and accept classification predictions",src:i(27398).A+"",width:"1901",height:"894"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Concepts count display"}),' \u2014 The pane displays the number of concepts used to annotate an image. For example, "Classifications (9)" means the model suggested nine concepts based on the defined probability threshold.']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Accept or remove annotations"})," \u2014 To manually accept a prediction, simply click on the checkmark next to it. You will notice a color change, and a confirmation message will indicate that the annotation has been successfully added to your app and annotated with your input. You can also remove an annotation by deselecting the checkmark. ",(0,s.jsx)(n.em,{children:"The removed annotation will revert to being a suggestion rather than being entirely removed from the list."})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"View individual annotators"})," \u2014 If you hover over the person icon on an annotation field, you can view the annotator(s) who added that annotation. The displayed number indicates how many annotators labeled that input. For example, it can be the annotator who manually accepted the suggestion and the model."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Update annotations"}),' \u2014 To update an already accepted annotation, hover over it and click the pencil icon that appears. Enter a new name for the annotation in the provided text field, then click the "Update" button to save your changes. The updated concept will be added to your app and annotated with your input. This updated concept is referred to as a concept relation, with the original concept shown as a superscript next to it. If you create an annotation using the original concept, its relation will be used instead. Note that if you edit the concept relation back to its original value, the concept relation annotation on the input will be removed. However, it will only be removed from the input and not from your app.']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Delete annotation"})," \u2014 If you hover over an already accepted annotation field, a delete icon will appear that you can use to remove the annotation. A small pop-up will appear, prompting you to confirm the deletion."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Hotkey assignment"}),' \u2014 Each annotation is assigned a hotkey number. Clicking this number will delete the corresponding annotation from the input. For example, clicking "1" will remove the ',(0,s.jsx)(n.code,{children:"animal"})," annotation from the image. Up to 20 hotkeys can be assigned to an input."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"objects-labeling-2",children:"Objects Labeling"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Objects"})," pane allows you to review and accept objects predictions. It displays categories of concepts used for annotations, along with individual annotation instances."]}),"\n",(0,s.jsx)(n.p,{children:"Reviewing and accepting object predictions is largely similar to classification labeling, with a few minor differences."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"review and accept objects predictions",src:i(83553).A+"",width:"1903",height:"900"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Annotation count display"}),' \u2014 The pane shows the number of annotation suggestions for each instance. For example, "Objects (6)" indicates that the workflow suggested six categories of concepts. Similarly, "sheep (8)" means the workflow suggested eight instances of the ',(0,s.jsx)(n.code,{children:"sheep"}),' concept. Individual annotations are numbered sequentially. For example, "sheep.1" represents the first annotation labeled with the ',(0,s.jsx)(n.code,{children:"sheep"}),' concept, "sheep.2" represents the second annotation, and so on.']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Update and hide suggested annotations"})," \u2014 Hovering over a concept category field reveals a pencil icon for updating the concept name (as described earlier) and an eye icon for hiding all the annotations in that category."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Drawing mode"})," \u2014 Clicking the bounding box icon or the polygon icon in a category field activates the drawing mode. This allows you to manually create bounding box or ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/input-viewer/annotate#segmentation-labeling",children:"polygon annotations"}),', respectively, using the selected concept. The drawing mode box, located in the upper-right corner of the canvas, displays the concept currently in use for detection labeling. To exit drawing mode, simply click the "Exit" button.']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Instance-specific actions"})," \u2014 Hovering over an individual annotation instance reveals these icons: pencil icon for reassigning the annotation to a different concept, eye icon for hiding the specific annotation instance, and delete icon for removing the specific annotation instance."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Edit suggestions"})," \u2014 Clicking an individual annotation instance highlights its corresponding bounding box in the canvas, enabling easy editing by resizing, repositioning, or adjusting to better suit your needs. You can also edit a region prediction by clicking on the labeled bounding box and dragging it to cover the specific areas you want it to encompass. After editing the bounding box, the label will be automatically added to your input."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Hotkey assignment"}),' \u2014 Each concept is assigned a hotkey, allowing quick labeling for that concept. For example, pressing "1" enables you to draw bounding boxes labeled with the ',(0,s.jsx)(n.em,{children:"sheep"})," concept. Up to 20 hotkeys can be assigned to your concepts."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},58916:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/ai_assist_image-1-ab39e8fe71ac7c3be00edd1fc4dd6bdb.png"},65675:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/ai_assist_2-70609206cabdcaaa2ebd017d46521197.png"},83553:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/ai_assist_8-2ec5b352fe4779d2a08396fbf6fc4670.png"},90036:(e,n,i)=>{i.d(n,{A:()=>t});const t=i.p+"assets/images/ai_assist_5-930085ab8686f474809d587477d32632.png"}}]);