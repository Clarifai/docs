"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[1565],{8651:(e,n,l)=>{l.r(n),l.d(n,{assets:()=>d,contentTitle:()=>u,default:()=>m,frontMatter:()=>c,metadata:()=>a,toc:()=>h});const a=JSON.parse('{"id":"compute/local-runners/ollama","title":"Run Ollama Models Locally","description":"Run Ollama models locally and make them available via a public API","source":"@site/docs/compute/local-runners/ollama.md","sourceDirName":"compute/local-runners","slug":"/compute/local-runners/ollama","permalink":"/compute/local-runners/ollama","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"Run Ollama models locally and make them available via a public API","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Local Runners","permalink":"/compute/local-runners/"},"next":{"title":"Agents","permalink":"/compute/agents/"}}');var r=l(74848),i=l(28453),t=l(11470),s=l(19365),o=l(73748);const c={description:"Run Ollama models locally and make them available via a public API",sidebar_position:1},u="Run Ollama Models Locally",d={},h=[{value:"Step 1: Perform Prerequisites",id:"step-1-perform-prerequisites",level:2},{value:"Install Ollama",id:"install-ollama",level:3},{value:"Sign Up or Log In",id:"sign-up-or-log-in",level:3},{value:"Install the Clarifai CLI",id:"install-the-clarifai-cli",level:3},{value:"Install OpenAI Package",id:"install-openai-package",level:3},{value:"Step 2: Initialize a Model From Ollama",id:"step-2-initialize-a-model-from-ollama",level:2},{value:"Step 3: Log In to Clarifai",id:"step-3-log-in-to-clarifai",level:2},{value:"Step 4: Start Your Local Runner",id:"step-4-start-your-local-runner",level:2},{value:"Step 5: Run Inference",id:"step-5-run-inference",level:2},{value:"Additional Examples",id:"additional-examples",level:2}];function p(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"run-ollama-models-locally",children:"Run Ollama Models Locally"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Run Ollama models locally and make them available via a public API"})}),"\n",(0,r.jsx)("hr",{}),"\n",(0,r.jsx)(n.p,{children:"Ollama is an open-source tool that allows you to download, run, and manage large language models (LLMs) directly on your local machine."}),"\n",(0,r.jsx)(n.p,{children:"When combined with Clarifai\u2019s Local Runners, it enables you to run Ollama models on your machine, expose them securely via a public URL, and tap into Clarifai\u2019s powerful platform \u2014 all while keeping the speed, privacy, and control of local deployment."}),"\n","\n",(0,r.jsx)(n.h2,{id:"step-1-perform-prerequisites",children:"Step 1: Perform Prerequisites"}),"\n",(0,r.jsx)(n.h3,{id:"install-ollama",children:"Install Ollama"}),"\n",(0,r.jsxs)(n.p,{children:["Go to the ",(0,r.jsx)(n.a,{href:"https://ollama.com/download",children:"Ollama website"})," and choose the appropriate installer for your system (macOS, Windows, or Linux)."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Note:"})," If you're using Windows, make sure to restart your machine after installing Ollama to ensure that the updated environment variables are properly applied."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"sign-up-or-log-in",children:"Sign Up or Log In"}),"\n",(0,r.jsxs)(n.p,{children:["Start by ",(0,r.jsx)(n.a,{href:"https://clarifai.com/login",children:"logging in"})," to your existing Clarifai account or ",(0,r.jsx)(n.a,{href:"https://clarifai.com/signup",children:"signing up"})," for a new one. Once logged in, you'll need the following credentials for setup:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"User ID"})," \u2013 Navigate to your personal settings and find your user ID under the ",(0,r.jsx)(n.strong,{children:"Account"})," section."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Personal Access Token (PAT)"})," \u2013 In the same personal settings page, go to the ",(0,r.jsx)(n.strong,{children:"Security"})," section to generate or copy your ",(0,r.jsx)(n.a,{href:"https://docs.clarifai.com/control/authentication/pat",children:"PAT"}),". This token is used to securely authenticate your connection to the Clarifai platform."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["You can then set the PAT as an environment variable using ",(0,r.jsx)(n.code,{children:"CLARIFAI_PAT"}),", which is important when running inference with your models."]}),"\n",(0,r.jsxs)(t.A,{groupId:"code",children:[(0,r.jsx)(s.A,{value:"bash",label:"Unix-Like Systems",children:(0,r.jsx)(o.A,{className:"language-bash",children:"export CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE"})}),(0,r.jsx)(s.A,{value:"bash2",label:"Windows",children:(0,r.jsx)(o.A,{className:"language-bash",children:"set CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE"})})]}),"\n",(0,r.jsx)(n.h3,{id:"install-the-clarifai-cli",children:"Install the Clarifai CLI"}),"\n",(0,r.jsxs)(n.p,{children:["Install the latest version of the ",(0,r.jsx)(n.a,{href:"https://docs.clarifai.com/sdk/cli",children:"Clarifai CLI"}),", which includes built-in support for Local Runners."]}),"\n",(0,r.jsx)(t.A,{groupId:"code",children:(0,r.jsx)(s.A,{value:"bash",label:"Bash",children:(0,r.jsx)(o.A,{className:"language-bash",children:"pip install --upgrade clarifai"})})}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Note:"})," You must have ",(0,r.jsx)(n.strong,{children:"Python 3.10 or higher"})," installed to use Local Runners."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"install-openai-package",children:"Install OpenAI Package"}),"\n",(0,r.jsxs)(n.p,{children:["Install the ",(0,r.jsx)(n.code,{children:"openai"})," package, which is required when performing inference with models using the ",(0,r.jsx)(n.a,{href:"https://docs.clarifai.com/compute/inference/#predict-with-openai-compatible-format",children:"OpenAI-compatible format"}),"."]}),"\n",(0,r.jsx)(t.A,{groupId:"code",children:(0,r.jsx)(s.A,{value:"bash",label:"Python",children:(0,r.jsx)(o.A,{className:"language-bash",children:" pip install openai "})})}),"\n",(0,r.jsx)(n.h2,{id:"step-2-initialize-a-model-from-ollama",children:"Step 2: Initialize a Model From Ollama"}),"\n",(0,r.jsx)(n.p,{children:"You can use the Clarifai CLI to download and initialize any model available in the Ollama library directly into your local environment."}),"\n",(0,r.jsxs)(n.p,{children:["For example, here's how to initialize the ",(0,r.jsx)(n.a,{href:"https://ollama.com/library/llama3.2",children:(0,r.jsx)(n.code,{children:"llama3.2"})})," model in your current directory:"]}),"\n",(0,r.jsx)(t.A,{groupId:"code",children:(0,r.jsx)(s.A,{value:"bash",label:"CLI",children:(0,r.jsx)(o.A,{className:"language-bash",children:"clarifai model init --toolkit ollama"})})}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Note:"})," The above command will create a new model directory structure that is compatible with the Clarifai platform. You can customize or optimize the generated model by modifying the ",(0,r.jsx)(n.code,{children:"1/model.py"})," file as needed."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"You can customize model initialization from the Ollama library using the Clarifai CLI with the following options:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"--model-name"})," \u2013 Name of the Ollama model to use (default: ",(0,r.jsx)(n.code,{children:"llama3.2"}),"). This lets you specify any model from the Ollama library"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"--port"})," \u2013 Port to run the model on (default: ",(0,r.jsx)(n.code,{children:"23333"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"--context-length"})," \u2013 Context window size for the model in tokens (default: ",(0,r.jsx)(n.code,{children:"8192"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"--verbose"})," \u2013 Enables detailed Ollama logs during execution. By default, logs are suppressed unless this flag is provided."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Learn more about setting up a model with Ollama ",(0,r.jsx)(n.a,{href:"https://docs.clarifai.com/resources/api-overview/cli#initialize-with-toolkit",children:"here"}),"."]}),"\n",(0,r.jsxs)(n.admonition,{title:"tip",type:"note",children:[(0,r.jsx)(n.p,{children:"Here is a quickstart for Ollama models and their common use cases:"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"llama3.2-vision:latest"})," \u2013 For multimodal tasks (text + image), like image captioning or visual Q&A."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"llama3-groq-tool-use:latest"})," \u2013 Ideal for tool calling and function execution in ",(0,r.jsx)(n.a,{href:"https://docs.clarifai.com/compute/agents/",children:"agent"})," tasks."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"devstral:latest"})," \u2013 Best for code generation, debugging, and development assistant use cases."]}),"\n"]})]}),"\n",(0,r.jsx)(n.h2,{id:"step-3-log-in-to-clarifai",children:"Step 3: Log In to Clarifai"}),"\n",(0,r.jsxs)(n.p,{children:["Use the following command to log in to the Clarifai platform to create a configuration ",(0,r.jsx)(n.a,{href:"/compute/local-runners/#step-2-create-a-context-optional",children:"context"})," and establish a connection:"]}),"\n",(0,r.jsx)(t.A,{groupId:"code",children:(0,r.jsx)(s.A,{value:"bash",label:"CLI",children:(0,r.jsx)(o.A,{className:"language-bash",children:"clarifai login"})})}),"\n",(0,r.jsx)(n.p,{children:"After running the command, you'll be prompted to provide a few details for authentication:"}),"\n",(0,r.jsx)(t.A,{groupId:"code",children:(0,r.jsx)(s.A,{value:"bash",label:"CLI",children:(0,r.jsx)(o.A,{className:"language-bash",children:(0,r.jsx)(n.p,{children:'context name (default: "default"):\nuser id:\npersonal access token value (default: "ENVVAR" to get our env var rather than config):'})})})}),"\n",(0,r.jsx)(n.p,{children:"Here\u2019s what each field means:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Context name"})," \u2013 You can assign a custom name to this configuration context, or simply press Enter to use the default name, ",(0,r.jsx)(n.code,{children:'"default"'}),". This is useful if you manage multiple environments or configurations."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"User ID"})," \u2013 Enter your Clarifai user ID."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Personal Access Token (PAT)"})," \u2013 Paste your Clarifai PAT here. If you've already set the ",(0,r.jsx)(n.code,{children:"CLARIFAI_PAT"})," environment variable, you can just press Enter to use it automatically."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"step-4-start-your-local-runner",children:"Step 4: Start Your Local Runner"}),"\n",(0,r.jsx)(n.p,{children:"Start a local runner using the following command:"}),"\n",(0,r.jsx)(t.A,{groupId:"code",children:(0,r.jsx)(s.A,{value:"bash",label:"CLI",children:(0,r.jsx)(o.A,{className:"language-bash",children:"clarifai model local-runner"})})}),"\n",(0,r.jsx)(n.p,{children:"If the necessary context configurations aren\u2019t detected, the CLI will guide you through creating them using default values."}),"\n",(0,r.jsxs)(n.p,{children:["This setup ensures all required components \u2014 such as compute clusters, nodepools, and deployments \u2014 are properly included in your configuration context, which are described ",(0,r.jsx)(n.a,{href:"/compute/local-runners/#start-your-local-runner-1",children:"here"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"Simply review each prompt and confirm to proceed."}),"\n",(0,r.jsx)(n.h2,{id:"step-5-run-inference",children:"Step 5: Run Inference"}),"\n",(0,r.jsx)(n.p,{children:"Once your local runner starts successfully, it will display a public URL where your model is hosted and accessible."}),"\n",(0,r.jsx)(n.p,{children:"The CLI also generates an example client code snippet to help you quickly test the model. Simply run the snippet in a separate terminal (within the same directory) to receive the model\u2019s response output."}),"\n",(0,r.jsx)(n.p,{children:"Below is an example of running inference using the OpenAI-compatible format:"}),"\n",(0,r.jsx)(t.A,{groupId:"code",children:(0,r.jsx)(s.A,{value:"python",label:"Python",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import os\nfrom openai import OpenAI\n\n# Initialize the OpenAI client with Clarifai\'s OpenAI-compatible endpoint\nclient = OpenAI(\n    base_url="https://api.clarifai.com/v2/ext/openai/v1",\n    api_key=os.environ[\'CLARIFAI_PAT\'],\n)\n\n# Replace \'user-id\' with your actual Clarifai user ID\nresponse = client.chat.completions.create(\n    model="https://clarifai.com/user-id/local-runner-app/models/local-runner-model",\n    messages=[\n        {"role": "system", "content": "Talk like a pirate."},\n        {"role": "user", "content": "How do I check if a Python object is an instance of a class?"},\n    ],\n    temperature=0.7,\n    stream=False,  # Set to True for streaming responses\n)\n\n# Print the full response\nprint(response)\n\n# Example for handling a streaming response:\n# if stream=True, uncomment below to print chunks as they arrive\n# for chunk in response:\n#     print(chunk.choices[0].message[\'content\'], end=\'\')\n'})})})}),"\n",(0,r.jsx)(n.p,{children:"When you're done, just close the terminal running the local runner to shut it down."}),"\n",(0,r.jsx)(n.h2,{id:"additional-examples",children:"Additional Examples"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/ollama/ollama-python/tree/main/examples",children:"More examples of calling Ollama models"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.clarifai.com/compute/inference/clarifai/api",children:"Clarifai-specific inference examples with Ollama models"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/Clarifai/runners-examples/tree/main/local-runners/ollama-model-upload",children:"Example for running Ollama models locally with Clarifai\u2019s Local Runners"})}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},11470:(e,n,l)=>{l.d(n,{A:()=>I});var a=l(96540),r=l(18215),i=l(23104),t=l(56347),s=l(205),o=l(57485),c=l(31682),u=l(70679);function d(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:n,children:l}=e;return(0,a.useMemo)(()=>{const e=n??function(e){return d(e).map(({props:{value:e,label:n,attributes:l,default:a}})=>({value:e,label:n,attributes:l,default:a}))}(l);return function(e){const n=(0,c.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,l])}function p({value:e,tabValues:n}){return n.some(n=>n.value===e)}function m({queryString:e=!1,groupId:n}){const l=(0,t.W6)(),r=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,o.aZ)(r),(0,a.useCallback)(e=>{if(!r)return;const n=new URLSearchParams(l.location.search);n.set(r,e),l.replace({...l.location,search:n.toString()})},[r,l])]}function f(e){const{defaultValue:n,queryString:l=!1,groupId:r}=e,i=h(e),[t,o]=(0,a.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!p({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const l=n.find(e=>e.default)??n[0];if(!l)throw new Error("Unexpected error: 0 tabValues");return l.value}({defaultValue:n,tabValues:i})),[c,d]=m({queryString:l,groupId:r}),[f,x]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[l,r]=(0,u.Dv)(n);return[l,(0,a.useCallback)(e=>{n&&r.set(e)},[n,r])]}({groupId:r}),g=(()=>{const e=c??f;return p({value:e,tabValues:i})?e:null})();(0,s.A)(()=>{g&&o(g)},[g]);return{selectedValue:t,selectValue:(0,a.useCallback)(e=>{if(!p({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);o(e),d(e),x(e)},[d,x,i]),tabValues:i}}var x=l(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var j=l(74848);function b({className:e,block:n,selectedValue:l,selectValue:a,tabValues:t}){const s=[],{blockElementScrollPositionUntilNextRender:o}=(0,i.a_)(),c=e=>{const n=e.currentTarget,r=s.indexOf(n),i=t[r].value;i!==l&&(o(n),a(i))},u=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const l=s.indexOf(e.currentTarget)+1;n=s[l]??s[0];break}case"ArrowLeft":{const l=s.indexOf(e.currentTarget)-1;n=s[l]??s[s.length-1];break}}n?.focus()};return(0,j.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},e),children:t.map(({value:e,label:n,attributes:a})=>(0,j.jsx)("li",{role:"tab",tabIndex:l===e?0:-1,"aria-selected":l===e,ref:e=>{s.push(e)},onKeyDown:u,onClick:c,...a,className:(0,r.A)("tabs__item",g.tabItem,a?.className,{"tabs__item--active":l===e}),children:n??e},e))})}function v({lazy:e,children:n,selectedValue:l}){const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=i.find(e=>e.props.value===l);return e?(0,a.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,j.jsx)("div",{className:"margin-top--md",children:i.map((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==l}))})}function y(e){const n=f(e);return(0,j.jsxs)("div",{className:(0,r.A)("tabs-container",g.tabList),children:[(0,j.jsx)(b,{...n,...e}),(0,j.jsx)(v,{...n,...e})]})}function I(e){const n=(0,x.A)();return(0,j.jsx)(y,{...e,children:d(e.children)},String(n))}},19365:(e,n,l)=>{l.d(n,{A:()=>t});l(96540);var a=l(18215);const r={tabItem:"tabItem_Ymn6"};var i=l(74848);function t({children:e,hidden:n,className:l}){return(0,i.jsx)("div",{role:"tabpanel",className:(0,a.A)(r.tabItem,l),hidden:n,children:e})}}}]);