"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[7470],{61154:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>Z,contentTitle:()=>Q,default:()=>tn,frontMatter:()=>$,metadata:()=>K,toc:()=>nn});var a=t(74848),i=t(28453),o=t(11470),s=t(19365),l=t(21432);const d='from clarifai.client.input import Inputs\n\nimg_url = "https://samples.clarifai.com/metro-north.jpg"\ninput_obj = Inputs(user_id="user_id", app_id="test_app", pat="YOUR_PAT")\n# You can also upload data through Bytes and Filepath,\n\n# Upload from file\n# input_obj.upload_from_file(input_id=\'demo\', image_file=\u2019image_filepath\')\n\n# Upload from bytes\n# input_obj.upload_from_bytes(input_id=\'demo\', image_bytes=image)\n\ninput_obj.upload_from_url(input_id="demo", image_url=img_url)\n',p='import { Input } from "clarifai-nodejs";\n\n\nconst imageUrl = "https://samples.clarifai.com/metro-north.jpg";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nawait input.uploadFromUrl({\n  inputId: "demo",\n  imageUrl,\n});\n',r='from clarifai.client.input import Inputs\n\ninput_text = b"Write a tweet on future of AI"\ninput_obj = Inputs(user_id="user_id", app_id="test_app", pat="YOUR_PAT")\n\n# You can also upload data through URLand Filepath,\n\n# Upload from file\n# input_obj.upload_from_file(input_id=\'text_dat\', text_file=\u2019text_filepath\')\n\n# Upload from url\n# input_obj.upload_from_url(input_id=\'text,text_url=\u201dtext_url\u201d)\n\ninput_obj.upload_from_bytes(input_id="text_data", text_bytes=input_text)',u='import { Input } from "clarifai-nodejs";\n\n\nconst inputText = "Write a tweet on future of AI";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\ninput.uploadText({\n  inputId: "text_data",\n  rawText: inputText,\n});\n',c='from clarifai.client.input import Inputs\n\naudio_url = "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav"\ninput_obj = Inputs(user_id="user_id", app_id="test_app", pat="YOUR_PAT")\n\n# You can also upload data through Bytes and Filepath,\n\n# Upload from file\n# input_obj.upload_from_file(input_id=\'audio_data\', audio_file=\u2019audio_filepath\')\n\n# Upload from bytes\n# input_obj.upload_from_bytes(input_id=\'audio_data\u2019, audio_bytes=audio)\n\ninput_obj.upload_from_url(\n    input_id="audio_data",\n    audio_url=audio_url,\n)',h='import { Input } from "clarifai-nodejs";\n\n\nconst audioUrl =\n  "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\ninput.uploadFromUrl({\n  inputId: "audio_data",\n  audioUrl,\n});\n',m='from clarifai.client.input import Inputs\nvideo_url = "https://samples.clarifai.com/beer.mp4"\ninput_obj = Inputs(user_id="user_id", app_id="test_app", pat="YOUR_PAT")\n\n# You can also upload data through Bytes and Filepath,\n\n# Upload from file\n# input_obj.upload_from_file(input_id=\'video_data\', video_file=\u2019video_filepath\')\n\n# Upload from bytes\n# input_obj.upload_from_bytes(input_id=\'video_data\u2019, video_bytes=video)\n\ninput_obj.upload_from_url(\n    input_id="video_data", video_url= video_url\n)',_='import { Input } from "clarifai-nodejs";\n\n\nconst videoUrl = "https://samples.clarifai.com/beer.mp4";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nawait input.uploadFromUrl({\n  inputId: "video_data",\n  videoUrl,\n});\n',f='from clarifai.client.input import Inputs\n\ninput_obj = Inputs(user_id="user_id", app_id="test_app", pat="YOUR_PAT")\n\n# initialize inputs of different type\nprompt = "What time of day is it?"\nimage_url = "https://samples.clarifai.com/metro-north.jpg"\n\n# Here you can give the value for different types of inputs\ninput_obj.get_multimodal_input(\n    input_id="multimodal_data", image_url=image_url, raw_text=prompt\n)',g='import { Input } from "clarifai-nodejs";\n\n\nconst prompt = "What time of day is it?";\nconst imageUrl = "https://samples.clarifai.com/metro-north.jpg";\nconst multimodalInput = Input.getMultimodalInput({\n  inputId: "multimodal_data",\n  imageUrl,\n  rawText: prompt,\n});\nconsole.log(multimodalInput);\n',b='from clarifai.client.user import User\n\n# Create the input object\ninput_obj = User(user_id="user_id").app(app_id="test_app", pat="YOUR_PAT").inputs()\n# list the inputs with pagination\nall_inputs = list(input_obj.list_inputs(page_no=1,per_page=3))\nprint(all_inputs)',x='from clarifai.client.user import User\n\ninput_obj = User(user_id="user_id", pat="YOUR_PAT").app(app_id="test_app").inputs()\n# provide the inputs ids as parameters in delete_inputs function\ninput_obj.delete_inputs(list(input_obj.list_inputs()))',j='# Import necessary modules\nfrom google.protobuf.struct_pb2 import Struct\nfrom clarifai.client.input import Inputs\n\n# Create an Inputs object with user_id and app_id\ninput_object = Inputs(user_id="user_id", app_id="app_id", pat="YOUR_PAT")\n\n# Create a Struct object for metadata\nmetadata = Struct()\n\n# Update metadata with filename and split information\nmetadata.update({"filename": "XiJinping.jpg", "split": "train"})\n\n# URL of the image to upload\nurl = "https://samples.clarifai.com/XiJinping.jpg"\n\n# Upload the image from the URL with associated metadata\ninput_object.upload_from_url(input_id="metadata", image_url=url, metadata=metadata)',y='import { Input } from "clarifai-nodejs";\n\n\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nconst metadata = {\n  filename: "XiJinping.jpg",\n  split: "train",\n};\nconst imageUrl = "https://samples.clarifai.com/XiJinping.jpg";\nawait input.uploadFromUrl({\n  inputId: "image_with_metadata",\n  imageUrl,\n  metadata,\n});\n',I='from google.protobuf.struct_pb2 import Struct\nfrom clarifai.client.input import Inputs\n\n# Initialize an Inputs object with specified user_id and app_id\ninput_object = Inputs(user_id="user_id", app_id="app_id", pat="YOUR_PAT")\n\n# Define the URL of the video to upload\nvideo_url = "https://samples.clarifai.com/beer.mp4"\n\n# Create a Struct object to hold metadata\nmetadata = Struct()\n\n# Update the metadata with filename and split information\nmetadata.update({"filename": "drinks.jpg", "split": "train"})\n\n# Upload the video from the specified URL with the provided metadata\ninput_object.upload_from_url(\n    input_id="video_data_metadata", video_url=video_url, metadata=metadata\n)\n',v='import { Input } from "clarifai-nodejs";\n\n\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nconst metadata = {\n  filename: "beer.mp4",\n  split: "train",\n};\nconst videoUrl = "https://samples.clarifai.com/beer.mp4";\nawait input.uploadFromUrl({\n  inputId: "video_data_metadata",\n  videoUrl,\n  metadata,\n});\n',w='# Import necessary modules\nfrom google.protobuf.struct_pb2 import Struct\nfrom clarifai.client.input import Inputs\n\n# Define the input object with user_id and app_id\ninput_object = Inputs(user_id="user_id", app_id="app_id", pat="YOUR_PAT")\n\n# Define the input text\ninput_text = b"Write a tweet on future of AI"\n\n# Create a Struct object for metadata\nmetadata = Struct()\n\n# Update metadata with filename and split information\nmetadata.update({"filename": "tweet.txt", "split": "train"})\n\n# Upload the input from bytes with custom metadata\ninput_object.upload_from_bytes(input_id="text_data_metadata", text_bytes=input_text, metadata=metadata)\n',A='import { Input } from "clarifai-nodejs";\n\n\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nconst textBytes = Buffer.from("Write a tweet on future of AI");\nconst metadata = {\n  filename: "tweet.txt",\n  split: "train",\n};\nawait input.uploadFromBytes({\n  inputId: "text_with_metadata",\n  textBytes,\n  metadata,\n});\n',U='# Import necessary modules\nfrom clarifai.client.input import Inputs\nfrom google.protobuf.struct_pb2 import Struct\n\n\n# Define the input object with user_id and app_id\ninput_object = Inputs(user_id="user_id", app_id="app_id", pat="YOUR_PAT")\n\n# Define the URL of the audio file\naudio_url = "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav"\n\n# Create a new Struct to hold metadata\nmetadata = Struct()\n\n# Update the metadata with filename and split information\nmetadata.update({"filename": "goodmorning.wav", "split": "test"})\n\n# Upload the input from the specified URL with metadata\ninput_object.upload_from_url(\n    input_id="audio_data_metadata",  # Specify an ID for the input\n    audio_url=audio_url,  # URL of the audio file\n    metadata=metadata  # Custom metadata associated with the input\n)\n',E='import { Input } from "clarifai-nodejs";\n\n\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nconst metadata = {\n  filename: "goodmorning.wav",\n  split: "test",\n};\nconst audioUrl =\n  "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav";\nawait input.uploadFromUrl({\n  inputId: "audio_data_metadata",\n  audioUrl,\n  metadata,\n});\n',R='from clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Upload the image with a specific input ID\ninput_object.upload_from_url(input_id="bbox", image_url="https://samples.clarifai.com/BarackObama.jpg")\n\n# Upload initial bounding box annotations\nbbox_points = [.1, .1, .8, .9]  # Coordinates of the bounding box\nannotation = input_object.get_bbox_proto(input_id="bbox", label="face", bbox=bbox_points, label_id="id-face", annot_id="demo")\ninput_object.upload_annotations([annotation])\n\n# Update existing bounding box annotations with new coordinates\nbbox_points = [.35, .45, .6, .7]  # New coordinates of the bounding box\nannotation = input_object.get_bbox_proto(input_id="bbox", label="face", bbox=bbox_points, label_id="id-face", annot_id="demo")\ninput_object.patch_annotations([annotation], action=\'merge\')\n\n# Remove the bounding box annotations\nbbox_points = [.3, .3, .6, .7]  # Coordinates of the bounding box to be removed\nannotation = input_object.get_bbox_proto(input_id="bbox", label="face", bbox=bbox_points, label_id="id-face", annot_id="demo")\ninput_object.patch_annotations([annotation], action=\'remove\')',D='from clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Upload the image with a specific input ID\ninput_object.upload_from_url(input_id="polygon", image_url="https://samples.clarifai.com/BarackObama.jpg")\n\n# Upload initial polygon annotations\npolygon_pts = [[.1,.1],[.1,.9],[.9,.9],[.9,.1]] # Coordinates of the polygon\nannotation = input_object.get_mask_proto(input_id="polygon", label="label", polygons=polygon_pts, annot_id="annotation_id")\ninput_object.upload_annotations([annotation])\n\n# Update existing polygon annotations with new coordinates\npolygon_pts = [[.15,.15],[.15,.95],[.95,.95],[.95,.15]] # New coordinates of the polygon\nannotation = input_object.get_mask_proto(input_id="polygon", label="label", polygons=polygon_pts, annot_id="annotation_id")\ninput_object.patch_annotations([annotation],action=\'merge\')\n\n# Remove the polygon annotations\npolygon_pts = [[.3,.3],[.3,.7],[.8,.8],[.7,.3]] # Coordinates of the polygon to be removed\nannotation = input_object.get_mask_proto(input_id="polygon", label="label", polygons=polygon_pts, annot_id="annotation_id")\ninput_object.patch_annotations([annotation],action=\'remove\')\n',O='from clarifai.client.input import Inputs\nfrom google.protobuf.struct_pb2 import Struct\n\n# Metadata structure should be of Struct, so we create it, add the necessary details and provide it to input proto\nmetadata = Struct() \nmetadata.update({"split": "test"}) \n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\nnew_input = input_object._get_proto(input_id="YOUR_INPUT_ID_HERE", metadata= metadata)\n\n# Update the metadata\ninput_object.patch_inputs([new_input],action="merge")\n\n# Overwrite the metadata\ninput_object.patch_inputs([new_input],action=\'overwrite\')\n',S='from clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# This example changes the existing concept label "id-face" to "obama_face"\ninput_object.patch_concepts(\n    concept_ids=["id-face"],  # The ID of the concept you want to update\n    labels=["obama_face"],    # The new label name to overwrite the existing one\n    values=[],                \n    action=\'overwrite\'        \n)\n',C='from clarifai.client.input import Inputs\n\n# URL of the image to upload\nimage_url = "https://samples.clarifai.com/Ferrari.jpg"\n\n# Provide the Geoinfo to be added to the input\n# geo_info=[longitude, latitude]\ngeo_points = [102,73]\n\n# Create an Inputs object with user_id and app_id\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Upload the image from the URL with associated GeoInfo\ninput_object.upload_from_url(input_id="geo_info", image_url=image_url, geo_info=geo_points)\n',P='# Start by uploading the image with a specific input ID as described earlier\n# For example, you can upload this image: https://samples.clarifai.com/BarackObama.jpg\n# Then, after successfully uploading it, apply the bounding box annotations\n\nfrom clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Upload bounding box annotations\nbbox_points = [.1, .1, .8, .9]  # Coordinates of the bounding box\nannotation = input_object.get_bbox_proto(input_id="bbox", label="face", bbox=bbox_points, label_id="id-face", annot_id="demo")\ninput_object.upload_annotations([annotation])\n',T='# Start by uploading the image with a specific input ID as described earlier\n# For example, you can upload this image: https://samples.clarifai.com/airplane.jpeg\n# Then, after successfully uploading it, apply the polygon annotations\n\nfrom clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Upload polygon annotations\n#polygons=[[[x,y],...,[x,y]],...]\npolygon_pts = [[.15,.24],[.4,.78],[.77,.62],[.65,.15]]\nannotation = input_object.get_mask_proto(input_id="mask", label="airplane", polygons=polygon_pts)\ninput_object.upload_annotations([annotation])\n',N='from clarifai.client.input import Inputs\n\nurl = "https://samples.clarifai.com/featured-models/Llama2_Conversational-agent.txt"\n\n# Change this depending on the type of input you want to annotate\nconcepts = ["mobile","camera"]\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n                      \n# Upload text data with concepts\ninput_object.upload_from_url(input_id="text1", text_url=url, labels=concepts)\n\n# Upload image data with concepts\n#input_object.upload_from_url(input_id="image1", image_url="ADD_URL_HERE", labels=concepts)\n\n# Upload video data with concepts\n#input_object.upload_from_url(input_id="video1", video_url="ADD_URL_HERE", labels=concepts)\n\n# Upload audio data with concepts\n#input_object.upload_from_url(input_id="audio1", audio_url="ADD_URL_HERE", labels=concepts)',k='from clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n                      \n# Bulk delete annotations\ninput_object.delete_annotations(input_ids=["input_id1", "input_id1", "input_id2"], annotation_ids=["annot_id11", "annot_id12", "annot_id21"])\n',Y='from clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Download inputs  \ninput_object.download_inputs(list(input_object.list_inputs()))\n',F='from clarifai.client.input import Inputs\n\n# Initialize the Inputs object with user and app IDs\ninput_object = Inputs(user_id="YOUR_USER_ID_HERE", app_id="YOUR_APP_ID_HERE", pat="YOUR_PAT_HERE")\n\n# Remove unicode from text \ndef remove_unicode_and_upload(input_id, text):\n    string_encode = text.encode("ascii", "ignore")\n    string_decode = string_encode.decode()\n    input_object.upload_text(input_id=input_id,raw_text=string_decode)\n\nremove_unicode_and_upload(input_id=\'test\', text="This is a test \\u200c example. ")\n',B='\n2024-01-15 16:38:49 INFO     clarifai.client.input:                                                    input.py:669\n\n                             Inputs Uploaded                                                                       \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             details: "All inputs successfully added"                                              \n\n                             req_id: "a14eda72951b06cd25561381d70ced74"    ',L='2024-01-16 14:14:41 INFO     clarifai.client.input:                                                    input.py:669\n\n                             Inputs Uploaded                                                                       \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             details: "All inputs successfully added"                                              \n\n                             req_id: "80d2454a1dea0411e20fb03b2fe0c8b1"',q='\n2024-01-16 14:18:58 INFO     clarifai.client.input:                                                    input.py:669\n\n                             Inputs Uploaded                                                                       \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             details: "All inputs successfully added"                                              \n\n                             req_id: "c16d3dd066d7ee48d038744daacef6e8" ',H='2024-01-16 14:25:26 INFO     clarifai.client.input:                                                    input.py:669\n\n                             Inputs Uploaded                                                                       \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             details: "All inputs successfully added"                                              \n\n                             req_id: "00576d040a6254019942ab4eceb306ad" ',M='id: "multimodal_data"\ndata {\n  image {\n    url: "https://samples.clarifai.com/metro-north.jpg"\n  }\n  text {\n    raw: "What time of day is it?"\n  }\n}\n',z='[id: "demo1"\ndata {\n  image {\n    url: "https://samples.clarifai.com/metro-north.jpg"\n    hosted {\n      prefix: "https://data.clarifai.com"\n      suffix: "users/8tzpjy1a841y/apps/test_app/inputs/image/140c856dc82565d2c4d6ea720fceff78"\n      sizes: "orig"\n      sizes: "tiny"\n      sizes: "small"\n      sizes: "large"\n      crossorigin: "use-credentials"\n    }\n    image_info {\n      width: 512\n      height: 384\n      format: "JPEG"\n      color_mode: "YUV"\n    }\n  }\n}\ncreated_at {\n  seconds: 1705917660\n  nanos: 789409000\n}\n...\n  code: INPUT_DOWNLOAD_SUCCESS\n  description: "Download complete"\n}\n]\n',W='2024-01-16 14:44:28 INFO     clarifai.client.input:                                                    input.py:732\n\n                             Inputs Deleted                                                                        \n\n                             code: SUCCESS                                                                         \n\n                             description: "Ok"                                                                     \n\n                             req_id: "4ae26cd15c7da98a1c2d3647b03d2768"  ',V='2024-04-05 13:03:24 INFO     clarifai.client.input:                                                    input.py:674\n                             Inputs Uploaded                                                                       \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             details: "All inputs successfully added"                                              \n                             req_id: "951a64b950cccf05c8d274c8acc1f0f6"                                            \n                                                                                                                   \nINFO:clarifai.client.input:\nInputs Uploaded\ncode: SUCCESS\ndescription: "Ok"\ndetails: "All inputs successfully added"\nreq_id: "951a64b950cccf05c8d274c8acc1f0f6"\n\n(\'8557e0f57f464c22b3483de76757fb4f\',\n status {\n   code: SUCCESS\n   description: "Ok"\n   details: "All inputs successfully added"\n   req_id: "951a64b950cccf05c8d274c8acc1f0f6"\n }\n inputs {\n   id: "metadata"\n   data {\n     image {\n       url: "https://samples.clarifai.com/XiJinping.jpg"\n       image_info {\n         format: "UnknownImageFormat"\n         color_mode: "UnknownColorMode"\n       }\n     }\n     metadata {\n       fields {\n         key: "filename"\n         value {\n           string_value: "XiJinping.jpg"\n         }\n       }\n       fields {\n         key: "split"\n         value {\n           string_value: "train"\n         }\n       }\n     }\n   }\n   created_at {\n     seconds: 1712322204\n     nanos: 737881425\n   }\n   modified_at {\n     seconds: 1712322204\n     nanos: 737881425\n   }\n   status {\n     code: INPUT_DOWNLOAD_PENDING\n     description: "Download pending"\n   }\n }\n inputs_add_job {\n   id: "8557e0f57f464c22b3483de76757fb4f"\n   progress {\n     pending_count: 1\n   }\n   created_at {\n     seconds: 1712322204\n     nanos: 714751000\n   }\n   modified_at {\n     seconds: 1712322204\n     nanos: 714751000\n   }\n   status {\n     code: JOB_QUEUED\n     description: "Job is queued to be ran."\n   }\n })',J='2024-04-05 13:05:49 INFO     clarifai.client.input:                                                    input.py:674\n                             Inputs Uploaded                                                                       \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             details: "All inputs successfully added"                                              \n                             req_id: "72c9820d805efb9f3ee7f0508778c1f3"                                            \n                                                                                                                   \nINFO:clarifai.client.input:\nInputs Uploaded\ncode: SUCCESS\ndescription: "Ok"\ndetails: "All inputs successfully added"\nreq_id: "72c9820d805efb9f3ee7f0508778c1f3"\n\n(\'7fdc30b9c2a24f31b6a41b32bd9fea02\',\n status {\n   code: SUCCESS\n   description: "Ok"\n   details: "All inputs successfully added"\n   req_id: "72c9820d805efb9f3ee7f0508778c1f3"\n }\n inputs {\n   id: "video_data_metadata"\n   data {\n     video {\n       url: "https://samples.clarifai.com/beer.mp4"\n       video_info {\n         video_format: "UnknownVideoFormat"\n       }\n     }\n     metadata {\n       fields {\n         key: "filename"\n         value {\n           string_value: "drinks.jpg"\n         }\n       }\n       fields {\n         key: "split"\n         value {\n           string_value: "train"\n         }\n       }\n     }\n   }\n   created_at {\n     seconds: 1712322349\n     nanos: 628288634\n   }\n   modified_at {\n     seconds: 1712322349\n     nanos: 628288634\n   }\n   status {\n     code: INPUT_DOWNLOAD_PENDING\n     description: "Download pending"\n   }\n }\n inputs_add_job {\n   id: "7fdc30b9c2a24f31b6a41b32bd9fea02"\n   progress {\n     pending_count: 1\n   }\n   created_at {\n     seconds: 1712322349\n     nanos: 602487000\n   }\n   modified_at {\n     seconds: 1712322349\n     nanos: 602487000\n   }\n   status {\n     code: JOB_QUEUED\n     description: "Job is queued to be ran."\n   }\n })',G='2024-04-05 13:07:04 INFO     clarifai.client.input:                                                    input.py:674\n                             Inputs Uploaded                                                                       \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             details: "All inputs successfully added"                                              \n                             req_id: "835f6c736f032947d1f4067e39c10b72"                                            \n                                                                                                                   \nINFO:clarifai.client.input:\nInputs Uploaded\ncode: SUCCESS\ndescription: "Ok"\ndetails: "All inputs successfully added"\nreq_id: "835f6c736f032947d1f4067e39c10b72"\n\n(\'e3de274f644a4e98a488e7c85f94c0d1\',\n status {\n   code: SUCCESS\n   description: "Ok"\n   details: "All inputs successfully added"\n   req_id: "835f6c736f032947d1f4067e39c10b72"\n }\n inputs {\n   id: "text_data_metadata"\n   data {\n     metadata {\n       fields {\n         key: "filename"\n         value {\n           string_value: "tweet.txt"\n         }\n       }\n       fields {\n         key: "split"\n         value {\n           string_value: "train"\n         }\n       }\n     }\n     text {\n       url: "https://data.clarifai.com/orig/users/8tzpjy1a841y/apps/visual_classifier_eval/inputs/text/c439598b04d8112867eec70097aa00c2"\n       text_info {\n         encoding: "UnknownTextEnc"\n       }\n     }\n   }\n   created_at {\n     seconds: 1712322424\n     nanos: 56818659\n   }\n   modified_at {\n     seconds: 1712322424\n     nanos: 56818659\n   }\n   status {\n     code: INPUT_DOWNLOAD_PENDING\n     description: "Download pending"\n   }\n }\n inputs_add_job {\n   id: "e3de274f644a4e98a488e7c85f94c0d1"\n   progress {\n     pending_count: 1\n   }\n   created_at {\n     seconds: 1712322423\n     nanos: 941401000\n   }\n   modified_at {\n     seconds: 1712322423\n     nanos: 941401000\n   }\n   status {\n     code: JOB_QUEUED\n     description: "Job is queued to be ran."\n   }\n })',X='2024-04-08 06:39:32 INFO     clarifai.client.input:                                                    input.py:674\n                             Inputs Uploaded                                                                       \n                             code: SUCCESS                                                                         \n                             description: "Ok"                                                                     \n                             details: "All inputs successfully added"                                              \n                             req_id: "4c96e4167170c174838c7987101f3478"                                            \n                                                                                                                   \nINFO:clarifai.client.input:\nInputs Uploaded\ncode: SUCCESS\ndescription: "Ok"\ndetails: "All inputs successfully added"\nreq_id: "4c96e4167170c174838c7987101f3478"\n\n(\'109349aa790a404db39f6324415a47a5\',\n status {\n   code: SUCCESS\n   description: "Ok"\n   details: "All inputs successfully added"\n   req_id: "4c96e4167170c174838c7987101f3478"\n }\n inputs {\n   id: "audio_data_metadata"\n   data {\n     metadata {\n       fields {\n         key: "filename"\n         value {\n           string_value: "goodmorning.wav"\n         }\n       }\n       fields {\n         key: "split"\n         value {\n           string_value: "test"\n         }\n       }\n     }\n     audio {\n       url: "https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav"\n       audio_info {\n         audio_format: "UnknownAudioFormat"\n       }\n     }\n   }\n   created_at {\n     seconds: 1712558372\n     nanos: 764691920\n   }\n   modified_at {\n     seconds: 1712558372\n     nanos: 764691920\n   }\n   status {\n     code: INPUT_DOWNLOAD_PENDING\n     description: "Download pending"\n   }\n }\n inputs_add_job {\n   id: "109349aa790a404db39f6324415a47a5"\n   progress {\n     pending_count: 1\n   }\n   created_at {\n     seconds: 1712558372\n     nanos: 751997000\n   }\n   modified_at {\n     seconds: 1712558372\n     nanos: 751997000\n   }\n   status {\n     code: JOB_QUEUED\n     description: "Job is queued to be ran."\n   }\n })',$={description:"Upload, list, download, update, or delete inputs",sidebar_position:5},Q="Managing Inputs",K={id:"sdk/managing-inputs",title:"Managing Inputs",description:"Upload, list, download, update, or delete inputs",source:"@site/docs/sdk/managing-inputs.md",sourceDirName:"sdk",slug:"/sdk/managing-inputs",permalink:"/sdk/managing-inputs",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/sdk/managing-inputs.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{description:"Upload, list, download, update, or delete inputs",sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"Advanced Concept Management",permalink:"/sdk/advanced-concept-management"},next:{title:"Inference From AI Models",permalink:"/sdk/Inference-from-AI-Models/"}},Z={},nn=[{value:"API Upload Limits",id:"api-upload-limits",level:2},{value:"Images",id:"images",level:4},{value:"Videos",id:"videos",level:4},{value:"Text Files",id:"text-files",level:4},{value:"Audio Files",id:"audio-files",level:4},{value:"Upload Image Data",id:"upload-image-data",level:2},{value:"Upload Text Data",id:"upload-text-data",level:2},{value:"Write Custom Functions for Data Processing",id:"write-custom-functions-for-data-processing",level:2},{value:"Upload Audio Data",id:"upload-audio-data",level:2},{value:"Upload Video Data",id:"upload-video-data",level:2},{value:"Upload Multimodal Data",id:"upload-multimodal-data",level:2},{value:"Upload Custom Metadata",id:"upload-custom-metadata",level:2},{value:"Image With Metadata",id:"image-with-metadata",level:3},{value:"Video With Metadata",id:"video-with-metadata",level:3},{value:"Text With Metadata",id:"text-with-metadata",level:3},{value:"Audio With Metadata",id:"audio-with-metadata",level:3},{value:"Upload Inputs with Geospatial Information",id:"upload-inputs-with-geospatial-information",level:2},{value:"Upload Inputs With Annotations",id:"upload-inputs-with-annotations",level:2},{value:"Bounding Box Annotations",id:"bounding-box-annotations",level:3},{value:"Polygon Annotations",id:"polygon-annotations",level:3},{value:"Concepts Annotations",id:"concepts-annotations",level:3},{value:"Bulk Delete Input Annotations",id:"bulk-delete-input-annotations",level:2},{value:"List inputs",id:"list-inputs",level:2},{value:"Download Inputs",id:"download-inputs",level:2},{value:"Delete Inputs",id:"delete-inputs",level:2},{value:"Patch Inputs",id:"patch-inputs",level:2},{value:"Metadata",id:"metadata",level:3},{value:"Bounding Box Annotation",id:"bounding-box-annotation",level:3},{value:"Polygon Annotation",id:"polygon-annotation",level:3},{value:"Concepts",id:"concepts",level:3}];function en(n){const e={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...n.components},{Details:t}=e;return t||function(n,e){throw new Error("Expected "+(e?"component":"object")+" `"+n+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.h1,{id:"managing-inputs",children:"Managing Inputs"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Upload, list, download, update, or delete inputs"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsx)(e.p,{children:"Managing inputs in the Clarifai platform is a streamlined process that includes uploading, updating, deleting, and performing various data processing tasks. Inputs can encompass a wide range of data types, such as images, videos, text, and more."}),"\n",(0,a.jsx)(e.p,{children:"Whether your inputs are hosted online via URLs, stored locally as file paths, or represented as bytes, our API supports all these formats, ensuring flexibility and ease of use."}),"\n",(0,a.jsx)(e.h2,{id:"api-upload-limits",children:"API Upload Limits"}),"\n",(0,a.jsxs)(e.p,{children:["When uploading data to the Clarifai platform by using methods like ",(0,a.jsx)(e.code,{children:"upload_from_bytes()"})," or ",(0,a.jsx)(e.code,{children:"upload_from_url()"})," (which are illustrated below), your inputs should meet the following conditions."]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.em,{children:"Note that these conditions also apply when uploading inputs for inferencing."})}),"\n",(0,a.jsx)(e.h4,{id:"images",children:"Images"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Each request can include up to 128 image inputs per batch."}),"\n",(0,a.jsx)(e.li,{children:"Each image file must be a maximum of 85 megapixels and less than 20MB in size."}),"\n",(0,a.jsx)(e.li,{children:"The total batch size (in bytes) for each request must be less than 128MB."}),"\n"]}),"\n",(0,a.jsx)(e.h4,{id:"videos",children:"Videos"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Each request can include only 1 video input."}),"\n",(0,a.jsx)(e.li,{children:"If uploading via URL, the video can be up to 300MB or 10 minutes long."}),"\n",(0,a.jsx)(e.li,{children:"If uploading via direct file upload, the video must be less than 128MB."}),"\n"]}),"\n",(0,a.jsx)(e.h4,{id:"text-files",children:"Text Files"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Each request can include up to 128 text files per batch."}),"\n",(0,a.jsx)(e.li,{children:"Each text file must be less than 20MB."}),"\n",(0,a.jsx)(e.li,{children:"The total batch size (in bytes) must be less than 128MB."}),"\n"]}),"\n",(0,a.jsx)(e.h4,{id:"audio-files",children:"Audio Files"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Each request can include up to 128 audio files per batch."}),"\n",(0,a.jsx)(e.li,{children:"Each audio file must be less than 20MB in size (suitable for a 48kHz, 60-second, 16-bit recording)."}),"\n",(0,a.jsx)(e.li,{children:"The total batch size (in bytes) must be less than 128MB."}),"\n"]}),"\n",(0,a.jsxs)(e.blockquote,{children:["\n",(0,a.jsxs)(e.p,{children:["You can bypass these limits by using the ",(0,a.jsxs)(e.a,{href:"https://docs.clarifai.com/sdk/managing-datasets/upload-data",children:[(0,a.jsx)(e.code,{children:"upload_from_folder()"})," method"]})," from the ",(0,a.jsx)(e.code,{children:"Dataset"})," class, which efficiently handles larger volumes of inputs by automatically batching them while adhering to upload restrictions."]}),"\n"]}),"\n",(0,a.jsxs)(e.blockquote,{children:["\n",(0,a.jsx)(e.p,{children:"For example, when uploading images in bulk, the method incrementally processes and uploads them in multiple batches, ensuring that each batch contains a maximum of 128 images and does not exceed 128MB in size."}),"\n"]}),"\n",(0,a.jsxs)(e.blockquote,{children:["\n",(0,a.jsxs)(e.p,{children:["You can also customize the ",(0,a.jsx)(e.code,{children:"batch_size"})," variable, which allows for concurrent upload of inputs and annotations. For example, if your folder exceeds 128MB, you can set the variable to ensure that each batch contains an appropriate number of images while staying within the 128MB per batch limit."]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"upload-image-data",children:"Upload Image Data"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to upload image data."}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:d}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:B})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:p})})]}),"\n",(0,a.jsx)(e.h2,{id:"upload-text-data",children:"Upload Text Data"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to upload text data."}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:r}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:L})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:u})})]}),"\n",(0,a.jsx)(e.h2,{id:"write-custom-functions-for-data-processing",children:"Write Custom Functions for Data Processing"}),"\n",(0,a.jsx)(e.p,{children:"You can add your own custom functions for data processing with ease."}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to clean text data by removing Unicode characters before uploading it to the Clarifai platform."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:F})})}),"\n",(0,a.jsx)(e.h2,{id:"upload-audio-data",children:"Upload Audio Data"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to upload audio data."}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:c}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:q})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:h})})]}),"\n",(0,a.jsx)(e.h2,{id:"upload-video-data",children:"Upload Video Data"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to upload video data."}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:m}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:H})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:_})})]}),"\n",(0,a.jsx)(e.h2,{id:"upload-multimodal-data",children:"Upload Multimodal Data"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to upload a combination of different input types, such as images and text, to the Clarifai platform."}),"\n",(0,a.jsxs)(e.p,{children:["Currently, Clarifai supports specific multimodal input combinations, such as ",(0,a.jsx)(e.code,{children:"[Image, Text] -> Text"}),". This allows you to process and analyze interconnected data types for advanced use cases."]}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:f}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:M})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:g})})]}),"\n",(0,a.jsx)(e.h2,{id:"upload-custom-metadata",children:"Upload Custom Metadata"}),"\n",(0,a.jsx)(e.p,{children:"When using the Clarifai SDKs, you can enhance your inputs by attaching custom metadata alongside concepts. This feature enables you to include additional contextual information, such as categorization, filtering criteria, or reference data, making it easier to organize and retrieve your inputs later."}),"\n",(0,a.jsx)(e.p,{children:"Below are examples of how to upload inputs with custom metadata. In these examples, the metadata includes details about the filename and the dataset split (e.g., train, validate, or test) to which the input belongs."}),"\n",(0,a.jsx)(e.h3,{id:"image-with-metadata",children:"Image With Metadata"}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:j}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:V})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:y})})]}),"\n",(0,a.jsx)(e.h3,{id:"video-with-metadata",children:"Video With Metadata"}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:I}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:J})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:v})})]}),"\n",(0,a.jsx)(e.h3,{id:"text-with-metadata",children:"Text With Metadata"}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:w}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:G})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:A})})]}),"\n",(0,a.jsx)(e.h3,{id:"audio-with-metadata",children:"Audio With Metadata"}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",children:[(0,a.jsx)(l.A,{className:"language-python",children:U}),(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:X})]})]}),(0,a.jsx)(s.A,{value:"typescript",label:"Typescript",children:(0,a.jsx)(l.A,{className:"language-typescript",children:E})})]}),"\n",(0,a.jsx)(e.h2,{id:"upload-inputs-with-geospatial-information",children:"Upload Inputs with Geospatial Information"}),"\n",(0,a.jsx)(e.p,{children:"When uploading inputs to Clarifai, you can enrich them by including geospatial data, such as longitude and latitude coordinates from the GPS system."}),"\n",(0,a.jsx)(e.p,{children:"This allows you to associate each input with a specific geographic location. Note that each input can have at most one geospatial point associated with it."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:C})})}),"\n",(0,a.jsx)(e.h2,{id:"upload-inputs-with-annotations",children:"Upload Inputs With Annotations"}),"\n",(0,a.jsx)(e.p,{children:"You can upload inputs along with their corresponding annotations, such as bounding boxes or polygons."}),"\n",(0,a.jsx)(e.h3,{id:"bounding-box-annotations",children:"Bounding Box Annotations"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to label a new rectangular bounding box for a specific region within an image. The bounding box coordinates should be normalized to the image dimensions, with values scaled to the range of [0, 1.0]."}),"\n",(0,a.jsx)(e.p,{children:"This ensures that the coordinates are independent of the image resolution, making the annotations consistent across different image sizes."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:P})})}),"\n",(0,a.jsx)(e.h3,{id:"polygon-annotations",children:"Polygon Annotations"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to annotate any polygon-shaped region within an image."}),"\n",(0,a.jsx)(e.p,{children:"A polygon is defined by a list of points, each specified by:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"row"})," \u2014 The row position of the point, represented as a value between 0.0 and 1.0, where 0.0 corresponds to the top row and 1.0 corresponds to the bottom."]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"col"})," \u2014 The column position of the point, represented as a value between 0.0 and 1.0, where 0.0 corresponds to the left column of the image and 1.0 corresponds to the right column."]}),"\n"]}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:T})})}),"\n",(0,a.jsx)(e.h3,{id:"concepts-annotations",children:"Concepts Annotations"}),"\n",(0,a.jsxs)(e.p,{children:["Below is an example of how to annotate different types of inputs with ",(0,a.jsx)(e.a,{href:"https://docs.clarifai.com/portal-guide/inputs-manager/concepts",children:"concepts"}),"."]}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:N})})}),"\n",(0,a.jsx)(e.h2,{id:"bulk-delete-input-annotations",children:"Bulk Delete Input Annotations"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to delete all the annotations associated with a given input by setting the input ID(s)."}),"\n",(0,a.jsxs)(e.p,{children:["The ",(0,a.jsx)(e.code,{children:"annotation_ids"})," parameter is optional. However, if provided, the number and order of ",(0,a.jsx)(e.code,{children:"annotation_ids"})," must match the corresponding ",(0,a.jsx)(e.code,{children:"input_ids"}),"."]}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:k})})}),"\n",(0,a.jsx)(e.h2,{id:"list-inputs",children:"List inputs"}),"\n",(0,a.jsxs)(e.p,{children:["You can retrieve all inputs within your app using the ",(0,a.jsx)(e.code,{children:"list_inputs()"})," method. This method supports pagination, so you can efficiently organize and display data."]}),"\n",(0,a.jsxs)(e.p,{children:["You can customize your queries by adjusting ",(0,a.jsx)(e.code,{children:"page_no"})," and ",(0,a.jsx)(e.code,{children:"per_page"})," parameters to fit your specific needs."]}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:b})})}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:z})]}),"\n",(0,a.jsx)(e.h2,{id:"download-inputs",children:"Download Inputs"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to download inputs from your app."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:Y})})}),"\n",(0,a.jsx)(e.h2,{id:"delete-inputs",children:"Delete Inputs"}),"\n",(0,a.jsx)(e.p,{children:"Below is an example of how to delete inputs from your app by providing a list of input IDs."}),"\n",(0,a.jsx)(e.admonition,{type:"caution",children:(0,a.jsx)(e.p,{children:"Be certain that you want to delete a particular input as the operation cannot be undone."})}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:x})})}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"Output"}),(0,a.jsx)(l.A,{className:"language-text",children:W})]}),"\n",(0,a.jsx)(e.h2,{id:"patch-inputs",children:"Patch Inputs"}),"\n",(0,a.jsx)(e.p,{children:"You can apply patch operations to an input, allowing for the merging or removal of items. By default, these actions overwrite existing data, but they behave differently when handling lists of objects."}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["The ",(0,a.jsx)(e.code,{children:"merge"})," action replaces a ",(0,a.jsx)(e.code,{children:"key:value"})," pair with a ",(0,a.jsx)(e.code,{children:"key:new_value"}),", or appends new values to an existing list. When dealing with dictionaries, it merges entries that share the same ",(0,a.jsx)(e.code,{children:"id"})," field."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["The ",(0,a.jsx)(e.code,{children:"remove"})," action replaces a ",(0,a.jsx)(e.code,{children:"key:value"})," pair with a ",(0,a.jsx)(e.code,{children:"key:new_value"}),", or removes any items from a list that match the IDs of the provided values."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:["The ",(0,a.jsx)(e.code,{children:"overwrite"})," action fully replaces an existing object with a new one."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"metadata",children:"Metadata"}),"\n",(0,a.jsx)(e.p,{children:"Here is an example of how to patch the metadata of an input."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:O})})}),"\n",(0,a.jsx)(e.h3,{id:"bounding-box-annotation",children:"Bounding Box Annotation"}),"\n",(0,a.jsx)(e.p,{children:"Here is an example of how to patch a bounding box annotation on an input."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:R})})}),"\n",(0,a.jsx)(e.h3,{id:"polygon-annotation",children:"Polygon Annotation"}),"\n",(0,a.jsx)(e.p,{children:"Here is an example of how to patch a polygon annotation on an input."}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:D})})}),"\n",(0,a.jsx)(e.h3,{id:"concepts",children:"Concepts"}),"\n",(0,a.jsxs)(e.p,{children:["Below is an example of performing a patch operation on concepts. Currently, only the ",(0,a.jsx)(e.code,{children:"overwrite"})," action is supported, allowing you to update the label names associated with an input."]}),"\n",(0,a.jsx)(o.A,{children:(0,a.jsx)(s.A,{value:"python",label:"Python",children:(0,a.jsx)(l.A,{className:"language-python",children:S})})})]})}function tn(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(en,{...n})}):en(n)}},19365:(n,e,t)=>{t.d(e,{A:()=>s});t(96540);var a=t(18215);const i={tabItem:"tabItem_Ymn6"};var o=t(74848);function s(n){let{children:e,hidden:t,className:s}=n;return(0,o.jsx)("div",{role:"tabpanel",className:(0,a.A)(i.tabItem,s),hidden:t,children:e})}},11470:(n,e,t)=>{t.d(e,{A:()=>I});var a=t(96540),i=t(18215),o=t(23104),s=t(56347),l=t(205),d=t(57485),p=t(31682),r=t(70679);function u(n){return a.Children.toArray(n).filter((n=>"\n"!==n)).map((n=>{if(!n||(0,a.isValidElement)(n)&&function(n){const{props:e}=n;return!!e&&"object"==typeof e&&"value"in e}(n))return n;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof n.type?n.type:n.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function c(n){const{values:e,children:t}=n;return(0,a.useMemo)((()=>{const n=e??function(n){return u(n).map((n=>{let{props:{value:e,label:t,attributes:a,default:i}}=n;return{value:e,label:t,attributes:a,default:i}}))}(t);return function(n){const e=(0,p.X)(n,((n,e)=>n.value===e.value));if(e.length>0)throw new Error(`Docusaurus error: Duplicate values "${e.map((n=>n.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(n),n}),[e,t])}function h(n){let{value:e,tabValues:t}=n;return t.some((n=>n.value===e))}function m(n){let{queryString:e=!1,groupId:t}=n;const i=(0,s.W6)(),o=function(n){let{queryString:e=!1,groupId:t}=n;if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,d.aZ)(o),(0,a.useCallback)((n=>{if(!o)return;const e=new URLSearchParams(i.location.search);e.set(o,n),i.replace({...i.location,search:e.toString()})}),[o,i])]}function _(n){const{defaultValue:e,queryString:t=!1,groupId:i}=n,o=c(n),[s,d]=(0,a.useState)((()=>function(n){let{defaultValue:e,tabValues:t}=n;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!h({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map((n=>n.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const a=t.find((n=>n.default))??t[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:e,tabValues:o}))),[p,u]=m({queryString:t,groupId:i}),[_,f]=function(n){let{groupId:e}=n;const t=function(n){return n?`docusaurus.tab.${n}`:null}(e),[i,o]=(0,r.Dv)(t);return[i,(0,a.useCallback)((n=>{t&&o.set(n)}),[t,o])]}({groupId:i}),g=(()=>{const n=p??_;return h({value:n,tabValues:o})?n:null})();(0,l.A)((()=>{g&&d(g)}),[g]);return{selectedValue:s,selectValue:(0,a.useCallback)((n=>{if(!h({value:n,tabValues:o}))throw new Error(`Can't select invalid tab value=${n}`);d(n),u(n),f(n)}),[u,f,o]),tabValues:o}}var f=t(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var b=t(74848);function x(n){let{className:e,block:t,selectedValue:a,selectValue:s,tabValues:l}=n;const d=[],{blockElementScrollPositionUntilNextRender:p}=(0,o.a_)(),r=n=>{const e=n.currentTarget,t=d.indexOf(e),i=l[t].value;i!==a&&(p(e),s(i))},u=n=>{let e=null;switch(n.key){case"Enter":r(n);break;case"ArrowRight":{const t=d.indexOf(n.currentTarget)+1;e=d[t]??d[0];break}case"ArrowLeft":{const t=d.indexOf(n.currentTarget)-1;e=d[t]??d[d.length-1];break}}e?.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":t},e),children:l.map((n=>{let{value:e,label:t,attributes:o}=n;return(0,b.jsx)("li",{role:"tab",tabIndex:a===e?0:-1,"aria-selected":a===e,ref:n=>d.push(n),onKeyDown:u,onClick:r,...o,className:(0,i.A)("tabs__item",g.tabItem,o?.className,{"tabs__item--active":a===e}),children:t??e},e)}))})}function j(n){let{lazy:e,children:t,selectedValue:i}=n;const o=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const n=o.find((n=>n.props.value===i));return n?(0,a.cloneElement)(n,{className:"margin-top--md"}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:o.map(((n,e)=>(0,a.cloneElement)(n,{key:e,hidden:n.props.value!==i})))})}function y(n){const e=_(n);return(0,b.jsxs)("div",{className:(0,i.A)("tabs-container",g.tabList),children:[(0,b.jsx)(x,{...e,...n}),(0,b.jsx)(j,{...e,...n})]})}function I(n){const e=(0,f.A)();return(0,b.jsx)(y,{...n,children:u(n.children)},String(e))}}}]);