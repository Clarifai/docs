"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[5552],{11470:(e,n,i)=>{i.d(n,{A:()=>k});var t=i(96540),a=i(18215),l=i(17559),r=i(23104),o=i(56347),s=i(205),c=i(57485),p=i(31682),d=i(70679);function u(e){return t.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:n,children:i}=e;return(0,t.useMemo)(()=>{const e=n??function(e){return u(e).map(({props:{value:e,label:n,attributes:i,default:t}})=>({value:e,label:n,attributes:i,default:t}))}(i);return function(e){const n=(0,p.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,i])}function m({value:e,tabValues:n}){return n.some(n=>n.value===e)}function f({queryString:e=!1,groupId:n}){const i=(0,o.W6)(),a=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,c.aZ)(a),(0,t.useCallback)(e=>{if(!a)return;const n=new URLSearchParams(i.location.search);n.set(a,e),i.replace({...i.location,search:n.toString()})},[a,i])]}function x(e){const{defaultValue:n,queryString:i=!1,groupId:a}=e,l=h(e),[r,o]=(0,t.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const i=n.find(e=>e.default)??n[0];if(!i)throw new Error("Unexpected error: 0 tabValues");return i.value}({defaultValue:n,tabValues:l})),[c,p]=f({queryString:i,groupId:a}),[u,x]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[i,a]=(0,d.Dv)(n);return[i,(0,t.useCallback)(e=>{n&&a.set(e)},[n,a])]}({groupId:a}),g=(()=>{const e=c??u;return m({value:e,tabValues:l})?e:null})();(0,s.A)(()=>{g&&o(g)},[g]);return{selectedValue:r,selectValue:(0,t.useCallback)(e=>{if(!m({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);o(e),p(e),x(e)},[p,x,l]),tabValues:l}}var g=i(92303);const y={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var _=i(74848);function j({className:e,block:n,selectedValue:i,selectValue:t,tabValues:l}){const o=[],{blockElementScrollPositionUntilNextRender:s}=(0,r.a_)(),c=e=>{const n=e.currentTarget,a=o.indexOf(n),r=l[a].value;r!==i&&(s(n),t(r))},p=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const i=o.indexOf(e.currentTarget)+1;n=o[i]??o[0];break}case"ArrowLeft":{const i=o.indexOf(e.currentTarget)-1;n=o[i]??o[o.length-1];break}}n?.focus()};return(0,_.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":n},e),children:l.map(({value:e,label:n,attributes:t})=>(0,_.jsx)("li",{role:"tab",tabIndex:i===e?0:-1,"aria-selected":i===e,ref:e=>{o.push(e)},onKeyDown:p,onClick:c,...t,className:(0,a.A)("tabs__item",y.tabItem,t?.className,{"tabs__item--active":i===e}),children:n??e},e))})}function w({lazy:e,children:n,selectedValue:i}){const l=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=l.find(e=>e.props.value===i);return e?(0,t.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,_.jsx)("div",{className:"margin-top--md",children:l.map((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==i}))})}function b(e){const n=x(e);return(0,_.jsxs)("div",{className:(0,a.A)(l.G.tabs.container,"tabs-container",y.tabList),children:[(0,_.jsx)(j,{...n,...e}),(0,_.jsx)(w,{...n,...e})]})}function k(e){const n=(0,g.A)();return(0,_.jsx)(b,{...e,children:u(e.children)},String(n))}},19365:(e,n,i)=>{i.d(n,{A:()=>r});i(96540);var t=i(18215);const a={tabItem:"tabItem_Ymn6"};var l=i(74848);function r({children:e,hidden:n,className:i}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,t.A)(a.tabItem,i),hidden:n,children:e})}},51811:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>w,contentTitle:()=>j,default:()=>I,frontMatter:()=>_,metadata:()=>t,toc:()=>b});const t=JSON.parse('{"id":"compute/pipelines/create-api","title":"Create and Run Pipelines [API]","description":"Create, upload, and run pipelines via our API effortlessly","source":"@site/docs/compute/pipelines/create-api.md","sourceDirName":"compute/pipelines","slug":"/compute/pipelines/create-api","permalink":"/compute/pipelines/create-api","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"Create, upload, and run pipelines via our API effortlessly","sidebar_position":1,"toc_max_heading_level":5},"sidebar":"tutorialSidebar","previous":{"title":"Pipelines","permalink":"/compute/pipelines/"},"next":{"title":"Manage Pipeline Runs","permalink":"/compute/pipelines/manage-run"}}');var a=i(74848),l=i(28453),r=i(11470),o=i(19365),s=i(88149);const c="clarifai pipeline init\nWelcome to Clarifai Pipeline Initialization!\nPlease provide the following information:\nUser ID: alfrick\nApp ID: pipelines-1\nPipeline ID [hello-world-pipeline]: \nNumber of pipeline steps [2]: \nName for step 1 [stepA]: \nName for step 2 [stepB]: \n\nCreating pipeline 'hello-world-pipeline' with steps: stepA, stepB\n[INFO] 08:25:06.765535 Created /Users/macbookpro/Desktop/pipelines/one/config.yaml |  thread=8329666752 \n[INFO] 08:25:06.766398 Created /Users/macbookpro/Desktop/pipelines/one/README.md |  thread=8329666752 \n[INFO] 08:25:06.767111 Created /Users/macbookpro/Desktop/pipelines/one/stepA/config.yaml |  thread=8329666752 \n[INFO] 08:25:06.767417 Created /Users/macbookpro/Desktop/pipelines/one/stepA/requirements.txt |  thread=8329666752 \n[INFO] 08:25:06.768022 Created /Users/macbookpro/Desktop/pipelines/one/stepA/1/pipeline_step.py |  thread=8329666752 \n[INFO] 08:25:06.768514 Created /Users/macbookpro/Desktop/pipelines/one/stepB/config.yaml |  thread=8329666752 \n[INFO] 08:25:06.768764 Created /Users/macbookpro/Desktop/pipelines/one/stepB/requirements.txt |  thread=8329666752 \n[INFO] 08:25:06.769000 Created /Users/macbookpro/Desktop/pipelines/one/stepB/1/pipeline_step.py |  thread=8329666752 \n[INFO] 08:25:06.769042 Pipeline initialization complete in /Users/macbookpro/Desktop/pipelines/one |  thread=8329666752 \n[INFO] 08:25:06.769080 Next steps: |  thread=8329666752 \n[INFO] 08:25:06.769116 1. Implement your pipeline step logic in the generated pipeline_step.py files |  thread=8329666752 \n[INFO] 08:25:06.769151 2. Add dependencies to requirements.txt files as needed |  thread=8329666752 \n[INFO] 08:25:06.769187 3. Run 'clarifai pipeline upload config.yaml' to upload your pipeline |  thread=8329666752 \n",p='pipeline:\n  id: "hello-world-pipeline"\n  user_id: "user-id"\n  app_id: "app-id"\n  step_directories:\n    - stepA\n    - stepB\n  orchestration_spec:\n    argo_orchestration_spec: |\n      apiVersion: argoproj.io/v1alpha1\n      kind: Workflow\n      spec:\n        entrypoint: sequence\n        arguments:\n          parameters:\n            - name: input_text\n              value: "Input Text Here"\n        templates:\n        - name: sequence\n          steps:\n          - - name: step-0\n              templateRef:\n                name: users/user-id/apps/app-id/pipeline_steps/stepA\n                template: users/user-id/apps/app-id/pipeline_steps/stepA\n              arguments:\n                parameters:\n                  - name: input_text\n                    value: "{{workflow.parameters.input_text}}"\n          - - name: step-1\n              templateRef:\n                name: users/user-id/apps/app-id/pipeline_steps/stepB\n                template: users/user-id/apps/app-id/pipeline_steps/stepB\n              arguments:\n                parameters:\n                  - name: input_text\n                    value: "{{workflow.parameters.input_text}}"\n  # Optional: Define secrets for pipeline steps\n  # config:\n  #   step_version_secrets:\n  #     step-0:\n  #       API_KEY: users/alfrick/apps//secrets/my-api-key\n  #       DB_PASSWORD: users/alfrick/apps/secrets/db-secret\n  #     step-1:\n  #       EMAIL_TOKEN: users/alfrick/apps/secrets/email-token\n',d='pipeline_step:\n  id: "stepA"\n  user_id: "user-id"\n  app_id: "app-id"\n\npipeline_step_input_params:\n  - name: input_text\n    description: "Text input for processing"\n\nbuild_info:\n  python_version: "3.12"\n\npipeline_step_compute_info:\n  cpu_limit: "500m"\n  cpu_memory: "500Mi"\n  num_accelerators: 0\n',u="clarifai==11.10.2\n# Add your pipeline step dependencies here\n# Example:\n# torch>=1.9.0\n# transformers>=4.20.0\n",h="import argparse\n\nimport clarifai\nfrom clarifai.utils.logging import logger\n\ndef main():\n    parser = argparse.ArgumentParser(description='stepA processing step.')\n    parser.add_argument('--input_text', type=str, required=True, help='Text input for processing')\n\n    args = parser.parse_args()\n\n    logger.info(clarifai.__version__)\n\n    # TODO: Implement your pipeline step logic here\n    logger.info(f\"stepA processed: {args.input_text}\")\n\n\nif __name__ == \"__main__\":\n    main()\n",m='clarifai pipeline upload\n[INFO] 17:13:59.215943 Starting pipeline upload from config: ./config.yaml |  thread=8329666752 \n[INFO] 17:13:59.216027 Uploading 2 pipeline steps... |  thread=8329666752 \n[INFO] 17:13:59.216063 Uploading pipeline step from directory: stepA |  thread=8329666752 \n[INFO] 17:13:59.221287 No config-lock.yaml found, will upload pipeline step |  thread=8329666752 \n[INFO] 17:13:59.221721 Created Dockerfile at /Users/macbookpro/Desktop/pipelines/one/stepA/Dockerfile |  thread=8329666752 \n[INFO] 17:14:01.613332 Creating new pipeline step stepA |  thread=8329666752 \n[INFO] 17:14:02.248411 Successfully created pipeline step stepA |  thread=8329666752 \n[INFO] 17:14:02.263631 Uploading pipeline step content... |  thread=6135148544 \n[INFO] 17:14:02.263920 Upload complete! |  thread=6135148544 \nStatus: Upload done, Upload Progress: 100%, Details: Completed upload of files, initiating pipelineStep version image build. request_id: sdk-python-11Status: Pipeline Step image is currently being built., Upload Progress: 100%, Details: Pipeline Step Version image is being built. request_id: sdk-pyt[INFO] 17:14:03.580160 54c3894e0cc62981ba3a4\nCreated Pipeline Step Version ID: 36e752e546334fa28d73bcbdc86d37a7 |  thread=8329666752 \n[INFO] 17:14:08.499014 2025-11-26 14:14:03.535648 INFO: Downloading uploaded buildable from storage...\n2025-11-26 14:14:04.413025 INFO: Done downloading buildable from storage\n2025-11-26 14:14:04.417035 INFO: Extracting upload...\n2025-11-26 14:14:04.422114 INFO: Done extracting upload\n2025-11-26 14:14:04.425067 INFO: Parsing requirements file for buildable version ID ****bcbdc86d37a7\n2025-11-26 14:14:04.452415 INFO: Dockerfile found at /shared/context/Dockerfile\n2025-11-26 14:14:05.160145 INFO: Setting up credentials\namazon-ecr-credential-helper\nVersion:    0.8.0\nGit commit: ********\n2025-11-26 14:14:05.165486 INFO: Building image...\n#1 \\[internal] load build definition from Dockerfile\n#1 transferring dockerfile: 776B done\n#1 WARN: FromAsCasing: \'as\' and \'FROM\' keywords\' casing do not match (line 1)\n#1 WARN: ****orm: Setting platform to predefined $TARGETPLATFORM in FROM is redundant as this is the default behavior (line 1)\n#1 DONE 0.0s\n\n#2 \\[linux/amd64 internal] load metadata for public.ecr.aws/clarifai-models/python-base:3.12-********\n#2 DONE 0.3s\n\n#3 \\[linux/arm64 internal] load metadata for public.ecr.aws/clarifai-models/python-base:3.12-********\n#3 DONE 0.3s\n\n#4 \\[internal] load .dockerignore\n#4 transferring context: 2B done\n#4 DONE 0.0s\n\n#5 \\[internal] load build context\n#5 transferring context: 1.28kB done\n#5 DONE 0.0s\n\n#6 \\[linux/amd64 1/5] FROM public.ecr.aws/clarifai-models/python-base:3.12-********@sha256:************2a62\n#6 resolve public.ecr.aws/clarifai-models/python-base:3.12-********@sha256:************2a62 done\n#6 CACHED\n\n#7 \\[linux/arm64 1/5] FROM public.ecr.aws/clarifai-models/python-base:3.12-********@sha256:************2a62\n#7 resolve public.ecr.aws/clarifai-models/python-base:3.12-********@sha256:************2a62 done\n#7 CACHED\n\n#8 \\[linux/amd64 2/5] COPY --link requirements.txt /home/nonroot/requirements.txt\n#8 merging done\n#8 DONE 0.0s\n\n#9 \\[linux/arm64 2/5] COPY --link requirements.txt /home/nonroot/requirements.txt\n#9 merging done\n#9 DONE 0.0s\n\n#10 \\[linux/arm64 3/5] RUN ["pip", "install", "--no-cache-dir", "-r", "/home/nonroot/requirements.txt"] |  thread=8329666752 \n[INFO] 17:14:14.728456 #10 4.906 Collecting clarifai==11.10.2 (from -r /home/nonroot/requirements.txt (line 1))\n#10 ...\n\n#11 \\[linux/amd64 3/5] RUN ["pip", "install", "--no-cache-dir", "-r", "/home/nonroot/requirements.txt"]\n#11 0.495 Collecting clarifai==11.10.2 (from -r /home/nonroot/requirements.txt (line 1))\n#11 0.537   Downloading clarifai-11.10.2-py3-none-any.whl.metadata (23 kB)\n#11 0.578 Collecting clarifai-grpc>=11.10.3 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 0.584   Downloading clarifai_grpc-11.10.9-py3-none-any.whl.metadata (4.4 kB)\n#11 0.622 Collecting clarifai-protocol>=0.0.33 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 0.627   Downloading clarifai_protocol-0.0.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n#11 0.760 Collecting numpy>=1.22.0 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 0.764   Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n#11 0.780 Requirement already satisfied: tqdm>=4.65.0 in /venv/lib/python3.12/site-packages (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (4.67.1)\n#11 0.780 Requirement already satisfied: PyYAML>=6.0.1 in /venv/lib/python3.12/site-packages (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (6.0.2)\n#11 0.787 Collecting schema==0.7.5 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 0.792   Downloading schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)\n#11 0.906 Collecting Pillow>=9.5.0 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 0.910   Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n#11 0.921 Collecting tabulate>=0.9.0 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 0.925   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n#11 0.929 Requirement already satisfied: fsspec>=2024.6.1 in /venv/lib/python3.12/site-packages (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (2025.2.0)\n#11 0.940 Collecting click>=8.1.7 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 0.943   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n#11 0.945 Requirement already satisfied: requests>=2.32.3 in /venv/lib/python3.12/site-packages (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (2.32.3)\n#11 1.298 Collecting aiohttp>=3.10.0 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 1.303   Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n#11 1.474 Collecting uv==0.7.12 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 1.479   Downloading uv-0.7.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n#11 1.719 Collecting ruff==0.11.4 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 1.724   Downloading ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n#11 1.793 Collecting psutil==7.0.0 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 1.797   Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n#11 1.813 Collecting pygments>=2.19.2 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 1.817   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n#11 2.258 Collecting pydantic_core==2.33.2 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 2.262   Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n#11 2.273 Collecting packaging==25.0 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 2.277   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n#11 2.281 Requirement already satisfied: typing-extensions!=4.7.0,>=4.6.0 in /venv/lib/python3.12/site-packages (from pydantic_core==2.33.2->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (4.12.2)\n#11 2.287 Collecting contextlib2>=0.5.5 (from schema==0.7.5->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 2.291   Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n#11 2.303 Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 2.307   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n#11 2.314 Collecting aiosignal>=1.4.0 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 2.317   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n#11 2.328 Collecting attrs>=17.3.0 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 2.332   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n#11 2.401 Collecting frozenlist>=1.1.1 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 2.406   Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n#11 2.559 Collecting multidict<7.0,>=4.5 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 2.563   Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n#11 2.599 Collecting propcache>=0.2.0 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 2.603   Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n#11 2.771 Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 2.776   Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n#11 3.138 Collecting grpcio>=1.53.2 (from clarifai-grpc>=11.10.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 3.143   Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n#11 3.248 Collecting protobuf>=5.29.5 (from clarifai-grpc>=11.10.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 3.252   Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n#11 3.264 Collecting googleapis-common-protos>=1.57.0 (from clarifai-grpc>=11.10.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#11 3.268   Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n#11 3.303 Requirement already satisfied: charset-normalizer<4,>=2 in /venv/lib/python3.12/site-packages (from requests>=2.32.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (3.4.1)\n#11 3.303 Requirement already satisfied: idna<4,>=2.5 in /venv/lib/python3.12/site-packages (from requests>=2.32.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (3.10)\n#11 3.304 Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/lib/python3.12/site-packages (from requests>=2.32.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (2.3.0)\n#11 3.304 Requirement already satisfied: certifi>=2017.4.17 in /venv/lib/python3.12/site-packages (from requests>=2.32.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (2025.1.31)\n#11 3.373 Downloading clarifai-11.10.2-py3-none-any.whl (306 kB)\n#11 3.390 Downloading packaging-25.0-py3-none-any.whl (66 kB)\n#11 3.395 Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n#11 3.406 Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n#11 3.445    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 59.3 MB/s eta 0:00:00\n#11 3.451 Downloading ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n#11 3.523    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 11.3/11.3 MB 164.1 MB/s eta 0:00:00\n#11 3.527 Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n#11 3.532 Downloading uv-0.7.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.8 MB)\n#11 3.597    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 17.8/17.8 MB 284.8 MB/s eta 0:00:00\n#11 3.602 Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n#11 3.607    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.8/1.8 MB 499.4 MB/s eta 0:00:00\n#11 3.612 Downloading clarifai_grpc-11.10.9-py3-none-any.whl (302 kB)\n#11 3.624 Downloading clarifai_protocol-0.0.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (449 kB)\n#11 3.629 Downloading click-8.3.1-py3-none-any.whl (108 kB)\n#11 3.632 Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n#11 3.672    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 16.6/16.6 MB 436.6 MB/s eta 0:00:00\n#11 3.675 Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n#11 3.694    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.0/7.0 MB 409.3 MB/s eta 0:00:00\n#11 3.698 Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n#11 3.702    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.2/1.2 MB 402.1 MB/s eta 0:00:00\n#11 3.706 Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n#11 3.710 Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n#11 3.714 Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n#11 3.717 Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n#11 3.721 Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n#11 3.725 Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n#11 3.729 Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n#11 3.733 Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n#11 3.757    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 321.3 MB/s eta 0:00:00\n#11 3.760 Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n#11 3.764 Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n#11 3.768 Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n#11 3.773 Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n#11 3.943 Installing collected packages: uv, tabulate, ruff, pygments, pydantic_core, psutil, protobuf, propcache, Pillow, packaging, numpy, multidict, grpcio, frozenlist, contextlib2, click, attrs, aiohappyeyeballs, yarl, schema, googleapis-common-protos, aiosignal, clarifai-grpc, aiohttp, clarifai-protocol, clarifai\n#11 ...\n\n#10 \\[linux/arm64 3/5] RUN ["pip", "install", "--no-cache-dir", "-r", "/home/nonroot/requirements.txt"]\n#10 5.322   Downloading clarifai-11.10.2-py3-none-any.whl.metadata (23 kB)\n#10 5.792 Collecting clarifai-grpc>=11.10.3 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 5.807   Downloading clarifai_grpc-11.10.9-py3-none-any.whl.metadata (4.4 kB)\n#10 6.197 Collecting clarifai-protocol>=0.0.33 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 6.213   Downloading clarifai_protocol-0.0.34-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (14 kB) |  thread=8329666752 \n[INFO] 17:14:19.500282 #10 7.682 Collecting numpy>=1.22.0 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 7.696   Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (62 kB)\n#10 7.888 Requirement already satisfied: tqdm>=4.65.0 in /venv/lib/python3.12/site-packages (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (4.67.1)\n#10 7.892 Requirement already satisfied: PyYAML>=6.0.1 in /venv/lib/python3.12/site-packages (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (6.0.2)\n#10 7.943 Collecting schema==0.7.5 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 7.956   Downloading schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)\n#10 ...\n\n#11 \\[linux/amd64 3/5] RUN ["pip", "install", "--no-cache-dir", "-r", "/home/nonroot/requirements.txt"]\n#11 5.453   Attempting uninstall: packaging\n#11 5.454     Found existing installation: packaging 24.2\n#11 5.458     Uninstalling packaging-24.2:\n#11 5.463       Successfully uninstalled packaging-24.2\n#11 7.939 Successfully installed Pillow-12.0.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 attrs-25.4.0 clarifai-11.10.2 clarifai-grpc-11.10.9 clarifai-protocol-0.0.34 click-8.3.1 contextlib2-21.6.0 frozenlist-1.8.0 googleapis-common-protos-1.72.0 grpcio-1.76.0 multidict-6.7.0 numpy-2.3.5 packaging-25.0 propcache-0.4.1 protobuf-6.33.1 psutil-7.0.0 pydantic_core-2.33.2 pygments-2.19.2 ruff-0.11.4 schema-0.7.5 tabulate-0.9.0 uv-0.7.12 yarl-1.22.0\n#11 8.028 \n#11 8.028 \\[notice] A new release of pip is available: 25.0.1 -> 25.3\n#11 8.028 \\[notice] To update, run: pip install --upgrade pip\n#11 DONE 8.2s\n\n#12 \\[linux/amd64 4/5] COPY --link=true 1 /home/nonroot/main/1\n#12 DONE 0.0s\n\n#13 \\[linux/amd64 5/5] COPY --link=true requirements.txt config.yaml /home/nonroot/main/\n#13 DONE 0.0s\n\n#10 \\[linux/arm64 3/5] RUN ["pip", "install", "--no-cache-dir", "-r", "/home/nonroot/requirements.txt"]\n#10 9.264 Collecting Pillow>=9.5.0 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 9.278   Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (8.8 kB)\n#10 9.363 Collecting tabulate>=0.9.0 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 9.377   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n#10 9.418 Requirement already satisfied: fsspec>=2024.6.1 in /venv/lib/python3.12/site-packages (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (2025.2.0)\n#10 9.519 Collecting click>=8.1.7 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 9.531   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n#10 9.546 Requirement already satisfied: requests>=2.32.3 in /venv/lib/python3.12/site-packages (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (2.32.3) |  thread=8329666752 \n[INFO] 17:14:23.845921 #10 13.42 Collecting aiohttp>=3.10.0 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 13.43   Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (8.1 kB)\n#10 15.26 Collecting uv==0.7.12 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 15.28   Downloading uv-0.7.12-py3-none-manylinux_2_28_aarch64.whl.metadata (11 kB) |  thread=8329666752 \n[INFO] 17:14:29.359543 #10 18.01 Collecting ruff==0.11.4 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 18.03   Downloading ruff-0.11.4-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (25 kB)\n#10 18.64 Collecting psutil==7.0.0 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 18.65   Downloading psutil-7.0.0-cp36-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (22 kB)\n#10 18.81 Collecting pygments>=2.19.2 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 18.82   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB) |  thread=8329666752 \n[INFO] 17:14:34.195938 #10 23.91 Collecting pydantic_core==2.33.2 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 23.92   Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.8 kB)\n#10 24.02 Collecting packaging==25.0 (from clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 24.03   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n#10 24.07 Requirement already satisfied: typing-extensions!=4.7.0,>=4.6.0 in /venv/lib/python3.12/site-packages (from pydantic_core==2.33.2->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (4.12.2)\n#10 24.11 Collecting contextlib2>=0.5.5 (from schema==0.7.5->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 24.12   Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n#10 24.23 Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 24.24   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n#10 24.28 Collecting aiosignal>=1.4.0 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 24.29   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n#10 24.38 Collecting attrs>=17.3.0 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 24.40   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n#10 24.97 Collecting frozenlist>=1.1.1 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 24.98   Downloading frozenlist-1.8.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (20 kB)\n#10 26.78 Collecting multidict<7.0,>=4.5 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 26.79   Downloading multidict-6.7.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (5.3 kB)\n#10 27.18 Collecting propcache>=0.2.0 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 27.19   Downloading propcache-0.4.1-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (13 kB) |  thread=8329666752 \n[INFO] 17:14:38.907503 #10 26.78 Collecting multidict<7.0,>=4.5 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 26.79   Downloading multidict-6.7.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (5.3 kB)\n#10 27.18 Collecting propcache>=0.2.0 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 27.19   Downloading propcache-0.4.1-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (13 kB)\n#10 29.18 Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.10.0->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 29.19   Downloading yarl-1.22.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (75 kB) |  thread=8329666752 \n[INFO] 17:14:44.744245 #10 33.12 Collecting grpcio>=1.53.2 (from clarifai-grpc>=11.10.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 33.13   Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.whl.metadata (3.7 kB)\n#10 34.34 Collecting protobuf>=5.29.5 (from clarifai-grpc>=11.10.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 34.35   Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_aarch64.whl.metadata (593 bytes)\n#10 34.47 Collecting googleapis-common-protos>=1.57.0 (from clarifai-grpc>=11.10.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1))\n#10 34.48   Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n#10 34.92 Requirement already satisfied: charset-normalizer<4,>=2 in /venv/lib/python3.12/site-packages (from requests>=2.32.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (3.4.1)\n#10 34.93 Requirement already satisfied: idna<4,>=2.5 in /venv/lib/python3.12/site-packages (from requests>=2.32.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (3.10)\n#10 34.93 Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/lib/python3.12/site-packages (from requests>=2.32.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (2.3.0)\n#10 34.93 Requirement already satisfied: certifi>=2017.4.17 in /venv/lib/python3.12/site-packages (from requests>=2.32.3->clarifai==11.10.2->-r /home/nonroot/requirements.txt (line 1)) (2025.1.31)\n#10 35.46 Downloading clarifai-11.10.2-py3-none-any.whl (306 kB)\n#10 35.47 Downloading packaging-25.0-py3-none-any.whl (66 kB)\n#10 35.49 Downloading psutil-7.0.0-cp36-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (279 kB)\n#10 35.51 Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.9 MB)\n#10 35.56    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.9/1.9 MB 71.6 MB/s eta 0:00:00\n#10 35.58 Downloading ruff-0.11.4-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (10.4 MB)\n#10 35.73    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 10.4/10.4 MB 75.2 MB/s eta 0:00:00\n#10 35.75 Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n#10 35.76 Downloading uv-0.7.12-py3-none-manylinux_2_28_aarch64.whl (16.6 MB)\n#10 36.00    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 16.6/16.6 MB 74.0 MB/s eta 0:00:00\n#10 36.02 Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (1.7 MB)\n#10 36.06    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.7/1.7 MB 76.8 MB/s eta 0:00:00\n#10 36.07 Downloading clarifai_grpc-11.10.9-py3-none-any.whl (302 kB)\n#10 36.09 Downloading clarifai_protocol-0.0.34-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (407 kB)\n#10 36.11 Downloading click-8.3.1-py3-none-any.whl (108 kB)\n#10 36.12 Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (14.3 MB)\n#10 36.34    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.3/14.3 MB 73.3 MB/s eta 0:00:00\n#10 36.35 Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (6.3 MB)\n#10 36.47    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 65.5 MB/s eta 0:00:00\n#10 36.48 Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n#10 36.51    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.2/1.2 MB 71.1 MB/s eta 0:00:00\n#10 36.53 Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n#10 36.54 Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n#10 36.55 Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n#10 36.56 Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n#10 36.58 Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n#10 36.59 Downloading frozenlist-1.8.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (243 kB)\n#10 36.61 Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n#10 36.62 Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (6.4 MB)\n#10 36.73    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.4/6.4 MB 73.0 MB/s eta 0:00:00\n#10 36.74 Downloading multidict-6.7.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (258 kB)\n#10 36.76 Downloading propcache-0.4.1-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (225 kB)\n#10 36.77 Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_aarch64.whl (324 kB)\n#10 36.79 Downloading yarl-1.22.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (372 kB) |  thread=8329666752 \n[INFO] 17:14:49.968390 #10 36.34    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.3/14.3 MB 73.3 MB/s eta 0:00:00\n#10 36.35 Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (6.3 MB)\n#10 36.47    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 65.5 MB/s eta 0:00:00\n#10 36.48 Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n#10 36.51    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.2/1.2 MB 71.1 MB/s eta 0:00:00\n#10 36.53 Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n#10 36.54 Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n#10 36.55 Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n#10 36.56 Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n#10 36.58 Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n#10 36.59 Downloading frozenlist-1.8.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (243 kB)\n#10 36.61 Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n#10 36.62 Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (6.4 MB)\n#10 36.73    \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.4/6.4 MB 73.0 MB/s eta 0:00:00\n#10 36.74 Downloading multidict-6.7.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (258 kB)\n#10 36.76 Downloading propcache-0.4.1-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (225 kB)\n#10 36.77 Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_aarch64.whl (324 kB)\n#10 36.79 Downloading yarl-1.22.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (372 kB)\n#10 38.44 Installing collected packages: uv, tabulate, ruff, pygments, pydantic_core, psutil, protobuf, propcache, Pillow, packaging, numpy, multidict, grpcio, frozenlist, contextlib2, click, attrs, aiohappyeyeballs, yarl, schema, googleapis-common-protos, aiosignal, clarifai-grpc, aiohttp, clarifai-protocol, clarifai |  thread=8329666752 \n[INFO] 17:14:59.489056 #10 48.51   Attempting uninstall: packaging\n#10 48.52     Found existing installation: packaging 24.2\n#10 48.55     Uninstalling packaging-24.2:\n#10 48.58       Successfully uninstalled packaging-24.2 |  thread=8329666752 \n[INFO] 17:15:20.793720 #10 68.14 Successfully installed Pillow-12.0.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 attrs-25.4.0 clarifai-11.10.2 clarifai-grpc-11.10.9 clarifai-protocol-0.0.34 click-8.3.1 contextlib2-21.6.0 frozenlist-1.8.0 googleapis-common-protos-1.72.0 grpcio-1.76.0 multidict-6.7.0 numpy-2.3.5 packaging-25.0 propcache-0.4.1 protobuf-6.33.1 psutil-7.0.0 pydantic_core-2.33.2 pygments-2.19.2 ruff-0.11.4 schema-0.7.5 tabulate-0.9.0 uv-0.7.12 yarl-1.22.0\n#10 69.27 \n#10 69.27 \\[notice] A new release of pip is available: 25.0.1 -> 25.3\n#10 69.27 \\[notice] To update, run: pip install --upgrade pip\n#10 DONE 69.8s\n\n#14 \\[linux/arm64 4/5] COPY --link=true 1 /home/nonroot/main/1\n#14 DONE 0.0s\n\n#15 \\[linux/arm64 5/5] COPY --link=true requirements.txt config.yaml /home/nonroot/main/\n#15 DONE 0.0s\n\n#16 exporting to image\n#16 exporting layers |  thread=8329666752 \n[INFO] 17:15:24.795350 #16 exporting layers 7.3s done\n#16 exporting manifest sha256:************2bb1 done\n#16 exporting config sha256:************fbda done\n#16 exporting manifest sha256:************87fc done\n#16 exporting config sha256:************29d1 done\n#16 exporting manifest list sha256:************2d60 done\n#16 pushing layers\n#16 ...\n\n#17 \\[auth] sharing credentials for 891377382885.dkr.ecr.us-east-1.amazonaws.com |  thread=8329666752 \n[INFO] 17:15:29.098369 #16 exporting layers 7.3s done\n#16 exporting manifest sha256:************2bb1 done\n#16 exporting config sha256:************fbda done\n#16 exporting manifest sha256:************87fc done\n#16 exporting config sha256:************29d1 done\n#16 exporting manifest list sha256:************2d60 done\n#16 pushing layers\n#16 ...\n\n#17 \\[auth] sharing credentials for 891377382885.dkr.ecr.us-east-1.amazonaws.com\n#17 DONE 0.0s\n\n#16 exporting to image\n#16 pushing layers 3.0s done\n#16 pushing manifest for ****/prod/pytorch:****bcbdc86d37a7@sha256:************2d60\n#16 pushing manifest for ****/prod/pytorch:****bcbdc86d37a7@sha256:************2d60 1.0s done\n#16 DONE 11.3s\n2025-11-26 14:15:26.682504 INFO: Done building image!!! |  thread=8329666752 \n[INFO] 17:15:31.301665 ng... (elapsed 86.5s)\nPipeline step build complete! |  thread=8329666752 \n[INFO] 17:15:31.302080 Build time elapsed 87.7s |  thread=8329666752 \n[INFO] 17:15:31.305764 Generated config-lock.yaml at /Users/macbookpro/Desktop/pipelines/one/stepA/config-lock.yaml |  thread=8329666752 \n[INFO] 17:15:31.305864 Generated config-lock.yaml for pipeline step with version 36e752e546334fa28d73bcbdc86d37a7 |  thread=8329666752 \n[INFO] 17:15:31.306267 Successfully uploaded pipeline step stepA with version 36e752e546334fa28d73bcbdc86d37a7 |  thread=8329666752 \n[INFO] 17:15:31.306353 Uploading pipeline step from directory: stepB |  thread=8329666752 \n[INFO] 17:15:31.308736 No config-lock.yaml found, will upload pipeline step |  thread=8329666752 \n[INFO] 17:15:31.309571 Created Dockerfile at /Users/macbookpro/Desktop/pipelines/one/stepB/Dockerfile |  thread=8329666752 \n[INFO] 17:15:35.054580 Creating new pipeline step stepB |  thread=8329666752 \n[INFO] 17:15:35.724878 Successfully created pipeline step stepB |  thread=8329666752 \n[INFO] 17:15:35.735020 Uploading pipeline step content... |  thread=6135721984 \n[INFO] 17:15:35.735406 Upload complete! |  thread=6135721984 \nStatus: Upload done, Upload Progress: 100%, Details: Completed upload of files, initiating pipelineStep version image build. request_id: sdk-python-11Status: Pipeline Step image is currently being built., Upload Progress: 100%, Details: Pipeline Step Version image is being built. request_id: sdk-pyt[INFO] 17:15:36.353718 a4e848dcda9d7ec46af50\nCreated Pipeline Step Version ID: 5e93c74ef8ae456ab353aa5e60e46f97 |  thread=8329666752 \n[INFO] 17:15:42.766275 2025-11-26 14:15:37.007123 INFO: Downloading uploaded buildable from storage...\n2025-11-26 14:15:37.835820 INFO: Done downloading buildable from storage\n2025-11-26 14:15:37.839806 INFO: Extracting upload...\n2025-11-26 14:15:37.844892 INFO: Done extracting upload\n2025-11-26 14:15:37.847844 INFO: Parsing requirements file for buildable version ID ****aa5e60e46f97\n2025-11-26 14:15:37.875202 INFO: Dockerfile found at /shared/context/Dockerfile\n2025-11-26 14:15:38.599716 INFO: Setting up credentials\namazon-ecr-credential-helper\nVersion:    0.8.0\nGit commit: ********\n2025-11-26 14:15:38.604653 INFO: Building image...\n#1 \\[internal] load build definition from Dockerfile\n#1 transferring dockerfile: 776B done\n#1 WARN: FromAsCasing: \'as\' and \'FROM\' keywords\' casing do not match (line 1)\n#1 WARN: ****orm: Setting platform to predefined $TARGETPLATFORM in FROM is redundant as this is the default behavior (line 1)\n#1 DONE 0.0s\n\n#2 \\[linux/amd64 internal] load metadata for public.ecr.aws/clarifai-models/python-base:3.12-********\n#2 ...\n\n#3 \\[linux/arm64 internal] load metadata for public.ecr.aws/clarifai-models/python-base:3.12-********\n#3 DONE 0.2s\n\n#4 \\[internal] load .dockerignore\n#4 transferring context: 2B done\n#4 DONE 0.0s\n\n#2 \\[linux/amd64 internal] load metadata for public.ecr.aws/clarifai-models/python-base:3.12-********\n#2 DONE 0.2s\n\n#5 \\[internal] load build context\n#5 transferring context: 1.28kB done\n#5 DONE 0.0s\n\n#6 \\[linux/amd64 1/5] FROM public.ecr.aws/clarifai-models/python-base:3.12-********@sha256:************2a62\n#6 resolve public.ecr.aws/clarifai-models/python-base:3.12-********@sha256:************2a62 done\n#6 DONE 0.0s\n\n#7 \\[linux/amd64 2/5] COPY --link requirements.txt /home/nonroot/requirements.txt\n#7 CACHED\n\n#8 \\[linux/amd64 3/5] RUN ["pip", "install", "--no-cache-dir", "-r", "/home/nonroot/requirements.txt"]\n#8 CACHED\n\n#9 \\[linux/arm64 1/5] FROM public.ecr.aws/clarifai-models/python-base:3.12-********@sha256:************2a62\n#9 resolve public.ecr.aws/clarifai-models/python-base:3.12-********@sha256:************2a62 done\n#9 DONE 0.0s\n\n#10 \\[linux/arm64 2/5] COPY --link requirements.txt /home/nonroot/requirements.txt\n#10 CACHED\n\n#11 \\[linux/arm64 3/5] RUN ["pip", "install", "--no-cache-dir", "-r", "/home/nonroot/requirements.txt"]\n#11 CACHED\n\n#12 \\[linux/arm64 4/5] COPY --link=true 1 /home/nonroot/main/1\n#12 DONE 0.0s\n\n#13 \\[linux/amd64 4/5] COPY --link=true 1 /home/nonroot/main/1\n#13 DONE 0.0s\n\n#14 \\[linux/arm64 5/5] COPY --link=true requirements.txt config.yaml /home/nonroot/main/\n#14 DONE 0.0s\n\n#15 \\[linux/amd64 5/5] COPY --link=true requirements.txt config.yaml /home/nonroot/main/\n#15 DONE 0.0s\n\n#16 exporting to image\n#16 exporting layers done\n#16 exporting manifest sha256:************2819 done\n#16 exporting config sha256:************daac done\n#16 exporting manifest sha256:************df9b done\n#16 exporting config sha256:************2d14 done\n#16 exporting manifest list sha256:************d0a7 done\n#16 pushing layers\n#16 ...\n\n#17 \\[auth] sharing credentials for 891377382885.dkr.ecr.us-east-1.amazonaws.com\n#17 DONE 0.0s\n\n#16 exporting to image\n#16 pushing layers 1.0s done\n#16 pushing manifest for ****/prod/pytorch:****aa5e60e46f97@sha256:************d0a7\n#16 pushing manifest for ****/prod/pytorch:****aa5e60e46f97@sha256:************d0a7 0.9s done\n#16 DONE 2.0s\n2025-11-26 14:15:40.875095 INFO: Done building image!!! |  thread=8329666752 \n[INFO] 17:15:48.372727 ng... (elapsed 7.4s)\nPipeline step build complete! |  thread=8329666752 \n[INFO] 17:15:48.373267 Build time elapsed 12.0s |  thread=8329666752 \n[INFO] 17:15:48.378134 Generated config-lock.yaml at /Users/macbookpro/Desktop/pipelines/one/stepB/config-lock.yaml |  thread=8329666752 \n[INFO] 17:15:48.378296 Generated config-lock.yaml for pipeline step with version 5e93c74ef8ae456ab353aa5e60e46f97 |  thread=8329666752 \n[INFO] 17:15:48.378631 Successfully uploaded pipeline step stepB with version 5e93c74ef8ae456ab353aa5e60e46f97 |  thread=8329666752 \n[INFO] 17:15:48.381909 Updated templateRef from users/alfrick/apps/pipelines-1/pipeline_steps/stepA to users/alfrick/apps/pipelines-1/pipeline_steps/stepA/versions/36e752e546334fa28d73bcbdc86d37a7 |  thread=8329666752 \n[INFO] 17:15:48.381975 Updated templateRef from users/alfrick/apps/pipelines-1/pipeline_steps/stepB to users/alfrick/apps/pipelines-1/pipeline_steps/stepB/versions/5e93c74ef8ae456ab353aa5e60e46f97 |  thread=8329666752 \n[INFO] 17:15:48.383960 Creating pipeline hello-world-pipeline... |  thread=8329666752 \n[INFO] 17:15:48.386609 Updated templateRef from users/alfrick/apps/pipelines-1/pipeline_steps/stepA to users/alfrick/apps/pipelines-1/pipeline_steps/stepA/versions/36e752e546334fa28d73bcbdc86d37a7 |  thread=8329666752 \n[INFO] 17:15:48.386652 Updated templateRef from users/alfrick/apps/pipelines-1/pipeline_steps/stepB to users/alfrick/apps/pipelines-1/pipeline_steps/stepB/versions/5e93c74ef8ae456ab353aa5e60e46f97 |  thread=8329666752 \n[INFO] 17:15:52.139766 Successfully created pipeline hello-world-pipeline |  thread=8329666752 \n[INFO] 17:15:52.140368 Pipeline ID: hello-world-pipeline |  thread=8329666752 \n[INFO] 17:15:52.140444 Pipeline version ID: 48862434906f482e94a2ec638a4233a1 |  thread=8329666752 \n[INFO] 17:15:52.144477 Generated lockfile: /Users/macbookpro/Desktop/pipelines/one/config-lock.yaml |  thread=8329666752 \n[INFO] 17:15:52.144650 Pipeline upload completed successfully with lockfile! |  thread=8329666752 ',f='clarifai pipeline run --compute_cluster_id advanced-cluster-b4z7 --nodepool_id advanced-nodepool-y43h\n[INFO] 11:14:29.351647 Found config-lock.yaml, using it as default config source |  thread=8329666752 \n[INFO] 11:14:29.372765 Starting pipeline run for pipeline hello-world-pipeline |  thread=8329666752 \n---\n[INFO] 11:16:32.978439 Pipeline run status: 64001 (JOB_RUNNING) |  thread=8329666752 \n[INFO] 11:16:32.978534 Pipeline run in progress: 64001 (JOB_RUNNING) |  thread=8329666752 \n[INFO] 11:16:45.383997 [LOG] time="2025-11-27T08:16:16.670Z" level=info msg="Starting Workflow Executor" version=v3.6.2\ntime="2025-11-27T08:16:16.672Z" level=info msg="Using executor retry strategy" Duration=1s Factor=1.6 Jitter=0.5 Steps=5\ntime="2025-11-27T08:16:16.672Z" level=info msg="Executor initialized" deadline="0001-01-01 00:00:00 +0000 UTC" includeScriptOutput=false namespace=prod-alfrick podName=cl-****65fa78cdf145-cl-****faeb11d525aa-4115062186 templateName=cl-****faeb11d525aa version="&Version{Version:v3.6.2,BuildDate:2024-12-02T14:13:35Z,GitCommit:********,GitTag:v3.6.2,GitTreeState:clean,GoVersion:go1.23.3,Compiler:gc,Platform:linux/amd64,}"\ntime="2025-11-27T08:16:16.687Z" level=info msg="Starting deadline monitor"\n{"msg": "11.10.2", "@timestamp": "2025-11-27T08:16:28.188937Z", "filename": "pipeline_step.py", "stack_info": null, "lineno": 12, "taskName": null, "level": "info"}\n{"msg": "stepA processed: Input Text Here", "@timestamp": "2025-11-27T08:16:28.189087Z", "filename": "pipeline_step.py", "stack_info": null, "lineno": 15, "taskName": null, "level": "info"}\ntime="2025-11-27T08:16:28.803Z" level=info msg="sub-process exited" argo=true error="<nil>"\ntime="2025-11-27T08:16:29.698Z" level=info msg="Main container completed" error="<nil>"\ntime="2025-11-27T08:16:29.698Z" level=info msg="No Script output reference in workflow. Capturing script output ignored"\ntime="2025-11-27T08:16:29.698Z" level=info msg="No output parameters"\ntime="2025-11-27T08:16:29.698Z" level=info msg="No output artifacts"\ntime="2025-11-27T08:16:29.721Z" level=info msg="Alloc=17269 TotalAlloc=21042 Sys=30805 NumGC=3 Goroutines=8" |  thread=8329666752 \n[INFO] 11:16:45.384670 Pipeline run monitoring... (elapsed 129.5s) |  thread=8329666752 \n[INFO] 11:16:45.384850 Pipeline run status: 64001 (JOB_RUNNING) |  thread=8329666752 \n[INFO] 11:16:45.384979 Pipeline run in progress: 64001 (JOB_RUNNING) |  thread=8329666752 \n[INFO] 11:16:58.557830 [LOG] time="2025-11-27T08:16:40.798Z" level=info msg="Starting Workflow Executor" version=v3.6.2\ntime="2025-11-27T08:16:40.801Z" level=info msg="Using executor retry strategy" Duration=1s Factor=1.6 Jitter=0.5 Steps=5\ntime="2025-11-27T08:16:40.801Z" level=info msg="Executor initialized" deadline="0001-01-01 00:00:00 +0000 UTC" includeScriptOutput=false namespace=prod-alfrick podName=cl-****65fa78cdf145-cl-****82ec90ebac58-2572335262 templateName=cl-****82ec90ebac58 version="&Version{Version:v3.6.2,BuildDate:2024-12-02T14:13:35Z,GitCommit:********,GitTag:v3.6.2,GitTreeState:clean,GoVersion:go1.23.3,Compiler:gc,Platform:linux/amd64,}"\ntime="2025-11-27T08:16:40.814Z" level=info msg="Starting deadline monitor"\n{"msg": "11.10.2", "@timestamp": "2025-11-27T08:16:42.679105Z", "filename": "pipeline_step.py", "stack_info": null, "lineno": 12, "taskName": null, "level": "info"}\n{"msg": "stepB processed: Input Text Here", "@timestamp": "2025-11-27T08:16:42.679306Z", "filename": "pipeline_step.py", "stack_info": null, "lineno": 15, "taskName": null, "level": "info"}\ntime="2025-11-27T08:16:43.308Z" level=info msg="sub-process exited" argo=true error="<nil>"\ntime="2025-11-27T08:16:43.815Z" level=info msg="Main container completed" error="<nil>"\ntime="2025-11-27T08:16:43.815Z" level=info msg="No Script output reference in workflow. Capturing script output ignored"\ntime="2025-11-27T08:16:43.815Z" level=info msg="No output parameters"\ntime="2025-11-27T08:16:43.815Z" level=info msg="No output artifacts"\ntime="2025-11-27T08:16:43.890Z" level=info msg="Alloc=17164 TotalAlloc=20956 Sys=30805 NumGC=3 Goroutines=8"\ntime="2025-11-27T08:16:43.897Z" level=info msg="Deadline monitor stopped"\ntime="2025-11-27T08:16:43.898Z" level=info msg="stopping progress monitor (context done)" error="context canceled" |  thread=8329666752 \n[INFO] 11:16:58.558881 Pipeline run monitoring... (elapsed 142.7s) |  thread=8329666752 \n[INFO] 11:16:58.559035 Pipeline run status: 64001 (JOB_RUNNING) |  thread=8329666752 \n[INFO] 11:16:58.559159 Pipeline run in progress: 64001 (JOB_RUNNING) |  thread=8329666752 \n[INFO] 11:17:10.044546 Pipeline run monitoring... (elapsed 154.2s) |  thread=8329666752 \n[INFO] 11:17:10.044669 Pipeline run status: 64002 (JOB_COMPLETED) |  thread=8329666752 \n[INFO] 11:17:10.044715 Pipeline run completed successfully! |  thread=8329666752 \n{\n  "status": "success",\n  "pipeline_version_run": {\n    "id": "e8c41c0b6d334daba757a73e99ef0e2d",\n    "pipeline_version": {\n      "id": "48862434906f482e94a2ec638a4233a1",\n      "app_id": "pipelines-1",\n      "user_id": "alfrick",\n      "orchestration_spec": {\n        "argo_orchestration_spec": {\n          "api_version": "argoproj.io/v1alpha1",\n          "spec_json": "{\\"apiVersion\\": \\"argoproj.io/v1alpha1\\", \\"kind\\": \\"Workflow\\", \\"spec\\": {\\"entrypoint\\": \\"sequence\\", \\"arguments\\": {\\"parameters\\": [{\\"name\\": \\"input_text\\", \\"value\\": \\"Input Text Here\\"}]}, \\"templates\\": [{\\"name\\": \\"sequence\\", \\"steps\\": [[{\\"name\\": \\"step-0\\", \\"templateRef\\": {\\"name\\": \\"users/alfrick/apps/pipelines-1/pipeline_steps/stepA/versions/36e752e546334fa28d73bcbdc86d37a7\\", \\"template\\": \\"users/alfrick/apps/pipelines-1/pipeline_steps/stepA/versions/36e752e546334fa28d73bcbdc86d37a7\\"}, \\"arguments\\": {\\"parameters\\": [{\\"name\\": \\"input_text\\", \\"value\\": \\"{{workflow.parameters.input_text}}\\"}]}}], [{\\"name\\": \\"step-1\\", \\"templateRef\\": {\\"name\\": \\"users/alfrick/apps/pipelines-1/pipeline_steps/stepB/versions/5e93c74ef8ae456ab353aa5e60e46f97\\", \\"template\\": \\"users/alfrick/apps/pipelines-1/pipeline_steps/stepB/versions/5e93c74ef8ae456ab353aa5e60e46f97\\"}, \\"arguments\\": {\\"parameters\\": [{\\"name\\": \\"input_text\\", \\"value\\": \\"{{workflow.parameters.input_text}}\\"}]}}]]}]}}"\n        }\n      },\n      "pipeline_id": "hello-world-pipeline",\n      "created_at": "2025-11-26T14:15:51.680568Z",\n      "modified_at": "2025-11-26T14:15:51.680568Z"\n    },\n    "nodepools": [\n      {\n        "id": "advanced-nodepool-y43h",\n        "created_at": "2025-11-27T06:02:02.006900Z",\n        "modified_at": "2025-11-27T06:02:02.006900Z",\n        "node_capacity_type": {\n          "capacity_types": [\n            "ON_DEMAND_TYPE"\n          ]\n        },\n        "instance_types": [\n          {\n            "id": "g6e.xlarge",\n            "description": "g6e.xlarge",\n            "compute_info": {\n              "cpu_memory": "29033Mi",\n              "num_accelerators": 1,\n              "accelerator_memory": "46068Mi",\n              "accelerator_type": [\n                "NVIDIA-L40S"\n              ],\n              "cpu_limit": "3535m"\n            },\n            "price": "65.000000",\n            "cloud_provider": {\n              "id": "aws",\n              "name": "aws"\n            },\n            "region": "us-east-1",\n            "feature_flag_group": "ComputeResourceMedium"\n          }\n        ],\n        "max_instances": 1,\n        "visibility": {\n          "gettable": "PRIVATE"\n        },\n        "enforced_max_instances": 1\n      }\n    ],\n    "orchestration_status": {\n      "argo_status": {\n        "status": "{\\"phase\\":\\"Succeeded\\",\\"startedAt\\":\\"2025-11-27T08:14:41Z\\",\\"finishedAt\\":\\"2025-11-27T08:16:48Z\\",\\"progress\\":\\"2/2\\",\\"nodes\\":{\\"cl-71575952e4355045ad2965fa78cdf145\\":{\\"id\\":\\"cl-71575952e4355045ad2965fa78cdf145\\",\\"name\\":\\"cl-71575952e4355045ad2965fa78cdf145\\",\\"displayName\\":\\"cl-71575952e4355045ad2965fa78cdf145\\",\\"type\\":\\"Steps\\",\\"templateName\\":\\"sequence\\",\\"templateScope\\":\\"local/cl-71575952e4355045ad2965fa78cdf145\\",\\"phase\\":\\"Succeeded\\",\\"startedAt\\":\\"2025-11-27T08:14:41Z\\",\\"finishedAt\\":\\"2025-11-27T08:16:48Z\\",\\"progress\\":\\"2/2\\",\\"resourcesDuration\\":{\\"cpu\\":1,\\"memory\\":26},\\"children\\":[\\"cl-71575952e4355045ad2965fa78cdf145-3359065953\\"],\\"outboundNodes\\":[\\"cl-71575952e4355045ad2965fa78cdf145-2572335262\\"]},\\"cl-71575952e4355045ad2965fa78cdf145-2572335262\\":{\\"id\\":\\"cl-71575952e4355045ad2965fa78cdf145-2572335262\\",\\"name\\":\\"cl-71575952e4355045ad2965fa78cdf145[1].step-1\\",\\"displayName\\":\\"step-1\\",\\"type\\":\\"Pod\\",\\"templateRef\\":{\\"name\\":\\"cl-d0a20398d7e446f0512982ec90ebac58\\",\\"template\\":\\"cl-d0a20398d7e446f0512982ec90ebac58\\"},\\"templateScope\\":\\"local/cl-71575952e4355045ad2965fa78cdf145\\",\\"phase\\":\\"Succeeded\\",\\"boundaryID\\":\\"cl-71575952e4355045ad2965fa78cdf145\\",\\"startedAt\\":\\"2025-11-27T08:16:38Z\\",\\"finishedAt\\":\\"2025-11-27T08:16:43Z\\",\\"progress\\":\\"1/1\\",\\"resourcesDuration\\":{\\"cpu\\":0,\\"memory\\":8},\\"inputs\\":{\\"parameters\\":[{\\"name\\":\\"input_text\\",\\"default\\":\\"\\",\\"value\\":\\"Input Text Here\\",\\"description\\":\\"Text input for processing\\"},{\\"name\\":\\"CLARIFAI_API_BASE\\",\\"value\\":\\"api.clarifai.com:443\\"},{\\"name\\":\\"CLARIFAI_USER_ID\\",\\"value\\":\\"alfrick\\"},{\\"name\\":\\"CLARIFAI_COMPUTE_CLUSTER_ID\\",\\"value\\":\\"advanced-cluster-b4z7\\"},{\\"name\\":\\"CLARIFAI_NODEPOOL_ID\\",\\"value\\":\\"advanced-nodepool-y43h\\"},{\\"name\\":\\"CLARIFAI_PIPELINE_VER_RUN_ID\\",\\"value\\":\\"e8c41c0b6d334daba757a73e99ef0e2d\\"}]},\\"outputs\\":{\\"exitCode\\":\\"0\\"},\\"hostNodeName\\":\\"ip-10-7-183-105.ec2.internal\\"},\\"cl-71575952e4355045ad2965fa78cdf145-3292102572\\":{\\"id\\":\\"cl-71575952e4355045ad2965fa78cdf145-3292102572\\",\\"name\\":\\"cl-71575952e4355045ad2965fa78cdf145[1]\\",\\"displayName\\":\\"[1]\\",\\"type\\":\\"StepGroup\\",\\"templateScope\\":\\"local/cl-71575952e4355045ad2965fa78cdf145\\",\\"phase\\":\\"Succeeded\\",\\"boundaryID\\":\\"cl-71575952e4355045ad2965fa78cdf145\\",\\"startedAt\\":\\"2025-11-27T08:16:38Z\\",\\"finishedAt\\":\\"2025-11-27T08:16:48Z\\",\\"progress\\":\\"1/1\\",\\"resourcesDuration\\":{\\"cpu\\":0,\\"memory\\":8},\\"nodeFlag\\":{},\\"children\\":[\\"cl-71575952e4355045ad2965fa78cdf145-2572335262\\"]},\\"cl-71575952e4355045ad2965fa78cdf145-3359065953\\":{\\"id\\":\\"cl-71575952e4355045ad2965fa78cdf145-3359065953\\",\\"name\\":\\"cl-71575952e4355045ad2965fa78cdf145[0]\\",\\"displayName\\":\\"[0]\\",\\"type\\":\\"StepGroup\\",\\"templateScope\\":\\"local/cl-71575952e4355045ad2965fa78cdf145\\",\\"phase\\":\\"Succeeded\\",\\"boundaryID\\":\\"cl-71575952e4355045ad2965fa78cdf145\\",\\"startedAt\\":\\"2025-11-27T08:14:41Z\\",\\"finishedAt\\":\\"2025-11-27T08:16:38Z\\",\\"progress\\":\\"2/2\\",\\"resourcesDuration\\":{\\"cpu\\":1,\\"memory\\":26},\\"nodeFlag\\":{},\\"children\\":[\\"cl-71575952e4355045ad2965fa78cdf145-4115062186\\"]},\\"cl-71575952e4355045ad2965fa78cdf145-4115062186\\":{\\"id\\":\\"cl-71575952e4355045ad2965fa78cdf145-4115062186\\",\\"name\\":\\"cl-71575952e4355045ad2965fa78cdf145[0].step-0\\",\\"displayName\\":\\"step-0\\",\\"type\\":\\"Pod\\",\\"templateRef\\":{\\"name\\":\\"cl-4495e1a8eea2dae2dad6faeb11d525aa\\",\\"template\\":\\"cl-4495e1a8eea2dae2dad6faeb11d525aa\\"},\\"templateScope\\":\\"local/cl-71575952e4355045ad2965fa78cdf145\\",\\"phase\\":\\"Succeeded\\",\\"boundaryID\\":\\"cl-71575952e4355045ad2965fa78cdf145\\",\\"startedAt\\":\\"2025-11-27T08:14:41Z\\",\\"finishedAt\\":\\"2025-11-27T08:16:29Z\\",\\"progress\\":\\"1/1\\",\\"resourcesDuration\\":{\\"cpu\\":1,\\"memory\\":18},\\"inputs\\":{\\"parameters\\":[{\\"name\\":\\"input_text\\",\\"default\\":\\"\\",\\"value\\":\\"Input Text Here\\",\\"description\\":\\"Text input for processing\\"},{\\"name\\":\\"CLARIFAI_API_BASE\\",\\"value\\":\\"api.clarifai.com:443\\"},{\\"name\\":\\"CLARIFAI_USER_ID\\",\\"value\\":\\"alfrick\\"},{\\"name\\":\\"CLARIFAI_COMPUTE_CLUSTER_ID\\",\\"value\\":\\"advanced-cluster-b4z7\\"},{\\"name\\":\\"CLARIFAI_NODEPOOL_ID\\",\\"value\\":\\"advanced-nodepool-y43h\\"},{\\"name\\":\\"CLARIFAI_PIPELINE_VER_RUN_ID\\",\\"value\\":\\"e8c41c0b6d334daba757a73e99ef0e2d\\"}]},\\"outputs\\":{\\"exitCode\\":\\"0\\"},\\"children\\":[\\"cl-71575952e4355045ad2965fa78cdf145-3292102572\\"],\\"hostNodeName\\":\\"ip-10-7-183-105.ec2.internal\\"}},\\"storedTemplates\\":{\\"namespaced/cl-4495e1a8eea2dae2dad6faeb11d525aa/cl-4495e1a8eea2dae2dad6faeb11d525aa\\":{\\"name\\":\\"cl-4495e1a8eea2dae2dad6faeb11d525aa\\",\\"inputs\\":{\\"parameters\\":[{\\"name\\":\\"input_text\\",\\"default\\":\\"\\",\\"description\\":\\"Text input for processing\\"},{\\"name\\":\\"CLARIFAI_API_BASE\\"},{\\"name\\":\\"CLARIFAI_USER_ID\\"},{\\"name\\":\\"CLARIFAI_COMPUTE_CLUSTER_ID\\"},{\\"name\\":\\"CLARIFAI_NODEPOOL_ID\\"},{\\"name\\":\\"CLARIFAI_PIPELINE_VER_RUN_ID\\"}]},\\"outputs\\":{},\\"metadata\\":{},\\"container\\":{\\"name\\":\\"\\",\\"image\\":\\"data.clarifai.com/users/alfrick/pipeline_step_versions/36e752e546334fa28d73bcbdc86d37a7/image\\",\\"command\\":[\\"python\\",\\"/home/nonroot/main/1/pipeline_step.py\\"],\\"args\\":[\\"--input_text\\",\\"{{inputs.parameters.input_text}}\\"],\\"env\\":[{\\"name\\":\\"CLARIFAI_API_BASE\\",\\"value\\":\\"{{inputs.parameters.CLARIFAI_API_BASE}}\\"},{\\"name\\":\\"CLARIFAI_USER_ID\\",\\"value\\":\\"{{inputs.parameters.CLARIFAI_USER_ID}}\\"},{\\"name\\":\\"CLARIFAI_COMPUTE_CLUSTER_ID\\",\\"value\\":\\"{{inputs.parameters.CLARIFAI_COMPUTE_CLUSTER_ID}}\\"},{\\"name\\":\\"CLARIFAI_NODEPOOL_ID\\",\\"value\\":\\"{{inputs.parameters.CLARIFAI_NODEPOOL_ID}}\\"},{\\"name\\":\\"CLARIFAI_PIPELINE_VER_RUN_ID\\",\\"value\\":\\"{{inputs.parameters.CLARIFAI_PIPELINE_VER_RUN_ID}}\\"},{\\"name\\":\\"CLARIFAI_PAT\\",\\"valueFrom\\":{\\"secretKeyRef\\":{\\"name\\":\\"cl-a021ef5e66fb7933a00b83f07a07a835\\",\\"key\\":\\"clarifaiPAT\\"}}}],\\"resources\\":{\\"limits\\":{\\"cpu\\":\\"500m\\",\\"memory\\":\\"500Mi\\"},\\"requests\\":{\\"cpu\\":\\"500m\\",\\"memory\\":\\"500Mi\\"}}}},\\"namespaced/cl-d0a20398d7e446f0512982ec90ebac58/cl-d0a20398d7e446f0512982ec90ebac58\\":{\\"name\\":\\"cl-d0a20398d7e446f0512982ec90ebac58\\",\\"inputs\\":{\\"parameters\\":[{\\"name\\":\\"input_text\\",\\"default\\":\\"\\",\\"description\\":\\"Text input for processing\\"},{\\"name\\":\\"CLARIFAI_API_BASE\\"},{\\"name\\":\\"CLARIFAI_USER_ID\\"},{\\"name\\":\\"CLARIFAI_COMPUTE_CLUSTER_ID\\"},{\\"name\\":\\"CLARIFAI_NODEPOOL_ID\\"},{\\"name\\":\\"CLARIFAI_PIPELINE_VER_RUN_ID\\"}]},\\"outputs\\":{},\\"metadata\\":{},\\"container\\":{\\"name\\":\\"\\",\\"image\\":\\"data.clarifai.com/users/alfrick/pipeline_step_versions/5e93c74ef8ae456ab353aa5e60e46f97/image\\",\\"command\\":[\\"python\\",\\"/home/nonroot/main/1/pipeline_step.py\\"],\\"args\\":[\\"--input_text\\",\\"{{inputs.parameters.input_text}}\\"],\\"env\\":[{\\"name\\":\\"CLARIFAI_API_BASE\\",\\"value\\":\\"{{inputs.parameters.CLARIFAI_API_BASE}}\\"},{\\"name\\":\\"CLARIFAI_USER_ID\\",\\"value\\":\\"{{inputs.parameters.CLARIFAI_USER_ID}}\\"},{\\"name\\":\\"CLARIFAI_COMPUTE_CLUSTER_ID\\",\\"value\\":\\"{{inputs.parameters.CLARIFAI_COMPUTE_CLUSTER_ID}}\\"},{\\"name\\":\\"CLARIFAI_NODEPOOL_ID\\",\\"value\\":\\"{{inputs.parameters.CLARIFAI_NODEPOOL_ID}}\\"},{\\"name\\":\\"CLARIFAI_PIPELINE_VER_RUN_ID\\",\\"value\\":\\"{{inputs.parameters.CLARIFAI_PIPELINE_VER_RUN_ID}}\\"},{\\"name\\":\\"CLARIFAI_PAT\\",\\"valueFrom\\":{\\"secretKeyRef\\":{\\"name\\":\\"cl-a021ef5e66fb7933a00b83f07a07a835\\",\\"key\\":\\"clarifaiPAT\\"}}}],\\"resources\\":{\\"limits\\":{\\"cpu\\":\\"500m\\",\\"memory\\":\\"500Mi\\"},\\"requests\\":{\\"cpu\\":\\"500m\\",\\"memory\\":\\"500Mi\\"}}}}},\\"conditions\\":[{\\"type\\":\\"PodRunning\\",\\"status\\":\\"False\\"},{\\"type\\":\\"Completed\\",\\"status\\":\\"True\\"}],\\"resourcesDuration\\":{\\"cpu\\":1,\\"memory\\":26},\\"artifactRepositoryRef\\":{\\"default\\":true,\\"artifactRepository\\":{}},\\"artifactGCStatus\\":{\\"notSpecified\\":true},\\"taskResultsCompletionStatus\\":{\\"cl-71575952e4355045ad2965fa78cdf145-2572335262\\":true,\\"cl-71575952e4355045ad2965fa78cdf145-4115062186\\":true}}"\n      },\n      "status": {\n        "code": "JOB_COMPLETED",\n        "description": "Argo workflow at phase: Succeeded, progress: 2/2, message: "\n      }\n    },\n    "user_id": "user-id",\n    "app_id": "pipelines-1",\n    "created_at": "2025-11-27T08:14:36.197820Z",\n    "modified_at": "2025-11-27T08:17:00.924518Z",\n    "orchestration_spec": {\n      "argo_orchestration_spec": {\n        "api_version": "argoproj.io/v1alpha1",\n        "spec_json": "{\\"apiVersion\\": \\"argoproj.io/v1alpha1\\", \\"kind\\": \\"Workflow\\", \\"spec\\": {\\"entrypoint\\": \\"sequence\\", \\"arguments\\": {\\"parameters\\": [{\\"name\\": \\"input_text\\", \\"value\\": \\"Input Text Here\\"}]}, \\"templates\\": [{\\"name\\": \\"sequence\\", \\"steps\\": [[{\\"name\\": \\"step-0\\", \\"templateRef\\": {\\"name\\": \\"users/alfrick/apps/pipelines-1/pipeline_steps/stepA/versions/36e752e546334fa28d73bcbdc86d37a7\\", \\"template\\": \\"users/alfrick/apps/pipelines-1/pipeline_steps/stepA/versions/36e752e546334fa28d73bcbdc86d37a7\\"}, \\"arguments\\": {\\"parameters\\": [{\\"name\\": \\"input_text\\", \\"value\\": \\"{{workflow.parameters.input_text}}\\"}]}}], [{\\"name\\": \\"step-1\\", \\"templateRef\\": {\\"name\\": \\"users/alfrick/apps/pipelines-1/pipeline_steps/stepB/versions/5e93c74ef8ae456ab353aa5e60e46f97\\", \\"template\\": \\"users/alfrick/apps/pipelines-1/pipeline_steps/stepB/versions/5e93c74ef8ae456ab353aa5e60e46f97\\"}, \\"arguments\\": {\\"parameters\\": [{\\"name\\": \\"input_text\\", \\"value\\": \\"{{workflow.parameters.input_text}}\\"}]}}]]}]}}"\n      }\n    }\n  }\n}\n',x='FROM --platform=$TARGETPLATFORM public.ecr.aws/clarifai-models/python-base:3.12-df565436eea93efb3e8d1eb558a0a46df29523ec as final\n\nCOPY --link requirements.txt /home/nonroot/requirements.txt\n\n# Update clarifai package so we always have latest protocol to the API. Everything should land in /venv\nRUN ["pip", "install", "--no-cache-dir", "-r", "/home/nonroot/requirements.txt"]\n\n# Copy in the actual files like config.yaml, requirements.txt, and most importantly 1/pipeline_step.py for the actual pipeline step.\nCOPY --link=true 1 /home/nonroot/main/1\n# At this point we only need these for validation in the SDK.\nCOPY --link=true requirements.txt config.yaml /home/nonroot/main/\n',g="build_info:\n  python_version: '3.12'\nhash:\n  algo: md5\n  value: f66785f39de8b22c68ee9c02929e7969\nid: 36e752e546334fa28d73bcbdc86d37a7\npipeline_step:\n  app_id: pipelines-1\n  id: stepA\n  user_id: user-id\npipeline_step_compute_info:\n  cpu_limit: 500m\n  cpu_memory: 500Mi\n  num_accelerators: 0\npipeline_step_input_params:\n- description: Text input for processing\n  name: input_text\n",y="pipeline:\n  id: hello-world-pipeline\n  user_id: alfrick\n  app_id: pipelines-1\n  version_id: 48862434906f482e94a2ec638a4233a1\n  orchestration_spec:\n    argo_orchestration_spec: |\n      apiVersion: argoproj.io/v1alpha1\n      kind: Workflow\n      spec:\n        arguments:\n          parameters:\n          - name: input_text\n            value: Input Text Here\n        entrypoint: sequence\n        templates:\n        - name: sequence\n          steps:\n          - - arguments:\n                parameters:\n                - name: input_text\n                  value: '{{workflow.parameters.input_text}}'\n              name: step-0\n              templateRef:\n                name: users/alfrick/apps/pipelines-1/pipeline_steps/stepA/versions/36e752e546334fa28d73bcbdc86d37a7\n                template: users/alfrick/apps/pipelines-1/pipeline_steps/stepA/versions/36e752e546334fa28d73bcbdc86d37a7\n          - - arguments:\n                parameters:\n                - name: input_text\n                  value: '{{workflow.parameters.input_text}}'\n              name: step-1\n              templateRef:\n                name: users/alfrick/apps/pipelines-1/pipeline_steps/stepB/versions/5e93c74ef8ae456ab353aa5e60e46f97\n                template: users/alfrick/apps/pipelines-1/pipeline_steps/stepB/versions/5e93c74ef8ae456ab353aa5e60e46f97\n",_={description:"Create, upload, and run pipelines via our API effortlessly",sidebar_position:1,toc_max_heading_level:5},j="Create and Run Pipelines [API]",w={},b=[{value:"Step 1: Perform Prerequisites",id:"step-1-perform-prerequisites",level:2},{value:"Sign Up or Log In",id:"sign-up-or-log-in",level:3},{value:"Install the Clarifai Python SDK",id:"install-the-clarifai-python-sdk",level:3},{value:"Create a Cluster and Nodepool",id:"create-a-cluster-and-nodepool",level:3},{value:"Step 2: Initialize a Pipeline Project",id:"step-2-initialize-a-pipeline-project",level:2},{value:"Pipeline Steps",id:"pipeline-steps",level:3},{value:"Step 3: Modify the Files",id:"step-3-modify-the-files",level:2},{value:"<code>config.yaml</code> (root)",id:"configyaml-root",level:3},{value:"Pipeline Metadata",id:"pipeline-metadata",level:4},{value:"Step Directories",id:"step-directories",level:4},{value:"Argo Workflow Definition",id:"argo-workflow-definition",level:4},{value:"Step Execution Order",id:"step-execution-order",level:4},{value:"Optional: Secrets Configuration",id:"optional-secrets-configuration",level:4},{value:"<code>step/config.yaml</code>",id:"stepconfigyaml",level:3},{value:"Step Metadata",id:"step-metadata",level:4},{value:"Input Interface",id:"input-interface",level:4},{value:"Runtime Environment",id:"runtime-environment",level:4},{value:"Compute Resources Allocation",id:"compute-resources-allocation",level:4},{value:"<code>step/requirements.txt</code>",id:"steprequirementstxt",level:3},{value:"<code>1/pipeline_step.py</code>",id:"1pipeline_steppy",level:3},{value:"Command-line Input Handling",id:"command-line-input-handling",level:4},{value:"Logging the Clarifai SDK Version",id:"logging-the-clarifai-sdk-version",level:4},{value:"Step Logic Placeholder",id:"step-logic-placeholder",level:4},{value:"Step 4: Upload the Pipeline",id:"step-4-upload-the-pipeline",level:2},{value:"Step 5: Run the Pipeline",id:"step-5-run-the-pipeline",level:2},{value:"Run Command Options",id:"run-command-options",level:3}];function k(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components},{Details:i}=n;return i||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"create-and-run-pipelines-api",children:"Create and Run Pipelines [API]"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Create, upload, and run pipelines via our API effortlessly"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsx)(n.p,{children:"Clarifai Pipelines let you design and launch asynchronous, multi-step AI workflows on our platform. You can effortlessly automate complex processes, orchestrate AI agents, and run long-running jobs at scale."}),"\n",(0,a.jsx)(n.p,{children:"Let\u2019s walk through how you can create, upload, and run pipelines via our API."}),"\n","\n","\n",(0,a.jsx)(n.h2,{id:"step-1-perform-prerequisites",children:"Step 1: Perform Prerequisites"}),"\n",(0,a.jsx)(n.h3,{id:"sign-up-or-log-in",children:"Sign Up or Log In"}),"\n",(0,a.jsxs)(n.p,{children:["To get started, ",(0,a.jsx)(n.a,{href:"https://clarifai.com/login",children:"log in"})," to your Clarifai account or ",(0,a.jsx)(n.a,{href:"https://clarifai.com/signup",children:"sign up"})," for a new one.\nIf you\u2019re creating a new account, a default application will be automatically created for you."]}),"\n",(0,a.jsx)(n.p,{children:"Next, gather the following details \u2014 they\u2019re needed to create and manage pipelines programmatically:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"App ID"})," \u2013 Go to your application\u2019s page and choose the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/create/applications/manage#app-overview",children:(0,a.jsx)(n.strong,{children:"Overview"})})," option in the collapsible left sidebar. Get the app ID from there."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"User ID"})," \u2013 Go to ",(0,a.jsx)(n.strong,{children:"Settings"})," in the collapsible left sidebar and choose the ",(0,a.jsx)(n.strong,{children:"Account"})," option. Then, copy your user ID from that page."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"PAT (Personal Access Token)"})," \u2013 From the same ",(0,a.jsx)(n.strong,{children:"Settings"})," menu, navigate to the ",(0,a.jsx)(n.strong,{children:"Secrets"})," page to generate or copy your ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/control/authentication/pat",children:"PAT"}),". This token authenticates your requests to the Clarifai platform."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Set your PAT as an environment variable before continuing:"}),"\n",(0,a.jsxs)(r.A,{groupId:"code",children:[(0,a.jsx)(o.A,{value:"bash",label:"Unix-Like Systems",children:(0,a.jsx)(s.A,{className:"language-bash",children:"export CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE"})}),(0,a.jsx)(o.A,{value:"bash2",label:"Windows",children:(0,a.jsx)(s.A,{className:"language-bash",children:"set CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE"})})]}),"\n",(0,a.jsx)(n.h3,{id:"install-the-clarifai-python-sdk",children:"Install the Clarifai Python SDK"}),"\n",(0,a.jsxs)(n.p,{children:["Install the latest version of the ",(0,a.jsx)(n.code,{children:"clarifai"})," Python SDK. It includes the ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/cli",children:"Clarifai CLI"}),", which you can use to interact with pipelines from the command line."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"pip install --upgrade clarifai\n"})}),"\n",(0,a.jsx)(n.h3,{id:"create-a-cluster-and-nodepool",children:"Create a Cluster and Nodepool"}),"\n",(0,a.jsx)(n.p,{children:"A compute cluster and nodepool define where your pipeline runs within Clarifai\u2019s compute environment. They are required to allocate and manage the resources your pipeline needs for execution."}),"\n",(0,a.jsxs)(n.p,{children:["You need to ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/getting-started/set-up-compute",children:"create"})," them and get their IDs."]}),"\n",(0,a.jsx)(n.h2,{id:"step-2-initialize-a-pipeline-project",children:"Step 2: Initialize a Pipeline Project"}),"\n",(0,a.jsx)(n.p,{children:"Run the following command to create a new pipeline project in your current directory:"}),"\n",(0,a.jsx)(r.A,{groupId:"code",children:(0,a.jsx)(o.A,{value:"bash",label:"CLI",children:(0,a.jsx)(s.A,{className:"language-bash",children:"clarifai pipeline init"})})}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Note:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["You can initialize a project in a specific location by providing a ",(0,a.jsx)(n.code,{children:"PIPELINE_PATH"}),". For example, running ",(0,a.jsx)(n.code,{children:"clarifai pipeline init <pipeline-name>"})," creates a new directory named ",(0,a.jsx)(n.code,{children:"<pipeline-name>"})," and populates it with all the required pipeline project files."]}),"\n",(0,a.jsxs)(n.li,{children:["You can shorten ",(0,a.jsx)(n.code,{children:"pipeline"})," to ",(0,a.jsx)(n.code,{children:"pl"})," when running pipeline commands. For example: ",(0,a.jsx)(n.code,{children:"clarifai pl init"}),"."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"After running the command, you\u2019ll be prompted to provide the following details:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"User ID"})," \u2014 Your Clarifai user ID."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"App ID"})," \u2014 Your Clarifai application ID where the pipeline lives."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"Pipeline ID"})," \u2014 The unique ID for your pipeline (or press ",(0,a.jsx)(n.strong,{children:"Enter"})," to use the default)."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"Number of steps"})," \u2014 How many steps your pipeline should have (or press ",(0,a.jsx)(n.strong,{children:"Enter"})," to use the default). You need to specify at least one step."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"Step names"})," \u2014 A name for each pipeline step (or press ",(0,a.jsx)(n.strong,{children:"Enter"})," to use the defaults)."]}),"\n"]}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Example Output"}),(0,a.jsx)(s.A,{className:"language-text",children:c})]}),"\n",(0,a.jsxs)(n.admonition,{type:"note",children:[(0,a.jsx)(n.mdxAdmonitionTitle,{}),(0,a.jsx)(n.h3,{id:"pipeline-steps",children:"Pipeline Steps"}),(0,a.jsx)(n.p,{children:"A step is a self-contained unit of execution in a Clarifai Pipeline. It represents one stage of your workflow and performs a specific task, then optionally passes its output to the next step."}),(0,a.jsx)(n.p,{children:"For example, a step might preprocess input data, call an AI model, transform results, or interact with an external API."}),(0,a.jsx)(n.p,{children:"In your pipeline project structure, each step is represented by its own folder. Steps are executed in sequence, parallel, or according to the definitions in the pipeline configuration."}),(0,a.jsx)(n.p,{children:"Each step runs in an isolated, containerized environment with:"}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Its own dependencies (",(0,a.jsx)(n.code,{children:"requirements.txt"}),")"]}),"\n",(0,a.jsxs)(n.li,{children:["Its own configuration (",(0,a.jsx)(n.code,{children:"config.yaml"}),")"]}),"\n",(0,a.jsxs)(n.li,{children:["Its own implementation logic (",(0,a.jsx)(n.code,{children:"/1/pipeline_step.py"}),")"]}),"\n"]}),(0,a.jsx)(n.p,{children:"This design makes steps modular, reusable, and independently versioned \u2014 allowing you to update or improve one step without impacting the rest of the pipeline."}),(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," You can also manage individual pipeline steps using the ",(0,a.jsx)(n.code,{children:"pipelinestep"})," (or ",(0,a.jsx)(n.code,{children:"ps"}),") command. This allows you to create, update, and reuse pipeline steps independently of the full pipeline. For example:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"clarifai pipelinestep init"})," \u2013 Initialize a new pipeline step project structure."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"clarifai pipelinestep upload"})," \u2013 Upload a pipeline step to the Clarifai platform."]}),"\n"]}),"\n"]})]}),"\n",(0,a.jsxs)(n.p,{children:["After running ",(0,a.jsx)(n.code,{children:"clarifai pipeline init"}),", the CLI scaffolds a complete boilerplate project for you. Each file and folder represents a specific part of how your pipeline is configured, versioned, and executed."]}),"\n",(0,a.jsx)(n.p,{children:"Here is the structure of the generated project:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"\u251c\u2500\u2500 config.yaml          # Pipeline configuration\n\u251c\u2500\u2500 stepA/               # First pipeline step\n\u2502   \u251c\u2500\u2500 config.yaml      # Step A configuration\n\u2502   \u251c\u2500\u2500 requirements.txt # Step A dependencies\n\u2502   \u2514\u2500\u2500 1/\n\u2502       \u2514\u2500\u2500 pipeline_step.py  # Step A implementation logic\n\u251c\u2500\u2500 stepB/               # Second pipeline step\n\u2502   \u251c\u2500\u2500 config.yaml      # Step B configuration\n\u2502   \u251c\u2500\u2500 requirements.txt # Step B dependencies\n\u2502   \u2514\u2500\u2500 1/\n\u2502       \u2514\u2500\u2500 pipeline_step.py  # Step B implementation logic\n\u2514\u2500\u2500 README.md            # Generated project documentation\n"})}),"\n",(0,a.jsx)(n.h2,{id:"step-3-modify-the-files",children:"Step 3: Modify the Files"}),"\n",(0,a.jsx)(n.p,{children:"The Clarifai CLI generates a structured, multi-step pipeline project, where each step is independently configurable, versioned, and deployable."}),"\n",(0,a.jsx)(n.p,{children:"Next, you can customize the generated files to define your pipeline\u2019s behavior."}),"\n",(0,a.jsx)(n.p,{children:"Let\u2019s walk through what each file does in the default project setup."}),"\n",(0,a.jsxs)(n.h3,{id:"configyaml-root",children:[(0,a.jsx)(n.code,{children:"config.yaml"})," (root)"]}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Example: config.yaml (root)"}),(0,a.jsx)(s.A,{className:"language-text",children:p})]}),"\n",(0,a.jsxs)(n.p,{children:["The root ",(0,a.jsx)(n.code,{children:"config.yaml"})," file defines your pipeline\u2019s identity, structure, and execution logic. It tells Clarifai what the pipeline is, which steps it contains, and how those steps should be orchestrated at runtime."]}),"\n",(0,a.jsx)(n.admonition,{title:"Argo Workflows",type:"tip",children:(0,a.jsxs)(n.p,{children:["Pipeline execution is powered by ",(0,a.jsx)(n.a,{href:"https://argoproj.github.io/workflows/",children:"Argo Workflows"}),", an open-source, Kubernetes-native orchestration engine used to schedule and manage containerized jobs. Argo models multi-step workflows as a sequence of tasks and captures the dependencies between them using a directed acyclic graph (DAG). Clarifai leverages this under the hood to coordinate step execution, manage dependencies, and handle long-running workloads."]})}),"\n",(0,a.jsxs)(n.p,{children:["Let\u2019s break down the ",(0,a.jsx)(n.code,{children:"config.yaml"})," file section by section."]}),"\n",(0,a.jsx)(n.h4,{id:"pipeline-metadata",children:"Pipeline Metadata"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'pipeline:\n  id: "hello-world-pipeline"\n  user_id: "user-id"\n  app_id: "app-id"\n'})}),"\n",(0,a.jsx)(n.p,{children:"These fields define your pipeline\u2019s identity and location when uploaded to the Clarifai platform. They are automatically filled based on the values you provide during initialization."}),"\n",(0,a.jsx)(n.h4,{id:"step-directories",children:"Step Directories"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"step_directories:\n  - stepA\n  - stepB\n"})}),"\n",(0,a.jsx)(n.p,{children:"This section tells Clarifai which folders in your project represent pipeline steps and how they should be ordered during execution.\nThe execution order is stipulated by the Argo Workflow Definition, as explained below."}),"\n",(0,a.jsxs)(n.p,{children:["Each listed directory corresponds to one pipeline step created during initialization. As mentioned ",(0,a.jsx)(n.a,{href:"#pipeline-steps",children:"earlier"}),", each step contains its own ",(0,a.jsx)(n.code,{children:"config.yaml"}),", ",(0,a.jsx)(n.code,{children:"requirements.txt"}),", and executable logic, allowing steps to be configured and maintained independently."]}),"\n",(0,a.jsx)(n.h4,{id:"argo-workflow-definition",children:"Argo Workflow Definition"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'orchestration_spec:\n  argo_orchestration_spec: |\n    apiVersion: argoproj.io/v1alpha1\n    kind: Workflow\n    spec:\n      entrypoint: sequence\n      arguments:\n        parameters:\n          - name: input_text\n            value: "Input Text Here"\n'})}),"\n",(0,a.jsx)(n.p,{children:"This section is the control center of your pipeline. It defines how Clarifai uses Argo Workflows to orchestrate and execute your multi-step workflow as a DAG."}),"\n",(0,a.jsx)(n.p,{children:"Here\u2019s what each part does:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"apiVersion"})," \u2014 Specifies the version of the Argo Workflow API being used."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"kind: Workflow"})," \u2014 Tells the system this is a multi-step Argo workflow."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"entrypoint"})," \u2014 Defines the starting point of execution. In this case, the workflow begins at a ",(0,a.jsx)(n.a,{href:"https://argo-workflows.readthedocs.io/en/release-3.5/workflow-concepts/",children:"template"})," named ",(0,a.jsx)(n.code,{children:"sequence"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["Input parameters \u2014 These are runtime variables passed into your pipeline when you run it. Here, a parameter called ",(0,a.jsx)(n.code,{children:"input_text"})," is defined. If no value is provided at runtime, it defaults to ",(0,a.jsx)(n.code,{children:'"Input Text Here"'}),". This value can then be consumed by any pipeline step."]}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"step-execution-order",children:"Step Execution Order"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'templates:\n- name: sequence\n  steps:\n  - - name: step-0\n      templateRef:\n        name: users/user-id/apps/app-id/pipeline_steps/stepA\n        template: users/user-id/apps/app-id/pipeline_steps/stepA\n      arguments:\n        parameters:\n          - name: input_text\n            value: "{{workflow.parameters.input_text}}"\n\n  - - name: step-1\n      templateRef:\n        name: users/user-id/apps/app-id/pipeline_steps/stepB\n        template: users/user-id/apps/app-id/pipeline_steps/stepB\n      arguments:\n        parameters:\n          - name: input_text\n            value: "{{workflow.parameters.input_text}}"\n'})}),"\n",(0,a.jsx)(n.p,{children:"The section defines how individual pipeline steps are connected and the exact order in which they run."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"step-0"})," \u2014 Executes first. It references the deployed pipeline step ",(0,a.jsx)(n.code,{children:"stepA"})," and receives the ",(0,a.jsx)(n.code,{children:"input_text"})," parameter."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"step-1"})," \u2014 Executes after ",(0,a.jsx)(n.code,{children:"step-0"})," completes. It references ",(0,a.jsx)(n.code,{children:"stepB"})," and also receives the same ",(0,a.jsx)(n.code,{children:"input_text"})," parameter."]}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," This structure defines a sequential workflow. Under the hood, Argo models this sequence as a DAG, ensuring that ",(0,a.jsx)(n.code,{children:"stepB"})," only runs once its dependency (",(0,a.jsx)(n.code,{children:"stepA"}),") has successfully completed. The ",(0,a.jsx)(n.code,{children:"templateRef"})," fields point to the deployed step implementations in your project directories (",(0,a.jsx)(n.code,{children:"stepA/"})," and ",(0,a.jsx)(n.code,{children:"stepB/"}),"). When deployed, Clarifai transforms these into executable Argo templates that power the pipeline."]}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," You can also structure your pipeline as a ",(0,a.jsx)(n.a,{href:"https://argo-workflows.readthedocs.io/en/release-3.4/walk-through/steps/",children:"parallel workflow"}),", where multiple steps run simultaneously instead of sequentially."]}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"optional-secrets-configuration",children:"Optional: Secrets Configuration"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"config:\n  step_version_secrets:\n    step-0:\n      API_KEY: users/user-id/apps/secrets/my-api-key\n      DB_PASSWORD: users/user-id/apps/secrets/db-secret\n    step-1:\n      EMAIL_TOKEN: users/user-id/apps/secrets/email-token\n"})}),"\n",(0,a.jsxs)(n.p,{children:["This section lets you securely inject ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/control/authentication/environment-secrets",children:"environment secrets"})," into specific pipeline steps. It\u2019s especially useful for handling sensitive data, like third-party API keys, without hardcoding them into your source code."]}),"\n",(0,a.jsxs)(n.p,{children:["Each key (for example, ",(0,a.jsx)(n.code,{children:"API_KEY"})," or ",(0,a.jsx)(n.code,{children:"DB_PASSWORD"}),") becomes an environment variable inside the corresponding step\u2019s runtime environment. The values reference secrets stored in the Clarifai secrets manager, which ensures they are encrypted, access-controlled, and never exposed directly in your project files."]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," Once the secrets are mounted, you can access them in your ",(0,a.jsx)(n.a,{href:"#1pipeline_steppy",children:(0,a.jsx)(n.code,{children:"pipeline_step.py"})})," file using standard environment variable calls, for example:"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import os\n\napi_key = os.environ['API_KEY']\n"})}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsx)(n.p,{children:"The secret value is then available to your code at runtime."}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"stepconfigyaml",children:(0,a.jsx)(n.code,{children:"step/config.yaml"})}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Example: step/config.yaml"}),(0,a.jsx)(s.A,{className:"language-text",children:d})]}),"\n",(0,a.jsxs)(n.p,{children:["Each pipeline step includes its own ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/upload/#prepare-configyaml",children:(0,a.jsx)(n.code,{children:"config.yaml"})})," file, which defines it as a self-contained, containerized unit of execution. These files usually share a common structure and similar resource settings, helping keep your pipeline consistent, predictable, and easy to manage."]}),"\n",(0,a.jsxs)(n.p,{children:["Let\u2019s break down the ",(0,a.jsx)(n.code,{children:"step/config.yaml"})," file section by section."]}),"\n",(0,a.jsx)(n.h4,{id:"step-metadata",children:"Step Metadata"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'pipeline_step:\n  id: "stepA"\n  user_id: "user-id"\n  app_id: "app-id"\n'})}),"\n",(0,a.jsxs)(n.p,{children:["This section defines how Clarifai identifies, scopes, and stores this pipeline step. These values are automatically filled with the information you provide when you ",(0,a.jsx)(n.a,{href:"#step-2-initialize-a-pipeline-project",children:"initialize"})," the pipeline project."]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," Clarifai Pipelines support cross-application orchestration for reusing logic. To integrate a shared step into your pipeline, simply configure it with the corresponding ",(0,a.jsx)(n.code,{children:"user_id"}),", ",(0,a.jsx)(n.code,{children:"app_id"}),", or step ",(0,a.jsx)(n.code,{children:"id"})," where the resource is hosted."]}),"\n"]}),"\n",(0,a.jsx)(n.h4,{id:"input-interface",children:"Input Interface"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'pipeline_step_input_params:\n  - name: input_text\n    description: "Text input for processing"\n'})}),"\n",(0,a.jsx)(n.p,{children:"This defines the data this step expects when it runs. The description helps document what this input is used for and how it should be provided by upstream steps or users."}),"\n",(0,a.jsx)(n.h4,{id:"runtime-environment",children:"Runtime Environment"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'build_info:\n  python_version: "3.12"\n'})}),"\n",(0,a.jsxs)(n.p,{children:["This specifies the environment used to run the step, ensuring ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/resources/api-overview/python-sdk#python-requirements",children:"compatibility"})," with your code and dependencies."]}),"\n",(0,a.jsx)(n.h4,{id:"compute-resources-allocation",children:"Compute Resources Allocation"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'pipeline_step_compute_info:\n  cpu_limit: "500m"\n  cpu_memory: "500Mi"\n  num_accelerators: 0\n'})}),"\n",(0,a.jsx)(n.p,{children:"This section controls the resources allocated to the step during execution. It is the most critical part for performance and cost."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:'cpu_limit: "500m"'})," allocates half of one CPU core's processing power (500 millicores = 0.5 CPU cores). This indicates the step is a lightweight task (like text parsing), not a heavy calculation."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:'cpu_memory: "500Mi"'})," limits memory usage to 500 Mebibytes of RAM."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"num_accelerators: 0"})," means no GPU or other ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/deployments/cloud-instances",children:"accelerators"})," are used. This keeps costs low, as you are running on standard CPU infrastructure."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"steprequirementstxt",children:(0,a.jsx)(n.code,{children:"step/requirements.txt"})}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Example: step/requirements.txt"}),(0,a.jsx)(s.A,{className:"language-text",children:u})]}),"\n",(0,a.jsxs)(n.p,{children:["Each pipeline step has its own ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/compute/upload/#prepare-requirementstxt",children:(0,a.jsx)(n.code,{children:"requirements.txt"})})," file, which specifies the Python packages required for that specific step to run."]}),"\n",(0,a.jsx)(n.p,{children:"These dependencies are installed in an isolated, containerized environment, meaning one step can use a different set of libraries or versions without affecting other steps in the pipeline."}),"\n",(0,a.jsx)(n.h3,{id:"1pipeline_steppy",children:(0,a.jsx)(n.code,{children:"1/pipeline_step.py"})}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Example: 1/pipeline_step.py"}),(0,a.jsx)(s.A,{className:"language-text",children:h})]}),"\n",(0,a.jsxs)(n.p,{children:["Each pipeline step has its own ",(0,a.jsx)(n.code,{children:"pipeline_step.py"})," file, which contains the core implementation for that specific step. This is where you define all the logic the step executes \u2014 including data processing, API interactions, model inference, and output transformations."]}),"\n",(0,a.jsx)(n.p,{children:"When the pipeline runs, Clarifai spins up this step\u2019s container and executes this script."}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," The ",(0,a.jsx)(n.code,{children:"pipeline_step.py"})," file is nested inside the ",(0,a.jsx)(n.code,{children:"step/1/"})," directory. The folder is named as ",(0,a.jsx)(n.strong,{children:"1"})," to fit Clarifai\u2019s naming convention."]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["Let\u2019s break down the example of a ",(0,a.jsx)(n.code,{children:"pipeline_step.py"})," file section by section."]}),"\n",(0,a.jsx)(n.h4,{id:"command-line-input-handling",children:"Command-line Input Handling"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"parser = argparse.ArgumentParser(description='stepA processing step.')\nparser.add_argument('--input_text', type=str, required=True, help='Text input for processing')\nargs = parser.parse_args()\n"})}),"\n",(0,a.jsxs)(n.p,{children:["This section receives its inputs as command-line arguments when Clarifai runs it. The ",(0,a.jsx)(n.code,{children:"--input_text"})," corresponds to the ",(0,a.jsx)(n.code,{children:"pipeline_step_input_params"})," you defined in the step\u2019s ",(0,a.jsx)(n.a,{href:"#stepconfigyaml",children:(0,a.jsx)(n.code,{children:"config.yaml"})}),"."]}),"\n",(0,a.jsx)(n.p,{children:"Clarifai automatically maps pipeline parameters to these arguments when the step is executed."}),"\n",(0,a.jsx)(n.h4,{id:"logging-the-clarifai-sdk-version",children:"Logging the Clarifai SDK Version"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"logger.info(clarifai.__version__)\n"})}),"\n",(0,a.jsx)(n.p,{children:"This section logs the version of the Clarifai Python SDK installed inside the step\u2019s container. It\u2019s useful for debugging and verifying that the correct environment is being used."}),"\n",(0,a.jsx)(n.h4,{id:"step-logic-placeholder",children:"Step Logic Placeholder"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# TODO: Implement your pipeline step logic here\nlogger.info(f"stepA processed: {args.input_text}")\n'})}),"\n",(0,a.jsx)(n.p,{children:"This section is where your step\u2019s core logic lives. In this example, it simply logs the input it receives, but in a real pipeline, this is where you would implement the actual work of the step, such as preprocessing input data or calling LLM models."}),"\n",(0,a.jsx)(n.h2,{id:"step-4-upload-the-pipeline",children:"Step 4: Upload the Pipeline"}),"\n",(0,a.jsx)(n.p,{children:"Run the following command in your current directory to upload the pipeline with associated pipeline steps to Clarifai."}),"\n",(0,a.jsx)(r.A,{groupId:"code",children:(0,a.jsx)(o.A,{value:"bash",label:"CLI",children:(0,a.jsx)(s.A,{className:"language-bash",children:"clarifai pipeline upload"})})}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," You can specify a path to the pipeline configuration file or directory containing the root ",(0,a.jsx)(n.code,{children:"config.yaml"})," file. If not specified, the current directory is used by default."]}),"\n"]}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Example Output"}),(0,a.jsx)(s.A,{className:"language-text",children:m})]}),"\n",(0,a.jsxs)(n.p,{children:["When you run the ",(0,a.jsx)(n.code,{children:"upload"})," command, the CLI reads your pipeline configuration, uploads each step, and automatically builds a container image for every step using its code, configs, and dependencies."]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Dockerfile"})," \u2014 For each step, it auto-generates a ",(0,a.jsx)(n.code,{children:"Dockerfile"})," behind the scenes, which defines how the container image for the step is built (base image, Python version, dependency installation, and entrypoint setup). You can also create your own customized Dockerfile."]}),"\n"]}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Example: Dockerfile"}),(0,a.jsx)(s.A,{className:"language-text",children:x})]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Lock file"})," \u2014 If the CLI detects that no lock file is existing, it auto-creates a new ",(0,a.jsx)(n.code,{children:"config-lock.yaml"})," to \u201cfreeze\u201d the exact step configuration and build details for that version.\nThis lock file captures the resolved configuration, including the Python runtime (",(0,a.jsx)(n.code,{children:"3.12"}),"), compute resources, input parameters, and a unique version ID. The ",(0,a.jsx)(n.code,{children:"step/config.yaml"})," file also stores an MD5 hash of the step contents, which is used to track changes and ensure reproducible builds."]}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Tip:"})," Use the ",(0,a.jsx)(n.code,{children:"--no-lockfile"})," flag to disable generation of ",(0,a.jsx)(n.code,{children:"config-lock.yaml"}),". Example: ",(0,a.jsx)(n.code,{children:"clarifai pipeline upload --no-lockfile"}),"."]}),"\n"]}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Example: config-lock.yaml (root)"}),(0,a.jsx)(s.A,{className:"language-text",children:y})]}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Example: step/config-lock.yaml"}),(0,a.jsx)(s.A,{className:"language-text",children:g})]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Container image"})," \u2014 Using the generated Dockerfile and the locked configuration, Clarifai then builds a multi-architecture container image on its infrastructure. This image becomes a versioned, immutable artifact that\u2019s tightly coupled with the ",(0,a.jsx)(n.code,{children:"config-lock.yaml"}),", ensuring every future pipeline execution runs with the exact same code, environment, and resource settings."]}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," If you modify your pipeline and upload it again to the Clarifai platform, a new version is automatically created. Only the updated sections are uploaded, ensuring efficient version management."]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"step-5-run-the-pipeline",children:"Step 5: Run the Pipeline"}),"\n",(0,a.jsx)(n.p,{children:"After successfully uploading your pipeline, you can execute it using the Clarifai CLI."}),"\n",(0,a.jsx)(n.p,{children:"Run the following command from your current project directory to start the pipeline and monitor its progress until completion or timeout."}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," You must specify both a compute ",(0,a.jsx)(n.a,{href:"#create-a-cluster-and-nodepool",children:"cluster ID and a nodepool ID"}),"."]}),"\n"]}),"\n",(0,a.jsx)(r.A,{groupId:"code",children:(0,a.jsx)(o.A,{value:"bash",label:"CLI",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"clarifai pipeline run --compute_cluster_id cluster_id_here --nodepool_id nodepool_id_here\n"})})})}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," The ",(0,a.jsx)(n.code,{children:"clarifai pipeline run"})," command requires the user ID, app ID, pipeline version ID, and pipeline version run ID, which it reads directly from ",(0,a.jsx)(n.code,{children:"config-lock.yaml"}),"."]}),"\n"]}),"\n",(0,a.jsxs)(i,{children:[(0,a.jsx)("summary",{children:"Example Output"}),(0,a.jsx)(s.A,{className:"language-text",children:f})]}),"\n",(0,a.jsx)(n.h3,{id:"run-command-options",children:"Run Command Options"}),"\n",(0,a.jsxs)(n.p,{children:["The table below summarizes the available options you can use with the ",(0,a.jsx)(n.code,{children:"clarifai pipeline run"})," command."]}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Option"}),(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Type"}),(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Description"}),(0,a.jsx)(n.th,{style:{textAlign:"left"},children:"Defaults / Notes"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.strong,{children:"Targeting & Identity"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"}}),(0,a.jsx)(n.td,{style:{textAlign:"left"}}),(0,a.jsx)(n.td,{style:{textAlign:"left"}})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--pipeline_id"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"TEXT"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"ID of the pipeline to execute"}),(0,a.jsx)(n.td,{style:{textAlign:"left"}})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--user_id"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"TEXT"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"User ID owning the pipeline"}),(0,a.jsx)(n.td,{style:{textAlign:"left"}})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--app_id"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"TEXT"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"App ID containing the pipeline"}),(0,a.jsx)(n.td,{style:{textAlign:"left"}})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--pipeline_version_id"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"TEXT"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Specific version of the pipeline to run"}),(0,a.jsx)(n.td,{style:{textAlign:"left"}})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--pipeline_url"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"TEXT"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Full URL to the pipeline resource"}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Alternative to providing IDs separately"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.strong,{children:"Execution Control"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"}}),(0,a.jsx)(n.td,{style:{textAlign:"left"}}),(0,a.jsx)(n.td,{style:{textAlign:"left"}})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--config"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"PATH"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Path to a local configuration file for the run"}),(0,a.jsx)(n.td,{style:{textAlign:"left"}})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--pipeline_version_run_id"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"TEXT"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Custom ID for this specific execution run"}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"A UUID is generated automatically if omitted"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--nodepool_id"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"TEXT"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Specific Nodepool to execute on"}),(0,a.jsx)(n.td,{style:{textAlign:"left"}})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--compute_cluster_id"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"TEXT"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Specific Compute Cluster to execute on"}),(0,a.jsx)(n.td,{style:{textAlign:"left"}})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.strong,{children:"Inputs & Parameters"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"}}),(0,a.jsx)(n.td,{style:{textAlign:"left"}}),(0,a.jsx)(n.td,{style:{textAlign:"left"}})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--set"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"TEXT"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Override parameter values inline"}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Format: ",(0,a.jsx)(n.code,{children:"key=value"}),". Can be used multiple times. Example ",(0,a.jsx)(n.code,{children:'--set prompt="hello"'}),", ",(0,a.jsx)(n.code,{children:'--set temperature="0.7"'})]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--overrides-file"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"PATH"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Path to JSON/YAML file for bulk parameter overrides"}),(0,a.jsx)(n.td,{style:{textAlign:"left"}})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.strong,{children:"Monitoring & Logging"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"}}),(0,a.jsx)(n.td,{style:{textAlign:"left"}}),(0,a.jsx)(n.td,{style:{textAlign:"left"}})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--monitor"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"FLAG"})}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Watch an ",(0,a.jsx)(n.em,{children:"existing"})," run instead of starting a new one"]}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:[(0,a.jsx)(n.strong,{children:"Requires"})," ",(0,a.jsx)(n.code,{children:"--pipeline_version_run_id"})]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--monitor_interval"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"INTEGER"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Frequency of status checks"}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Default: ",(0,a.jsx)(n.strong,{children:"10 seconds"}),"."]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--timeout"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"INTEGER"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"Max time to wait for completion"}),(0,a.jsxs)(n.td,{style:{textAlign:"left"},children:["Default: ",(0,a.jsx)(n.strong,{children:"3600 seconds"})," (1 hour)"]})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"--log_file"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:(0,a.jsx)(n.code,{children:"PATH"})}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"File path to save execution logs"}),(0,a.jsx)(n.td,{style:{textAlign:"left"},children:"If omitted, logs output to console"})]})]})]}),"\n",(0,a.jsx)(n.p,{children:"That's it!"})]})}function I(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(k,{...e})}):k(e)}}}]);