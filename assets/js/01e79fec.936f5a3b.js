"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[5359],{40491:(a,e,t)=>{t.r(e),t.d(e,{assets:()=>P,contentTitle:()=>T,default:()=>S,frontMatter:()=>U,metadata:()=>n,toc:()=>k});const n=JSON.parse('{"id":"create-manage/datasets/upload","title":"Upload Data to Dataset via API","description":"Learn how to upload data to a dataset","source":"@site/docs/create-manage/datasets/upload.md","sourceDirName":"create-manage/datasets","slug":"/create-manage/datasets/upload","permalink":"/create-manage/datasets/upload","draft":false,"unlisted":false,"editUrl":"https://github.com/Clarifai/docs/blob/main/docs/create-manage/datasets/upload.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"description":"Learn how to upload data to a dataset","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Datasets Creation","permalink":"/create-manage/datasets/create"},"next":{"title":"Datasets Management","permalink":"/create-manage/datasets/manage"}}');var o=t(74848),i=t(28453),s=t(65537),r=t(79329),l=t(58069);const d='from clarifai.client.dataset import Dataset\n\n\n# Create a dataset object\ndataset = Dataset(user_id="user_id", app_id="test_app", dataset_id="first_dataset",pat=\u201dYOUR_PAT\u201d)\n#To upload without concepts(labels=False)\n#upload data from folder\ndataset.upload_from_folder(folder_path=\'./images\', input_type=\'image\', labels=True)',p='import { Dataset } from "clarifai-nodejs";\nimport path from "path";\n\n\nconst dataset = new Dataset({\n  datasetId: "first_dataset",\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n    userId: process.env.CLARIFAI_USER_ID,\n    appId: "test_app",\n  },\n});\n\nawait dataset.uploadFromFolder({\n  folderPath: path.resolve(__dirname, "../../assets/voc/images"),\n  inputType: "image",\n  labels: true,\n});\n',u='from clarifai.client.dataset import Dataset\n\n# Create the dataset object\ndataset = Dataset(user_id="user_id", app_id="test_app", dataset_id="first_dataset",pat=\u201dYOUR_PAT\u201d)\n#To upload without concepts(labels=False)\n# upload dataset from folder\ndataset.upload_from_folder(folder_path=\'./data\', input_type=\'text\', labels=True)',c='import { Dataset } from "clarifai-nodejs";\nimport path from "path";\n\n\nconst dataset = new Dataset({\n  datasetId: "first_dataset",\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n    userId: process.env.CLARIFAI_USER_ID,\n    appId: "test_app",\n  },\n});\n\nawait dataset.uploadFromFolder({\n  folderPath: path.resolve(__dirname, "../../assets"),\n  inputType: "text",\n  labels: true,\n});\n',h="from clarifai.client.dataset import Dataset\n\n\n#Create a dataset object\ndataset = Dataset(user_id=\"user_id\", app_id=\"test_app\", dataset_id=\"first_dataset\",pat=\u201dYOUR_PAT\u201d)\n#To upload without concepts(labels=False)\n#Upload data from csv\ndataset.upload_from_csv(csv_path='/Users/adithyansukumar/Desktop/data/test.csv', input_type='audio',csv_type='url', labels=True)",m='import { Dataset } from "clarifai-nodejs";\nimport path from "path";\n\n\nconst dataset = new Dataset({\n  datasetId: "first_dataset",\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n    userId: process.env.CLARIFAI_USER_ID,\n    appId: "test_app",\n  },\n});\n\nawait dataset.uploadFromCSV({\n  csvPath: path.resolve(__dirname, "../../assets/audio.csv"),\n  csvType: "file",\n  labels: true,\n  inputType: "audio",\n});\n',f='import { Dataset } from "clarifai-nodejs";\nimport path from "path";\n\n\nconst dataset = new Dataset({\n  datasetId: "first_dataset",\n  authConfig: {\n    pat: process.env.CLARIFAI_PAT,\n    userId: process.env.CLARIFAI_USER_ID,\n    appId: "test_app",\n  },\n});\n\nawait dataset.uploadFromCSV({\n  csvPath: path.resolve(__dirname, "../../assets/video.csv"),\n  csvType: "file",\n  inputType: "video",\n  labels: true,\n});\n',_='from clarifai.client.input import Inputs\n\n\nurl = "https://samples.clarifai.com/BarackObama.jpg"\n#replace your "user_id", "app_id", "dataset_id".\ninput_object = Inputs(user_id="user_id", app_id="test_app",pat=\u201dYOUR_PAT\u201d)\n\n# Upload image data from a specified URL with a unique input ID "bbox"\ninput_object.upload_from_url(input_id="bbox", image_url=url)\n\n# Define bounding box coordinates for the annotation (left, top, right, bottom)\nbbox_points = [.1, .1, .8, .9]\n\n# Generate a bounding box annotation proto with specified label ("face") and bounding box coordinates\nannotation = input_object.get_bbox_proto(input_id="bbox", label="face", bbox=bbox_points)\n\n# Upload the generated annotation to associate with the previously uploaded image\ninput_object.upload_annotations([annotation])\n',b='import { Input } from "clarifai-nodejs";\n\n\nconst imageUrl = "https://samples.clarifai.com/BarackObama.jpg";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nawait input.uploadFromUrl({\n  inputId: "bbox",\n  imageUrl,\n});\nconst bboxPoints = [0.1, 0.1, 0.8, 0.9];\nconst annotation = Input.getBboxProto({\n  inputId: "bbox",\n  label: "face",\n  bbox: bboxPoints,\n});\nawait input.uploadAnnotations({\n  batchAnnot: [annotation],\n});\n',g='from clarifai.client.input import Inputs\n\nurl = "https://samples.clarifai.com/beer.mp4"\n#replace your "user_id", "app_id", "dataset_id".\ninput_object = Inputs(user_id="user_id", app_id="test_app",pat=\u201dYOUR_PAT\u201d)\n\n# Upload an image from a URL with a specified input ID\ninput_object.upload_from_url(input_id="bbox", video_url=url)\n\n# Define bounding box coordinates for annotation\nbbox_points = [.1, .1, .8, .9]\n\n# Create an annotation using the bounding box coordinates\nannotation = input_object.get_bbox_proto(input_id="video_bbox", label="glass", bbox=bbox_points)\n\n# Upload the annotation associated with the image\ninput_object.upload_annotations([annotation])\n',x='import { Input } from "clarifai-nodejs";\n\n\nconst videoUrl = "https://samples.clarifai.com/beer.mp4";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nawait input.uploadFromUrl({\n  inputId: "video-bbox",\n  videoUrl,\n});\nconst bboxPoints = [0.1, 0.1, 0.8, 0.9];\nconst annotation = Input.getBboxProto({\n  inputId: "bbox",\n  label: "glass",\n  bbox: bboxPoints,\n});\nawait input.uploadAnnotations({\n  batchAnnot: [annotation],\n});\n',v='from clarifai.client.input import Inputs\n\nurl = "https://samples.clarifai.com/featured-models/Llama2_Conversational-agent.txt"\nconcepts = ["mobile","camera"]\n#replace your "user_id", "app_id", "dataset_id".\ninput_object = Inputs(user_id="user_id", app_id="test_app",pat=\u201dYOUR_PAT\u201d)\n#Upload data from url with annotation\ninput_object.upload_from_url(input_id="text1",text_url=url, labels=concepts)\n',j='import { Input } from "clarifai-nodejs";\n\n\nconst textUrl =\n  "https://samples.clarifai.com/featured-models/Llama2_Conversational-agent.txt";\nconst concepts = ["mobile", "camera"];\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nawait input.uploadFromUrl({\n  inputId: "text1",\n  textUrl,\n  labels: concepts,\n});\n',y='from clarifai.client.dataset import Dataset\nfrom clarifai.datasets.upload.utils import load_module_dataloader\n\n\n#replace your "user_id", "app_id", "dataset_id".\ndataset = Dataset(user_id="user_id", app_id="test_app", dataset_id="first_dataset")\n#create dataloader object\ncifar_dataloader = load_module_dataloader(\'./image_classification/cifar10\')\n#set get_upload_status=True for showing upload status\ndataset.upload_dataset(dataloader=cifar_dataloader,get_upload_status=True)\n',A='from clarifai.client.input import Inputs\n\n\nurl = "https://samples.clarifai.com/BarackObama.jpg"\n#replace your "user_id", "app_id", "dataset_id".\ninput_object = Inputs(user_id="USER_ID", app_id="APP_ID",pat="YOUR_PAT")\n\n# Upload image data from a specified URL with a unique input ID "mask"\ninput_object.upload_from_url(input_id="mask", image_url=url)\n\n# Define mask points\nmask = [[0.87, 0.66],[0.45 , 1.0], [0.82 ,0.42]]# polygon points\n\nannotation = input_object.get_mask_proto(input_id="mask", label="obama", polygons=mask)\n\n# Upload the generated annotation to associate with the previously uploaded image\ninput_object.upload_annotations([annotation])',I='import { Input, Polygon } from "clarifai-nodejs";\n\n\nconst imageUrl = "https://samples.clarifai.com/BarackObama.jpg";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: process.env.CLARIFAI_APP_ID,\n  },\n});\nawait input.uploadFromUrl({\n  inputId: "mask",\n  imageUrl,\n});\nconst maskPoints:Polygon[] = [[[0.87, 0.66],[0.45 , 1.0], [0.82 ,0.42]]];\nconst annotation = Input.getMaskProto({\n  inputId: "mask",\n  label: "obama",\n  polygons: maskPoints,\n});\nawait input.uploadAnnotations({\n  batchAnnot: [annotation],\n});',D='#importing load_module_dataloader for calling the dataloader object in dataset.py in the local data folder\nfrom clarifai.datasets.upload.utils import load_module_dataloader\nfrom clarifai.client.dataset import Dataset\n\n\n#replace your "user_id", "app_id", "dataset_id".\ndataset = Dataset(user_id="user_id", app_id="app_id", dataset_id="dataset_id")\n\ncifar_dataloader = load_module_dataloader(\'./image_classification/cifar10\')\n\ndataset.retry_upload_from_logs(dataloader=cifar_dataloader, log_file_path=\'path to log file\', retry_duplicates=True, log_warnings=True)',w='curl --location --request POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/datasets/YOUR_DATASET_ID_HERE/inputs" \\\n  --header "Authorization: Key YOUR_PAT_HERE" \\\n  --header "Content-Type: application/json" \\\n  --data-raw \'{\n    "dataset_inputs": [\n      {\n        "input": {\n          "id": "YOUR_INPUT_ID_HERE"\n        }\n      }\n    ]\n  }\'',U={description:"Learn how to upload data to a dataset",sidebar_position:2},T="Upload Data to Dataset via API",P={},k=[{value:"Add Inputs to a Dataset",id:"add-inputs-to-a-dataset",level:2},{value:"Upload Image Data",id:"upload-image-data",level:2},{value:"Upload Text Data",id:"upload-text-data",level:2},{value:"Upload Audio Data",id:"upload-audio-data",level:2},{value:"Upload Video Data",id:"upload-video-data",level:2},{value:"Upload Image Data With Annotations",id:"upload-image-data-with-annotations",level:2},{value:"Upload Image Data With Mask Annotations",id:"upload-image-data-with-mask-annotations",level:2},{value:"Upload Video Data With Annotations",id:"upload-video-data-with-annotations",level:2},{value:"Upload Text Data With Annotations",id:"upload-text-data-with-annotations",level:2},{value:"Batch Upload Image Data While Tracking Status",id:"batch-upload-image-data-while-tracking-status",level:2},{value:"Retry Upload From Log File",id:"retry-upload-from-log-file",level:2}];function R(a){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",strong:"strong",...(0,i.R)(),...a.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"upload-data-to-dataset-via-api",children:"Upload Data to Dataset via API"})}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Learn how to upload data to a dataset via the API"})}),"\n",(0,o.jsx)("hr",{}),"\n",(0,o.jsx)(e.p,{children:"Uploading data to a dataset in Clarifai is essential for training and evaluating your machine learning models."}),"\n",(0,o.jsx)(e.p,{children:"Whether you're working with images, videos, text, audio, or other data types, we provide flexible and efficient methods to upload data from various sources."}),"\n",(0,o.jsx)(e.admonition,{type:"info",children:(0,o.jsxs)(e.p,{children:["Before using the ",(0,o.jsx)(e.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/python-sdk",children:"Python SDK"}),", ",(0,o.jsx)(e.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/nodejs-sdk",children:"Node.js SDK"}),", or any of our ",(0,o.jsx)(e.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/grpc-clients",children:"gRPC clients"}),", ensure they are properly installed on your machine. Refer to their respective installation guides for instructions on how to install and initialize them."]})}),"\n",(0,o.jsx)(e.admonition,{type:"tip",children:(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.a,{href:"https://docs.clarifai.com/additional-resources/api-references/api-reference/#dataset",children:"Click here"})," to learn more about the different methods of uploading data to a dataset."]})}),"\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n",(0,o.jsxs)(e.admonition,{title:"Customize Batch Size",type:"note",children:[(0,o.jsxs)(e.p,{children:["When uploading inputs to the Clarifai platform, there are limits on the size and number of inputs per upload, as detailed ",(0,o.jsx)(e.a,{href:"https://docs.clarifai.com/create-manage/inputs/upload/#upload-limits",children:"here"}),". However, by using methods from the ",(0,o.jsx)(e.code,{children:"Dataset"})," class \u2014 such as ",(0,o.jsx)(e.code,{children:"Dataset.upload_from_folder()"}),", ",(0,o.jsx)(e.code,{children:"Dataset.upload_from_url()"}),", or ",(0,o.jsx)(e.code,{children:"Dataset.upload_dataset()"})," \u2014 you can bypass these restrictions and efficiently upload larger volumes of inputs."]}),(0,o.jsx)(e.p,{children:"For example, when uploading images in bulk, such methods incrementally process and upload them in multiple batches, ensuring that each batch contains a maximum of 128 images and does not exceed 128MB in size \u2013 which ensures adherence to the upload restrictions."}),(0,o.jsxs)(e.p,{children:["You can also customize the ",(0,o.jsx)(e.code,{children:"batch_size"})," variable, which allows for concurrent upload of inputs and annotations. For example, if your images folder exceeds 128MB, you can set the variable to ensure that each batch contains an appropriate number of images while staying within the 128MB per batch limit."]}),(0,o.jsxs)(e.p,{children:["The default ",(0,o.jsx)(e.code,{children:"batch_size"})," is set to 32, but you can customize it to any value between 1 (minimum) and 128 (maximum)."]}),(0,o.jsx)(e.p,{children:"Here is an example:"}),(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-text",children:"dataset.upload_from_folder(folder_path='./images', input_type='image', labels=True, batch_size=50)\n"})})]}),"\n",(0,o.jsx)(e.h2,{id:"add-inputs-to-a-dataset",children:"Add Inputs to a Dataset"}),"\n",(0,o.jsx)(e.p,{children:"You can add inputs to a dataset by specifying their input IDs."}),"\n",(0,o.jsx)(s.A,{children:(0,o.jsx)(r.A,{value:"curl",label:"cURL",children:(0,o.jsx)(l.A,{className:"language-bash",children:w})})}),"\n",(0,o.jsx)(e.h2,{id:"upload-image-data",children:"Upload Image Data"}),"\n",(0,o.jsxs)(e.p,{children:["You can upload image data in bulk either from a folder or by using a ",(0,o.jsx)(e.a,{href:"https://docs.clarifai.com/additional-resources/api-references/api-reference/#datasetupload_from_csv",children:"CSV file"}),"."]}),"\n",(0,o.jsxs)(s.A,{children:[(0,o.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,o.jsx)(l.A,{className:"language-python",children:d})}),(0,o.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,o.jsx)(l.A,{className:"language-typescript",children:p})})]}),"\n",(0,o.jsx)(e.h2,{id:"upload-text-data",children:"Upload Text Data"}),"\n",(0,o.jsx)(e.p,{children:"You can upload text data in bulk either from a folder or by using a CSV file."}),"\n",(0,o.jsxs)(s.A,{children:[(0,o.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,o.jsx)(l.A,{className:"language-python",children:u})}),(0,o.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,o.jsx)(l.A,{className:"language-typescript",children:c})})]}),"\n",(0,o.jsx)(e.h2,{id:"upload-audio-data",children:"Upload Audio Data"}),"\n",(0,o.jsx)(e.p,{children:"You can upload audio data in bulk either from a folder or by using a CSV file."}),"\n",(0,o.jsxs)(s.A,{children:[(0,o.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,o.jsx)(l.A,{className:"language-python",children:h})}),(0,o.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,o.jsx)(l.A,{className:"language-typescript",children:m})})]}),"\n",(0,o.jsx)(e.h2,{id:"upload-video-data",children:"Upload Video Data"}),"\n",(0,o.jsx)(e.p,{children:"You can upload video data in bulk either from a folder or by using a CSV file."}),"\n",(0,o.jsxs)(s.A,{children:[(0,o.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,o.jsx)(l.A,{className:"language-python",children:h})}),(0,o.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,o.jsx)(l.A,{className:"language-typescript",children:f})})]}),"\n",(0,o.jsx)(e.h2,{id:"upload-image-data-with-annotations",children:"Upload Image Data With Annotations"}),"\n",(0,o.jsx)(e.p,{children:"You can upload image data along with bounding box annotations, allowing you to add depth and contextual information to your visual data."}),"\n",(0,o.jsxs)(s.A,{children:[(0,o.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,o.jsx)(l.A,{className:"language-python",children:_})}),(0,o.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,o.jsx)(l.A,{className:"language-typescript",children:b})})]}),"\n",(0,o.jsx)(e.h2,{id:"upload-image-data-with-mask-annotations",children:"Upload Image Data With Mask Annotations"}),"\n",(0,o.jsx)(e.p,{children:"You can add masks to image data by providing polygon coordinates along with the image, enabling precise region-based annotations."}),"\n",(0,o.jsxs)(s.A,{children:[(0,o.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,o.jsx)(l.A,{className:"language-python",children:A})}),(0,o.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,o.jsx)(l.A,{className:"language-typescript",children:I})})]}),"\n",(0,o.jsx)(e.h2,{id:"upload-video-data-with-annotations",children:"Upload Video Data With Annotations"}),"\n",(0,o.jsx)(e.p,{children:"You can upload videos with enriched annotations by including bounding box coordinates that define regions of interest within individual frames, adding valuable context to your video content."}),"\n",(0,o.jsxs)(s.A,{children:[(0,o.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,o.jsx)(l.A,{className:"language-python",children:g})}),(0,o.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,o.jsx)(l.A,{className:"language-typescript",children:x})})]}),"\n",(0,o.jsx)(e.h2,{id:"upload-text-data-with-annotations",children:"Upload Text Data With Annotations"}),"\n",(0,o.jsx)(e.p,{children:"You can enrich your uploaded text data by attaching metadata, categorizing the content, or adding detailed annotations to enhance structure and context."}),"\n",(0,o.jsxs)(s.A,{children:[(0,o.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,o.jsx)(l.A,{className:"language-python",children:v})}),(0,o.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,o.jsx)(l.A,{className:"language-typescript",children:j})})]}),"\n",(0,o.jsx)(e.h2,{id:"batch-upload-image-data-while-tracking-status",children:"Batch Upload Image Data While Tracking Status"}),"\n",(0,o.jsx)(e.p,{children:"You can actively monitor the status of your dataset upload, giving you clear visibility into the progress and making it easy to track and analyze the data transfer process."}),"\n",(0,o.jsx)(s.A,{children:(0,o.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,o.jsx)(l.A,{className:"language-python",children:y})})}),"\n",(0,o.jsx)(e.h2,{id:"retry-upload-from-log-file",children:"Retry Upload From Log File"}),"\n",(0,o.jsxs)(e.p,{children:["You can retry uploads for failed inputs directly from the logs. When using the ",(0,o.jsx)(e.code,{children:"upload_dataset"})," function, any failed inputs are automatically logged to a file, which can later be used to resume and retry the upload process seamlessly."]}),"\n",(0,o.jsx)(e.admonition,{type:"info",children:(0,o.jsxs)(e.p,{children:["Set ",(0,o.jsx)(e.code,{children:"retry_duplicates"})," to ",(0,o.jsx)(e.code,{children:"True"})," if you want to retry duplicate with new Input_id in current dataset."]})}),"\n",(0,o.jsx)(s.A,{children:(0,o.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,o.jsx)(l.A,{className:"language-python",children:D})})})]})}function S(a={}){const{wrapper:e}={...(0,i.R)(),...a.components};return e?(0,o.jsx)(e,{...a,children:(0,o.jsx)(R,{...a})}):R(a)}},65537:(a,e,t)=>{t.d(e,{A:()=>y});var n=t(96540),o=t(18215),i=t(65627),s=t(56347),r=t(50372),l=t(30604),d=t(11861),p=t(78749);function u(a){return n.Children.toArray(a).filter((a=>"\n"!==a)).map((a=>{if(!a||(0,n.isValidElement)(a)&&function(a){const{props:e}=a;return!!e&&"object"==typeof e&&"value"in e}(a))return a;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof a.type?a.type:a.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function c(a){const{values:e,children:t}=a;return(0,n.useMemo)((()=>{const a=e??function(a){return u(a).map((a=>{let{props:{value:e,label:t,attributes:n,default:o}}=a;return{value:e,label:t,attributes:n,default:o}}))}(t);return function(a){const e=(0,d.XI)(a,((a,e)=>a.value===e.value));if(e.length>0)throw new Error(`Docusaurus error: Duplicate values "${e.map((a=>a.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(a),a}),[e,t])}function h(a){let{value:e,tabValues:t}=a;return t.some((a=>a.value===e))}function m(a){let{queryString:e=!1,groupId:t}=a;const o=(0,s.W6)(),i=function(a){let{queryString:e=!1,groupId:t}=a;if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,l.aZ)(i),(0,n.useCallback)((a=>{if(!i)return;const e=new URLSearchParams(o.location.search);e.set(i,a),o.replace({...o.location,search:e.toString()})}),[i,o])]}function f(a){const{defaultValue:e,queryString:t=!1,groupId:o}=a,i=c(a),[s,l]=(0,n.useState)((()=>function(a){let{defaultValue:e,tabValues:t}=a;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!h({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map((a=>a.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=t.find((a=>a.default))??t[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:e,tabValues:i}))),[d,u]=m({queryString:t,groupId:o}),[f,_]=function(a){let{groupId:e}=a;const t=function(a){return a?`docusaurus.tab.${a}`:null}(e),[o,i]=(0,p.Dv)(t);return[o,(0,n.useCallback)((a=>{t&&i.set(a)}),[t,i])]}({groupId:o}),b=(()=>{const a=d??f;return h({value:a,tabValues:i})?a:null})();(0,r.A)((()=>{b&&l(b)}),[b]);return{selectedValue:s,selectValue:(0,n.useCallback)((a=>{if(!h({value:a,tabValues:i}))throw new Error(`Can't select invalid tab value=${a}`);l(a),u(a),_(a)}),[u,_,i]),tabValues:i}}var _=t(9136);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var g=t(74848);function x(a){let{className:e,block:t,selectedValue:n,selectValue:s,tabValues:r}=a;const l=[],{blockElementScrollPositionUntilNextRender:d}=(0,i.a_)(),p=a=>{const e=a.currentTarget,t=l.indexOf(e),o=r[t].value;o!==n&&(d(e),s(o))},u=a=>{let e=null;switch(a.key){case"Enter":p(a);break;case"ArrowRight":{const t=l.indexOf(a.currentTarget)+1;e=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(a.currentTarget)-1;e=l[t]??l[l.length-1];break}}e?.focus()};return(0,g.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":t},e),children:r.map((a=>{let{value:e,label:t,attributes:i}=a;return(0,g.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:a=>{l.push(a)},onKeyDown:u,onClick:p,...i,className:(0,o.A)("tabs__item",b.tabItem,i?.className,{"tabs__item--active":n===e}),children:t??e},e)}))})}function v(a){let{lazy:e,children:t,selectedValue:i}=a;const s=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const a=s.find((a=>a.props.value===i));return a?(0,n.cloneElement)(a,{className:(0,o.A)("margin-top--md",a.props.className)}):null}return(0,g.jsx)("div",{className:"margin-top--md",children:s.map(((a,e)=>(0,n.cloneElement)(a,{key:e,hidden:a.props.value!==i})))})}function j(a){const e=f(a);return(0,g.jsxs)("div",{className:(0,o.A)("tabs-container",b.tabList),children:[(0,g.jsx)(x,{...e,...a}),(0,g.jsx)(v,{...e,...a})]})}function y(a){const e=(0,_.A)();return(0,g.jsx)(j,{...a,children:u(a.children)},String(e))}},79329:(a,e,t)=>{t.d(e,{A:()=>s});t(96540);var n=t(18215);const o={tabItem:"tabItem_Ymn6"};var i=t(74848);function s(a){let{children:e,hidden:t,className:s}=a;return(0,i.jsx)("div",{role:"tabpanel",className:(0,n.A)(o.tabItem,s),hidden:t,children:e})}}}]);