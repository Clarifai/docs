"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[4409],{65537:(e,t,n)=>{n.d(t,{A:()=>_});var a=n(96540),r=n(18215),s=n(65627),i=n(56347),o=n(50372),l=n(30604),c=n(11861),d=n(78749);function u(e){return a.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function h(e){const{values:t,children:n}=e;return(0,a.useMemo)((()=>{const e=t??function(e){return u(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:r}}=e;return{value:t,label:n,attributes:a,default:r}}))}(n);return function(e){const t=(0,c.XI)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function p(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function m(e){let{queryString:t=!1,groupId:n}=e;const r=(0,i.W6)(),s=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,l.aZ)(s),(0,a.useCallback)((e=>{if(!s)return;const t=new URLSearchParams(r.location.search);t.set(s,e),r.replace({...r.location,search:t.toString()})}),[s,r])]}function g(e){const{defaultValue:t,queryString:n=!1,groupId:r}=e,s=h(e),[i,l]=(0,a.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!p({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:s}))),[c,u]=m({queryString:n,groupId:r}),[g,f]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[r,s]=(0,d.Dv)(n);return[r,(0,a.useCallback)((e=>{n&&s.set(e)}),[n,s])]}({groupId:r}),y=(()=>{const e=c??g;return p({value:e,tabValues:s})?e:null})();(0,o.A)((()=>{y&&l(y)}),[y]);return{selectedValue:i,selectValue:(0,a.useCallback)((e=>{if(!p({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),f(e)}),[u,f,s]),tabValues:s}}var f=n(9136);const y={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=n(74848);function w(e){let{className:t,block:n,selectedValue:a,selectValue:i,tabValues:o}=e;const l=[],{blockElementScrollPositionUntilNextRender:c}=(0,s.a_)(),d=e=>{const t=e.currentTarget,n=l.indexOf(t),r=o[n].value;r!==a&&(c(t),i(r))},u=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const n=l.indexOf(e.currentTarget)+1;t=l[n]??l[0];break}case"ArrowLeft":{const n=l.indexOf(e.currentTarget)-1;t=l[n]??l[l.length-1];break}}t?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},t),children:o.map((e=>{let{value:t,label:n,attributes:s}=e;return(0,x.jsx)("li",{role:"tab",tabIndex:a===t?0:-1,"aria-selected":a===t,ref:e=>{l.push(e)},onKeyDown:u,onClick:d,...s,className:(0,r.A)("tabs__item",y.tabItem,s?.className,{"tabs__item--active":a===t}),children:n??t},t)}))})}function v(e){let{lazy:t,children:n,selectedValue:s}=e;const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=i.find((e=>e.props.value===s));return e?(0,a.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:i.map(((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==s})))})}function b(e){const t=g(e);return(0,x.jsxs)("div",{className:(0,r.A)("tabs-container",y.tabList),children:[(0,x.jsx)(w,{...t,...e}),(0,x.jsx)(v,{...t,...e})]})}function _(e){const t=(0,f.A)();return(0,x.jsx)(b,{...e,children:u(e.children)},String(t))}},79329:(e,t,n)=>{n.d(t,{A:()=>i});n(96540);var a=n(18215);const r={tabItem:"tabItem_Ymn6"};var s=n(74848);function i(e){let{children:t,hidden:n,className:i}=e;return(0,s.jsx)("div",{role:"tabpanel",className:(0,a.A)(r.tabItem,i),hidden:n,children:t})}},94714:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>u,contentTitle:()=>d,default:()=>m,frontMatter:()=>c,metadata:()=>a,toc:()=>h});const a=JSON.parse('{"id":"integrations/DSPy/multistage-dspy","title":"Multistage RAG Pipeline With DSPy","description":"A tutorial by Mogith PN","source":"@site/docs/integrations/DSPy/multistage-dspy.md","sourceDirName":"integrations/DSPy","slug":"/integrations/DSPy/multistage-dspy","permalink":"/integrations/DSPy/multistage-dspy","draft":false,"unlisted":false,"editUrl":"https://github.com/Clarifai/docs/blob/main/docs/integrations/DSPy/multistage-dspy.md","tags":[],"version":"current","sidebarPosition":3.1,"frontMatter":{"sidebar_position":3.1,"pagination_next":null},"sidebar":"tutorialSidebar","previous":{"title":"Building RAG with DSPy","permalink":"/integrations/DSPy/rag-dspy"}}');var r=n(74848),s=n(28453),i=(n(65537),n(79329),n(58069));const o='Keywords extracted : 1. "Misuse of large language models"\n2. "Quality control in LLM outputs"\n3. "Ethical implications of LLMs"\nRating score for context 1: score=1.0\nRating score for context 2: score=2.0\nRating score for context 3: score=2.0\nRating score for context 4: score=2.0\nRating score for context 5: score=2.0\nRating score for context 6: score=1.0\nRating score for context 7: score=1.0\nRating score for context 8: score=1.0\nRating score for context 9: score=1.0\nRating score for context 10: score=1.0\nQuestion: What are the potential risks associated with large language models (LLMs) according to the context information?\nPredicted Answer: The potential risks associated with large language models (LLMs) according to the context information include data leakage, performance inconsistency in tasks involving long textual contexts, and complexity in managing and utilizing extensive APIs.',l="According to the context information provided, the potential risks associated with large language models (LLMs) are not explicitly stated. However, it is mentioned that there are risks associated with LLMs, and these risks are considered particularly important given their widespread use. Additionally, the context information highlights the importance of detecting, measuring, and mitigating biases in LLMs to prevent associated harms. It also mentions that a better understanding of bias metrics can help researchers better adapt and deploy LLMs. For more specific risks, one might need to refer to the cited source (Bender et al., 2021).",c={sidebar_position:3.1,pagination_next:null},d="Multistage RAG Pipeline With DSPy",u={},h=[{value:"What is RAG?",id:"what-is-rag",level:2},{value:"Why do we need a Re-ranker node?",id:"why-do-we-need-a-re-ranker-node",level:2},{value:"DSPY Typed Predictors",id:"dspy-typed-predictors",level:3}];function p(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components},{Details:n}=t;return n||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"multistage-rag-pipeline-with-dspy",children:"Multistage RAG Pipeline With DSPy"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"A tutorial by Mogith PN"})}),"\n",(0,r.jsx)("hr",{}),"\n",(0,r.jsx)(t.p,{children:"Information retrieval techniques are growing at such a high pace that the quest for ever-more efficient and accurate systems continues. One such advanced methodology is called RAG. But what if we could push the boundaries of RAG even further? Today, we'll explore the exciting potential of multi-stage, multi-model RAG systems built with DSPy."}),"\n",(0,r.jsx)(t.h2,{id:"what-is-rag",children:"What is RAG?"}),"\n",(0,r.jsx)(t.p,{children:"Imagine a system that can sift through mountains of information, identify the most relevant bits, and then craft a clear and concise response to your query. That's the essence of RAG. It operates in three key stages:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["Retrieval: A ",(0,r.jsx)(t.code,{children:"retriever"})," module dives into a vast corpus of documents, seeking information related to the user's query."]}),"\n",(0,r.jsxs)(t.li,{children:["Augmentation: The retrieved information changes at the ",(0,r.jsx)(t.code,{children:"augmenter"})," stage. This might involve filtering, summarising, or enriching the data with additional context."]}),"\n",(0,r.jsxs)(t.li,{children:["Generation: Finally, the ",(0,r.jsx)(t.code,{children:"generator"})," creates a high-quality response that effectively addresses the user's query."]}),"\n"]}),"\n",(0,r.jsxs)(t.p,{children:["Visit ",(0,r.jsx)(t.a,{href:"https://docs.clarifai.com/sdk/rag",children:"this"})," page to learn more about RAG."]}),"\n",(0,r.jsx)(t.p,{children:"But how will DSPy help RAG? Well, DSPy supercharges the process inside RAG. Traditional large language model applications often suffer from \"fragility,\" requiring constant tweaking and adjustments when components change. DSPy framework optimizes the entire pipeline for your specific task, eliminating the need for repetitive manual fine-tuning whenever you modify a component. By integrating Clarifai with DSPy, you unlock access to Clarifai's powerful capabilities, including its ability to seamlessly call language models (LLMs) directly from the Clarifai platform. This integration empowers you to leverage Clarifai's application as a retriever specifically suited for vector search use cases."}),"\n",(0,r.jsx)(t.p,{children:"Before we move on, install and setup some packages,"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{children:"!pip install dspy-ai\n!pip install clarifai\n"})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"import os\n#Replace your PAT\nos.environ['CLARIFAI_PAT'] =\"YOUR_PAT\"\n"})}),"\n",(0,r.jsx)("center",{children:(0,r.jsx)("img",{src:"/img/python-sdk/multistage-rag.png"})}),"\n",(0,r.jsx)(t.p,{children:"Now let's explore a possible implementation of a multi-stage, multi-model RAG system using DSPy.  The motive of this experiment is to test the functionality of DSPy in building multi-stage systems in our RAG pipelines. Also, the compatibility to call and use multi models at different stages of the pipeline."}),"\n",(0,r.jsxs)(t.p,{children:["You can choose any LLM\u2019s from ",(0,r.jsx)(t.a,{href:"https://clarifai.com/explore/models?searchQuery=llm&page=1&perPage=24",children:"this"})," page."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import dspy\nfrom dspy.retrieve.clarifai_rm import ClarifaiRM\n\nMODEL_URL1 = "https://clarifai.com/mistralai/completion/models/mistral-7B-Instruct"\nMODEL_URL2 = "https://clarifai.com/meta/Llama-2/models/llama2-7b-chat"\nPAT = "**********"\nUSER_ID = "USER_ID"\nAPP_ID = "APP_ID"\n\nmistral_llm=dspy.Clarifai(model=MODEL_URL1, api_key=PAT, n=1, inference_params={\'temperature\':0.6})\nretriever_clarifai=ClarifaiRM(clarifai_user_id=USER_ID, clarfiai_app_id=APP_ID, clarifai_pat=PAT, k=5)\n'})}),"\n",(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.code,{children:"GenerateAnswer"})," class acts as a module within the DSPy pipeline. It takes the user's question and a relevant summary passage as inputs and then utilizes these to generate a concise answer."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'class GenerateAnswer(dspy.Signature):\n    """Think and Answer the questions based on the context provided."""\n\n context = dspy.InputField(desc="may contain relevant summary passage about user query")\n question = dspy.InputField(desc="User query")\n answer = dspy.OutputField(desc="Generate a brief answer")\n'})}),"\n",(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.code,{children:"GenerateKeywords"})," class acts as a module within the DSPy pipeline. It takes the user's query as input and then generates a set of keywords that are closely related to the user's original query."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'class GenerateKeywords(dspy.Signature):\n  """Generate Key words for search, which will be related to user\'s query"""\n query = dspy.InputField(desc="User query")\n answer = dspy.OutputField(desc="3 Search Key words related to user query")\n'})}),"\n",(0,r.jsx)(t.h2,{id:"why-do-we-need-a-re-ranker-node",children:"Why do we need a Re-ranker node?"}),"\n",(0,r.jsx)(t.p,{children:"We are retrieving contexts in 2 ways for our pipeline, starting with query search and keyword search, so our retrieved contexts will be quite huge for the model to handle."}),"\n",(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.code,{children:"Reranker"})," class acts as a quality control step within the DSPy pipeline. It takes a single retrieved document and the user's question as input. It then analyzes the document to assess how well it aligns with the user's query and provides a factual answer. The assigned rating (between 1 and 5) serves as an indicator of the document's relevance, potentially influencing how the retrieved information is used in subsequent stages of the pipeline."]}),"\n",(0,r.jsx)(t.h3,{id:"dspy-typed-predictors",children:"DSPY Typed Predictors"}),"\n",(0,r.jsx)(t.p,{children:"In DSPy, typed predictors are a mechanism to enforce type constraints on the inputs and outputs of modules within a pipeline."}),"\n",(0,r.jsxs)(t.p,{children:["Click ",(0,r.jsx)(t.a,{href:"https://dspy-docs.vercel.app/docs/building-blocks/typed_predictors",children:"here"})," to learn more about typed predictors."]}),"\n",(0,r.jsxs)(t.p,{children:["First, let's define the output for the re-ranker model to be float using ",(0,r.jsx)(t.code,{children:"dspy typed predictors"}),". And then we will create the ",(0,r.jsx)(t.code,{children:"Reranker"})," class."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from pydantic import BaseModel, Field\n\nclass Reranker_Output(BaseModel):\n score: float = Field(desc="A rating between 1 to 10 based on relevance and semantic match, IMPORTANT !  `float` . Nothing else return only float value as output.")\n'})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'class Reranker(dspy.Signature):\n  """Evaluate and rate the retrieved contexts based on their relevance in providing factual answers to user questions."""\n\n context = dspy.InputField(desc="The context retrieved for answering question")\n question = dspy.InputField(desc="User query")\n rating = dspy.OutputField(desc="A rating between 1 to 5, IMPORTANT !  `float` . Nothing else return only float value as output.")\n'})}),"\n",(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.code,{children:"Multi_RAG"})," module constructs a multi-stage information retrieval system using DSPy. It extracts keywords to broaden the search, retrieves information using both the query and keywords, and then employs a separate language model to evaluate and rank the retrieved passages based on their relevance to the user's question. This multi-stage approach with distinct components allows for a more comprehensive and potentially more accurate information retrieval process."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"import re\nimport functools\n\nclass Multi_RAG(dspy.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.retrieve = dspy.Retrieve(k=5)\n        self.generate_kv = dspy.ChainOfThought(GenerateKeywords)\n        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n        self.generate_ratings = dspy.functional.TypedPredictor(Reranker)\n\n    def forward(self, question):\n      with dspy.context(lm=llama_llm):\n kv = self.generate_kv(query=question).answer\n        print(f\"Keywords extracted : {(kv)}\")\n\n context=[]\n      for search_query in [question,kv]:\n results = self.retrieve(search_query).passages\n\n context.extend(results)\n\n context_rating = []\n counter=0\n      for retrieved_context in context:\n _rating={}\n        with dspy.context(lm=mistral_llm):\n rating = self.generate_ratings(context=retrieved_context, question=question).rating\n _rating['id'] = counter\n _rating['score'] = rating\n _rating['context'] = retrieved_context\n counter+=1\n        print(f\"Rating score for context {counter}: {rating}\")\n context_rating.append(_rating)\n\n sorted_data = sorted(context_rating, key=lambda x: float(x['score'].score))\n\n ranked_context = [passage[\"context\"] for passage in sorted_data[:5]]\n      \n\n      with dspy.context(lm=solar_llm):\n prediction = self.generate_answer(context=str(ranked_context), question=question)\n        return dspy.Prediction(context=str(ranked_context), answer=prediction.answer)\n"})}),"\n",(0,r.jsxs)(t.p,{children:["And finally, we run a query on the ",(0,r.jsx)(t.code,{children:"Multi_Rag"})," class,"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'my_question = "What are the potential risks associated with large language models (LLMs) according to the context information?"\n\n# Get the prediction. This contains `pred.context` and `pred.answer`.\nRag_obj= Multi_RAG()\npredict_response = Rag_obj(my_question)\n\n# Print the contexts and the answer.\nprint(f"Question: {my_question}")\nprint(f"Predicted Answer: {predict_response.answer}")\n'})}),"\n",(0,r.jsxs)(n,{children:[(0,r.jsx)("summary",{children:"Output"}),(0,r.jsx)(i.A,{className:"language-python",children:o})]}),"\n",(0,r.jsx)(t.p,{children:"Now we will compare the results obtained from Multistage DSPy RAG with a Vanilla RAG."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from clarifai.rag import RAG\n\nrag_agent = RAG.setup(app_url="YOUR_APP_URL",\n                      llm_url="https://clarifai.com/mistralai/completion/models/mistral-large", max_results=5)\nn_rag_response = rag_agent.chat(messages=[{"role": "human", "content": "What are the potential risks associated with large language models (LLMs) according to the context information?"}])\nprint(n_rag_response[0]["content"])\n'})}),"\n",(0,r.jsxs)(n,{children:[(0,r.jsx)("summary",{children:"Output"}),(0,r.jsx)(i.A,{className:"language-python",children:l})]}),"\n",(0,r.jsxs)(t.p,{children:["Then we can evaluate the performance of each RAG with the help of ",(0,r.jsx)(t.code,{children:"ragas"})," library. Ragas is a valuable tool for assessing the performance of RAG pipelines."]}),"\n",(0,r.jsx)(t.p,{children:"Evaluation of Multistage DSPy RAG,"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from datasets import Dataset\nfrom ragas.metrics import faithfulness, answer_correctness\nfrom ragas import evaluate\n\ndata_samples = {\n    \'question\': [benchmark_files["examples"][0]["query"]],\n    \'answer\': [predict_response.answer],\n    \'ground_truth\': [benchmark_files["examples"][0]["reference_answer"]]\n}\ndataset = Dataset.from_dict(data_samples)\nscore = evaluate(dataset,metrics=[answer_correctness])\nscore.to_pandas()\n'})}),"\n",(0,r.jsxs)(n,{children:[(0,r.jsx)("summary",{children:"Output"}),(0,r.jsx)("img",{src:"/img/python-sdk/multistage-eval.png"})]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from datasets import Dataset\nfrom ragas.metrics import faithfulness, answer_correctness\nfrom ragas import evaluate\n\ndata_samples = {\n    \'question\': [benchmark_files["examples"][0]["query"]],\n    \'answer\': [n_rag_response[0]["content"]],\n    \'ground_truth\': [benchmark_files["examples"][0]["reference_answer"]]\n}\ndataset = Dataset.from_dict(data_samples)\nscore = evaluate(dataset,metrics=[answer_correctness])\nscore.to_pandas()\n'})}),"\n",(0,r.jsxs)(n,{children:[(0,r.jsx)("summary",{children:"Output"}),(0,r.jsx)("img",{src:"/img/python-sdk/vanilla_rag_eval.png"})]}),"\n",(0,r.jsxs)(t.p,{children:["If you observe the values of ",(0,r.jsx)(t.code,{children:"answer_correctness"})," for both RAGs, it can be seen that Multistage DSPy RAG outperforms Naive RAG. This Multi-Stage Multi-model RAG is a testament to the ability of DSPy framework and its modular nature of building different sets of stages within our LLM application."]})]})}function m(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}}}]);