"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[8856],{32593:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>f,contentTitle:()=>m,default:()=>v,frontMatter:()=>h,metadata:()=>r,toc:()=>g});const r=JSON.parse('{"id":"compute/agents/mcp","title":"Clarifai MCP Servers","description":"Build performant MCP Servers with Clarifai","source":"@site/docs/compute/agents/mcp.md","sourceDirName":"compute/agents","slug":"/compute/agents/mcp","permalink":"/compute/agents/mcp","draft":false,"unlisted":false,"editUrl":"https://github.com/Clarifai/docs/blob/main/docs/compute/agents/mcp.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"Build performant MCP Servers with Clarifai","sidebar_position":1,"toc_max_heading_level":4},"sidebar":"tutorialSidebar","previous":{"title":"Agents","permalink":"/compute/agents/"},"next":{"title":"Authentication","permalink":"/control/authentication/"}}');var i=t(74848),a=t(28453),s=t(65537),o=t(79329),l=t(58069);const c='from typing import Annotated\n\nfrom fastmcp import FastMCP  # use fastmcp v2 not the built in mcp\nfrom pydantic import Field\n\nserver = FastMCP(\n    "perplexity-mcp-server",\n    instructions="A Perplexity-style question answering and information service",\n    stateless_http=True,\n)\n\n\n@server.tool(\n    "ask_question", description="Ask a question and get a comprehensive answer with sources"\n)\ndef ask_question(\n    question: Annotated[str, Field(description="The question to ask")],\n    search_focus: Annotated[\n        str, Field(description="Focus area for search (academic, news, general)")\n    ] = "general",\n) -> str:\n    """\n    Simulate asking a question to Perplexity AI for comprehensive answers.\n    In a real implementation, this would call the Perplexity API.\n    """\n    # Mock implementation - replace with actual Perplexity API call\n    responses = {\n        "what is machine learning": "Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves.\\n\\nSources:\\n- Stanford CS229 Machine Learning Course\\n- MIT Introduction to Machine Learning",\n        "latest news on ai": "Recent developments in AI include advances in large language models, breakthrough research in computer vision, and new applications in healthcare and scientific research. Major tech companies continue to invest heavily in AI infrastructure and capabilities.\\n\\nSources:\\n- TechCrunch AI News\\n- MIT Technology Review\\n- Nature AI Research",\n        "python programming": "Python is a high-level, interpreted programming language known for its simple syntax and versatility. It\'s widely used in web development, data science, artificial intelligence, automation, and scientific computing.\\n\\nSources:\\n- Python.org Official Documentation\\n- Real Python Tutorials\\n- Stack Overflow Developer Survey",\n    }\n\n    # Find best match or provide general response\n    question_lower = question.lower()\n    for key, response in responses.items():\n        if any(word in question_lower for word in key.split()):\n            return response\n\n    return f"Based on your question \'{question}\', here\'s what I found:\\n\\nThis appears to be a question about {question}. While I don\'t have specific information cached for this query, I would typically search across academic papers, recent news articles, and authoritative sources to provide you with a comprehensive answer.\\n\\nFocus area: {search_focus}\\n\\nSources would be gathered from:\\n- Academic databases\\n- News outlets\\n- Expert publications\\n- Official documentation"\n\n\n@server.tool("search_sources", description="Search for reliable sources on a topic")\ndef search_sources(\n    topic: Annotated[str, Field(description="The topic to search sources for")],\n    source_type: Annotated[\n        str, Field(description="Type of sources (academic, news, web, all)")\n    ] = "all",\n    max_results: Annotated[\n        int, Field(description="Maximum number of sources to return", ge=1, le=20)\n    ] = 5,\n) -> str:\n    """\n    Search for reliable sources on a given topic.\n    In a real implementation, this would query multiple databases and APIs.\n    """\n    # Mock source data\n    mock_sources = {\n        "machine learning": [\n            {\n                "title": "Pattern Recognition and Machine Learning",\n                "author": "Christopher Bishop",\n                "type": "academic",\n                "url": "academic-source.com",\n            },\n            {\n                "title": "The Elements of Statistical Learning",\n                "author": "Hastie, Tibshirani, Friedman",\n                "type": "academic",\n                "url": "academic-source2.com",\n            },\n            {\n                "title": "Google\'s Latest ML Research",\n                "author": "Google AI",\n                "type": "news",\n                "url": "news-source.com",\n            },\n        ],\n        "python": [\n            {\n                "title": "Python Documentation",\n                "author": "Python Software Foundation",\n                "type": "web",\n                "url": "python.org",\n            },\n            {\n                "title": "Effective Python",\n                "author": "Brett Slatkin",\n                "type": "academic",\n                "url": "book-source.com",\n            },\n            {\n                "title": "Python 3.12 Release Notes",\n                "author": "Python Team",\n                "type": "news",\n                "url": "python-news.com",\n            },\n        ],\n    }\n\n    # Find relevant sources\n    topic_lower = topic.lower()\n    found_sources = []\n\n    for key, sources in mock_sources.items():\n        if any(word in topic_lower for word in key.split()):\n            found_sources.extend(sources)\n\n    if not found_sources:\n        found_sources = [\n            {\n                "title": f"Search Results for {topic}",\n                "author": "Various",\n                "type": "web",\n                "url": "search-engine.com",\n            },\n            {\n                "title": f"Academic Papers on {topic}",\n                "author": "Academic Database",\n                "type": "academic",\n                "url": "academic-db.com",\n            },\n        ]\n\n    # Filter by source type if specified\n    if source_type != "all":\n        found_sources = [s for s in found_sources if s["type"] == source_type]\n\n    # Limit results\n    found_sources = found_sources[:max_results]\n\n    # Format response\n    result = f"Found {len(found_sources)} sources for \'{topic}\':\\n\\n"\n    for i, source in enumerate(found_sources, 1):\n        result += f"{i}. {source[\'title\']} by {source[\'author\']} ({source[\'type\']})\\n   URL: {source[\'url\']}\\n\\n"\n\n    return result\n\n\n@server.tool("get_trending_topics", description="Get currently trending topics and questions")\ndef get_trending_topics(\n    category: Annotated[\n        str, Field(description="Category of trends (tech, science, news, all)")\n    ] = "all",\n) -> str:\n    """\n    Get trending topics and popular questions.\n    In a real implementation, this would pull from Perplexity\'s trending data.\n    """\n    trending_data = {\n        "tech": [\n            "AI model fine-tuning techniques",\n            "Quantum computing breakthroughs",\n            "Cybersecurity in cloud environments",\n            "Web3 and blockchain development",\n        ],\n        "science": [\n            "Climate change mitigation strategies",\n            "Gene therapy advances",\n            "Space exploration missions",\n            "Renewable energy innovations",\n        ],\n        "news": [\n            "Global economic trends",\n            "International policy changes",\n            "Healthcare system updates",\n            "Education technology adoption",\n        ],\n    }\n\n    if category == "all":\n        topics = []\n        for cat_topics in trending_data.values():\n            topics.extend(cat_topics)\n    else:\n        topics = trending_data.get(category, ["No trends found for this category"])\n\n    result = f"Trending topics in {category}:\\n\\n"\n    for i, topic in enumerate(topics[:10], 1):  # Limit to 10 topics\n        result += f"{i}. {topic}\\n"\n\n    return result\n\n\n@server.tool("fact_check", description="Verify claims and check facts")\ndef fact_check(\n    claim: Annotated[str, Field(description="The claim or statement to fact-check")],\n    include_sources: Annotated[\n        bool, Field(description="Whether to include verification sources")\n    ] = True,\n) -> str:\n    """\n    Fact-check a claim or statement.\n    In a real implementation, this would cross-reference multiple authoritative sources.\n    """\n    # Mock fact-checking responses\n    mock_facts = {\n        "earth is flat": {\n            "verdict": "FALSE",\n            "explanation": "The Earth is an oblate spheroid, confirmed by centuries of scientific evidence including satellite imagery, physics, and direct observation.",\n            "sources": ["NASA", "International Space Station", "Scientific consensus"],\n        },\n        "python is open source": {\n            "verdict": "TRUE",\n            "explanation": "Python is released under an open-source license (Python Software Foundation License) and its source code is freely available.",\n            "sources": [\n                "Python Software Foundation",\n                "GitHub Python repository",\n                "Open Source Initiative",\n            ],\n        },\n        "ai will replace all jobs": {\n            "verdict": "PARTIALLY FALSE",\n            "explanation": "While AI will automate some jobs, it\'s expected to also create new types of work. The impact will vary significantly across industries and roles.",\n            "sources": [\n                "McKinsey Global Institute",\n                "World Economic Forum",\n                "MIT Technology Review",\n            ],\n        },\n    }\n\n    claim_lower = claim.lower()\n\n    # Find matching fact-check\n    for key, fact_data in mock_facts.items():\n        if any(word in claim_lower for word in key.split()):\n            result = f"FACT-CHECK: {claim}\\n\\n"\n            result += f"VERDICT: {fact_data[\'verdict\']}\\n\\n"\n            result += f"EXPLANATION: {fact_data[\'explanation\']}\\n"\n\n            if include_sources:\n                result += "\\nSOURCES:\\n"\n                for source in fact_data[\'sources\']:\n                    result += f"- {source}\\n"\n\n            return result\n\n    # Default response for unrecognized claims\n    return f"FACT-CHECK: {claim}\\n\\nVERDICT: NEEDS VERIFICATION\\n\\nEXPLANATION: This claim requires additional research and verification from authoritative sources. I recommend checking with multiple reliable sources including academic institutions, government agencies, and established news organizations.\\n\\nSUGGESTED VERIFICATION SOURCES:\\n- Academic journals and databases\\n- Government and international organization reports\\n- Established news outlets with fact-checking departments\\n- Expert opinions from relevant fields"\n\n\n# Static resource\n@server.resource("config://search_settings")\ndef get_search_settings():\n    return {\n        "default_sources": ["academic", "news", "web"],\n        "max_results_per_query": 10,\n        "supported_languages": ["en", "es", "fr", "de"],\n        "fact_check_enabled": True,\n    }\n\n\n# Dynamic resource template\n@server.resource("topic://{topic_name}/summary")\ndef get_topic_summary(topic_name: str):\n    return {\n        "topic": topic_name,\n        "last_updated": "2024-01-15",\n        "summary": f"Comprehensive information about {topic_name}",\n        "source_count": 42,\n    }\n\n\n@server.prompt()\ndef research_prompt(topic: str) -> str:\n    """Generate a research prompt for a given topic."""\n    return f"Please provide a comprehensive research summary on \'{topic}\', including:\\n\\n1. Key concepts and definitions\\n2. Current state of knowledge\\n3. Recent developments and trends\\n4. Credible sources and references\\n5. Areas needing further research\\n\\nFocus on accuracy and cite reliable sources."\n\n\nfrom clarifai.runners.models.mcp_class import MCPModelClass\n\n\nclass MyModelClass(MCPModelClass):\n    def get_server(self) -> FastMCP:\n        return server',u="build_info:\n  python_version: '3.11'\ninference_compute_info:\n  cpu_limit: 1000m\n  cpu_memory: 1Gi\n  num_accelerators: 0\nmodel:\n  app_id: app-id\n  id: model-id\n  model_type_id: mcp\n  user_id: user-id",d="clarifai>=11.4.5\nanyio==4.9.0\nmcp==1.9.0\nfastmcp==2.3.4\nrequests>=2.31.0",p='import asyncio\nimport os\n\nfrom clarifai.urls.helper import ClarifaiUrlHelper\nfrom fastmcp import Client\nfrom fastmcp.client.transports import StreamableHttpTransport\n\nPAT = os.environ[\'CLARIFAI_PAT\']\nurl = ClarifaiUrlHelper().mcp_api_url()  # get url from the current clarifai config\n\ntransport = StreamableHttpTransport(url=url, headers={"Authorization": "Bearer " + PAT})\n\n\nasync def main():\n    print("=== Perplexity MCP Server Examples ===\\n")\n\n    async with Client(transport) as client:\n        # List available tools first\n        print("Available tools:")\n        tools = await client.list_tools()\n        for tool in tools:\n            print(f"- {tool.name}: {tool.description}")\n        print("\\n" + "=" * 50 + "\\n")\n\n        # Example 1: Ask a question\n        print("1. Asking a question about machine learning:")\n        try:\n            result = await client.call_tool(\n                "ask_question",\n                {"question": "What is machine learning?", "search_focus": "academic"},\n            )\n            print(result[0].text)\n        except Exception as e:\n            print(f"Error: {e}")\n        print("\\n" + "=" * 50 + "\\n")\n\n        # Example 2: Search for sources\n        print("2. Searching for sources on Python:")\n        try:\n            result = await client.call_tool(\n                "search_sources",\n                {"topic": "python programming", "source_type": "all", "max_results": 3},\n            )\n            print(result[0].text)\n        except Exception as e:\n            print(f"Error: {e}")\n        print("\\n" + "=" * 50 + "\\n")\n\n        # Example 3: Get trending topics\n        print("3. Getting trending topics in technology:")\n        try:\n            result = await client.call_tool("get_trending_topics", {"category": "tech"})\n            print(result[0].text)\n        except Exception as e:\n            print(f"Error: {e}")\n        print("\\n" + "=" * 50 + "\\n")\n\n        # Example 4: Fact-check a claim\n        print("4. Fact-checking a claim:")\n        try:\n            result = await client.call_tool(\n                "fact_check", {"claim": "Python is open source", "include_sources": True}\n            )\n            print(result[0].text)\n        except Exception as e:\n            print(f"Error: {e}")\n        print("\\n" + "=" * 50 + "\\n")\n\n\nif __name__ == "__main__":\n    asyncio.run(main())',h={description:"Build performant MCP Servers with Clarifai",sidebar_position:1,toc_max_heading_level:4},m="Clarifai MCP Servers",f={},g=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Install Clarifai Package",id:"install-clarifai-package",level:3},{value:"Set a PAT Key",id:"set-a-pat-key",level:3},{value:"Create Files",id:"create-files",level:3},{value:"<code>model.py</code>",id:"modelpy",level:4},{value:"<code>requirements.txt</code>",id:"requirementstxt",level:4},{value:"<code>config.yaml</code>",id:"configyaml",level:4},{value:"<code>client.py</code>",id:"clientpy",level:4},{value:"Run an Example",id:"run-an-example",level:2},{value:"Upload to Clarifai",id:"upload-to-clarifai",level:2}];function y(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"clarifai-mcp-servers",children:"Clarifai MCP Servers"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Build performant MCP Servers with Clarifai"})}),"\n",(0,i.jsx)("hr",{}),"\n",(0,i.jsx)(n.p,{children:"The Model Context Protocol (MCP) is a standardized, secure framework for building servers that expose data and functionality to LLM-based applications.\nThink of it as a specialized web API built specifically for LLM interactions."}),"\n",(0,i.jsxs)(n.p,{children:["Clarifai allows you to build ",(0,i.jsx)(n.a,{href:"https://www.clarifai.com/blog/mcp-vs-a2a-clearly-explained",children:"MCP servers"})," by providing the necessary infrastructure and tools to define and deploy custom MCP servers. This allows you to seamlessly integrate your proprietary data sources, custom APIs, and application-specific functionalities with various LLM applications."]}),"\n",(0,i.jsxs)(n.p,{children:["Let's illustrate how you can build an MCP server that answers questions and provides information using ",(0,i.jsx)(n.a,{href:"https://www.perplexity.ai/",children:"Perplexity's"})," web search capabilities. We'll build it with the ",(0,i.jsx)(n.a,{href:"https://github.com/jlowin/fastmcp",children:"FastMCP"})," framework, which allows for building MCP servers with minimal boilerplate."]}),"\n","\n","\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(n.h3,{id:"install-clarifai-package",children:"Install Clarifai Package"}),"\n",(0,i.jsxs)(n.p,{children:["Install the latest version of the ",(0,i.jsx)(n.code,{children:"clarifai"})," Python SDK. This also installs the Clarifai ",(0,i.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/cli",children:"Command Line Interface (CLI)"}),", which we'll use for uploading the model."]}),"\n",(0,i.jsx)(s.A,{children:(0,i.jsx)(o.A,{value:"bash",label:"Bash",children:(0,i.jsx)(l.A,{className:"language-bash",children:" pip install --upgrade clarifai "})})}),"\n",(0,i.jsx)(n.h3,{id:"set-a-pat-key",children:"Set a PAT Key"}),"\n",(0,i.jsxs)(n.p,{children:["You need to set the ",(0,i.jsx)(n.code,{children:"CLARIFAI_PAT"})," (Personal Access Token) as an environment variable. You can generate the PAT key in your personal settings page by navigating to the ",(0,i.jsx)(n.a,{href:"https://clarifai.com/settings/security",children:"Security section"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"This token is essential for authenticating your connection to the Clarifai platform."}),"\n",(0,i.jsxs)(s.A,{children:[(0,i.jsx)(o.A,{value:"bash",label:"Unix-Like Systems",children:(0,i.jsx)(l.A,{className:"language-bash",children:" export CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE "})}),(0,i.jsx)(o.A,{value:"bash2",label:"Windows",children:(0,i.jsx)(l.A,{className:"language-bash",children:" set CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE "})})]}),"\n",(0,i.jsx)(n.h3,{id:"create-files",children:"Create Files"}),"\n",(0,i.jsx)(n.p,{children:"Create a project directory and organize your files as indicated below to fit the requirements of building servers for the Clarifai platform."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"your_model_directory/\n\u251c\u2500\u2500 1/\n\u2502   \u2514\u2500\u2500 model.py\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 config.yaml\n\u2514\u2500\u2500 client.py\n"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"your_model_directory/"})," \u2013 The root directory containing all files related to your server.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"1/"})," \u2013 A subdirectory that holds the model file (",(0,i.jsxs)(n.em,{children:["Note that the folder is named as ",(0,i.jsx)(n.strong,{children:"1"})]}),").","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"model.py"})," \u2013 Contains the main MCP server implementation."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"requirements.txt"})," \u2013 Lists the Python dependencies required to run your server."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"config.yaml"})," \u2013 Contains metadata and configuration settings, such as compute requirements, needed for uploading the model to Clarifai."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"client.py"})," \u2013 Contains the example client demonstrating usage."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Add the following snippets to each of the respective files."}),"\n",(0,i.jsx)(n.h4,{id:"modelpy",children:(0,i.jsx)(n.code,{children:"model.py"})}),"\n",(0,i.jsx)(s.A,{children:(0,i.jsx)(o.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:c})})}),"\n",(0,i.jsx)(n.h4,{id:"requirementstxt",children:(0,i.jsx)(n.code,{children:"requirements.txt"})}),"\n",(0,i.jsx)(s.A,{children:(0,i.jsx)(o.A,{value:"text",label:"Text",children:(0,i.jsx)(l.A,{className:"language-text",children:d})})}),"\n",(0,i.jsx)(n.h4,{id:"configyaml",children:(0,i.jsx)(n.code,{children:"config.yaml"})}),"\n",(0,i.jsx)(n.admonition,{title:"important",type:"info",children:(0,i.jsxs)(n.p,{children:["In the ",(0,i.jsx)(n.code,{children:"model"})," section of the ",(0,i.jsx)(n.code,{children:"config.yaml"})," file, specify your model ID, Clarifai user ID, and Clarifai app ID. These will define where your model will be uploaded on the Clarifai platform."]})}),"\n",(0,i.jsx)(s.A,{children:(0,i.jsx)(o.A,{value:"yaml",label:"YAML",children:(0,i.jsx)(l.A,{className:"language-yaml",children:u})})}),"\n",(0,i.jsx)(n.h4,{id:"clientpy",children:(0,i.jsx)(n.code,{children:"client.py"})}),"\n",(0,i.jsx)(s.A,{children:(0,i.jsx)(o.A,{value:"python",label:"Python",children:(0,i.jsx)(l.A,{className:"language-python",children:p})})}),"\n",(0,i.jsx)(n.admonition,{title:"Mock Data",type:"note",children:(0,i.jsx)(n.p,{children:"This example includes mock data and fallback implementations when external services are not available, allowing you to test the MCP interface without requiring all external dependencies."})}),"\n",(0,i.jsx)(n.h2,{id:"run-an-example",children:"Run an Example"}),"\n",(0,i.jsx)(n.p,{children:"After setting up the required files, navigate to your directory and run the following command to install the dependencies:"}),"\n",(0,i.jsx)(s.A,{children:(0,i.jsx)(o.A,{value:"bash",label:"Bash",children:(0,i.jsx)(l.A,{className:"language-bash",children:" pip install -r requirements.txt "})})}),"\n",(0,i.jsx)(n.p,{children:"Then, run the client example:"}),"\n",(0,i.jsx)(s.A,{children:(0,i.jsx)(o.A,{value:"bash",label:"Bash",children:(0,i.jsx)(l.A,{className:"language-bash",children:" python client.py "})})}),"\n",(0,i.jsx)(n.h2,{id:"upload-to-clarifai",children:"Upload to Clarifai"}),"\n",(0,i.jsx)(n.p,{children:"You can upload the MCP server to the Clarifai platform by navigating to its directory and running the following command:"}),"\n",(0,i.jsx)(s.A,{children:(0,i.jsx)(o.A,{value:"bash",label:"CLI",children:(0,i.jsx)(l.A,{className:"language-bash",children:" clarifai model upload "})})})]})}function v(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(y,{...e})}):y(e)}},65537:(e,n,t)=>{t.d(n,{A:()=>w});var r=t(96540),i=t(18215),a=t(65627),s=t(56347),o=t(50372),l=t(30604),c=t(11861),u=t(78749);function d(e){return r.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(e){const{values:n,children:t}=e;return(0,r.useMemo)((()=>{const e=n??function(e){return d(e).map((e=>{let{props:{value:n,label:t,attributes:r,default:i}}=e;return{value:n,label:t,attributes:r,default:i}}))}(t);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function h(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function m(e){let{queryString:n=!1,groupId:t}=e;const i=(0,s.W6)(),a=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,l.aZ)(a),(0,r.useCallback)((e=>{if(!a)return;const n=new URLSearchParams(i.location.search);n.set(a,e),i.replace({...i.location,search:n.toString()})}),[a,i])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:i}=e,a=p(e),[s,l]=(0,r.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!h({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const r=t.find((e=>e.default))??t[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:n,tabValues:a}))),[c,d]=m({queryString:t,groupId:i}),[f,g]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[i,a]=(0,u.Dv)(t);return[i,(0,r.useCallback)((e=>{t&&a.set(e)}),[t,a])]}({groupId:i}),y=(()=>{const e=c??f;return h({value:e,tabValues:a})?e:null})();(0,o.A)((()=>{y&&l(y)}),[y]);return{selectedValue:s,selectValue:(0,r.useCallback)((e=>{if(!h({value:e,tabValues:a}))throw new Error(`Can't select invalid tab value=${e}`);l(e),d(e),g(e)}),[d,g,a]),tabValues:a}}var g=t(9136);const y={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var v=t(74848);function x(e){let{className:n,block:t,selectedValue:r,selectValue:s,tabValues:o}=e;const l=[],{blockElementScrollPositionUntilNextRender:c}=(0,a.a_)(),u=e=>{const n=e.currentTarget,t=l.indexOf(n),i=o[t].value;i!==r&&(c(n),s(i))},d=e=>{let n=null;switch(e.key){case"Enter":u(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return(0,v.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":t},n),children:o.map((e=>{let{value:n,label:t,attributes:a}=e;return(0,v.jsx)("li",{role:"tab",tabIndex:r===n?0:-1,"aria-selected":r===n,ref:e=>{l.push(e)},onKeyDown:d,onClick:u,...a,className:(0,i.A)("tabs__item",y.tabItem,a?.className,{"tabs__item--active":r===n}),children:t??n},n)}))})}function b(e){let{lazy:n,children:t,selectedValue:a}=e;const s=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=s.find((e=>e.props.value===a));return e?(0,r.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,v.jsx)("div",{className:"margin-top--md",children:s.map(((e,n)=>(0,r.cloneElement)(e,{key:n,hidden:e.props.value!==a})))})}function _(e){const n=f(e);return(0,v.jsxs)("div",{className:(0,i.A)("tabs-container",y.tabList),children:[(0,v.jsx)(x,{...n,...e}),(0,v.jsx)(b,{...n,...e})]})}function w(e){const n=(0,g.A)();return(0,v.jsx)(_,{...e,children:d(e.children)},String(n))}},79329:(e,n,t)=>{t.d(n,{A:()=>s});t(96540);var r=t(18215);const i={tabItem:"tabItem_Ymn6"};var a=t(74848);function s(e){let{children:n,hidden:t,className:s}=e;return(0,a.jsx)("div",{role:"tabpanel",className:(0,r.A)(i.tabItem,s),hidden:t,children:n})}}}]);