"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[4496],{28453:(e,a,n)=>{n.d(a,{R:()=>s,x:()=>l});var t=n(96540);const o={},i=t.createContext(o);function s(e){const a=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function l(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),t.createElement(i.Provider,{value:a},e.children)}},56391:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>r,contentTitle:()=>l,default:()=>m,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"create/models/deep-fine-tuning/visual-anomaly","title":"Visual Anomaly","description":"Learn about our visual anomaly  model type","source":"@site/docs/create/models/deep-fine-tuning/visual-anomaly.md","sourceDirName":"create/models/deep-fine-tuning","slug":"/create/models/deep-fine-tuning/visual-anomaly","permalink":"/create/models/deep-fine-tuning/visual-anomaly","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"description":"Learn about our visual anomaly  model type","sidebar_position":5,"keywords":["visual anomaly detection","anomaly detection models","Clarifai visual anomaly","AI anomaly detection","machine learning anomaly detection","computer vision anomaly detection","visual anomaly detector","image anomaly detection","AI visual anomaly"]},"sidebar":"tutorialSidebar","previous":{"title":"Visual Segmenter","permalink":"/create/models/deep-fine-tuning/visual-segmenter"},"next":{"title":"Visual Embedder","permalink":"/create/models/deep-fine-tuning/visual-embedder"}}');var o=n(74848),i=n(28453);const s={description:"Learn about our visual anomaly  model type",sidebar_position:5,keywords:["visual anomaly detection","anomaly detection models","Clarifai visual anomaly","AI anomaly detection","machine learning anomaly detection","computer vision anomaly detection","visual anomaly detector","image anomaly detection","AI visual anomaly"]},l="Visual Anomaly",r={},c=[{value:"Example use case",id:"example-use-case",level:2}];function d(e){const a={a:"a",admonition:"admonition",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(a.header,{children:(0,o.jsx)(a.h1,{id:"visual-anomaly",children:"Visual Anomaly"})}),"\n",(0,o.jsx)(a.p,{children:(0,o.jsx)(a.strong,{children:"Learn about our visual anomaly model type"})}),"\n",(0,o.jsx)("hr",{}),"\n",(0,o.jsxs)(a.p,{children:[(0,o.jsx)(a.strong,{children:"Input"}),": Images and videos"]}),"\n",(0,o.jsxs)(a.p,{children:[(0,o.jsx)(a.strong,{children:"Output"}),": ",(0,o.jsx)(a.a,{href:"https://docs.clarifai.com/portal-guide/concepts",children:"Concepts"})]}),"\n",(0,o.jsx)(a.p,{children:"Visual anomaly is a type of deep fine-tuned model that can be used to identify unusual or anomalous patterns in images and videos that differ from the expected norm."}),"\n",(0,o.jsx)(a.p,{children:"It does this by learning to identify normal patterns in images or videos and then using those patterns to detect anomalies in new images or videos."}),"\n",(0,o.jsx)(a.p,{children:"It works by first creating a heatmap of an image. The heatmap is a representation of the image where each pixel is assigned a value that indicates how likely it is to be anomalous. The model then calculates an image-level score for the image based on the heatmap. The image-level score indicates how likely it is that the image contains an anomaly."}),"\n",(0,o.jsx)(a.admonition,{type:"info",children:(0,o.jsx)(a.p,{children:"The visual anomaly model type also comes with various templates that give you the control to choose the specific architecture used by your neural network, as well as define a set of hyperparameters you can use to fine-tune the way that your model learns."})}),"\n",(0,o.jsx)(a.p,{children:"The visual anomaly model type can be used in a wide range of applications, including:"}),"\n",(0,o.jsxs)(a.ul,{children:["\n",(0,o.jsxs)(a.li,{children:[(0,o.jsx)(a.strong,{children:"Object anomalies"}),": These are anomalies that occur in the objects in an image. For example, an object may be missing, or it may be in a different location than it should be."]}),"\n",(0,o.jsxs)(a.li,{children:[(0,o.jsx)(a.strong,{children:"Background anomalies"}),": These are anomalies that occur in the background of an image. For example, there may be a strange object in the background, or the background may be blurry."]}),"\n",(0,o.jsxs)(a.li,{children:[(0,o.jsx)(a.strong,{children:"Lighting anomalies"}),": These are anomalies that occur due to changes in lighting. For example, the image may be too dark or too bright, or there may be shadows in the image that should not be there."]}),"\n"]}),"\n",(0,o.jsx)(a.p,{children:"You may choose a visual anomaly model type in cases where:"}),"\n",(0,o.jsxs)(a.ul,{children:["\n",(0,o.jsx)(a.li,{children:"You want to accurately find anomalous examples with only normal examples in training."}),"\n",(0,o.jsxs)(a.li,{children:['You need a visual anomaly model to detect anomalous patterns not recognized by the existing Clarifai models. In that case, you may need to "deep fine-tune" your custom model and integrate it directly within your ',(0,o.jsx)(a.a,{href:"https://docs.clarifai.com/portal-guide/workflows/",children:"workflows"}),"."]}),"\n",(0,o.jsx)(a.li,{children:"You have a custom-tailored dataset, accurate labels, and the expertise and time to fine-tune models."}),"\n"]}),"\n",(0,o.jsx)(a.h2,{id:"example-use-case",children:"Example use case"}),"\n",(0,o.jsx)(a.p,{children:"In a manufacturing facility that produces electronic circuit boards, the quality control process is crucial to ensuring that the circuit boards are free from defects before they are shipped to customers. However, defects can occasionally occur during the manufacturing process, leading to malfunctioning products and customer dissatisfaction. In this scenario, a visual anomaly detection model can be employed to automatically inspect each circuit board for anomalies or defects."})]})}function m(e={}){const{wrapper:a}={...(0,i.R)(),...e.components};return a?(0,o.jsx)(a,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}}}]);