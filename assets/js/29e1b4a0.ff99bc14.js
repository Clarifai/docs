"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[115],{4401:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>C,contentTitle:()=>v,default:()=>k,frontMatter:()=>b,metadata:()=>A,toc:()=>w});var o=n(74848),l=n(28453),r=n(11470),s=n(19365),i=n(21432);const a='from clarifai.client.user import User\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" \n\n# Initialize the client\nclient = User(\n    user_id="YOUR_USER_ID_HERE",\n    base_url="https://api.clarifai.com"\n)\n\n# Create a new compute cluster\ncompute_cluster = client.create_compute_cluster(\n    compute_cluster_id="test-compute-cluster",\n    config_filepath="./configs/compute_cluster_config.yaml"\n)\n',c="$ clarifai computecluster create --config <compute-cluster-config-filepath>",d='from clarifai.client.compute_cluster import ComputeCluster\n\n# Initialize the ComputeCluster instance\ncompute_cluster = ComputeCluster(\n    user_id="YOUR_USER_ID_HERE",           \n    compute_cluster_id="test-compute-cluster",\n    base_url="https://api.clarifai.com"          \n)\n',u='from clarifai.client.compute_cluster import ComputeCluster\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE"  \n\n# Initialize the ComputeCluster instance\ncompute_cluster = ComputeCluster(\n    user_id="YOUR_USER_ID_HERE",\n    compute_cluster_id="test-compute-cluster",\n    base_url="https://api.clarifai.com"\n)\n\n# Create a new nodepool \nnodepool = compute_cluster.create_nodepool(\n    nodepool_id="test-nodepool",\n    config_filepath="./configs/nodepool_config.yaml"\n)\n',p="$ clarifai nodepool create --config <nodepool-config-filepath>",h='from clarifai.client.nodepool import Nodepool\n\n# Initialize the Nodepool instance\nnodepool = Nodepool(\n    user_id="YOUR_USER_ID_HERE",            \n    nodepool_id="test-nodepool",   \n    base_url="https://api.clarifai.com"            \n)\n',m='from clarifai.client.nodepool import Nodepool\nimport os\n\n# Set the PAT key\nos.environ["CLARIFAI_PAT"] = "YOUR_PAT_HERE" \n\n# Initialize the Nodepool instance\nnodepool = Nodepool(\n    user_id="YOUR_USER_ID_HERE",            \n    nodepool_id="test-nodepool",   \n    base_url="https://api.clarifai.com"            \n)\n\n# Create a new deployment\ndeployment = nodepool.create_deployment(\n    deployment_id="test-deployment", \n    config_filepath="./configs/deployment_config.yaml"\n)',f="$ clarifai deployment create --config <deployment-config-filepath>",y='from clarifai.client.deployment import Deployment\n\n# Initialize the deployment\ndeployment = Deployment(\n    user_id="YOUR_USER_ID_HERE", \n    deployment_id="test-deployment",\n    base_url="https://api.clarifai.com"\n)\n',_='from clarifai.client.model import Model\n\nmodel_url = "https://clarifai.com/stepfun-ai/ocr/models/got-ocr-2_0"\n\n# URL of the image to analyze\nimage_url = "https://samples.clarifai.com/featured-models/model-ocr-scene-text-las-vegas-sign.png"\n\n# Initialize the model \nmodel = Model(\n    url=model_url, \n    pat="YOUR_PAT_HERE" \n)\n\n# Make a prediction using the model with the specified compute cluster and nodepool\nmodel_prediction = model.predict_by_url(\n    image_url,\n    input_type="image",\n    deployment_id="test-deployment"     \n)\n\n# Print the output\nprint(model_prediction.outputs[0].data.text.raw)\n',x='$ clarifai model predict --model_id got-ocr-2_0 --user_id stepfun-ai --app_id ocr --url "https://samples.clarifai.com/featured-models/ocr-woman-holding-sold-sign.jpg" --input_type image --deployment_id "test-deployment"\n',g='from clarifai.client.model import Model\n\nmodel_url = "https://clarifai.com/meta/Llama-3/models/llama-3_2-3b-instruct"\n\n# URL of the prompt text\ntext_url = "https://samples.clarifai.com/featured-models/falcon-instruction-guidance.txt"\n\n# Initialize the model \nmodel = Model(\n    url=model_url, \n    pat="YOUR_PAT_HERE" \n)\n\n# Perform unary-stream prediction with the specified compute cluster and nodepool\nstream_response = model.generate_by_url(\n    text_url, \n    input_type="text",\n    deployment_id="test-deployment"\n)\n\n# Handle the stream of responses\nlist_stream_response = [response for response in stream_response]\n',j='from clarifai.client.model import Model\n\nmodel_url = "https://clarifai.com/meta/Llama-3/models/llama-3_2-3b-instruct"\n\n# URL of the prompt text\ntext_url = "https://samples.clarifai.com/featured-models/falcon-instruction-guidance.txt"\n\n# Initialize the model \nmodel = Model(\n    url=model_url, \n    pat="YOUR_PAT_HERE" \n)\n\n# Perform stream-stream prediction with the specified compute cluster and nodepool\nstream_response = model.stream_by_url(\n    iter([text_url]), \n    input_type="text",\n    deployment_id="test-deployment"\n)\n\n# Handle the stream of responses\nlist_stream_response = [response for response in stream_response]\n',b={description:"Set up your compute clusters and nodepools",sidebar_position:2},v="Clusters and Nodepools",A={id:"sdk/compute-orchestration/set-up-compute",title:"Clusters and Nodepools",description:"Set up your compute clusters and nodepools",source:"@site/docs/sdk/compute-orchestration/set-up-compute.md",sourceDirName:"sdk/compute-orchestration",slug:"/sdk/compute-orchestration/set-up-compute",permalink:"/sdk/compute-orchestration/set-up-compute",draft:!1,unlisted:!1,editUrl:"https://github.com/Clarifai/docs/blob/main/docs/sdk/compute-orchestration/set-up-compute.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{description:"Set up your compute clusters and nodepools",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Model Upload",permalink:"/sdk/compute-orchestration/model-upload"},next:{title:"Managing Your Compute",permalink:"/sdk/compute-orchestration/manage-compute"}},C={},w=[{value:"Cluster Operations",id:"cluster-operations",level:2},{value:"Create a Compute Cluster",id:"create-a-compute-cluster",level:3},{value:"Initialize the <code>ComputeCluster</code> Class",id:"initialize-the-computecluster-class",level:3},{value:"Nodepool Operations",id:"nodepool-operations",level:2},{value:"Create a Nodepool",id:"create-a-nodepool",level:3},{value:"Initialize the <code>Nodepool</code> Class",id:"initialize-the-nodepool-class",level:3},{value:"Deployment Operations",id:"deployment-operations",level:2},{value:"Create a Deployment",id:"create-a-deployment",level:3},{value:"Initialize the <code>Deployment</code> Class",id:"initialize-the-deployment-class",level:3},{value:"Predict With Deployed Model",id:"predict-with-deployed-model",level:2},{value:"Unary-Unary Predict Call",id:"unary-unary-predict-call",level:3},{value:"Unary-Stream Predict Call",id:"unary-stream-predict-call",level:3},{value:"Stream-Stream Predict Call",id:"stream-stream-predict-call",level:3}];function I(e){const t={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h1,{id:"clusters-and-nodepools",children:"Clusters and Nodepools"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.strong,{children:"Set up your compute clusters and nodepools"})}),"\n",(0,o.jsx)("hr",{}),"\n",(0,o.jsx)(t.p,{children:"A compute cluster serves as the primary environment for running models, whether for training or inference. Each cluster consists of multiple nodepools \u2014 groups of virtual machine instances with similar configurations, such as CPU/GPU type and memory."}),"\n",(0,o.jsx)(t.p,{children:"After setting up a custom cluster, you can configure nodepools to optimize resource usage, tailoring the infrastructure to specific hardware, performance, cost, or compliance requirements."}),"\n",(0,o.jsxs)(t.blockquote,{children:["\n",(0,o.jsxs)(t.p,{children:["The following sections will guide you through creating clusters and nodepools and deploying your models. Note that Compute Orchestration supports only models uploaded to the Clarifai platform via the Python SDK, as outlined ",(0,o.jsx)(t.a,{href:"/sdk/compute-orchestration/model-upload",children:"here"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(t.blockquote,{children:["\n",(0,o.jsxs)(t.p,{children:["Before configuring compute clusters and nodepools, ensure you have completed the necessary prerequisites, as outlined ",(0,o.jsx)(t.a,{href:"/sdk/compute-orchestration/#prerequisites",children:"here"}),"."]}),"\n"]}),"\n","\n","\n",(0,o.jsx)(t.h2,{id:"cluster-operations",children:"Cluster Operations"}),"\n",(0,o.jsx)(t.h3,{id:"create-a-compute-cluster",children:"Create a Compute Cluster"}),"\n",(0,o.jsxs)(t.p,{children:["To create a new compute cluster, pass the ",(0,o.jsx)(t.code,{children:"compute_cluster_id"})," and ",(0,o.jsx)(t.code,{children:"config_filepath"})," as arguments to the ",(0,o.jsx)(t.code,{children:"create_compute_cluster"})," method of the ",(0,o.jsx)(t.code,{children:"User"})," class."]}),"\n",(0,o.jsxs)(r.A,{children:[(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:a})}),(0,o.jsx)(s.A,{value:"bash",label:"Bash",children:(0,o.jsx)(i.A,{className:"language-yaml",children:c})})]}),"\n",(0,o.jsxs)(t.h3,{id:"initialize-the-computecluster-class",children:["Initialize the ",(0,o.jsx)(t.code,{children:"ComputeCluster"})," Class"]}),"\n",(0,o.jsxs)(t.p,{children:["To initialize the ",(0,o.jsx)(t.code,{children:"ComputeCluster"})," class, provide the ",(0,o.jsx)(t.code,{children:"user_id"})," and ",(0,o.jsx)(t.code,{children:"compute_cluster_id"})," as parameters."]}),"\n",(0,o.jsx)(t.p,{children:"Initialization is essential because it establishes the specific user and compute cluster context, which allows the subsequent operations to accurately target and manage the intended resources."}),"\n",(0,o.jsx)(r.A,{children:(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:d})})}),"\n",(0,o.jsx)(t.h2,{id:"nodepool-operations",children:"Nodepool Operations"}),"\n",(0,o.jsx)(t.h3,{id:"create-a-nodepool",children:"Create a Nodepool"}),"\n",(0,o.jsxs)(t.p,{children:["To create a new nodepool, use the ",(0,o.jsx)(t.code,{children:"create_nodepool"})," method with the ",(0,o.jsx)(t.code,{children:"nodepool_id"})," and ",(0,o.jsx)(t.code,{children:"config_filepath"})," as parameters."]}),"\n",(0,o.jsxs)(r.A,{children:[(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:u})}),(0,o.jsx)(s.A,{value:"bash",label:"Bash",children:(0,o.jsx)(i.A,{className:"language-yaml",children:p})})]}),"\n",(0,o.jsxs)(t.h3,{id:"initialize-the-nodepool-class",children:["Initialize the ",(0,o.jsx)(t.code,{children:"Nodepool"})," Class"]}),"\n",(0,o.jsxs)(t.p,{children:["To initialize the ",(0,o.jsx)(t.code,{children:"Nodepool"})," class, provide the ",(0,o.jsx)(t.code,{children:"user_id"})," and ",(0,o.jsx)(t.code,{children:"nodepool_id"})," parameters."]}),"\n",(0,o.jsx)(r.A,{children:(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:h})})}),"\n",(0,o.jsx)(t.h2,{id:"deployment-operations",children:"Deployment Operations"}),"\n",(0,o.jsx)(t.h3,{id:"create-a-deployment",children:"Create a Deployment"}),"\n",(0,o.jsxs)(t.p,{children:["To deploy a model within a nodepool, provide the ",(0,o.jsx)(t.code,{children:"deployment_id"})," and ",(0,o.jsx)(t.code,{children:"config_filepath"})," parameters to the ",(0,o.jsx)(t.code,{children:"create_deployment"})," method of the ",(0,o.jsx)(t.code,{children:"Nodepool"})," class."]}),"\n",(0,o.jsx)(t.admonition,{type:"note",children:(0,o.jsx)(t.p,{children:"Each model or workflow can only have one deployment per nodepool."})}),"\n",(0,o.jsxs)(r.A,{children:[(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:m})}),(0,o.jsx)(s.A,{value:"bash",label:"Bash",children:(0,o.jsx)(i.A,{className:"language-yaml",children:f})})]}),"\n",(0,o.jsxs)(t.h3,{id:"initialize-the-deployment-class",children:["Initialize the ",(0,o.jsx)(t.code,{children:"Deployment"})," Class"]}),"\n",(0,o.jsxs)(t.p,{children:["To initialize the ",(0,o.jsx)(t.code,{children:"Deployment"})," class, provide the ",(0,o.jsx)(t.code,{children:"user_id"})," and ",(0,o.jsx)(t.code,{children:"deployment_id"})," parameters."]}),"\n",(0,o.jsx)(r.A,{children:(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:y})})}),"\n",(0,o.jsx)(t.h2,{id:"predict-with-deployed-model",children:"Predict With Deployed Model"}),"\n",(0,o.jsx)(t.p,{children:"Once your model is deployed, it can be used to make predictions by calling the appropriate prediction methods. Clarifai's Compute Orchestration system offers different types of prediction calls to suit various use cases."}),"\n",(0,o.jsx)(t.admonition,{title:"important",type:"warning",children:(0,o.jsxs)(t.p,{children:["To ensure proper routing and execution, you must specify the ",(0,o.jsx)(t.code,{children:"deployment_id"})," parameter. This parameter is essential in directing prediction requests to the appropriate cluster. For example, you can assign a specific deployment ID to route requests to a GCP cluster, a different ID for an AWS cluster, and yet another for an on-premises deployment. This is important for performance optimization, scalability, and better load balancing."]})}),"\n",(0,o.jsx)(t.admonition,{type:"tip",children:(0,o.jsxs)(t.p,{children:["The following examples illustrate how to make predictions with inputs provided as publicly accessible URLs. ",(0,o.jsx)(t.a,{href:"https://docs.clarifai.com/sdk/Inference-from-AI-Models/",children:"Click here"})," to learn how to make predictions using other types of inputs and models."]})}),"\n",(0,o.jsx)(t.h3,{id:"unary-unary-predict-call",children:"Unary-Unary Predict Call"}),"\n",(0,o.jsx)(t.p,{children:"This is the simplest type of prediction. In this method, a single input is sent to the model, and it returns a single response. This is ideal for tasks where a quick, non-streaming prediction is required, such as classifying an image."}),"\n",(0,o.jsx)(t.p,{children:"It supports the following prediction methods:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"predict_by_url"}),"  \u2014 Use a publicly accessible URL for the input."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"predict_by_bytes"})," \u2014 Pass raw input data directly."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"predict_by_filepath"})," \u2014 Provide the local file path for the input."]}),"\n"]}),"\n",(0,o.jsxs)(r.A,{children:[(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:_})}),(0,o.jsx)(s.A,{value:"bash",label:"Bash",children:(0,o.jsx)(i.A,{className:"language-yaml",children:x})})]}),"\n",(0,o.jsx)(t.h3,{id:"unary-stream-predict-call",children:"Unary-Stream Predict Call"}),"\n",(0,o.jsxs)(t.p,{children:["The ",(0,o.jsx)(t.strong,{children:"Unary-Stream"})," predict call processes a single input, but returns a stream of responses. It is particularly useful for tasks where multiple outputs are generated from a single input, such as generating text completions from a prompt."]}),"\n",(0,o.jsx)(t.p,{children:"It supports the following prediction methods:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"generate_by_url"}),"  \u2014 Provide a publicly accessible URL and handle the streamed responses iteratively."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"generate_by_bytes"})," \u2014 Use raw input data."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"generate_by_filepath"})," \u2014 Use a local file path for the input."]}),"\n"]}),"\n",(0,o.jsx)(r.A,{children:(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:g})})}),"\n",(0,o.jsx)(t.h3,{id:"stream-stream-predict-call",children:"Stream-Stream Predict Call"}),"\n",(0,o.jsxs)(t.p,{children:["The ",(0,o.jsx)(t.strong,{children:"stream-stream"})," predict call enables bidirectional streaming of both inputs and outputs, making it highly effective for processing large datasets or real-time applications."]}),"\n",(0,o.jsx)(t.p,{children:"In this setup, multiple inputs can be continuously sent to the model, and the corresponding multiple predictions are streamed back in real-time. This is ideal for tasks like real-time video processing/predictions or live sensor data analysis."}),"\n",(0,o.jsx)(t.p,{children:"It supports the following prediction methods:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"stream_by_url"})," \u2014 Stream a list of publicly accessible URLs and receive a stream of predictions. It takes an iterator of inputs and returns a stream of predictions."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"stream_by_bytes"})," \u2014 Stream raw input data."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"stream_by_filepath"})," \u2014 Stream inputs from local file paths."]}),"\n"]}),"\n",(0,o.jsx)(r.A,{children:(0,o.jsx)(s.A,{value:"python",label:"Python",children:(0,o.jsx)(i.A,{className:"language-python",children:j})})})]})}function k(e={}){const{wrapper:t}={...(0,l.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(I,{...e})}):I(e)}},19365:(e,t,n)=>{n.d(t,{A:()=>s});n(96540);var o=n(18215);const l={tabItem:"tabItem_Ymn6"};var r=n(74848);function s(e){let{children:t,hidden:n,className:s}=e;return(0,r.jsx)("div",{role:"tabpanel",className:(0,o.A)(l.tabItem,s),hidden:n,children:t})}},11470:(e,t,n)=>{n.d(t,{A:()=>v});var o=n(96540),l=n(18215),r=n(23104),s=n(56347),i=n(205),a=n(57485),c=n(31682),d=n(70679);function u(e){return o.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(e){const{values:t,children:n}=e;return(0,o.useMemo)((()=>{const e=t??function(e){return u(e).map((e=>{let{props:{value:t,label:n,attributes:o,default:l}}=e;return{value:t,label:n,attributes:o,default:l}}))}(n);return function(e){const t=(0,c.X)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function h(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function m(e){let{queryString:t=!1,groupId:n}=e;const l=(0,s.W6)(),r=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,a.aZ)(r),(0,o.useCallback)((e=>{if(!r)return;const t=new URLSearchParams(l.location.search);t.set(r,e),l.replace({...l.location,search:t.toString()})}),[r,l])]}function f(e){const{defaultValue:t,queryString:n=!1,groupId:l}=e,r=p(e),[s,a]=(0,o.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!h({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const o=n.find((e=>e.default))??n[0];if(!o)throw new Error("Unexpected error: 0 tabValues");return o.value}({defaultValue:t,tabValues:r}))),[c,u]=m({queryString:n,groupId:l}),[f,y]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[l,r]=(0,d.Dv)(n);return[l,(0,o.useCallback)((e=>{n&&r.set(e)}),[n,r])]}({groupId:l}),_=(()=>{const e=c??f;return h({value:e,tabValues:r})?e:null})();(0,i.A)((()=>{_&&a(_)}),[_]);return{selectedValue:s,selectValue:(0,o.useCallback)((e=>{if(!h({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);a(e),u(e),y(e)}),[u,y,r]),tabValues:r}}var y=n(92303);const _={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=n(74848);function g(e){let{className:t,block:n,selectedValue:o,selectValue:s,tabValues:i}=e;const a=[],{blockElementScrollPositionUntilNextRender:c}=(0,r.a_)(),d=e=>{const t=e.currentTarget,n=a.indexOf(t),l=i[n].value;l!==o&&(c(t),s(l))},u=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const n=a.indexOf(e.currentTarget)+1;t=a[n]??a[0];break}case"ArrowLeft":{const n=a.indexOf(e.currentTarget)-1;t=a[n]??a[a.length-1];break}}t?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.A)("tabs",{"tabs--block":n},t),children:i.map((e=>{let{value:t,label:n,attributes:r}=e;return(0,x.jsx)("li",{role:"tab",tabIndex:o===t?0:-1,"aria-selected":o===t,ref:e=>a.push(e),onKeyDown:u,onClick:d,...r,className:(0,l.A)("tabs__item",_.tabItem,r?.className,{"tabs__item--active":o===t}),children:n??t},t)}))})}function j(e){let{lazy:t,children:n,selectedValue:l}=e;const r=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=r.find((e=>e.props.value===l));return e?(0,o.cloneElement)(e,{className:"margin-top--md"}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:r.map(((e,t)=>(0,o.cloneElement)(e,{key:t,hidden:e.props.value!==l})))})}function b(e){const t=f(e);return(0,x.jsxs)("div",{className:(0,l.A)("tabs-container",_.tabList),children:[(0,x.jsx)(g,{...t,...e}),(0,x.jsx)(j,{...t,...e})]})}function v(e){const t=(0,y.A)();return(0,x.jsx)(b,{...e,children:u(e.children)},String(t))}}}]);