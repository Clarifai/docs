"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[7789],{10354:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-7-af07f85fc948f62aed1c033ab86332f8.png"},24918:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-3-4c77455383f746187b5511ca297dd530.png"},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>l});var i=t(96540);const a={},o=i.createContext(a);function s(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),i.createElement(o.Provider,{value:n},e.children)}},31899:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-6-7a263e2ec8999af0f31464e561be89b0.png"},35091:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-4-1-72c6a5ecf22d4c1f1560545689c3cbff.png"},39509:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-8-4f99446c141bab643451998a8746e0ab.png"},42964:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"portal-guide/input-viewer/annotate","title":"Manual Annotation","description":"Create, get, update, and delete annotations on Input-Viewer page","source":"@site/docs/portal-guide/input-viewer/annotate.md","sourceDirName":"portal-guide/input-viewer","slug":"/portal-guide/input-viewer/annotate","permalink":"/portal-guide/input-viewer/annotate","draft":false,"unlisted":false,"editUrl":"https://github.com/Clarifai/docs/blob/main/docs/portal-guide/input-viewer/annotate.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"Create, get, update, and delete annotations on Input-Viewer page","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Single Input-Viewer","permalink":"/portal-guide/input-viewer/"},"next":{"title":"AI-Assisted Labeling","permalink":"/portal-guide/input-viewer/ai-assist"}}');var a=t(74848),o=t(28453);const s={description:"Create, get, update, and delete annotations on Input-Viewer page",sidebar_position:1},l="Manual Annotation",r={},c=[{value:"Classification Labeling",id:"classification-labeling",level:2},{value:"Image Classification",id:"image-classification",level:3},{value:"View Individual Annotators",id:"view-individual-annotators",level:4},{value:"Update Annotations",id:"update-annotations",level:4},{value:"Delete Annotations",id:"delete-annotations",level:4},{value:"Text Classification",id:"text-classification",level:3},{value:"Video Classification",id:"video-classification",level:3},{value:"Detection Labeling",id:"detection-labeling",level:2},{value:"Detection for Still Images",id:"detection-for-still-images",level:3},{value:"Detection for Video",id:"detection-for-video",level:3},{value:"Segmentation Labeling",id:"segmentation-labeling",level:2},{value:"Masks Labeling",id:"masks-labeling",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"manual-annotation",children:"Manual Annotation"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Create, get, update, and delete annotations on Input-Viewer page"})}),"\n",(0,a.jsx)("hr",{}),"\n",(0,a.jsxs)(n.p,{children:["Labeling, or annotation, involves assigning one or more descriptive tags or keywords \u2014 known as ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/inputs-manager/concepts",children:"concepts"})," \u2014 to accurately characterize the attributes or content of your inputs."]}),"\n",(0,a.jsx)(n.p,{children:"For example, annotations can indicate whether an image contains a dog or a cat, identify the spoken words in an audio recording, or recognize cracks in a concrete block."}),"\n",(0,a.jsx)(n.p,{children:"Within the Input-Viewer page, you can add annotations to inputs, get the ones already added to inputs, remove them from inputs, or carry out other management tasks with them."}),"\n",(0,a.jsx)(n.p,{children:"We support different types of labeling methods, each suited for different tasks and data characteristics. This lets you create high-quality training data depending on the objective you want your AI model to achieve."}),"\n",(0,a.jsx)(n.p,{children:"These are the different types of labels we support for your image, video, and text inputs:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Classification"})," \u2014 Categorizes images, videos, and texts into categories;"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Detection"})," \u2014 Detects where an object of interest is and draws a bounding box around it;"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Segmentation"})," (polygons for segmentation) \u2014 Outlines the exact shape or contour of the object;"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Masks"})," \u2014  A type of image segmentation that defines the exact boundaries of an object at a pixel level."]}),"\n"]}),"\n",(0,a.jsx)(n.admonition,{title:"AI-assisted labeling",type:"info",children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/annotate/ai-assist",children:"Click here"})," to learn how to use the AI-assisted labeling feature to carry out different label types."]})}),"\n",(0,a.jsx)(n.admonition,{title:"Labeling Tasks Tool",type:"info",children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/annotate/labeling-tools",children:"Click here"})," to learn how to use the Labeling Tasks tool to carry out different label types."]})}),"\n",(0,a.jsxs)(n.p,{children:["To carry out manual annotation on the Input-Viewer page, ensure the page's mode is set to ",(0,a.jsx)(n.strong,{children:"Annotate"}),", which is the default status. You can find the mode settings in the upper-left corner of the page."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(77092).A+"",width:"1906",height:"902"})}),"\n",(0,a.jsx)(n.h2,{id:"classification-labeling",children:"Classification Labeling"}),"\n",(0,a.jsx)(n.p,{children:"The classification label type lets you assign annotations to an entire image, a single frame of video, or a piece of text."}),"\n",(0,a.jsx)(n.h3,{id:"image-classification",children:"Image Classification"}),"\n",(0,a.jsxs)(n.p,{children:["To manually classify an image on the Input-Viewer page, start by clicking the ",(0,a.jsx)(n.strong,{children:"Select / Edit"})," tool in the navigation bar (this tool is selected by default)."]}),"\n",(0,a.jsxs)(n.p,{children:["Next, use the ",(0,a.jsx)(n.strong,{children:"Select label"})," menu  that drops down to select the concept you want to use to annotate the image \u2014 that is, if the concept already exists in your app."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(62367).A+"",width:"1907",height:"886"})}),"\n",(0,a.jsxs)(n.p,{children:["If you want to annotate an image with a new concept that does not already exist in your app, click the ",(0,a.jsx)(n.strong,{children:"+"})," (plus) button in the dropdown menu and type the concept's name in the field. Then, click the dropdown box that appears with the concept name beneath that field."]}),"\n",(0,a.jsx)(n.p,{children:"The new concept will be added to your app and labeled with your input."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(24918).A+"",width:"1320",height:"903"})}),"\n",(0,a.jsxs)(n.p,{children:["You can add as many annotations as you want. The added annotations will appear in the ",(0,a.jsx)(n.strong,{children:"Select label"})," dropdown menu as well as in the ",(0,a.jsx)(n.strong,{children:"Classifications"})," pane in the right sidebar of the page."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(74889).A+"",width:"1904",height:"887"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Alternatively, you can manually classify an image on the Input Viewer page by navigating to the ",(0,a.jsx)(n.strong,{children:"Classifications"})," pane. Then, use the ",(0,a.jsx)(n.strong,{children:"Select or add concepts"})," search box to choose or add concepts for annotating your inputs, as described earlier."]})}),"\n",(0,a.jsx)(n.h4,{id:"view-individual-annotators",children:"View Individual Annotators"}),"\n",(0,a.jsxs)(n.p,{children:["If you hover over the person icon on an annotation field in the ",(0,a.jsx)(n.strong,{children:"Classifications"})," pane, you can view the annotator(s) who added that annotation. The displayed number indicates how many annotators labeled that input."]}),"\n",(0,a.jsx)(n.h4,{id:"update-annotations",children:"Update Annotations"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(35091).A+"",width:"1911",height:"898"})}),"\n",(0,a.jsxs)(n.p,{children:["To update an annotation, hover over its field in the right sidebar and click the pencil icon that appears. Next, enter a new name for the annotation in the text field that appears, then click the ",(0,a.jsx)(n.strong,{children:"Update"})," button to save your changes."]}),"\n",(0,a.jsxs)(n.p,{children:["The new concept will be added to your app and annotated with your input. This newly added concept is referred to as a ",(0,a.jsx)(n.strong,{children:"concept relation"}),", with the original concept displayed as a superscript next to it. As a result, if you create an annotation using the original concept, the updated concept will be used instead."]}),"\n",(0,a.jsx)(n.p,{children:"Note that if you edit the concept relation back to its original value, the existing concept relation annotation on the input will be removed. It will only be removed from the input, and not from your app."}),"\n",(0,a.jsx)(n.h4,{id:"delete-annotations",children:"Delete Annotations"}),"\n",(0,a.jsx)(n.p,{children:"There are several ways of deleting an annotation via the Input-Viewer page:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"If you hover over an annotation field, a delete icon will appear that you can use to remove the annotation. Note that deleting an annotation only removes it from the input; it does not delete the concept from your app."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:"You can remove an annotation by deselecting the checkmark next to it in the annotation field."}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:['Additionally, each annotation is assigned a hotkey number. Clicking this number will delete the corresponding annotation from the input. For example, clicking "2" will remove the ',(0,a.jsx)(n.strong,{children:"sheep"})," annotation from the image. Up to 20 hotkeys can be assigned to an input."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"text-classification",children:"Text Classification"}),"\n",(0,a.jsx)(n.p,{children:"You can classify your text inputs into predefined categories in the same way as described earlier for image classification."}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["Ensure you select the appropriate ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/workflows/base-workflows",children:"base workflow"})," when creating an app for text inputs."]})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(50688).A+"",width:"1910",height:"894"})}),"\n",(0,a.jsx)(n.h3,{id:"video-classification",children:"Video Classification"}),"\n",(0,a.jsxs)(n.p,{children:["Support for video labeling within this tool is coming soon. If you need to label videos, you can create a ",(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/labeling-tasks/create-a-task",children:"Labeling Task"})," and label a dataset with videos."]}),"\n",(0,a.jsx)(n.h2,{id:"detection-labeling",children:"Detection Labeling"}),"\n",(0,a.jsx)(n.p,{children:"The detection label type lets you identify the objects in your inputs and also draw bounding boxes around them."}),"\n",(0,a.jsx)(n.h3,{id:"detection-for-still-images",children:"Detection for Still Images"}),"\n",(0,a.jsxs)(n.p,{children:["To manually add detection labels on the Input-Viewer page, start by clicking the ",(0,a.jsx)(n.strong,{children:"Bounding Box"})," tool in the navigation bar."]}),"\n",(0,a.jsxs)(n.p,{children:["Next, use the ",(0,a.jsx)(n.strong,{children:"Select label"})," menu that drops down to select the concept you want to use to annotate the image \u2014 that is, if the concept already exists in your app. If it's not already existing, you'll need to add it as described earlier."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(98284).A+"",width:"1908",height:"896"})}),"\n",(0,a.jsx)(n.p,{children:"Next, draw a rectangle as accurately as possible around the region of interest in the image. You can also create cascading bounding boxes; that is, a hierarchy of annotations where one bounding box is nested or dependent on another."}),"\n",(0,a.jsx)(n.p,{children:"After creating the bounding box, you can edit it by clicking on it until dotted lines appear around the edges. This will enable you to resize, reposition, or adjust the bounding box to better suit your needs."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(31899).A+"",width:"1892",height:"893"})}),"\n",(0,a.jsx)(n.admonition,{title:"drawing mode",type:"note",children:(0,a.jsxs)(n.p,{children:["After selecting a concept for labeling, the drawing mode will be activated, allowing you to draw bounding boxes to annotate your image(s) easily. The drawing mode box, located in the upper-right corner of the canvas, displays the concept currently in use for detection labeling. To exit drawing mode, simply click the ",(0,a.jsx)(n.strong,{children:"Exit"})," button."]})}),"\n",(0,a.jsxs)(n.p,{children:["You can add as many detection annotations as you want for each concept. The added annotations will appear in the ",(0,a.jsx)(n.strong,{children:"Select label"})," dropdown menu as well as in the ",(0,a.jsx)(n.strong,{children:"Objects"})," pane in the right sidebar of the page."]}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.strong,{children:"Objects"})," pane displays categories of concepts used for annotations, along with individual annotation instances. It supports several detection labeling activities, including:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Annotation count display"}),' \u2014 The pane shows the number of annotations for each instance. For example, "Objects(2)" indicates that two concept categories were used for the detection annotations in the image, while "sheep(4)" means that four instances are labeled with the ',(0,a.jsx)(n.code,{children:"sheep"}),' concept. Individual annotations are numbered sequentially. For example, "sheep.1" represents the first annotation labeled with the ',(0,a.jsx)(n.code,{children:"sheep"}),' concept, "sheep.2" the second annotation, and so on.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Hotkey assignment"}),' \u2014 Each concept is assigned a hotkey. Pressing a hotkey initiates labeling for that concept. For example, pressing "1" enables you to draw bounding boxes labeled with the ',(0,a.jsx)(n.code,{children:"sheep"})," concept. Up to 20 hotkeys can be assigned to your concepts."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Category-specific actions"})," \u2014 These are the actions you can complete on an annotation category:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Clicking the bounding box icon in a category field activates the drawing mode, which allows you to create annotations with the selected concept."}),"\n",(0,a.jsx)(n.li,{children:"Hovering over a category of annotations reveals these icons: pencil icon for updating the concept name (as described earlier), eye icon for hiding all the annotations in that category, and delete icon for removing all the annotations in that category."}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Instance-specific actions"})," \u2014 These are the actions you can complete on an individual annotation instance:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"To delete an individual annotation, deselect its checkmark."}),"\n",(0,a.jsx)(n.li,{children:"Hovering over the person icon on an annotation instance shows the annotator(s) responsible for that annotation. The number displayed represents how many annotators labeled the input."}),"\n",(0,a.jsx)(n.li,{children:"Hovering over an individual annotation instance reveals these icons: pencil icon for reassigning the annotation to a different concept, eye icon for hiding the specific annotation instance, and delete icon for removing the specific annotation instance."}),"\n",(0,a.jsx)(n.li,{children:"Clicking an individual annotation instance highlights its corresponding bounding box in the canvas, enabling easy editing or deletion (by clicking the delete button on the keyboard)."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"detection-for-video",children:"Detection for Video"}),"\n",(0,a.jsx)(n.p,{children:"Support for video labeling is coming soon."}),"\n",(0,a.jsx)(n.admonition,{title:"object mode",type:"info",children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/portal-guide/inputs-manager/#object-mode",children:"Click here"})," to learn how to get the objects that have been labeled on your inputs using the Object Mode of the Inputs-Manager page."]})}),"\n",(0,a.jsx)(n.h2,{id:"segmentation-labeling",children:"Segmentation Labeling"}),"\n",(0,a.jsx)(n.p,{children:"The segmentation label type lets you outline a boundary of an object using a series of vertices that define a closed polygonal shape. It's ideal for annotating irregularly shaped areas or objects."}),"\n",(0,a.jsxs)(n.p,{children:["To manually add segmentation labels to an image on the Input-Viewer page, first click the ",(0,a.jsx)(n.strong,{children:"Polygon"})," tool on the navigation bar."]}),"\n",(0,a.jsxs)(n.p,{children:["Next, use the ",(0,a.jsx)(n.strong,{children:"Select label"})," menu that drops down to select the concept you want to use to annotate the image \u2014 that is, if the concept already exists in your app. If it's not already existing, you'll need to add it as described earlier."]}),"\n",(0,a.jsx)(n.p,{children:"Next, use the dots to draw a contour as closely as possible around the image's region of interest."}),"\n",(0,a.jsx)(n.p,{children:"After creating the initial shape by placing your dots, you'll need to close the loop. Simply click on the first dot you made again, and this action will close the loop, completing the polygon."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(39509).A+"",width:"1913",height:"885"})}),"\n",(0,a.jsx)(n.p,{children:"Note that segmentation labeling works just as the previously described detection labeling. For example, if you click the polygon icon in an annotation category field, the drawing mode will be activated, enabling you to create annotations with the selected concept."}),"\n",(0,a.jsx)(n.h2,{id:"masks-labeling",children:"Masks Labeling"}),"\n",(0,a.jsx)(n.p,{children:"The mask label type lets you label each pixel within the region of interest. It provides pixel-level labeling that allows you to precisely identify and delineate objects within an image."}),"\n",(0,a.jsx)(n.p,{children:"Currently, you can only minimally review existing image mask annotations on the Input-Viewer page. After creating mask images via the API and uploading them to our platform, you can view them on that page."}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://docs.clarifai.com/api-guide/annotate/annotations#annotate-images-with-mask",children:"Click here"})," to learn how to add image mask annotations using our API."]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:"You can delete an entire image mask annotation for an input directly from the Input-Viewer page. However, the Input-Viewer page does not currently support creating or editing mask annotations."})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:t(10354).A+"",width:"893",height:"201"})})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},50688:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-5-d60c6153d773120214321e7d42920d33.png"},62367:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-2-fbcbffa8014f1056541ae4d1dc3bd7b7.png"},74889:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-4-c0faf6c73f44c937a70f75d5d9b3c94a.png"},77092:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/label-types-1-b17db9297e8491d3d892616119996d3e.png"},98284:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/annotate-9-4ee8926346be1a0dc77228b630ee032b.png"}}]);