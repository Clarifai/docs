"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[5404],{14795:(e,n,t)=>{t.d(n,{A:()=>v});t(96540);var r=t(18215),s=t(26972),a=t(28774),i=t(53465),o=t(16654),l=t(21312),c=t(51107);const d={cardContainer:"cardContainer_fWXF",cardTitle:"cardTitle_rnsV",cardDescription:"cardDescription_PWke"};var u=t(74848);function h({className:e,href:n,children:t}){return(0,u.jsx)(a.A,{href:n,className:(0,r.A)("card padding--lg",d.cardContainer,e),children:t})}function m({className:e,href:n,icon:t,title:s,description:a}){return(0,u.jsxs)(h,{href:n,className:e,children:[(0,u.jsxs)(c.A,{as:"h2",className:(0,r.A)("text--truncate",d.cardTitle),title:s,children:[t," ",s]}),a&&(0,u.jsx)("p",{className:(0,r.A)("text--truncate",d.cardDescription),title:a,children:a})]})}function f({item:e}){const n=(0,s.Nr)(e),t=function(){const{selectMessage:e}=(0,i.W)();return n=>e(n,(0,l.T)({message:"1 item|{count} items",id:"theme.docs.DocCard.categoryDescription.plurals",description:"The default description for a category card in the generated index about how many items this category includes"},{count:n}))}();return n?(0,u.jsx)(m,{className:e.className,href:n,icon:"\ud83d\uddc3\ufe0f",title:e.label,description:e.description??t(e.items.length)}):null}function p({item:e}){const n=(0,o.A)(e.href)?"\ud83d\udcc4\ufe0f":"\ud83d\udd17",t=(0,s.cC)(e.docId??void 0);return(0,u.jsx)(m,{className:e.className,href:e.href,icon:n,title:e.label,description:e.description??t?.description})}function g({item:e}){switch(e.type){case"link":return(0,u.jsx)(p,{item:e});case"category":return(0,u.jsx)(f,{item:e});default:throw new Error(`unknown item type ${JSON.stringify(e)}`)}}const x={docCardListItem:"docCardListItem_W1sv"};function j({className:e}){const n=(0,s.a4)();return(0,u.jsx)(v,{items:n,className:e})}function w({item:e}){return(0,u.jsx)("article",{className:(0,r.A)(x.docCardListItem,"col col--6"),children:(0,u.jsx)(g,{item:e})})}function v(e){const{items:n,className:t}=e;if(!n)return(0,u.jsx)(j,{...e});const a=(0,s.d1)(n);return(0,u.jsx)("section",{className:(0,r.A)("row",t),children:a.map((e,n)=>(0,u.jsx)(w,{item:e},n))})}},28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>o});var r=t(96540);const s={},a=r.createContext(s);function i(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),r.createElement(a.Provider,{value:n},e.children)}},53465:(e,n,t)=>{t.d(n,{W:()=>c});var r=t(96540),s=t(44586);const a=["zero","one","two","few","many","other"];function i(e){return a.filter(n=>e.includes(n))}const o={locale:"en",pluralForms:i(["one","other"]),select:e=>1===e?"one":"other"};function l(){const{i18n:{currentLocale:e}}=(0,s.A)();return(0,r.useMemo)(()=>{try{return function(e){const n=new Intl.PluralRules(e);return{locale:e,pluralForms:i(n.resolvedOptions().pluralCategories),select:e=>n.select(e)}}(e)}catch(n){return console.error(`Failed to use Intl.PluralRules for locale "${e}".\nDocusaurus will fallback to the default (English) implementation.\nError: ${n.message}\n`),o}},[e])}function c(){const e=l();return{selectMessage:(n,t)=>function(e,n,t){const r=e.split("|");if(1===r.length)return r[0];r.length>t.pluralForms.length&&console.error(`For locale=${t.locale}, a maximum of ${t.pluralForms.length} plural forms are expected (${t.pluralForms.join(",")}), but the message contains ${r.length}: ${e}`);const s=t.select(n),a=t.pluralForms.indexOf(s);return r[Math.min(a,r.length-1)]}(t,n,e)}}},68026:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>m,frontMatter:()=>l,metadata:()=>r,toc:()=>u});const r=JSON.parse('{"id":"create/models/transfer-learning/README","title":"Transfer Learning","description":"Build upon pre-existing knowledge, streamline the learning process for novel tasks","source":"@site/docs/create/models/transfer-learning/README.mdx","sourceDirName":"create/models/transfer-learning","slug":"/create/models/transfer-learning/","permalink":"/create/models/transfer-learning/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"description":"Build upon pre-existing knowledge, streamline the learning process for novel tasks"},"sidebar":"tutorialSidebar","previous":{"title":"Create and Train Models","permalink":"/create/models/"},"next":{"title":"Text Classifier","permalink":"/create/models/transfer-learning/text-classifier"}}');var s=t(74848),a=t(28453),i=t(14795),o=t(95068);const l={description:"Build upon pre-existing knowledge, streamline the learning process for novel tasks"},c="Transfer Learning",d={},u=[];function h(e){const n={a:"a",blockquote:"blockquote",h1:"h1",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"transfer-learning",children:"Transfer Learning"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Build upon pre-existing knowledge, streamline the learning process for novel tasks"})}),"\n",(0,s.jsx)("hr",{}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Input"}),": Images, videos, and texts"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Output"}),": ",(0,s.jsx)(n.a,{href:"https://docs.clarifai.com/create-manage/concepts/",children:"Concepts"})]}),"\n",(0,s.jsx)(n.p,{children:'A transfer-learning model, which we previously called an "embedding-classifier", is a type of machine learning model that uses an embedding layer to represent images, videos, or texts as low-dimensional vectors, and then uses a classifier layer to predict the class of the input.'}),"\n",(0,s.jsx)(n.p,{children:"The embedding layer takes the input image, video, or text, and converts it into a vector of numbers, where each number represents the similarity of the input to a particular word or concept. The classifier layer then takes the embedding vector as input and predicts the class of the input."}),"\n",(0,s.jsx)(n.p,{children:"A key advantage of transfer-learning models is that they can be trained on large datasets of images, videos, or texts without requiring a lot of computational resources. This is because the embedding layer can be pre-trained on a large dataset of images, videos, or texts, and then the classifier layer can be trained on a smaller dataset of labeled images, videos, or texts."}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note:"})," Essentially, ",(0,s.jsx)(n.a,{href:"https://www.clarifai.com/blog/what-is-transfer-learning",children:"transfer learning"})," leverages the knowledge gained from a pre-trained model to facilitate the learning process of a new model for a related problem. The pre-trained embedding model serves as a feature extractor that has already learned useful features from a large dataset. This knowledge is transferred to the classifier layers, enabling effective classification with minimal training data."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"You may choose the transfer learning model type if you want to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Seamlessly transfer the knowledge gained from existing models to solve problems without necessarily having to train a new model from scratch."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Take advantage of a model that has been trained on a similar task, such as object recognition in images. Then, fine-tune this pre-trained model to recognize the specific classes that align with your objectives."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Get results in seconds, not minutes or hours \u2014 allowing you to achieve significant progress with minimal training data. You do not need many inputs to get started creating a custom model using our transfer learning technology. You can even start with 10 inputs and add more as needed."}),"\n"]}),"\n"]}),"\n","\n",(0,s.jsx)(i.A,{items:(0,o.$S)().items})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},95068:(e,n,t)=>{t.d(n,{$S:()=>r});t(44586);function r(...e){return t(48295).$S(...e)}}}]);