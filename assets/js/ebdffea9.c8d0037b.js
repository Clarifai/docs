"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[7955],{85162:(e,n,t)=>{t.d(n,{Z:()=>i});var a=t(67294),r=t(86010);const s="tabItem_Ymn6";function i(e){let{children:n,hidden:t,className:i}=e;return a.createElement("div",{role:"tabpanel",className:(0,r.Z)(s,i),hidden:t},n)}},74866:(e,n,t)=>{t.d(n,{Z:()=>D});var a=t(87462),r=t(67294),s=t(86010),i=t(12466),o=t(76775),l=t(91980),u=t(67392),c=t(50012);function d(e){return function(e){return r.Children.map(e,(e=>{if((0,r.isValidElement)(e)&&"value"in e.props)return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))}(e).map((e=>{let{props:{value:n,label:t,attributes:a,default:r}}=e;return{value:n,label:t,attributes:a,default:r}}))}function p(e){const{values:n,children:t}=e;return(0,r.useMemo)((()=>{const e=n??d(t);return function(e){const n=(0,u.l)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function _(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function m(e){let{queryString:n=!1,groupId:t}=e;const a=(0,o.k6)(),s=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,l._X)(s),(0,r.useCallback)((e=>{if(!s)return;const n=new URLSearchParams(a.location.search);n.set(s,e),a.replace({...a.location,search:n.toString()})}),[s,a])]}function E(e){const{defaultValue:n,queryString:t=!1,groupId:a}=e,s=p(e),[i,o]=(0,r.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!_({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const a=t.find((e=>e.default))??t[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:n,tabValues:s}))),[l,u]=m({queryString:t,groupId:a}),[d,E]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[a,s]=(0,c.Nk)(t);return[a,(0,r.useCallback)((e=>{t&&s.set(e)}),[t,s])]}({groupId:a}),h=(()=>{const e=l??d;return _({value:e,tabValues:s})?e:null})();(0,r.useLayoutEffect)((()=>{h&&o(h)}),[h]);return{selectedValue:i,selectValue:(0,r.useCallback)((e=>{if(!_({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);o(e),u(e),E(e)}),[u,E,s]),tabValues:s}}var h=t(72389);const g="tabList__CuJ",f="tabItem_LNqP";function v(e){let{className:n,block:t,selectedValue:o,selectValue:l,tabValues:u}=e;const c=[],{blockElementScrollPositionUntilNextRender:d}=(0,i.o5)(),p=e=>{const n=e.currentTarget,t=c.indexOf(n),a=u[t].value;a!==o&&(d(n),l(a))},_=e=>{var n;let t=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{const n=c.indexOf(e.currentTarget)+1;t=c[n]??c[0];break}case"ArrowLeft":{const n=c.indexOf(e.currentTarget)-1;t=c[n]??c[c.length-1];break}}null==(n=t)||n.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.Z)("tabs",{"tabs--block":t},n)},u.map((e=>{let{value:n,label:t,attributes:i}=e;return r.createElement("li",(0,a.Z)({role:"tab",tabIndex:o===n?0:-1,"aria-selected":o===n,key:n,ref:e=>c.push(e),onKeyDown:_,onClick:p},i,{className:(0,s.Z)("tabs__item",f,null==i?void 0:i.className,{"tabs__item--active":o===n})}),t??n)})))}function I(e){let{lazy:n,children:t,selectedValue:a}=e;if(t=Array.isArray(t)?t:[t],n){const e=t.find((e=>e.props.value===a));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},t.map(((e,n)=>(0,r.cloneElement)(e,{key:n,hidden:e.props.value!==a}))))}function b(e){const n=E(e);return r.createElement("div",{className:(0,s.Z)("tabs-container",g)},r.createElement(v,(0,a.Z)({},e,n)),r.createElement(I,(0,a.Z)({},e,n)))}function D(e){const n=(0,h.Z)();return r.createElement(b,(0,a.Z)({key:String(n)},e))}},27464:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>u,default:()=>m,frontMatter:()=>l,metadata:()=>c,toc:()=>p});var a=t(87462),r=(t(67294),t(3905)),s=t(74866),i=t(85162),o=t(90814);const l={description:"Learn to interpret model evaluations.",sidebar_position:1},u="Interpreting Evaluations",c={unversionedId:"api-guide/evaluate/interpreting-evaluations",id:"api-guide/evaluate/interpreting-evaluations",title:"Interpreting Evaluations",description:"Learn to interpret model evaluations.",source:"@site/docs/api-guide/evaluate/interpreting-evaluations.md",sourceDirName:"api-guide/evaluate",slug:"/api-guide/evaluate/interpreting-evaluations",permalink:"/api-guide/evaluate/interpreting-evaluations",draft:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{description:"Learn to interpret model evaluations.",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Evaluating Models",permalink:"/api-guide/evaluate/"},next:{title:"Improving Your Model",permalink:"/api-guide/evaluate/improving-your-model"}},d={},p=[{value:"Get Evaluation Results",id:"get-evaluation-results",level:2}],_={toc:p};function m(e){let{components:n,...t}=e;return(0,r.kt)("wrapper",(0,a.Z)({},_,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"interpreting-evaluations"},"Interpreting Evaluations"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Learn to interpret model evaluations")),(0,r.kt)("hr",null),(0,r.kt)("h2",{id:"get-evaluation-results"},"Get Evaluation Results"),(0,r.kt)("p",null,"Below is an example of how you would get the evaluation results of a specific version of a custom model. "),(0,r.kt)("p",null,"You can use the results to assess the performance of your model. "),(0,r.kt)("p",null,"Note that the initialization code used here is outlined in detail on the ",(0,r.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/api-guide/api-overview/api-clients/#client-installation-instructions"},"client installation page.")),(0,r.kt)(s.Z,{mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)(o.Z,{className:"language-python",mdxType:"CodeBlock"},"####################################################################################\n# In this section, we set the user authentication, app ID, and the model's  \n# details. Change these strings to run your own example.\n###################################################################################\n\nUSER_ID = 'YOUR_USER_ID_HERE'\n# Your PAT (Personal Access Token) can be found in the portal under Authentification\nPAT = 'YOUR_PAT_HERE'\nAPP_ID = 'YOUR_APP_ID_HERE'\n# Change these to get your own model evaluation results\nMODEL_ID = 'YOUR_MODEL_ID_HERE'\nMODEL_VERSION_ID = 'YOUR_MODEL_VERSION_HERE'\n\n##########################################################################\n# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n##########################################################################\n\nfrom clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\nfrom clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\nfrom clarifai_grpc.grpc.api.status import status_code_pb2\n\nchannel = ClarifaiChannel.get_grpc_channel()\nstub = service_pb2_grpc.V2Stub(channel)\n\nmetadata = (('authorization', 'Key ' + PAT),)\n\nuserDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n\nget_model_version_metrics = stub.GetModelVersionMetrics(\n    service_pb2.GetModelVersionMetricsRequest(\n        user_app_id=userDataObject,\n        model_id=MODEL_ID,\n        version_id=MODEL_VERSION_ID      \n    ),\n    metadata=metadata\n)\n\nif get_model_version_metrics.status.code != status_code_pb2.SUCCESS:\n    print(get_model_version_metrics.status)\n    raise Exception(\"Get model metrics failed, status: \" + get_model_version_metrics.status.description)\n\nprint(get_model_version_metrics)")),(0,r.kt)(i.Z,{value:"js_rest",label:"JavaScript (REST)",mdxType:"TabItem"},(0,r.kt)(o.Z,{className:"language-javascript",mdxType:"CodeBlock"},"\x3c!--index.html file--\x3e\n\n<script>\n    ////////////////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, and the model's  \n    // details. Change these strings to run your own example.\n    ///////////////////////////////////////////////////////////////////////////////////////////\n\n    const USER_ID = 'YOUR_USER_ID_HERE';\n    // Your PAT (Personal Access Token) can be found in the portal under Authentification\n    const PAT = 'YOUR_PAT_HERE';\n    const APP_ID = 'YOUR_APP_ID_HERE';\n    // Change these to get your own model evaluation results\n    const MODEL_ID = 'YOUR_MODEL_ID_HERE';\n    const MODEL_VERSION_ID = 'YOUR_MODEL_VERSION_HERE';\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    const requestOptions = {\n        method: 'GET',\n        headers: {\n            'Accept': 'application/json',\n            'Authorization': 'Key ' + PAT\n        }\n    \n    };\n\n    fetch(`https://api.clarifai.com/v2/users/${USER_ID}/apps/${APP_ID}/models/${MODEL_ID}/versions/${MODEL_VERSION_ID}/metrics`, requestOptions)\n        .then(response => response.text())\n        .then(result => console.log(result))\n        .catch(error => console.log('error', error));\n\n<\/script>")),(0,r.kt)(i.Z,{value:"nodejs",label:"NodeJS",mdxType:"TabItem"},(0,r.kt)(o.Z,{className:"language-javascript",mdxType:"CodeBlock"},"//index.js file\n\n///////////////////////////////////////////////////////////////////////////////////\n// In this section, we set the user authentication, app ID, and the model's\n// details. Change these strings to run your own example.\n//////////////////////////////////////////////////////////////////////////////////\n\nconst USER_ID = 'YOUR_USER_ID_HERE';\n// Your PAT (Personal Access Token) can be found in the portal under Authentification\nconst PAT = 'YOUR_PAT_HERE';\nconst APP_ID = 'YOUR_APP_ID_HERE';\n// Change these to get your own model evaluation results\nconst MODEL_ID = 'YOUR_MODEL_ID_HERE';\nconst MODEL_VERSION_ID = 'YOUR_MODEL_VERSION_HERE';\n\n///////////////////////////////////////////////////////////////////////////////////\n// YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n///////////////////////////////////////////////////////////////////////////////////\n\nconst { ClarifaiStub, grpc } = require(\"clarifai-nodejs-grpc\");\n\nconst stub = ClarifaiStub.grpc();\n\n// This will be used by every Clarifai endpoint call\nconst metadata = new grpc.Metadata();\nmetadata.set(\"authorization\", \"Key \" + PAT);\n\nstub.GetModelVersionMetrics(\n  {\n    user_app_id: {\n      user_id: USER_ID,\n      app_id: APP_ID,\n    },\n\n    model_id: MODEL_ID,\n    model_version: MODEL_VERSION_ID,\n  },\n\n  metadata,\n\n  (err, response) => {\n    if (err) {\n      throw new Error(err);\n    }\n\n    if (response.status.code !== 10000) {\n      throw new Error(\"Get model metrics failed, status: \" + response.status.description);\n    }  \n\n    console.log(response);\n\n  }\n\n);\n")),(0,r.kt)(i.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)(o.Z,{className:"language-java",mdxType:"CodeBlock"},'package com.clarifai.example;\n\nimport com.clarifai.channel.ClarifaiChannel;\nimport com.clarifai.credentials.ClarifaiCallCredentials;\nimport com.clarifai.grpc.api.*;\nimport com.clarifai.grpc.api.status.StatusCode;\n\npublic class ClarifaiExample {\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // In this section, we set the user authentication, app ID, and the model\'s\n    // details. Change these strings to run your own example.\n    //////////////////////////////////////////////////////////////////////////////////\n\n    static final String USER_ID = "YOUR_USER_ID_HERE";\n    //Your PAT (Personal Access Token) can be found in the portal under Authentication\n    static final String PAT = "YOUR_PAT_HERE";\n    static final String APP_ID = "YOUR_APP_ID_HERE";\n    // Change these to get your own model evaluation results\n    static final String MODEL_ID = "YOUR_MODEL_ID_HERE";\n    static final String MODEL_VERSION_ID = "YOUR_MODEL_VERSION_HERE";\n\n    ///////////////////////////////////////////////////////////////////////////////////\n    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n    ///////////////////////////////////////////////////////////////////////////////////\n\n    public static void main(String[] args) {\n\n        V2Grpc.V2BlockingStub stub = V2Grpc.newBlockingStub(ClarifaiChannel.INSTANCE.getGrpcChannel())\n            .withCallCredentials(new ClarifaiCallCredentials(PAT));\n\n        SingleModelVersionResponse getModelVersionMetricsResponse = stub.getModelVersionMetrics(\n            GetModelVersionMetricsRequest.newBuilder()\n            .setUserAppId(UserAppIDSet.newBuilder().setUserId(USER_ID).setAppId(APP_ID))\n            .setModelId(MODEL_ID)\n            .setVersionId(MODEL_VERSION_ID)\n            .build()\n        );\n\n        if (getModelVersionMetricsResponse.getStatus().getCode() != StatusCode.SUCCESS) {\n            throw new RuntimeException("Get model metrics failed, status: " + getModelVersionMetricsResponse.getStatus());\n        }\n        \n        System.out.println(getModelVersionMetricsResponse);\n    }\n\n}')),(0,r.kt)(i.Z,{value:"curl",label:"cURL",mdxType:"TabItem"},(0,r.kt)(o.Z,{className:"language-bash",mdxType:"CodeBlock"},'curl -X GET "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/models/YOUR_MODEL_ID_HERE/versions/YOUR_MODEL_VERSION_ID_HERE/metrics" \\\n  -H "Authorization: Key YOUR_PAT_HERE" \\\n  -H "Content-Type: application/json" \n  '))),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Code Output Example"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-text"},'status {\n  code: SUCCESS\n  description: "Ok"\n  req_id: "c0168837e14b654f4487ab1846660ad9"\n}\nmodel_version {\n  id: "4fa241e368534224a07be38955a16a98"\n  created_at {\n    seconds: 1659633219\n    nanos: 356537000\n  }\n  status {\n    code: MODEL_TRAINED\n    description: "Model is trained and ready"\n  }\n  active_concept_count: 1\n  metrics {\n    status {\n      code: MODEL_EVALUATED\n      description: "Model was successfully evaluated."\n    }\n    summary {\n      macro_avg_roc_auc: 0.75\n      macro_std_roc_auc: 0.25\n      macro_avg_f1_score: 1.0\n      macro_avg_precision: 1.0\n      macro_avg_recall: 0.5\n    }\n  }\n  total_input_count: 24\n  completed_at {\n    seconds: 1659633222\n    nanos: 16763000\n  }\n  visibility {\n    gettable: PRIVATE\n  }\n  app_id: "deep-learning"\n  user_id: "ei2leoz3s3iy"\n  metadata {\n  }\n}\n'))),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"You can also learn how to interpret a model's evaluation results on the Portal ",(0,r.kt)("a",{parentName:"p",href:"https://docs.clarifai.com/portal-guide/evaluate/interpreting-evaluations"},"here"),". ")))}m.isMDXComponent=!0}}]);