"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[9316],{48819:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>A,contentTitle:()=>b,default:()=>I,frontMatter:()=>x,metadata:()=>a,toc:()=>v});const a=JSON.parse('{"id":"compute/providers/open-ai","title":"OpenAI","description":"Run inferences on Clarifai models using OpenAI","source":"@site/docs/compute/providers/open-ai.md","sourceDirName":"compute/providers","slug":"/compute/providers/open-ai","permalink":"/compute/providers/open-ai","draft":false,"unlisted":false,"editUrl":"https://github.com/Clarifai/docs/blob/main/docs/compute/providers/open-ai.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"Run inferences on Clarifai models using OpenAI","sidebar_position":1,"toc_max_heading_level":4},"sidebar":"tutorialSidebar","previous":{"title":"Providers","permalink":"/compute/providers/"},"next":{"title":"LiteLLM","permalink":"/compute/providers/litellm"}}');var o=t(74848),i=t(28453),s=t(65537),l=t(79329),r=t(58069);const c='import os\nfrom openai import OpenAI\n\n# Initialize the OpenAI client, pointing to Clarifai\'s API\nclient = OpenAI(     \n    base_url="https://api.clarifai.com/v2/ext/openai/v1",  # Clarifai\'s OpenAI-compatible API endpoint\n    api_key=os.environ["CLARIFAI_PAT"]  # Ensure CLARIFAI_PAT is set as an environment variable\n)\n\n# Make a chat completion request to a Clarifai-hosted model\nresponse = client.chat.completions.create(    \n    model="https://clarifai.com/anthropic/completion/models/claude-sonnet-4",\n    #model="anthropic/completion/models/claude-sonnet-4", # Or, provide Clarifai model name\n    messages=[\n        {"role": "system", "content": "You are a helpful assistant."},\n        {"role": "user", "content": "Who are you?"}\n    ],\n    # You can also add other OpenAI-compatible parameters like max_tokens, etc.\n    max_completion_tokens=100,  # Limits the response length\n    temperature=0.7,  # Controls randomness of the output    \n)\n\n# Print the model\'s response\nprint(response.choices[0].message.content)',p='import OpenAI from "openai";\n\nconst client = new OpenAI({\n  baseURL: "https://api.clarifai.com/v2/ext/openai/v1",\n  apiKey: process.env.CLARIFAI_PAT,\n});\n\nconst response = await client.chat.completions.create({\n  model: "https://clarifai.com/anthropic/completion/models/claude-sonnet-4",\n  messages: [\n    { role: "system", content: "You are a helpful assistant." },\n    { role: "user", content: "Who are you?" },\n  ],\n});\n\nconsole.log(response.choices?.[0]?.message.content);',m='import os\nfrom openai import OpenAI\n\n# Initialize the OpenAI client, pointing to Clarifai\'s API\nclient = OpenAI(     \n    base_url="https://api.clarifai.com/v2/ext/openai/v1",  # Clarifai\'s OpenAI-compatible API endpoint\n    api_key=os.environ["CLARIFAI_PAT"]  # Ensure CLARIFAI_PAT is set as an environment variable\n)\n\n# Make a chat completion request to a Clarifai-hosted model\nresponse = client.chat.completions.create(    \n    model="https://clarifai.com/anthropic/completion/models/claude-sonnet-4",\n    #model="anthropic/completion/models/claude-sonnet-4", # Or, provide Clarifai model name\n    messages=[\n        {"role": "system", "content": "You are a helpful assistant."},\n        {"role": "user", "content": "Who are you?"}\n    ],\n    # You can also add other OpenAI-compatible parameters like max_tokens, etc.\n    max_completion_tokens=100,  # Limits the response length\n    temperature=0.7,  # Controls randomness of the output\n    stream=True  # Enables streaming the response token by token\n)\n\nprint("Assistant\'s Response:")\nfor chunk in response:\n    # Safely check if choices, delta, and content exist before accessing\n    if chunk.choices and \\\n       chunk.choices[0].delta and \\\n       chunk.choices[0].delta.content is not None:\n        print(chunk.choices[0].delta.content, end=\'\')\nprint("\\n")  ',h='import os\nfrom openai import OpenAI\n\n# Initialize the OpenAI-compatible client for Clarifai\nclient = OpenAI(    \n    base_url="https://api.clarifai.com/v2/ext/openai/v1",\n    api_key=os.environ["CLARIFAI_PAT"]  # Ensure CLARIFAI_PAT is set as an environment variable   \n)\n\n# Define the external tools (functions) that the LLM can call.\n# In this example, it\'s a \'get_weather\' function.\ntools = [\n    {\n        "type": "function",\n        "function": {\n            "name": "get_weather",\n            "description": "Returns the current temperature for a given location.",\n            "parameters": {\n                "type": "object",\n                "properties": {\n                    "location": {\n                        "type": "string",\n                        "description": "City and country, e.g., \'Bogot\xe1, Colombia\'"\n                    }\n                },\n                "required": ["location"],\n                "additionalProperties": False # Ensures no extra parameters are passed\n            }\n        }\n    }\n]\n\n# Create a chat completion request with tool-calling enabled\nresponse = client.chat.completions.create(\n    model="https://clarifai.com/anthropic/completion/models/claude-sonnet-4",\n    #model="anthropic/completion/models/claude-sonnet-4", # Or, provide Clarifai model name\n    messages=[\n        {"role": "user", "content": "What is the weather like in New York today?"}\n    ],\n    tools=tools,\n    tool_choice=\'auto\' # Let the LLM decide if it needs to use a tool\n)\n\n# Print the tool call proposed by the model, if any\ntool_calls = response.choices[0].message.tool_calls\nprint("Tool calls:", tool_calls)\n',d='import OpenAI from "openai";\nimport type { ChatCompletionTool } from "openai/resources";\n\nconst client = new OpenAI({\n  baseURL: "https://api.clarifai.com/v2/ext/openai/v1",\n  apiKey: process.env.CLARIFAI_PAT,\n});\n\nconst tools: ChatCompletionTool[] = [\n  {\n    type: "function",\n    function: {\n      name: "get_weather",\n      description: "Get current temperature for a given location.",\n      parameters: {\n        type: "object",\n        properties: {\n          location: {\n            type: "string",\n            description: "City and country e.g. Bogot\xe1, Colombia",\n          },\n        },\n        required: ["location"],\n        additionalProperties: false,\n      },\n      strict: true,\n    },\n  },\n];\n\nconst toolCompletion = await client.chat.completions.create({\n  model: "https://clarifai.com/anthropic/completion/models/claude-sonnet-4",\n  messages: [\n    { role: "system", content: "You are a helpful assistant." },\n    { role: "user", content: "What is the weather in New York?" },\n  ],\n  tools,\n});\n\nconsole.log(toolCompletion.choices?.[0]?.message.tool_calls);\n',u='import os\nimport json\nfrom openai import OpenAI\n\n# Initialize the OpenAI client, pointing to Clarifai\'s OpenAI-compatible API endpoint\nclient = OpenAI(\n    base_url="https://api.clarifai.com/v2/ext/openai/v1",\n    api_key=os.environ["CLARIFAI_PAT"]  # Ensure CLARIFAI_PAT is set as an environment variable  \n)\n\n# Define the external tools (functions) that the LLM can call.\n# In this example, it\'s a \'get_weather\' function.\ntools = [{\n    "type": "function",\n    "function": {\n        "name": "get_weather",\n        "description": "Get current temperature for a given location.",\n        "parameters": {\n            "type": "object",\n            "properties": {\n                "location": {\n                    "type": "string",\n                    "description": "City and country, e.g., \'Bogot\xe1, Colombia\'"\n                }\n            },\n            "required": ["location"],\n            "additionalProperties": False # Ensures no extra parameters are passed\n        },\n        "strict": True # Enforces strict adherence to parameter schema\n    }\n}]\n\n## Simulate Tool Execution (for demonstration)\n\n# This function simulates calling an external weather API.\n# In a real application, this would make an actual API request.\ndef get_weather(location: str):\n    """Simulates fetching weather for a given location."""\n    # Placeholder data for demonstration\n    if "New York" in location:\n        return {"location": "New York", "temperature": "20\xb0C", "conditions": "Partly cloudy"}\n    elif "London" in location:\n        return {"location": "London", "temperature": "15\xb0C", "conditions": "Rainy"}\n    else:\n        return {"location": location, "temperature": "N/A", "conditions": "Unknown"}\n\n## LLM Call with Tooling\n\n# First API call: The LLM decides if a tool needs to be called.\nprint("--- Initial LLM Call (Tool Recommendation) ---")\nfirst_response = client.chat.completions.create(\n    model="anthropic/completion/models/claude-sonnet-4", # Ensure this model supports tool calling on Clarifai\'s platform\n    messages=[\n        {"role": "user", "content": "What is the weather like in New York today?"}\n    ],\n    tools=tools, # Provide the list of available tools\n    tool_choice="auto", # Let the LLM decide if it needs to use a tool\n)\n\n\n## Process LLM\'s Response and Execute Tool (if recommended)\n\n# Check if the LLM decided to call a tool\nif first_response.choices[0].message.tool_calls:\n    tool_calls = first_response.choices[0].message.tool_calls\n    print(f"\\nLLM recommended tool calls: {tool_calls}")\n\n    # Execute each recommended tool call\n    available_functions = {\n        "get_weather": get_weather, # Map function name to actual Python function\n    }\n\n    messages = [\n        {"role": "user", "content": "What is the weather like in New York today?"}\n    ]\n    messages.append(first_response.choices[0].message) # Add LLM\'s tool call suggestion to messages\n\n    for tool_call in tool_calls:\n        function_name = tool_call.function.name\n        function_to_call = available_functions[function_name]\n        function_args = json.loads(tool_call.function.arguments)\n\n        # Call the actual Python function\n        function_response = function_to_call(**function_args)\n        print(f"\\nExecuting tool: {function_name}({function_args}) -> {function_response}")\n\n        # Add the tool\'s output to the conversation for the LLM to process\n        messages.append(\n            {\n                "tool_call_id": tool_call.id,\n                "role": "tool",\n                "name": function_name,\n                "content": json.dumps(function_response),\n            }\n        )\n\n    # ---\n    ## Second LLM Call (Summarize Tool Output)\n    \n\n    # Now, send the tool\'s output back to the LLM to get a natural language response\n    print("\\n--- Second LLM Call (Summarizing Tool Output) ---")\n    second_response = client.chat.completions.create(\n        model="https://clarifai.com/anthropic/completion/models/claude-sonnet-4",\n        #model="anthropic/completion/models/claude-sonnet-4", # Or, provide Clarifai model name\n        messages=messages, # Continue the conversation with tool output\n    )\n\n    print("\\nFinal Assistant\'s Response:")\n    print(second_response.choices[0].message.content)\n\nelse:\n    print("\\nLLM did not recommend any tool calls.")\n    print("Assistant\'s direct response:")\n    print(first_response.choices[0].message.content)',f="--- Initial LLM Call (Tool Recommendation) ---\n\nLLM recommended tool calls: [ChatCompletionMessageToolCall(id='toolu_01Mhqb1c7ne4GPKWY9eZtgxd', function=Function(arguments='{\"location\": \"New York, United States\"}', name='get_weather'), type='function')]\n\nExecuting tool: get_weather({'location': 'New York, United States'}) -> {'location': 'New York', 'temperature': '20\xb0C', 'conditions': 'Partly cloudy'}\n\n--- Second LLM Call (Summarizing Tool Output) ---\n\nFinal Assistant's Response:\nThe weather in New York today is:\n- **Temperature:** 20\xb0C (68\xb0F)\n- **Conditions:** Partly cloudy\n\nIt's a pleasant day with mild temperatures and partly cloudy skies!",g='import os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    base_url="https://api.clarifai.com/v2/ext/openai/v1",\n    api_key=os.environ[\'CLARIFAI_PAT\'],\n)\nresponse = client.images.generate(\n    model="https://clarifai.com/xai/image-generation/models/grok-2-image-1212",\n    prompt="A cat in a tree",\n)\nprint(response)',x={description:"Run inferences on Clarifai models using OpenAI",sidebar_position:1,toc_max_heading_level:4},b="OpenAI",A={},v=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Install OpenAI Package",id:"install-openai-package",level:3},{value:"Get a PAT Key",id:"get-a-pat-key",level:3},{value:"Get a Clarifai Model",id:"get-a-clarifai-model",level:3},{value:"Chat Completions",id:"chat-completions",level:2},{value:"Streaming",id:"streaming",level:2},{value:"Tool Calling",id:"tool-calling",level:2},{value:"Image Generation",id:"image-generation",level:2}];function y(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",strong:"strong",...(0,i.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"openai",children:"OpenAI"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Run inferences on Clarifai models using OpenAI"})}),"\n",(0,o.jsx)("hr",{}),"\n",(0,o.jsx)(n.p,{children:"You can run inferences on Clarifai-hosted models using the OpenAI client library by leveraging the Clarifai\u2019s OpenAI-compatible API endpoint."}),"\n",(0,o.jsx)(n.p,{children:"This allows you to use the same code and tools you would with OpenAI, in either Python or JavaScript, by simply configuring the client to point to Clarifai and providing your PAT (Personal Access Token) key."}),"\n","\n","\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsx)(n.h3,{id:"install-openai-package",children:"Install OpenAI Package"}),"\n",(0,o.jsxs)(n.p,{children:["Install the ",(0,o.jsx)(n.code,{children:"openai"})," package."]}),"\n",(0,o.jsxs)(s.A,{groupId:"code",children:[(0,o.jsx)(l.A,{value:"bash",label:"Python",children:(0,o.jsx)(r.A,{className:"language-bash",children:" pip install openai "})}),(0,o.jsx)(l.A,{value:"node.js",label:"Node.js",children:(0,o.jsx)(r.A,{className:"language-bash",children:" npm install openai "})})]}),"\n",(0,o.jsx)(n.h3,{id:"get-a-pat-key",children:"Get a PAT Key"}),"\n",(0,o.jsxs)(n.p,{children:["You need a ",(0,o.jsx)(n.a,{href:"https://docs.clarifai.com/control/authentication/pat",children:"PAT"})," key to authenticate your connection to the Clarifai platform. You can generate the PAT key in your personal settings page by navigating to the ",(0,o.jsx)(n.a,{href:"https://clarifai.com/settings/security",children:"Security section"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["You can then set the PAT as an environment variable using ",(0,o.jsx)(n.code,{children:"CLARIFAI_PAT"}),":"]}),"\n",(0,o.jsxs)(s.A,{groupId:"code",children:[(0,o.jsx)(l.A,{value:"bash",label:"Unix-Like Systems",children:(0,o.jsx)(r.A,{className:"language-bash",children:" export CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE "})}),(0,o.jsx)(l.A,{value:"bash2",label:"Windows",children:(0,o.jsx)(r.A,{className:"language-bash",children:" set CLARIFAI_PAT=YOUR_PERSONAL_ACCESS_TOKEN_HERE "})})]}),"\n",(0,o.jsx)(n.h3,{id:"get-a-clarifai-model",children:"Get a Clarifai Model"}),"\n",(0,o.jsxs)(n.p,{children:["Go to the Clarifai ",(0,o.jsx)(n.a,{href:"https://clarifai.com/explore",children:"Community"})," platform and select the model you want to use for making predictions."]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Some Clarifai models that support OpenAI"}),(0,o.jsxs)(r.A,{className:"language-python",children:[(0,o.jsx)(n.a,{href:"https://clarifai.com/deepseek-ai/deepseek-chat/models/DeepSeek-R1-0528-Qwen3-8B",children:"https://clarifai.com/deepseek-ai/deepseek-chat/models/DeepSeek-R1-0528-Qwen3-8B"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/meta/Llama-3/models/Llama-3_2-3B-Instruct",children:"https://clarifai.com/meta/Llama-3/models/Llama-3_2-3B-Instruct"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/anthropic/completion/models/claude-sonnet-4",children:"https://clarifai.com/anthropic/completion/models/claude-sonnet-4"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/qwen/qwenLM/models/Qwen3-14B",children:"https://clarifai.com/qwen/qwenLM/models/Qwen3-14B"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/mistralai/completion/models/Devstral-Small-2505_gguf-4bit",children:"https://clarifai.com/mistralai/completion/models/Devstral-Small-2505_gguf-4bit"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/clarifai/main/models/general-image-recognition",children:"https://clarifai.com/clarifai/main/models/general-image-recognition"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/xai/chat-completion/models/grok-3",children:"https://clarifai.com/xai/chat-completion/models/grok-3"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/openai/chat-completion/models/gpt-4o",children:"https://clarifai.com/openai/chat-completion/models/gpt-4o"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/openai/chat-completion/models/gpt-4_1",children:"https://clarifai.com/openai/chat-completion/models/gpt-4_1"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/gcp/generate/models/gemini-2_5-flash",children:"https://clarifai.com/gcp/generate/models/gemini-2_5-flash"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/anthropic/completion/models/claude-3_5-haiku",children:"https://clarifai.com/anthropic/completion/models/claude-3_5-haiku"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/qwen/qwenLM/models/Qwen3-30B-A3B-GGUF",children:"https://clarifai.com/qwen/qwenLM/models/Qwen3-30B-A3B-GGUF"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/gcp/generate/models/gemini-2_0-flash",children:"https://clarifai.com/gcp/generate/models/gemini-2_0-flash"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/gcp/generate/models/gemma-3-12b-it",children:"https://clarifai.com/gcp/generate/models/gemma-3-12b-it"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/microsoft/text-generation/models/Phi-4-reasoning-plus",children:"https://clarifai.com/microsoft/text-generation/models/Phi-4-reasoning-plus"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/openbmb/miniCPM/models/MiniCPM3-4B",children:"https://clarifai.com/openbmb/miniCPM/models/MiniCPM3-4B"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/microsoft/text-generation/models/phi-4-mini-instruct",children:"https://clarifai.com/microsoft/text-generation/models/phi-4-mini-instruct"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/qwen/qwen-VL/models/Qwen2_5-VL-7B-Instruct",children:"https://clarifai.com/qwen/qwen-VL/models/Qwen2_5-VL-7B-Instruct"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/microsoft/text-generation/models/phi-4",children:"https://clarifai.com/microsoft/text-generation/models/phi-4"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/xai/chat-completion/models/grok-2-vision-1212",children:"https://clarifai.com/xai/chat-completion/models/grok-2-vision-1212"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/xai/image-generation/models/grok-2-image-1212",children:"https://clarifai.com/xai/image-generation/models/grok-2-image-1212"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/xai/chat-completion/models/grok-2-1212",children:"https://clarifai.com/xai/chat-completion/models/grok-2-1212"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/qwen/qwenLM/models/QwQ-32B-AWQ",children:"https://clarifai.com/qwen/qwenLM/models/QwQ-32B-AWQ"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/gcp/generate/models/gemini-2_0-flash-lite",children:"https://clarifai.com/gcp/generate/models/gemini-2_0-flash-lite"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/anthropic/completion/models/claude-opus-4",children:"https://clarifai.com/anthropic/completion/models/claude-opus-4"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/openai/chat-completion/models/o4-mini",children:"https://clarifai.com/openai/chat-completion/models/o4-mini"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/openai/chat-completion/models/o3",children:"https://clarifai.com/openai/chat-completion/models/o3"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/openbmb/miniCPM/models/MiniCPM-o-2_6-language",children:"https://clarifai.com/openbmb/miniCPM/models/MiniCPM-o-2_6-language"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/deepseek-ai/deepseek-chat/models/DeepSeek-R1-Distill-Qwen-7B",children:"https://clarifai.com/deepseek-ai/deepseek-chat/models/DeepSeek-R1-Distill-Qwen-7B"}),"\n",(0,o.jsx)(n.a,{href:"https://clarifai.com/qwen/qwenCoder/models/Qwen2_5-Coder-7B-Instruct",children:"https://clarifai.com/qwen/qwenCoder/models/Qwen2_5-Coder-7B-Instruct"})]})]}),"\n",(0,o.jsx)(n.h2,{id:"chat-completions",children:"Chat Completions"}),"\n",(0,o.jsxs)(n.p,{children:["The OpenAI ",(0,o.jsx)(n.a,{href:"https://platform.openai.com/docs/api-reference/chat",children:"Chat Completions"})," API endpoint enables you to generate a model response by providing a list of messages that constitute a conversation."]}),"\n",(0,o.jsxs)(s.A,{groupId:"code",children:[(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:c})}),(0,o.jsx)(l.A,{value:"typescript",label:"TypeScript",children:(0,o.jsx)(r.A,{className:"language-typescript",children:p})})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Example Output"}),(0,o.jsx)(r.A,{className:"language-text",children:"I'm Claude, an AI assistant created by Anthropic. I'm here to help with a wide variety of tasks like answering questions, helping with analysis and research, creative writing, math and coding problems, and having conversations. Is there something specific I can help you with today?"})]}),"\n",(0,o.jsx)(n.h2,{id:"streaming",children:"Streaming"}),"\n",(0,o.jsx)(n.p,{children:"Clarifai offers support for streaming \u2014 the response is streamed back token by token, rather than waiting for the entire completion to be generated before returning."}),"\n",(0,o.jsx)(s.A,{groupId:"code",children:(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:m})})}),"\n",(0,o.jsx)(n.h2,{id:"tool-calling",children:"Tool Calling"}),"\n",(0,o.jsx)(n.p,{children:"Tool calling (also known as function calling) enables LLMs to autonomously decide when and how to invoke external tools \u2014 such as APIs or custom functions \u2014 based on user input."}),"\n",(0,o.jsx)(n.p,{children:'Here is an example code that sets up a basic tool-calling interaction. It simulates a weather API and shows how the LLM would "call" that tool when asked about the weather.'}),"\n",(0,o.jsxs)(s.A,{groupId:"code",children:[(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:h})}),(0,o.jsx)(l.A,{value:"typescript",label:"TypeScript",children:(0,o.jsx)(r.A,{className:"language-typescript",children:d})})]}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Tool Calling Implementation Example"}),(0,o.jsx)(r.A,{className:"language-python",children:u}),(0,o.jsx)(r.A,{className:"language-text",children:f})]}),"\n",(0,o.jsx)(n.h2,{id:"image-generation",children:"Image Generation"}),"\n",(0,o.jsx)(n.p,{children:"Here is an example of how to generate an image using a model that supports Clarifai's OpenAI-compatible API endpoint."}),"\n",(0,o.jsx)(s.A,{groupId:"code",children:(0,o.jsx)(l.A,{value:"python",label:"Python",children:(0,o.jsx)(r.A,{className:"language-python",children:g})})}),"\n",(0,o.jsxs)(t,{children:[(0,o.jsx)("summary",{children:"Example Output"}),(0,o.jsxs)(r.A,{className:"language-text",children:["ImagesResponse(created=None, data=[Image(b64_json=None, revised_prompt='A high-resolution photograph of a cat perched on a branch in a lush, green tree during the daytime. The cat, possibly a tabby, is the central focus of the image, looking slightly to the side with its fur naturally positioned. The background features a soft, slightly blurred forest setting with sunlight filtering through the leaves, creating a serene and natural environment. The composition avoids any distracting elements, ensuring the cat remains the primary subject in a peaceful outdoor scene.', url='",(0,o.jsx)(n.a,{href:"https://imgen.x.ai/xai-imgen/xai-tmp-imgen-41202340-c0e1-4669-bed5-e70f7b491176.jpeg",children:"https://imgen.x.ai/xai-imgen/xai-tmp-imgen-41202340-c0e1-4669-bed5-e70f7b491176.jpeg"}),"')],"," usage=None)"]})]})]})}function I(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(y,{...e})}):y(e)}},65537:(e,n,t)=>{t.d(n,{A:()=>I});var a=t(96540),o=t(18215),i=t(65627),s=t(56347),l=t(50372),r=t(30604),c=t(11861),p=t(78749);function m(e){return a.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function h(e){const{values:n,children:t}=e;return(0,a.useMemo)((()=>{const e=n??function(e){return m(e).map((e=>{let{props:{value:n,label:t,attributes:a,default:o}}=e;return{value:n,label:t,attributes:a,default:o}}))}(t);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function d(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function u(e){let{queryString:n=!1,groupId:t}=e;const o=(0,s.W6)(),i=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,r.aZ)(i),(0,a.useCallback)((e=>{if(!i)return;const n=new URLSearchParams(o.location.search);n.set(i,e),o.replace({...o.location,search:n.toString()})}),[i,o])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:o}=e,i=h(e),[s,r]=(0,a.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!d({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const a=t.find((e=>e.default))??t[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:n,tabValues:i}))),[c,m]=u({queryString:t,groupId:o}),[f,g]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[o,i]=(0,p.Dv)(t);return[o,(0,a.useCallback)((e=>{t&&i.set(e)}),[t,i])]}({groupId:o}),x=(()=>{const e=c??f;return d({value:e,tabValues:i})?e:null})();(0,l.A)((()=>{x&&r(x)}),[x]);return{selectedValue:s,selectValue:(0,a.useCallback)((e=>{if(!d({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);r(e),m(e),g(e)}),[m,g,i]),tabValues:i}}var g=t(9136);const x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var b=t(74848);function A(e){let{className:n,block:t,selectedValue:a,selectValue:s,tabValues:l}=e;const r=[],{blockElementScrollPositionUntilNextRender:c}=(0,i.a_)(),p=e=>{const n=e.currentTarget,t=r.indexOf(n),o=l[t].value;o!==a&&(c(n),s(o))},m=e=>{let n=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{const t=r.indexOf(e.currentTarget)+1;n=r[t]??r[0];break}case"ArrowLeft":{const t=r.indexOf(e.currentTarget)-1;n=r[t]??r[r.length-1];break}}n?.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":t},n),children:l.map((e=>{let{value:n,label:t,attributes:i}=e;return(0,b.jsx)("li",{role:"tab",tabIndex:a===n?0:-1,"aria-selected":a===n,ref:e=>{r.push(e)},onKeyDown:m,onClick:p,...i,className:(0,o.A)("tabs__item",x.tabItem,i?.className,{"tabs__item--active":a===n}),children:t??n},n)}))})}function v(e){let{lazy:n,children:t,selectedValue:i}=e;const s=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=s.find((e=>e.props.value===i));return e?(0,a.cloneElement)(e,{className:(0,o.A)("margin-top--md",e.props.className)}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:s.map(((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==i})))})}function y(e){const n=f(e);return(0,b.jsxs)("div",{className:(0,o.A)("tabs-container",x.tabList),children:[(0,b.jsx)(A,{...n,...e}),(0,b.jsx)(v,{...n,...e})]})}function I(e){const n=(0,g.A)();return(0,b.jsx)(y,{...e,children:m(e.children)},String(n))}},79329:(e,n,t)=>{t.d(n,{A:()=>s});t(96540);var a=t(18215);const o={tabItem:"tabItem_Ymn6"};var i=t(74848);function s(e){let{children:n,hidden:t,className:s}=e;return(0,i.jsx)("div",{role:"tabpanel",className:(0,a.A)(o.tabItem,s),hidden:t,children:n})}}}]);