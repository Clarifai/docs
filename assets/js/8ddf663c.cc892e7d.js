"use strict";(self.webpackChunkdocs_new=self.webpackChunkdocs_new||[]).push([[8835],{11470:(e,n,a)=>{a.d(n,{A:()=>y});var t=a(96540),i=a(18215),o=a(23104),s=a(56347),r=a(205),l=a(57485),d=a(31682),c=a(70679);function p(e){return t.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function u(e){const{values:n,children:a}=e;return(0,t.useMemo)(()=>{const e=n??function(e){return p(e).map(({props:{value:e,label:n,attributes:a,default:t}})=>({value:e,label:n,attributes:a,default:t}))}(a);return function(e){const n=(0,d.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,a])}function h({value:e,tabValues:n}){return n.some(n=>n.value===e)}function m({queryString:e=!1,groupId:n}){const a=(0,s.W6)(),i=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,l.aZ)(i),(0,t.useCallback)(e=>{if(!i)return;const n=new URLSearchParams(a.location.search);n.set(i,e),a.replace({...a.location,search:n.toString()})},[i,a])]}function _(e){const{defaultValue:n,queryString:a=!1,groupId:i}=e,o=u(e),[s,l]=(0,t.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!h({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const a=n.find(e=>e.default)??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:n,tabValues:o})),[d,p]=m({queryString:a,groupId:i}),[_,f]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[a,i]=(0,c.Dv)(n);return[a,(0,t.useCallback)(e=>{n&&i.set(e)},[n,i])]}({groupId:i}),x=(()=>{const e=d??_;return h({value:e,tabValues:o})?e:null})();(0,r.A)(()=>{x&&l(x)},[x]);return{selectedValue:s,selectValue:(0,t.useCallback)(e=>{if(!h({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);l(e),p(e),f(e)},[p,f,o]),tabValues:o}}var f=a(92303);const x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var g=a(74848);function b({className:e,block:n,selectedValue:a,selectValue:t,tabValues:s}){const r=[],{blockElementScrollPositionUntilNextRender:l}=(0,o.a_)(),d=e=>{const n=e.currentTarget,i=r.indexOf(n),o=s[i].value;o!==a&&(l(n),t(o))},c=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const a=r.indexOf(e.currentTarget)+1;n=r[a]??r[0];break}case"ArrowLeft":{const a=r.indexOf(e.currentTarget)-1;n=r[a]??r[r.length-1];break}}n?.focus()};return(0,g.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":n},e),children:s.map(({value:e,label:n,attributes:t})=>(0,g.jsx)("li",{role:"tab",tabIndex:a===e?0:-1,"aria-selected":a===e,ref:e=>{r.push(e)},onKeyDown:c,onClick:d,...t,className:(0,i.A)("tabs__item",x.tabItem,t?.className,{"tabs__item--active":a===e}),children:n??e},e))})}function j({lazy:e,children:n,selectedValue:a}){const o=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=o.find(e=>e.props.value===a);return e?(0,t.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,g.jsx)("div",{className:"margin-top--md",children:o.map((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==a}))})}function v(e){const n=_(e);return(0,g.jsxs)("div",{className:(0,i.A)("tabs-container",x.tabList),children:[(0,g.jsx)(b,{...n,...e}),(0,g.jsx)(j,{...n,...e})]})}function y(e){const n=(0,f.A)();return(0,g.jsx)(v,{...e,children:p(e.children)},String(n))}},19365:(e,n,a)=>{a.d(n,{A:()=>s});a(96540);var t=a(18215);const i={tabItem:"tabItem_Ymn6"};var o=a(74848);function s({children:e,hidden:n,className:a}){return(0,o.jsx)("div",{role:"tabpanel",className:(0,t.A)(i.tabItem,a),hidden:n,children:e})}},44773:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>D,contentTitle:()=>w,default:()=>T,frontMatter:()=>I,metadata:()=>t,toc:()=>U});const t=JSON.parse('{"id":"create/datasets/upload","title":"Upload Data to Dataset via API","description":"Learn how to upload data to a dataset","source":"@site/docs/create/datasets/upload.md","sourceDirName":"create/datasets","slug":"/create/datasets/upload","permalink":"/create/datasets/upload","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"description":"Learn how to upload data to a dataset","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Datasets Creation","permalink":"/create/datasets/create"},"next":{"title":"Datasets Management","permalink":"/create/datasets/manage"}}');var i=a(74848),o=a(28453),s=a(11470),r=a(19365),l=a(73748);const d='from clarifai.client.input import Inputs\nimport time\n\n# Set PAT as an environment variable before running this script\n#   export CLARIFAI_PAT=YOUR_PAT_HERE   # Unix-like systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE      # Windows\n\n# Initialize the Inputs client\ninput_client = Inputs(\n    user_id="YOUR_USER_ID",\n    app_id="YOUR_APP_ID"\n)\n\n# Upload image data from a specified URL with a unique input ID\ninput_id = "bbox_example"\ninput_client.upload_from_url(\n    input_id=input_id,\n    dataset_id="YOUR_DATASET_ID", # Optional: specify dataset ID to add the input to a dataset\n    image_url="https://samples.clarifai.com/BarackObama.jpg"\n)\n\n# Poll until input is processed successfully\nstatus = None\nfor _ in range(10):  # max retries\n    inp = input_client.get_input(input_id)\n    status = inp.status.code\n    if status == 30000:  # SUCCESS\n        break\n    time.sleep(2)\n\nif status != 30000:\n    raise RuntimeError("Input not processed, cannot add annotations yet.")\n\n# Define bounding box coordinates (format: [left, top, right, bottom])\nbbox_points = [0.1, 0.1, 0.8, 0.9]\n\n# Generate a bounding box annotation with specified label ("face") and bounding box coordinates\nannotation = input_client.get_bbox_proto(\n    input_id=input_id,\n    label="face",\n    bbox=bbox_points\n)\n\n# Upload the generated annotation to associate with the previously uploaded image\ninput_client.upload_annotations([annotation])\n',c='import { Input } from "clarifai-nodejs";\n\n\nconst imageUrl = "https://samples.clarifai.com/BarackObama.jpg";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nawait input.uploadFromUrl({\n  inputId: "bbox",\n  imageUrl,\n});\nconst bboxPoints = [0.1, 0.1, 0.8, 0.9];\nconst annotation = Input.getBboxProto({\n  inputId: "bbox",\n  label: "face",\n  bbox: bboxPoints,\n});\nawait input.uploadAnnotations({\n  batchAnnot: [annotation],\n});\n',p='from clarifai.client.input import Inputs\nimport time\nfrom clarifai_grpc.grpc.api import resources_pb2 as r\n\n# Set PAT as an environment variable before running this script\n#   export CLARIFAI_PAT=YOUR_PAT_HERE   # Unix-like systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE      # Windows\n\n# Initialize the Inputs client\ninput_client = Inputs(\n    user_id="YOUR_USER_ID",\n    app_id="YOUR_APP_ID",\n)\n\n# Upload video data from a specified URL with a unique input ID\ninput_id = "video_bbox_example" # change per test if re-running\ninput_client.upload_from_url(\n    input_id=input_id,\n    dataset_id="YOUR_DATASET_ID", # Optional: specify dataset ID to add the input to a dataset\n    video_url="https://samples.clarifai.com/beer.mp4"\n)\n\n# Poll until input is processed successfully\nstatus = None\nfor _ in range(10):  # max retries\n    inp = input_client.get_input(input_id)\n    status = inp.status.code\n    if status == 30000:  # SUCCESS\n        break\n    time.sleep(2)\n\nif status != 30000:\n    raise RuntimeError("Input not processed, cannot add annotations yet.")\n\n# Bounding box coordinates for annotation, (top_row, left_col, bottom_row, right_col), relative 0\u20131\nbbox_points = [0.1, 0.1, 0.8, 0.9]\n\n# Build a video frame annotation with one region (Clarifai requires frame -> region -> bbox)\nbbox_pb = r.BoundingBox(\n    top_row=bbox_points[0],\n    left_col=bbox_points[1],\n    bottom_row=bbox_points[2],\n    right_col=bbox_points[3],\n)\nregion = r.Region(\n    region_info=r.RegionInfo(bounding_box=bbox_pb),\n    data=r.Data(concepts=[r.Concept(id="glass", name="glass", value=1.0)])\n)\nframe = r.Frame(\n    frame_info=r.FrameInfo(time=0, index=0),   # first frame (time in ms)\n    data=r.Data(regions=[region])\n)\nannotation = r.Annotation(\n    input_id=input_id,\n    data=r.Data(frames=[frame])\n)\n\n# Upload the annotation associated with the video\ninput_client.upload_annotations([annotation])\n\n# -------- OPTIONAL: multiple labels or multiple frames --------\n\'\'\'\n# Example: multiple labels on separate frames (one annotation per frame)\nlabels = ["glass", "person", "dog"]\nannotations = []\nfor i, lab in enumerate(labels):\n    bb = r.BoundingBox(top_row=0.1+i*0.05, left_col=0.1, bottom_row=0.4+i*0.05, right_col=0.4)\n    reg = r.Region(region_info=r.RegionInfo(bounding_box=bb),\n                   data=r.Data(concepts=[r.Concept(id=lab, name=lab, value=1.0)]))\n    frm = r.Frame(frame_info=r.FrameInfo(time=i*1000, index=i), data=r.Data(regions=[reg]))\n    annotations.append(r.Annotation(input_id=input_id, data=r.Data(frames=[frm])))\n\ninput_client.upload_annotations(annotations)\n\'\'\'',u='import { Input } from "clarifai-nodejs";\n\n\nconst videoUrl = "https://samples.clarifai.com/beer.mp4";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nawait input.uploadFromUrl({\n  inputId: "video-bbox",\n  videoUrl,\n});\nconst bboxPoints = [0.1, 0.1, 0.8, 0.9];\nconst annotation = Input.getBboxProto({\n  inputId: "bbox",\n  label: "glass",\n  bbox: bboxPoints,\n});\nawait input.uploadAnnotations({\n  batchAnnot: [annotation],\n});\n',h='from clarifai.client.input import Inputs\n\n# Set PAT as an environment variable before running this script\n#   export CLARIFAI_PAT=YOUR_PAT_HERE   # Unix-like systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE      # Windows\n\n# Initialize the Inputs client\ninput_client = Inputs(\n    user_id="YOUR_USER_ID",\n    app_id="YOUR_APP_ID",\n)\n\n# Define input details\ninput_id = "text_example"\nconcepts = ["mobile", "camera"]\n\n# Upload data from URL and annotate with concepts\ninput_client.upload_from_url(\n    input_id=input_id,\n    dataset_id="YOUR_DATASET_ID",  # Optional: specify dataset ID to add the input to a dataset\n    text_url="https://samples.clarifai.com/featured-models/Llama2_Conversational-agent.txt",\n    labels=concepts\n)\n',m='import { Input } from "clarifai-nodejs";\n\n\nconst textUrl =\n  "https://samples.clarifai.com/featured-models/Llama2_Conversational-agent.txt";\nconst concepts = ["mobile", "camera"];\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: "test_app",\n  },\n});\nawait input.uploadFromUrl({\n  inputId: "text1",\n  textUrl,\n  labels: concepts,\n});\n',_='from clarifai.client.dataset import Dataset\nfrom clarifai.datasets.upload.utils import load_module_dataloader\n\n\n#replace your "user_id", "app_id", "dataset_id".\ndataset = Dataset(user_id="user_id", app_id="test_app", dataset_id="first_dataset")\n#create dataloader object\ncifar_dataloader = load_module_dataloader(\'./image_classification/cifar10\')\n#set get_upload_status=True for showing upload status\ndataset.upload_dataset(dataloader=cifar_dataloader,get_upload_status=True)\n',f='from clarifai.client.input import Inputs\nimport time\n\n# Set PAT as an environment variable before running this script\n#   export CLARIFAI_PAT=YOUR_PAT_HERE   # Unix-like systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE      # Windows\n\n# Initialize the Inputs client\ninput_client = Inputs(\n    user_id="YOUR_USER_ID",\n    app_id="YOUR_APP_ID"\n)\n\n# Upload image data from a specified URL with a unique input ID\ninput_id = "mask_example"\ninput_client.upload_from_url(\n    input_id=input_id,\n    dataset_id="YOUR_DATASET_ID", # Optional: specify dataset ID to add the input to a dataset\n    image_url="https://samples.clarifai.com/BarackObama.jpg"\n)\n\n# Poll until input is processed successfully\nstatus = None\nfor _ in range(10):  # max retries\n    inp = input_client.get_input(input_id)\n    status = inp.status.code\n    if status == 30000:  # SUCCESS\n        break\n    time.sleep(2)\n\nif status != 30000:\n    raise RuntimeError("Input not processed, cannot add annotations yet.")\n\n# Define polygon points for the mask \n# Coordinates are normalized (0.0 to 1.0) relative to image width and height\nmask_points = [\n    [0.30, 0.20],  # top-left forehead\n    [0.70, 0.20],  # top-right forehead\n    [0.85, 0.45],  # right cheek\n    [0.70, 0.80],  # right jaw\n    [0.30, 0.80],  # left jaw\n    [0.15, 0.45]   # left cheek\n]\n\n# Create a mask annotation with label "obama"\nannotation = input_client.get_mask_proto(\n    input_id=input_id,\n    label="obama",\n    polygons=mask_points\n)\n\n# Upload the generated annotation to associate with the previously uploaded image\ninput_client.upload_annotations([annotation])',x='import { Input, Polygon } from "clarifai-nodejs";\n\n\nconst imageUrl = "https://samples.clarifai.com/BarackObama.jpg";\nconst input = new Input({\n  authConfig: {\n    userId: process.env.CLARIFAI_USER_ID,\n    pat: process.env.CLARIFAI_PAT,\n    appId: process.env.CLARIFAI_APP_ID,\n  },\n});\nawait input.uploadFromUrl({\n  inputId: "mask",\n  imageUrl,\n});\nconst maskPoints:Polygon[] = [[[0.87, 0.66],[0.45 , 1.0], [0.82 ,0.42]]];\nconst annotation = Input.getMaskProto({\n  inputId: "mask",\n  label: "obama",\n  polygons: maskPoints,\n});\nawait input.uploadAnnotations({\n  batchAnnot: [annotation],\n});',g='#importing load_module_dataloader for calling the dataloader object in dataset.py in the local data folder\nfrom clarifai.datasets.upload.utils import load_module_dataloader\nfrom clarifai.client.dataset import Dataset\n\n\n#replace your "user_id", "app_id", "dataset_id".\ndataset = Dataset(user_id="user_id", app_id="app_id", dataset_id="dataset_id")\n\ncifar_dataloader = load_module_dataloader(\'./image_classification/cifar10\')\n\ndataset.retry_upload_from_logs(dataloader=cifar_dataloader, log_file_path=\'path to log file\', retry_duplicates=True, log_warnings=True)',b='curl --location --request POST "https://api.clarifai.com/v2/users/YOUR_USER_ID_HERE/apps/YOUR_APP_ID_HERE/datasets/YOUR_DATASET_ID_HERE/inputs" \\\n  --header "Authorization: Key YOUR_PAT_HERE" \\\n  --header "Content-Type: application/json" \\\n  --data-raw \'{\n    "dataset_inputs": [\n      {\n        "input": {\n          "id": "YOUR_EXISTING_INPUT_ID_HERE"\n        }\n      }\n    ]\n  }\'',j='from clarifai.client.dataset import Dataset\n\n# Set PAT as an environment variable before running this script\n#   export CLARIFAI_PAT=YOUR_PAT_HERE   # Unix-like systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE      # Windows\n\n# Create a dataset object\ndataset = Dataset(\n    user_id="YOUR_USER_ID",\n    app_id="YOUR_APP_ID",\n    dataset_id="YOUR_DATASET_ID"\n)\n\n# Upload data from a folder\ndataset.upload_from_folder(\n    folder_path="/path/to/your/folder",\n    input_type="image", # or "text" for text files\n    labels=True   # Set to False to upload without concepts\n)',v='from clarifai.client.dataset import Dataset\n\n# Set PAT as an environment variable before running this script\n#   export CLARIFAI_PAT=YOUR_PAT_HERE   # Unix-like systems\n#   set CLARIFAI_PAT=YOUR_PAT_HERE      # Windows\n\n# Create a dataset object\ndataset = Dataset(\n    user_id="YOUR_USER_ID",\n    app_id="YOUR_APP_ID",\n    dataset_id="YOUR_DATASET_ID"\n)\n\n# Upload local image files\ndataset.upload_from_csv(\n    csv_path="path_to_your_csv_file.csv",\n    input_type="image",\n    csv_type="file_path",\n    labels=True # Set to False to upload without concepts\n)\n\n\'\'\'\n# Upload image data from URLs\ndataset.upload_from_csv(\n    csv_path="sample_images.csv",\n    input_type="image",\n    csv_type="url",\n    labels=True\n)\n\n# Upload raw text data\ndataset.upload_from_csv(\n    csv_path="sample_texts.csv",\n    input_type="text",\n    csv_type="raw",\n    labels=True\n)\n\n# Upload video data from file paths\ndataset.upload_from_csv(\n    csv_path="sample_videos.csv",\n    input_type="video",\n    csv_type="file_path",\n    labels=True\n)\n\n# Upload audio data from URLs\ndataset.upload_from_csv(\n    csv_path="sample_audio.csv",\n    input_type="audio",\n    csv_type="url",\n    labels=True\n)\n\'\'\'\n',y='const { Dataset } = require("clarifai-nodejs");\nconst path = require("path");\n\n(async () => {\n  const dataset = new Dataset({\n    datasetId: "YOUR_DATASET_ID",\n    authConfig: {\n      pat: process.env.CLARIFAI_PAT,\n      userId: "YOUR_USER_ID",\n      appId: "YOUR_APP_ID",\n    },\n  });\n\n  await dataset.uploadFromFolder({\n    folderPath: path.resolve(__dirname, "/path/to/your/folder"),\n    inputType: "image",\n    labels: true,\n  });\n})();\n',A='const { Dataset } = require("clarifai-nodejs");\nconst path = require("path");\n\n(async () => {\n  const dataset = new Dataset({\n    datasetId: "YOUR_DATASET_ID",\n    authConfig: {\n      pat: process.env.CLARIFAI_PAT,\n      userId: "YOUR_USER_ID",\n      appId: "YOUR_APP_ID",\n    },\n  });\n\n  await dataset.uploadFromCSV({\n    csvPath: path.resolve(__dirname, "/path/to/your/folder"),\n    inputType: "image", \n    csvType: "file", // can also be "url" or "raw"\n    labels: true      \n  });\n})();\n',I={description:"Learn how to upload data to a dataset",sidebar_position:2},w="Upload Data to Dataset via API",D={},U=[{value:"Customize Batch Size",id:"customize-batch-size",level:2},{value:"Add Inputs to a Dataset",id:"add-inputs-to-a-dataset",level:2},{value:"Upload From Folder",id:"upload-from-folder",level:2},{value:"Upload From CSV",id:"upload-from-csv",level:2},{value:"Upload Image Data With Annotations",id:"upload-image-data-with-annotations",level:2},{value:"Upload Image Data With Mask Annotations",id:"upload-image-data-with-mask-annotations",level:2},{value:"Upload Video Data With Annotations",id:"upload-video-data-with-annotations",level:2},{value:"Upload Text Data With Annotations",id:"upload-text-data-with-annotations",level:2},{value:"Batch Upload Image Data While Tracking Status",id:"batch-upload-image-data-while-tracking-status",level:2},{value:"Retry Upload From Log File",id:"retry-upload-from-log-file",level:2}];function R(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components},{Details:a}=n;return a||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"upload-data-to-dataset-via-api",children:"Upload Data to Dataset via API"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Learn how to upload data to a dataset via the API"})}),"\n",(0,i.jsx)("hr",{}),"\n",(0,i.jsx)(n.p,{children:"Uploading data to a dataset in Clarifai is essential for training and evaluating your machine learning models."}),"\n",(0,i.jsx)(n.p,{children:"Whether you're working with images, videos, text, audio, or other data types, we provide flexible and efficient methods to upload data from various sources."}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["Before using the ",(0,i.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/python-sdk",children:"Python SDK"}),", ",(0,i.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/nodejs-sdk",children:"Node.js SDK"}),", or any of our ",(0,i.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-overview/grpc-clients",children:"gRPC clients"}),", ensure they are properly installed on your machine. Refer to their respective installation guides for instructions on how to install and initialize them."]})}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://docs.clarifai.com/additional-resources/api-references/api-reference/#dataset",children:"Click here"})," to learn more about working with the ",(0,i.jsx)(n.code,{children:"Dataset"})," class."]})}),"\n","\n","\n",(0,i.jsxs)(n.admonition,{type:"note",children:[(0,i.jsx)(n.mdxAdmonitionTitle,{}),(0,i.jsx)(n.h2,{id:"customize-batch-size",children:"Customize Batch Size"}),(0,i.jsxs)(n.p,{children:["When uploading inputs to the Clarifai platform, there are limits on the size and number of inputs per upload, as detailed ",(0,i.jsx)(n.a,{href:"https://docs.clarifai.com/create-manage/inputs/upload/#upload-limits",children:"here"}),". However, by using methods from the ",(0,i.jsx)(n.code,{children:"Dataset"})," class \u2014 such as ",(0,i.jsx)(n.code,{children:"Dataset.upload_from_folder()"})," or ",(0,i.jsx)(n.code,{children:"Dataset.upload_from_csv()"})," \u2014 you can bypass these restrictions and efficiently upload larger volumes of inputs."]}),(0,i.jsx)(n.p,{children:"For example, when uploading images in bulk, such methods incrementally process and upload them in multiple batches, ensuring that each batch contains a maximum of 128 images and does not exceed 128MB in size \u2013 which ensures adherence to the upload restrictions."}),(0,i.jsxs)(n.p,{children:["You can also customize the ",(0,i.jsx)(n.code,{children:"batch_size"})," variable, which allows for concurrent upload of inputs and annotations. For example, if your images folder exceeds 128MB, you can set the variable to ensure that each batch contains an appropriate number of images while staying within the 128MB per batch limit."]}),(0,i.jsxs)(n.p,{children:["The default ",(0,i.jsx)(n.code,{children:"batch_size"})," is set to 32, but you can customize it to any value between 1 (minimum) and 128 (maximum)."]}),(0,i.jsx)(n.p,{children:"Here is an example:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:"dataset.upload_from_folder(folder_path='/path/to/your/folder', input_type='image', labels=True, batch_size=50)\n"})})]}),"\n",(0,i.jsx)(n.h2,{id:"add-inputs-to-a-dataset",children:"Add Inputs to a Dataset"}),"\n",(0,i.jsx)(n.p,{children:"After uploading inputs to the Clarifai platform, you can add them to a dataset by specifying their input IDs."}),"\n",(0,i.jsx)(s.A,{groupId:"code",children:(0,i.jsx)(r.A,{value:"curl",label:"cURL",children:(0,i.jsx)(l.A,{className:"language-bash",children:b})})}),"\n",(0,i.jsx)(n.h2,{id:"upload-from-folder",children:"Upload From Folder"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"upload_from_folder"})," method lets you bulk-upload images or text files from a local folder directly into a Clarifai dataset."]}),"\n",(0,i.jsxs)(s.A,{groupId:"code",children:[(0,i.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:j})}),(0,i.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,i.jsx)(l.A,{className:"language-typescript",children:y})})]}),"\n",(0,i.jsx)(n.p,{children:"Note that:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["The ",(0,i.jsx)(n.code,{children:"upload_from_folder"})," method only supports ",(0,i.jsx)(n.code,{children:'"image"'})," and ",(0,i.jsx)(n.code,{children:'"text"'})," input types."]}),"\n",(0,i.jsxs)(n.li,{children:["Ensure your dataset (",(0,i.jsx)(n.code,{children:"dataset_id"}),") already exists before calling this method."]}),"\n",(0,i.jsxs)(n.li,{children:["Large datasets should be uploaded with an appropriate ",(0,i.jsx)(n.a,{href:"#customize-batch-size",children:(0,i.jsx)(n.code,{children:"batch_size"})})," (default 128)."]}),"\n",(0,i.jsxs)(n.li,{children:["If ",(0,i.jsx)(n.code,{children:"labels=True"}),", the folder name is assigned as the input\u2019s concept label."]}),"\n",(0,i.jsxs)(n.li,{children:["The filename (without extension) is used as the ",(0,i.jsx)(n.code,{children:"input_id"})," in Clarifai."]}),"\n",(0,i.jsxs)(n.li,{children:["When uploading text data, the target app should be configured to accept text inputs. Set the primary input type to ",(0,i.jsx)(n.strong,{children:"Text/Document"})," when ",(0,i.jsx)(n.a,{href:"https://docs.clarifai.com/create/applications/create#create-via-the-ui",children:"creating the app"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"upload-from-csv",children:"Upload From CSV"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"upload_from_csv"})," method lets you bulk-upload data into a Clarifai dataset using a CSV file. This method is useful when your data is already structured in tabular form with URLs, local file paths, or raw text."]}),"\n",(0,i.jsxs)(s.A,{groupId:"code",children:[(0,i.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:v})}),(0,i.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,i.jsx)(l.A,{className:"language-typescript",children:A})})]}),"\n",(0,i.jsxs)(a,{children:[(0,i.jsx)("summary",{children:"Example CSV Files"}),(0,i.jsxs)(a,{children:[(0,i.jsx)("summary",{children:"File-path based (for local files)"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:'inputid,input,concepts,metadata\nimg1,"data/metro-north.jpg","train","{\'source\': \'local\'}"\nimg2,"data/puppy.jpeg","dog","{\'source\': \'local\'}"\n'})})]}),(0,i.jsxs)(a,{children:[(0,i.jsx)("summary",{children:'Raw text dataset (only valid with input_type="text")'}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:'inputid,input,concepts,metadata\ntxt1,"The sky is clear and blue","weather","{\'lang\': \'en\'}"\ntxt2,"The puppy is playing in the garden","dog","{\'lang\': \'en\'}"\n'})})]}),(0,i.jsxs)(a,{children:[(0,i.jsx)("summary",{children:"With geopoints"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-text",children:'inputid,input,concepts,metadata,geopoints\nimg1,"data/metro-north.jpg","train","{\'source\': \'clarifai-samples\'}","-73.935242,40.730610"\nimg2,"data/puppy.jpeg","dog","{\'source\': \'clarifai-samples\'}","-118.243683,34.052235"\n'})})]})]}),"\n",(0,i.jsx)(n.p,{children:"Note that:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["The ",(0,i.jsx)(n.code,{children:"upload_from_csv"})," method supports ",(0,i.jsx)(n.code,{children:'"image"'}),", ",(0,i.jsx)(n.code,{children:'"text"'}),", ",(0,i.jsx)(n.code,{children:'"video"'}),", and ",(0,i.jsx)(n.code,{children:'"audio"'})," file types."]}),"\n",(0,i.jsxs)(n.li,{children:["The ",(0,i.jsx)(n.code,{children:"csv_type"})," parameter defines how the CSV file will be interpreted. It can be:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:'"url"'})," \u2014 Inputs are hosted online, and the CSV provides URLs."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:'"file_path"'})," \u2014 Inputs are stored locally, and the CSV provides file paths."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:'"raw"'})," \u2014 Only valid for text datasets; the CSV provides raw text strings."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["If ",(0,i.jsx)(n.code,{children:"labels=True"})," (default), the CSV must include a ",(0,i.jsx)(n.code,{children:"concepts"})," column with labels. If ",(0,i.jsx)(n.code,{children:"False"}),", inputs are uploaded without labels."]}),"\n",(0,i.jsxs)(n.li,{children:["The ",(0,i.jsx)(n.a,{href:"#customize-batch-size",children:(0,i.jsx)(n.code,{children:"batch_size"})})," (default = 128) parameter defines the maximum number of inputs to upload concurrently in one batch."]}),"\n",(0,i.jsxs)(n.li,{children:["The CSV file must include column headers. These are the supported headers:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"inputid"})," \u2014 Unique identifier for the input."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"input"})," \u2014 URL, file path, or raw text depending on ",(0,i.jsx)(n.code,{children:"csv_type"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"concepts"})," \u2014 Concept labels (if ",(0,i.jsx)(n.code,{children:"labels=True"}),")."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"metadata"})," \u2014 JSON metadata, formatted with single quotes inside. Example: ",(0,i.jsx)(n.code,{children:"\"{'source': 'web'}\""}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"geopoints"})," \u2014 Geolocation in ",(0,i.jsx)(n.code,{children:'"longitude,latitude"'})," format."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"All the data in the CSV file should be enclosed in double quotes."}),"\n",(0,i.jsxs)(n.li,{children:["When uploading text data, ensure the target app is configured to accept text inputs. Set the primary input type to ",(0,i.jsx)(n.strong,{children:"Text/Document"})," when creating the app."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"upload-image-data-with-annotations",children:"Upload Image Data With Annotations"}),"\n",(0,i.jsxs)(n.p,{children:["You can ",(0,i.jsx)(n.a,{href:"https://docs.clarifai.com/create/inputs/upload/api#upload-image-data",children:"upload image data"})," together with bounding box annotations into a Clarifai dataset, adding richer context and detail to your visual data."]}),"\n",(0,i.jsxs)(s.A,{groupId:"code",children:[(0,i.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:d})}),(0,i.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,i.jsx)(l.A,{className:"language-typescript",children:c})})]}),"\n",(0,i.jsx)(n.h2,{id:"upload-image-data-with-mask-annotations",children:"Upload Image Data With Mask Annotations"}),"\n",(0,i.jsx)(n.p,{children:"You can add masks to image data in a Clarifai dataset by providing polygon coordinates with the image, enabling precise region-based annotations."}),"\n",(0,i.jsxs)(s.A,{groupId:"code",children:[(0,i.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:f})}),(0,i.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,i.jsx)(l.A,{className:"language-typescript",children:x})})]}),"\n",(0,i.jsx)(n.h2,{id:"upload-video-data-with-annotations",children:"Upload Video Data With Annotations"}),"\n",(0,i.jsxs)(n.p,{children:["You can ",(0,i.jsx)(n.a,{href:"https://docs.clarifai.com/create/inputs/upload/api#upload-video-data",children:"upload videos"})," in a Clarifai dataset with enriched annotations by including bounding box coordinates that define regions of interest within individual frames, adding valuable context to your video content."]}),"\n",(0,i.jsxs)(s.A,{groupId:"code",children:[(0,i.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:p})}),(0,i.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,i.jsx)(l.A,{className:"language-typescript",children:u})})]}),"\n",(0,i.jsx)(n.h2,{id:"upload-text-data-with-annotations",children:"Upload Text Data With Annotations"}),"\n",(0,i.jsxs)(n.p,{children:["You can ",(0,i.jsx)(n.a,{href:"https://docs.clarifai.com/create/inputs/upload/api#upload-text-data",children:"upload text data"})," in a Clarifai dataset and enrich it by attaching metadata, categorizing the content, or adding detailed annotations to enhance structure and context."]}),"\n",(0,i.jsxs)(s.A,{groupId:"code",children:[(0,i.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:h})}),(0,i.jsx)(r.A,{value:"typescript",label:"Node.js SDK",children:(0,i.jsx)(l.A,{className:"language-typescript",children:m})})]}),"\n",(0,i.jsx)(n.h2,{id:"batch-upload-image-data-while-tracking-status",children:"Batch Upload Image Data While Tracking Status"}),"\n",(0,i.jsx)(n.p,{children:"You can actively monitor the status of your dataset upload, giving you clear visibility into the progress and making it easy to track and analyze the data transfer process."}),"\n",(0,i.jsx)(s.A,{groupId:"code",children:(0,i.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:_})})}),"\n",(0,i.jsx)(n.h2,{id:"retry-upload-from-log-file",children:"Retry Upload From Log File"}),"\n",(0,i.jsxs)(n.p,{children:["You can retry uploads for failed inputs directly from the logs. When using the ",(0,i.jsx)(n.code,{children:"upload_dataset"})," function, any failed inputs are automatically logged to a file, which can later be used to resume and retry the upload process seamlessly."]}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["Set ",(0,i.jsx)(n.code,{children:"retry_duplicates"})," to ",(0,i.jsx)(n.code,{children:"True"})," if you want to retry duplicate with new ",(0,i.jsx)(n.code,{children:"input_id"})," in current dataset."]})}),"\n",(0,i.jsx)(s.A,{groupId:"code",children:(0,i.jsx)(r.A,{value:"python",label:"Python SDK",children:(0,i.jsx)(l.A,{className:"language-python",children:g})})})]})}function T(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(R,{...e})}):R(e)}}}]);