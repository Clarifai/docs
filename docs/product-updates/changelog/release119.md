---
description: Changelog for Clarifai Release 11.9
# For versioning, we use a negative position so that the oldest versions are displayed at the bottom. Any time you add a new version, increase the position by -1. 
sidebar_position: -72
pagination_next: null
pagination_prev: product-updates/changelog/release118
draft: true
---

# Release 11.9

**Release Date:** October 7th, 2025

<hr/>

<br />

| New Feature | Improvement | Bug Fix | Enterprise Only |
| :---: | :---: | :---: | :---: |
| ![new-feature](/img/new_feature.jpg) |![improvement](/img/improvement.jpg) | ![bug](/img/bug.jpg) | ![enterprise](/img/enterprise.jpg) |

## Reasoning Engine

|Status                                |Change                  |Details                    |
|--------------------------------------|------------------------|---------------------------|
| ![new-feature](/img/new_feature.jpg)| Clarifai has launched a Reasoning Engine optimized for agentic AI inference | <ul>  <li> In independent benchmarks conducted by Artificial Analysis on GPT-OSS 120B, the Clarifai Reasoning Engine set new records on standard GPUs: 544 tokens/sec throughput, 3.6s time-to-first-token, and $0.16 per million tokens. </li> <li> Learn more [here](https://www.clarifai.com/press-release-clarifai-launches-reasoning-engine-optimized-for-agentic-ai-inference). </li> </ul>  |

## Toolkits

|Status                                |Change                  |Details                    |
|--------------------------------------|------------------------|---------------------------|
| ![new-feature](/img/new_feature.jpg)|  Added support for toolkits  | <ul> <li>Added support for initializing models with the `vLLM`, `LMStudio`, and  `Hugging Face` toolkits for local runners.</li> </ul>  |


## Third-Party API Keys

|Status                                |Change                  |Details                    |
|--------------------------------------|------------------------|---------------------------|
| ![new-feature](/img/new_feature.jpg)| Introduced third-party API keys | <ul> <li> These keys are used to authenticate and authorize external applications or services, enabling them to securely interact with your data without exposing your primary credentials, such as your Personal Access Token (PAT). </li> <li> Learn more [here](https://docs.clarifai.com/control/authentication/third-party-api-keys).</li> </ul>  |


## Published Models

|Status                                |Change                  |Details                    |
|--------------------------------------|------------------------|---------------------------|
| ![new-feature](/img/new_feature.jpg)| Published new models | <ul> <li> Published [Qwen3-Next-80B-A3B-Thinking](https://clarifai.com/qwen/qwen3/models/qwen3-next-80B-A3B-Thinking), a 80B-parameter, sparsely activated reasoning-optimized LLM that delivers near-flagship performance on complex reasoning tasks with extreme efficiency in training and ultra-long context inference (up to 256K tokens). </li> <li> Published [Qwen3-30B-A3B-Instruct-2507](https://clarifai.com/qwen/qwenLM/models/Qwen3-30B-A3B-Instruct-2507), which improves comprehension, coding, multilingual knowledge, user alignment, and has 256K long-context handling. </li> <li> Published [Qwen3-30B-A3B-Thinking-2507](https://clarifai.com/qwen/qwenLM/models/Qwen3-30B-A3B-Thinking-2507), which is an enhanced version with significantly improved reasoning, general capabilities, user alignment, and a long-context understanding.</li></ul>  |

## B200s and GH200s 

|Status                                |Change                  |Details                    |
|--------------------------------------|------------------------|---------------------------|
| ![new-feature](/img/new_feature.jpg)| Added new Vultr [cloud instances](https://docs.clarifai.com/compute/deployments/cloud-instances)   | <ul> <li> Introduced competitively priced B200 instances operating from Seattle and GH200 instances powered by Vultr. </li> </ul>  |

## Platform

|Status                                |Change                  |Details                    |
|--------------------------------------|------------------------|---------------------------|
| ![improvement](/img/improvement.jpg)|  Made some platform improvements  | <ul> <li> Added short [role descriptions](https://docs.clarifai.com/control/clarifai-organizations/members-teams#roles-for-members) in the Invite Member modal to clarify each memberâ€™s permissions when inviting them to an organization or modifying their access. </li> <li> In the [Control Center](https://docs.clarifai.com/control/control-center/), charts for computer vision models (displaying predictions) and for LLMs (displaying tokens) are now presented separately, each with its own usage and cost information. </li> </ul>  |
| ![bug](/img/bug.jpg) | Fixed some bugs| <ul> <li> Fixed an issue that prevented the signup/login modal from appearing on the Compute page ([clarifai.com/compute](https://clarifai.com/compute)).</li> </ul>  |


## Python SDK

|Status                                |Change                  |Details                    |
|--------------------------------------|------------------------|---------------------------|
| ![improvement](/img/improvement.jpg) | Improved the Python SDK <br/> <br/> Learn more [here](https://github.com/Clarifai/clarifai-python/blob/master/CHANGELOG.md)   | <ul>  <li>Introduced a new `patch_version` method in the Model class and integrated it into local runner workflows.</li>   <li>Improved logging by highlighting example code scripts printed during local runner workflows.</li><li>Changed the default local development model type from `text-to-text` to `any-to-any`.</li> <li>Fixed an issue with converting gRPC response enums to integers during runner creation.</li>  <li>Fixed a `TypeError` when parsing checkpoint size from an environment variable.</li>  <li>Enabled health probe support, allowing `ModelClass` implementations to define liveness/readiness checks.</li>  <li>Improved interactive pipeline initialization with user prompts that replace placeholder TODO values.</li>  <li>Implemented Git registry metadata capture during model upload with model-scoped change detection.</li>  <li>Local runner now automatically uses the latest local-dev model version.</li>  <li>Reduced friction by continuing to leverage a single prebuilt AMD base image.</li>  <li>Updated type hints and docstring descriptions across all major files in the `clarifai/client` folder for better code quality, maintainability, and developer experience.</li>  <li>Improved overall Model CLI UX with consolidated flags, clearer help text, and better error surfacing.</li>   <li>Updated the `clarifai model predict` CLI to align with recent Pythonic model changes.</li>   <li>Updated the local runner default API base URL.</li>   <li>Refined logging in model and pipeline step builders for clearer diagnostics.</li>   <li>Added pagination support to pipeline log monitoring, returning all entries beyond the first 50.</li>   </ul>|