<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-compute/toolkits/lmstudio" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">LM Studio | Clarifai Docs</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://docs.clarifai.com/compute/toolkits/lmstudio"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="LM Studio | Clarifai Docs"><meta data-rh="true" name="description" content="Download and run LM Studio models locally and expose them via a public API"><meta data-rh="true" property="og:description" content="Download and run LM Studio models locally and expose them via a public API"><link data-rh="true" rel="icon" href="/img/favicon.svg"><link data-rh="true" rel="canonical" href="https://docs.clarifai.com/compute/toolkits/lmstudio"><link data-rh="true" rel="alternate" href="https://docs.clarifai.com/compute/toolkits/lmstudio" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.clarifai.com/compute/toolkits/lmstudio" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://E9LMD97ZH2-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Toolkits","item":"https://docs.clarifai.com/compute/toolkits/"},{"@type":"ListItem","position":2,"name":"LM Studio","item":"https://docs.clarifai.com/compute/toolkits/lmstudio"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3R20NHSS5H"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-3R20NHSS5H",{anonymize_ip:!0})</script>
<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-5W9P7GR",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>




<link rel="search" type="application/opensearchdescription+xml" title="Clarifai Docs" href="/opensearch.xml">




<script src="/scripts/sidebar.js" async></script>
<script src="/scripts/intercomConfig.js" async></script>
<script src="https://cdn.amplitude.com/libs/analytics-browser-2.12.0-min.js.gz" defer="defer"></script>
<script src="https://cdn.amplitude.com/libs/plugin-session-replay-browser-1.4.0-min.js.gz" defer="defer"></script>
<script src="/scripts/amplitude.js" defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.cd86c358.css">
<script src="/assets/js/runtime~main.9c0df257.js" defer="defer"></script>
<script src="/assets/js/main.bcccae44.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5W9P7GR" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementWrapper_Ma07"><div class="announcementBar_s0pr" role="banner"><div class="announcementBarPlaceholder_qxfj"></div><div class="announcementBarClose_iXyO"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="none" viewBox="0 0 32 32"><rect width="32" height="32" fill="#F3F4F6" rx="16"></rect><path stroke="#1F2A37" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21.714 10.286 10.285 21.714m0-11.428 11.429 11.428"></path></svg></div><div class="content_knG7 announcementBarContent_dpRF"><span>Clarifai Reasoning Engine:</span>Benchmarked by Artificial Analysis on GPT-OSS-120B → 544 tokens/sec, 3.6s TTFA, $0.16/M — Faster, Cheaper, Adaptive. <a target="_blank" rel="noopener noreferrer" href="https://www.clarifai.com/press-release-clarifai-launches-reasoning-engine-optimized-for-agentic-ai-inference">Learn More.</a></div></div></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo-dark.svg" alt="Clarifai Docs" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo-light.svg" alt="Clarifai Docs" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><div class="navbar__item dropdown dropdown--hoverable" style="width:unset"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">API References</a><ul class="dropdown__menu" style="display:flex;flex-direction:column;height:auto;max-height:300px;max-width:unset;flex-wrap:wrap;overflow-y:unset;width:300px;column-gap:32px"><li><a class="dropdown__link" href="/resources/api-references/python">Python SDK Reference</a></li><li><a class="dropdown__link" href="/resources/api-references/node/">Node.js SDK Reference</a></li><li><a href="https://documenter.getpostman.com/view/30622694/2s9YkuZdro" target="_blank" rel="noopener noreferrer" class="dropdown__link">Postman API Reference<svg width="12" height="12" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li><a href="https://api.clarifai.com/api-doc/?url=https://api.clarifai.com/v2/swagger.json" target="_blank" rel="noopener noreferrer" class="dropdown__link">Swagger API Reference<svg width="12" height="12" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Meta+k)" aria-keyshortcuts="Meta+k"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 24 24" aria-hidden="true"><circle cx="11" cy="11" r="8" stroke="currentColor" fill="none" stroke-width="1.4"></circle><path d="m21 21-4.3-4.3" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div><a href="https://github.com/Clarifai/docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="Github repository"></a><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-discord-link" aria-label="Discord"></a><a href="https://x.com/clarifai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-x-link" aria-label="X"></a><a href="https://www.linkedin.com/company/clarifai/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-linkedin-link" aria-label="LinkedIn"></a><a href="https://clarifai.com/login?__hstc=56460205.941fd3bdff0d161c2f70ccba4c9dcb6b.1707280236564.1715406292479.1715409915530.11&amp;__hssc=56460205.1.1715409915530&amp;__hsfp=1566939966" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link login-link" aria-label="Login">Login<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><a href="https://clarifai.com/signup?__hstc=56460205.941fd3bdff0d161c2f70ccba4c9dcb6b.1707280236564.1715406292479.1715409915530.11&amp;__hssc=56460205.1.1715409915530&amp;__hsfp=1566939966" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link signup-button" aria-label="Start for free">Start for free<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_ntye" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/"><span title="Welcome" class="linkLabel_WmDU">Welcome</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Getting Started" class="categoryLinkLabel_W154">Getting Started</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/quickstart"><span title="Quick Start With API" class="linkLabel_WmDU">Quick Start With API</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/quickstart-playground"><span title="Quick Start With Playground" class="linkLabel_WmDU">Quick Start With Playground</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/first-deployment"><span title="Deploy Your First Model" class="linkLabel_WmDU">Deploy Your First Model</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/set-up-compute"><span title="Set Up Compute Fast" class="linkLabel_WmDU">Set Up Compute Fast</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/upload-model"><span title="Build and Upload a Model" class="linkLabel_WmDU">Build and Upload a Model</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--active"><span title="Compute" class="categoryLinkLabel_W154">Compute</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/overview"><span title="Compute Orchestration" class="linkLabel_WmDU">Compute Orchestration</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/compute/deployments/"><span title="Deployments" class="categoryLinkLabel_W154">Deployments</span></a><button aria-label="Expand sidebar category &#x27;Deployments&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/compute/inference/"><span title="Inference" class="categoryLinkLabel_W154">Inference</span></a><button aria-label="Expand sidebar category &#x27;Inference&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/compute/upload/"><span title="Build and Upload Models" class="categoryLinkLabel_W154">Build and Upload Models</span></a><button aria-label="Expand sidebar category &#x27;Build and Upload Models&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/local-runners/"><span title="Local Runners" class="linkLabel_WmDU">Local Runners</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/compute/toolkits/"><span title="Toolkits" class="categoryLinkLabel_W154">Toolkits</span></a><button aria-label="Collapse sidebar category &#x27;Toolkits&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/toolkits/ollama"><span title="Ollama" class="linkLabel_WmDU">Ollama</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/toolkits/hf"><span title="Hugging Face" class="linkLabel_WmDU">Hugging Face</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/compute/toolkits/lmstudio"><span title="LM Studio" class="linkLabel_WmDU">LM Studio</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/toolkits/vllm"><span title="vLLM" class="linkLabel_WmDU">vLLM</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/compute/agents/"><span title="Agents" class="categoryLinkLabel_W154">Agents</span></a><button aria-label="Expand sidebar category &#x27;Agents&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Control and Governance" class="categoryLinkLabel_W154">Control and Governance</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/control/authentication/"><span title="Authentication" class="categoryLinkLabel_W154">Authentication</span></a><button aria-label="Expand sidebar category &#x27;Authentication&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/control/control-center/"><span title="Control Center" class="categoryLinkLabel_W154">Control Center</span></a><button aria-label="Expand sidebar category &#x27;Control Center&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/control/clarifai-organizations/"><span title="Clarifai Organizations" class="categoryLinkLabel_W154">Clarifai Organizations</span></a><button aria-label="Expand sidebar category &#x27;Clarifai Organizations&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Create and Manage" class="categoryLinkLabel_W154">Create and Manage</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/applications/"><span title="Applications" class="categoryLinkLabel_W154">Applications</span></a><button aria-label="Expand sidebar category &#x27;Applications&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/inputs/"><span title="Inputs" class="categoryLinkLabel_W154">Inputs</span></a><button aria-label="Expand sidebar category &#x27;Inputs&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/search/"><span title="Vector Search" class="categoryLinkLabel_W154">Vector Search</span></a><button aria-label="Expand sidebar category &#x27;Vector Search&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/datasets/"><span title="Datasets" class="categoryLinkLabel_W154">Datasets</span></a><button aria-label="Expand sidebar category &#x27;Datasets&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/concepts/"><span title="Concepts" class="categoryLinkLabel_W154">Concepts</span></a><button aria-label="Expand sidebar category &#x27;Concepts&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/labeling/"><span title="Labeling" class="categoryLinkLabel_W154">Labeling</span></a><button aria-label="Expand sidebar category &#x27;Labeling&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/models/"><span title="Models" class="categoryLinkLabel_W154">Models</span></a><button aria-label="Expand sidebar category &#x27;Models&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/workflows/"><span title="Workflows" class="categoryLinkLabel_W154">Workflows</span></a><button aria-label="Expand sidebar category &#x27;Workflows&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/agent-system-operators/"><span title="Agent System Operators" class="categoryLinkLabel_W154">Agent System Operators</span></a><button aria-label="Expand sidebar category &#x27;Agent System Operators&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/modules/"><span title="Modules" class="categoryLinkLabel_W154">Modules</span></a><button aria-label="Expand sidebar category &#x27;Modules&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Additional Resources" class="categoryLinkLabel_W154">Additional Resources</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/api-overview/"><span title="API Overview" class="categoryLinkLabel_W154">API Overview</span></a><button aria-label="Expand sidebar category &#x27;API Overview&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/platform/"><span title="Platform Overview" class="linkLabel_WmDU">Platform Overview</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/api-references/"><span title="API References" class="categoryLinkLabel_W154">API References</span></a><button aria-label="Expand sidebar category &#x27;API References&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/glossary/"><span title="Glossary" class="categoryLinkLabel_W154">Glossary</span></a><button aria-label="Expand sidebar category &#x27;Glossary&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/data-utils/"><span title="Data Utils" class="categoryLinkLabel_W154">Data Utils</span></a><button aria-label="Expand sidebar category &#x27;Data Utils&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/sdk-examples"><span title="Python SDK Notebook Examples" class="linkLabel_WmDU">Python SDK Notebook Examples</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/complementary-topics/"><span title="Complementary Topics" class="categoryLinkLabel_W154">Complementary Topics</span></a><button aria-label="Expand sidebar category &#x27;Complementary Topics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/troubleshooting"><span title="Troubleshooting" class="linkLabel_WmDU">Troubleshooting</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/tips"><span title="Additional Tips" class="linkLabel_WmDU">Additional Tips</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/privacy-security"><span title="Data Privacy and Security" class="linkLabel_WmDU">Data Privacy and Security</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Product Updates" class="categoryLinkLabel_W154">Product Updates</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/product-updates/upcoming-api-changes/"><span title="Upcoming Platform Changes" class="categoryLinkLabel_W154">Upcoming Platform Changes</span></a><button aria-label="Expand sidebar category &#x27;Upcoming Platform Changes&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/product-updates/changelog"><span title="Changelog" class="categoryLinkLabel_W154">Changelog</span></a><button aria-label="Expand sidebar category &#x27;Changelog&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Integrations" class="categoryLinkLabel_W154">Integrations</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/embedchain/"><span title="Embedchain" class="categoryLinkLabel_W154">Embedchain</span></a><button aria-label="Expand sidebar category &#x27;Embedchain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/langchain/"><span title="LangChain" class="categoryLinkLabel_W154">LangChain</span></a><button aria-label="Expand sidebar category &#x27;LangChain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/llamaindex/"><span title="LlamaIndex" class="categoryLinkLabel_W154">LlamaIndex</span></a><button aria-label="Expand sidebar category &#x27;LlamaIndex&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/databricks/"><span title="Databricks" class="categoryLinkLabel_W154">Databricks</span></a><button aria-label="Expand sidebar category &#x27;Databricks&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/DSPy/"><span title="DSPy" class="categoryLinkLabel_W154">DSPy</span></a><button aria-label="Expand sidebar category &#x27;DSPy&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/unstructured/"><span title="Unstructured.io" class="categoryLinkLabel_W154">Unstructured.io</span></a><button aria-label="Expand sidebar category &#x27;Unstructured.io&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Additional Links" class="categoryLinkLabel_W154">Additional Links</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://api.clarifai.com/api-doc/?url=https://api.clarifai.com/v2/swagger.json" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0"><span title="Swagger API Guide" class="linkLabel_WmDU">Swagger API Guide</span><svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://stackoverflow.com/tags/clarifai/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0"><span title="Stack Overflow" class="linkLabel_WmDU">Stack Overflow</span><svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://status.clarifai.com/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0"><span title="API Status" class="linkLabel_WmDU">API Status</span><svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://www.clarifai.com/blog/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0"><span title="Clarifai Blog" class="linkLabel_WmDU">Clarifai Blog</span><svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Compute</span></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/compute/toolkits/"><span>Toolkits</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">LM Studio</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>LM Studio</h1></header>
<p><strong>Download and run LM Studio models locally and expose them via a public API</strong></p>
<hr>
<p><a href="https://lmstudio.ai/" target="_blank" rel="noopener noreferrer" class="">LM Studio</a> is a desktop application that lets you run and chat with open-source large language models (LLMs) locally — no internet connection required.</p>
<p>With Clarifai’s <a href="https://docs.clarifai.com/compute/local-runners/" target="_blank" rel="noopener noreferrer" class="">Local Runners</a>, you can take this a step further: run LM Studio models directly on your machine, expose them securely through a public URL, and leverage Clarifai’s powerful AI platform — all while maintaining the speed, privacy, and control of local deployment.</p>
<blockquote>
<p><strong>Note:</strong> After downloading the model using the LM Studio toolkit, you can <a href="https://docs.clarifai.com/compute/upload/#step-4-upload-the-model-to-clarifai" target="_blank" rel="noopener noreferrer" class="">upload</a> it to Clarifai to leverage the platform’s capabilities.</p>
</blockquote>
<!-- -->
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-1-perform-prerequisites">Step 1: Perform Prerequisites<a href="#step-1-perform-prerequisites" class="hash-link" aria-label="Direct link to Step 1: Perform Prerequisites" title="Direct link to Step 1: Perform Prerequisites" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="sign-up-or-log-in">Sign Up or Log In<a href="#sign-up-or-log-in" class="hash-link" aria-label="Direct link to Sign Up or Log In" title="Direct link to Sign Up or Log In" translate="no">​</a></h3>
<p><a href="https://clarifai.com/login" target="_blank" rel="noopener noreferrer" class=""><strong>Log in</strong></a> to your existing Clarifai account or <a href="https://clarifai.com/signup" target="_blank" rel="noopener noreferrer" class=""><strong>sign up</strong></a> for a new one. After logging in, gather the following credentials for setup:</p>
<ul>
<li class=""><strong>App ID</strong> – Go to the application you’ll use to run your model and select <strong><a href="https://docs.clarifai.com/create/applications/manage/#app-overview" target="_blank" rel="noopener noreferrer" class="">Overview</a></strong> in the collapsible left sidebar. Get the app ID from there.</li>
<li class=""><strong>User ID</strong> – In the collapsible left sidebar, select <strong>Settings</strong> and select <strong>Account</strong> from the dropdown list. Then, find your user ID.</li>
<li class=""><strong>Personal Access Token (PAT)</strong> – From the same <strong>Settings</strong> option, select <strong>Secrets</strong> to create or copy your <a href="https://docs.clarifai.com/control/authentication/pat" target="_blank" rel="noopener noreferrer" class="">PAT</a>. This token is required to authenticate your connection with the Clarifai platform.</li>
</ul>
<p>Once you have your PAT, set it as an environment variable for secure authentication:</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Unix-like Systems</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Windows</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(189, 147, 249);font-style:italic">CLARIFAI_PAT</span><span class="token operator">=</span><span class="token plain">YOUR_PERSONAL_ACCESS_TOKEN_HERE</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">set</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(189, 147, 249);font-style:italic">CLARIFAI_PAT</span><span class="token operator">=</span><span class="token plain">YOUR_PERSONAL_ACCESS_TOKEN_HERE</span><br></span></code></pre></div></div></div></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="install-the-clarifai-cli">Install the Clarifai CLI<a href="#install-the-clarifai-cli" class="hash-link" aria-label="Direct link to Install the Clarifai CLI" title="Direct link to Install the Clarifai CLI" translate="no">​</a></h3>
<p>Next, install the latest version of the <a href="https://docs.clarifai.com/sdk/cli" target="_blank" rel="noopener noreferrer" class=""><strong>Clarifai CLI</strong></a>, which includes built-in support for Local Runners.</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Bash</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip </span><span class="token function" style="color:rgb(80, 250, 123)">install</span><span class="token plain"> </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--upgrade</span><span class="token plain"> clarifai</span><br></span></code></pre></div></div></div></div></div>
<blockquote>
<p><strong>Note:</strong> Ensure you have <strong><a href="https://docs.clarifai.com/resources/api-overview/python-sdk#python-requirements" target="_blank" rel="noopener noreferrer" class="">Python 3.11 or 3.12</a></strong> installed to successfully run Local Runners.</p>
</blockquote>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="install-the-openai-package">Install the OpenAI Package<a href="#install-the-openai-package" class="hash-link" aria-label="Direct link to Install the OpenAI Package" title="Direct link to Install the OpenAI Package" translate="no">​</a></h3>
<p>Install the <code>openai</code> package — it’s required to perform inference with LM Studio models that support the <a href="https://docs.clarifai.com/compute/inference/#predict-with-openai-compatible-format" target="_blank" rel="noopener noreferrer" class="">OpenAI-compatible</a> format.</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Bash</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip </span><span class="token function" style="color:rgb(80, 250, 123)">install</span><span class="token plain"> openai</span><br></span></code></pre></div></div></div></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="install-lm-studio">Install LM Studio<a href="#install-lm-studio" class="hash-link" aria-label="Direct link to Install LM Studio" title="Direct link to Install LM Studio" translate="no">​</a></h3>
<p><a href="https://lmstudio.ai/download" target="_blank" rel="noopener noreferrer" class="">Download</a> and install the LM Studio desktop application to run open-source large language models locally.</p>
<p>Ensure the LM Studio remains open and running when you start a Clarifai Local Runner, as the runner relies on LM Studio’s internal model runtime for successful execution.</p>
<blockquote>
<p><strong>Note:</strong> Currently, Clarifai Local Runners support running LLMs through LM Studio only on Apple devices (macOS).</p>
</blockquote>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-2-initialize-a-model">Step 2: Initialize a Model<a href="#step-2-initialize-a-model" class="hash-link" aria-label="Direct link to Step 2: Initialize a Model" title="Direct link to Step 2: Initialize a Model" translate="no">​</a></h2>
<p>Using the Clarifai CLI, you can download and set up any model available in the <a href="https://lmstudio.ai/models" target="_blank" rel="noopener noreferrer" class="">LM Studio Model Catalog</a> that supports the GGUF format.</p>
<p>For example, the command below initializes the default model (<a href="https://lmstudio.ai/models/liquid/lfm2-1.2b" target="_blank" rel="noopener noreferrer" class="">LiquidAI/LFM2-1.2B</a>) in your current directory:</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Bash</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai model init </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--toolkit</span><span class="token plain"> lmstudio</span><br></span></code></pre></div></div></div></div></div>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example Output</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai model init --toolkit lmstudio</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:07:03.086018 Parsed GitHub repository: owner=Clarifai, repo=runners-examples, branch=lmstudio, folder_path= |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:07:05.331174 Files to be downloaded are:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">1. 1/model.py</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">2. config.yaml</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">3. requirements.txt |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Press Enter to continue...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:07:09.895510 Initializing model from GitHub repository: https://github.com/Clarifai/runners-examples |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:07:37.976873 Successfully cloned repository from https://github.com/Clarifai/runners-examples (branch: lmstudio) |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:07:37.980528 Model initialization complete with GitHub repository |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:07:37.980580 Next steps: |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:07:37.980603 1. Review the model configuration |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:07:37.980619 2. Install any required dependencies manually |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:07:37.980635 3. Test the model locally using &#x27;clarifai model local-test&#x27; |  thread=8309383360 </span><br></span></code></pre></div></div></div></div></details>
<p>Running this command creates a new model directory structure compatible with the Clarifai platform. You can further customize or optimize the model by modifying the generated files as needed.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>To initialize a specific LM Studio model that supports the GGUF format, use the <code>--model-name</code> flag.</p><div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Bash</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai model init </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--toolkit</span><span class="token plain"> lmstudio --model-name qwen/qwen3-4b-thinking-2507</span><br></span></code></pre></div></div></div></div></div></div></div>
<blockquote>
<p><strong>Note:</strong> Some models are quite large and require substantial memory or GPU resources. Ensure your machine has sufficient compute capacity to load and run the model locally before initializing it.</p>
</blockquote>
<p>The generated structure includes:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── 1/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   └── model.py</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── requirements.txt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">└── config.yaml</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="modelpy"><code>model.py</code><a href="#modelpy" class="hash-link" aria-label="Direct link to modelpy" title="Direct link to modelpy" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example: model.py</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import sys</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import time</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import socket</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import subprocess</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import List, Iterator</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.openai_class import OpenAIModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_types import Image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.openai_convertor import build_openai_messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from openai import OpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">VERBOSE_LMSTUDIO = True # Set to True to see the output of the lmstudio server in the logs</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def _stream_command(cmd: str, verbose: bool = True):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Run a shell command, streaming its combined stdout/stderr line by line.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Returns True on exit code 0, else raises RuntimeError.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logger.info(f&quot;Running: {cmd}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Force line buffering from many tools by setting environment tweaks</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    env = os.environ.copy()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    env[&quot;PYTHONUNBUFFERED&quot;] = &quot;1&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Start process</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    process = subprocess.Popen(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        cmd,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        shell=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        stdout=subprocess.PIPE,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        stderr=subprocess.STDOUT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        text=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        bufsize=1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        env=env</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if verbose and process.stdout:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for line in iter(process.stdout.readline, &quot;&quot;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if line:  # strip trailing newline for cleaner log</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                logger.info(f&quot;[lms logs] {line.rstrip()}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ret = process.wait()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if ret != 0:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        raise RuntimeError(f&quot;Command failed ({ret}): {cmd}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def _wait_for_port(port: int, timeout: float = 30.0):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Wait until something is listening on localhost:port.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    start = time.time()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    while time.time() - start &lt; timeout:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            sock.settimeout(1)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if sock.connect_ex((&quot;127.0.0.1&quot;, port)) == 0:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    return True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            except Exception:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                pass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        time.sleep(0.5)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    raise RuntimeError(f&quot;Server did not start listening on port {port} within {timeout}s&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def run_lms_server(model_name: str = &#x27;LiquidAI/LFM2-1.2B-GGUF&#x27;, port: int = 11434,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                   context_length: int = 4096) -&gt; None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Start the lmstudio server with ordered, real‑time logs.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    from clarifai.runners.utils.model_utils import terminate_process  # keep if needed elsewhere</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # 1. Pull model</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        _stream_command(f&quot;lms get https://huggingface.co/{model_name} --verbose&quot;, verbose=VERBOSE_LMSTUDIO)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;Model {model_name} pulled successfully.&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # 2. Unload previous models</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        _stream_command(&quot;lms unload --all&quot;, verbose=VERBOSE_LMSTUDIO)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;All models unloaded successfully.&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # 3. Load target model</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        _stream_command(f&quot;lms load {model_name} --verbose --context-length {context_length}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        verbose=VERBOSE_LMSTUDIO)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;Model {model_name} loaded (context_length={context_length}).&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # 4. Start server (run in background so we return)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;Starting lmstudio server on port {port}...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Start server detached so we can still stream its startup output briefly if verbose.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        server_proc = subprocess.Popen(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;lms server start --port {port}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            shell=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            stdout=None if not VERBOSE_LMSTUDIO else sys.stdout,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            stderr=None if not VERBOSE_LMSTUDIO else sys.stderr</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # 5. Wait for port to be open</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        _wait_for_port(port)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;lms server started successfully on port {port} (pid={server_proc.pid}).&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.error(f&quot;Error starting lmstudio server: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        raise RuntimeError(f&quot;Failed to start lmstudio server: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Check if Image has content before building messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def has_image_content(image: Image) -&gt; bool:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Check if Image object has either bytes or URL.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return bool(getattr(image, &#x27;url&#x27;, None) or getattr(image, &#x27;bytes&#x27;, None))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class LMstudioModelClass(OpenAIModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    client =  True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model = True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Load the lmstudio model.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        builder = ModelBuilder(model_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model = builder.config[&#x27;toolkit&#x27;][&#x27;model&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.port = builder.config[&#x27;toolkit&#x27;][&#x27;port&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.context_length = builder.config[&#x27;toolkit&#x27;][&#x27;context_length&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        #start lmstudio server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        run_lms_server(model_name=self.model, port=self.port, context_length=self.context_length)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.client = OpenAI(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                api_key=&quot;notset&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                base_url= f&quot;http://localhost:{self.port}/v1&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;LMstudio model loaded successfully: {self.model}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def predict(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                image: Image = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                images: List[Image] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                tools: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                tool_choice: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                max_tokens: int = Param(default=2048, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                top_p: float = Param(default=0.95, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                ) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      This method is used to predict the response for the given prompt and chat history using the model and tools.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if tools is not None and tool_choice is None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tool_choice = &quot;auto&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      img_content = image if has_image_content(image) else None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      messages = build_openai_messages(prompt=prompt, image=img_content, images=images, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      response = self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tools=tools,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tool_choice=tool_choice,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          top_p=top_p)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if response.usage is not None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self.set_output_context(prompt_tokens=response.usage.prompt_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                    completion_tokens=response.usage.completion_tokens)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if len(response.choices) == 0:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                # still need to send the usage back.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                return &quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if response.choices[0] and response.choices[0].message.tool_calls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # If the response contains tool calls, return as a string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_calls = response.choices[0].message.tool_calls</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_calls_json = json.dumps([tc.to_dict() for tc in tool_calls], indent=2)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return tool_calls_json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Otherwise, return the content of the first choice</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return response.choices[0].message.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def generate(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                image: Image = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                images: List[Image] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                tools: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                tool_choice: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                max_tokens: int = Param(default=2048, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                top_p: float = Param(default=0.95, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;)) -&gt; Iterator[str]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      This method is used to stream generated text tokens from a prompt + optional chat history and tools.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if tools is not None and tool_choice is None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tool_choice = &quot;auto&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      img_content = image if has_image_content(image) else None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      messages = build_openai_messages(prompt=prompt, image=img_content, images=images, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      for chunk in self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tools=tools,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tool_choice=tool_choice,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            top_p=top_p,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            stream=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            stream_options={&quot;include_usage&quot;: True}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if chunk.usage is not None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if chunk.usage.prompt_tokens or chunk.usage.completion_tokens:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    self.set_output_context(prompt_tokens=chunk.usage.prompt_tokens, completion_tokens=chunk.usage.completion_tokens)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if len(chunk.choices) == 0: # still need to send the usage back.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    yield &quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if chunk.choices:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if chunk.choices[0].delta.tool_calls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                # If the response contains tool calls, return the first one as a string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    import json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    tool_calls = chunk.choices[0].delta.tool_calls</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    tool_calls_json = [tc.to_dict() for tc in tool_calls]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    # Convert to JSON string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    json_string = json.dumps(tool_calls_json, indent=2)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    # Yield the JSON string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    yield json_string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    # Otherwise, return the content of the first choice</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    text = (chunk.choices[0].delta.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                            if (chunk and chunk.choices[0].delta.content) is not None else &#x27;&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    yield text</span><br></span></code></pre></div></div></div></div></details>
<p>The <a href="https://docs.clarifai.com/compute/upload/#prepare-modelpy" target="_blank" rel="noopener noreferrer" class=""><code>model.py</code></a> file inside the <code>1/</code> directory defines the model’s logic — including how predictions are made and how inputs and outputs are handled.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="configyaml"><code>config.yaml</code><a href="#configyaml" class="hash-link" aria-label="Direct link to configyaml" title="Direct link to configyaml" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example: config.yaml</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.12&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &#x27;3&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 14Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: local-runner-app</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: local-env-model</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: text-to-text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: clarifai-user-id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">toolkit:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  provider: lmstudio</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model: LiquidAI/LFM2-1.2B</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  port: 11434</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  context_length: 2048</span><br></span></code></pre></div></div></div></div></details>
<p>The <code>config.yaml</code> file defines key configuration details, such as compute resource requirements and toolkit metadata.</p>
<p>In the <code>model</code> section, specify a unique model ID (any name of your choice) and your Clarifai user ID and app ID. These parameters determine where the model will be deployed on the Clarifai platform.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="requirementstxt"><code>requirements.txt</code><a href="#requirementstxt" class="hash-link" aria-label="Direct link to requirementstxt" title="Direct link to requirementstxt" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example: requirements.txt</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">openai</span><br></span></code></pre></div></div></div></div></details>
<p>The <code>requirements.txt</code> file lists the Python dependencies your model needs. If you haven’t installed them yet, run the following command to install the dependencies:</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Bash</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip </span><span class="token function" style="color:rgb(80, 250, 123)">install</span><span class="token plain"> </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">-r</span><span class="token plain"> requirements.txt</span><br></span></code></pre></div></div></div></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-3-log-in-to-clarifai">Step 3: Log In to Clarifai<a href="#step-3-log-in-to-clarifai" class="hash-link" aria-label="Direct link to Step 3: Log In to Clarifai" title="Direct link to Step 3: Log In to Clarifai" translate="no">​</a></h2>
<p>Use the Clarifai CLI to log in to your account and create a configuration <a href="https://docs.clarifai.com/compute/local-runners/#step-2-create-a-context-optional" target="_blank" rel="noopener noreferrer" class=""><strong>context</strong></a> that securely connects your local environment to the Clarifai platform.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai login</span><br></span></code></pre></div></div>
<p>You’ll be prompted to enter the following details:</p>
<ul>
<li class=""><strong>User ID</strong> – Your Clarifai User ID.</li>
<li class=""><strong>PAT</strong> – Your Clarifai Personal Access Token.
If you’ve already set the <code>CLARIFAI_PAT</code> environment variable, type <code>ENVVAR</code> to use it automatically.</li>
<li class=""><strong>Context name</strong> – Optionally, specify a custom name for this configuration context, or press <strong>Enter</strong> to use the default <code>&quot;default&quot;</code>.
Contexts are useful when working with multiple environments or projects.</li>
</ul>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example Output</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai login</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Enter your Clarifai user ID: alfrick</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&gt; To authenticate, you&#x27;ll need a Personal Access Token (PAT).</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&gt; You can create one from your account settings: https://clarifai.com/alfrick/settings/security</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Enter your Personal Access Token (PAT) value (or type &quot;ENVVAR&quot; to use an environment variable): ENVVAR</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&gt; Verifying token...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:38:03.867057 Validating the Context Credentials... |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:38:05.176881 ✅ Context is valid |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&gt; Let&#x27;s save these credentials to a new context.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&gt; You can have multiple contexts to easily switch between accounts or projects.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Enter a name for this context [default]: </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">✅ Success! You are now logged in.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Credentials saved to the &#x27;default&#x27; context.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">💡 To switch contexts later, use `clarifai config use-context &lt;name&gt;`.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:38:10.706639 Login successful for user &#x27;alfrick&#x27; in context &#x27;default&#x27; |  thread=8309383360 </span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-4-start-the-local-runner">Step 4: Start the Local Runner<a href="#step-4-start-the-local-runner" class="hash-link" aria-label="Direct link to Step 4: Start the Local Runner" title="Direct link to Step 4: Start the Local Runner" translate="no">​</a></h2>
<p>Next, start your <strong>Local Runner</strong>, which connects to the LM Studio runtime to execute your model locally.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai model local-runner</span><br></span></code></pre></div></div>
<p>If configuration contexts or defaults are missing, the CLI will guide you through setting them up automatically.</p>
<p>This setup ensures that all necessary components — such as compute clusters, nodepools, and deployments — are properly defined in your configuration context.
For more details, see <a href="https://docs.clarifai.com/compute/local-runners/#step-2-create-a-context-optional" target="_blank" rel="noopener noreferrer" class="">here</a>.</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example Output</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai model local-runner</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:36.097539 Detected OpenAI chat completions for Clarifai model streaming - validating stream_options... |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:36.098189 &gt; Checking local runner requirements... |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:36.118322 Checking 2 dependencies... |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:36.118807 ✅ All 2 dependencies are installed! |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:36.119033 &gt; Verifying local runner setup... |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:36.119083 Current context: default |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:36.119120 Current user_id: alfrick |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:36.119150 Current PAT: d6570**** |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:36.121055 Current compute_cluster_id: local-runner-compute-cluster |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[WARNING] 09:40:37.622490 Failed to get compute cluster with ID &#x27;local-runner-compute-cluster&#x27;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">code: CONN_DOES_NOT_EXIST</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">description: &quot;Resource does not exist&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">details: &quot;ComputeCluster with ID \&#x27;local-runner-compute-cluster\&#x27; not found. Check your request fields.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">req_id: &quot;sdk-python-11.8.2-c324cbe5deb248e19d5d0ed1e32e49d0&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Compute cluster not found. Do you want to create a new compute cluster alfrick/local-runner-compute-cluster? (y/n): y</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:44.198312 Compute Cluster with ID &#x27;local-runner-compute-cluster&#x27; is created:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">code: SUCCESS</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">description: &quot;Ok&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">req_id: &quot;sdk-python-11.8.2-e5b312b4a46f4e2984efc65abb5124c5&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:44.203633 Current nodepool_id: local-runner-nodepool |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[WARNING] 09:40:46.398631 Failed to get nodepool with ID &#x27;local-runner-nodepool&#x27;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">code: CONN_DOES_NOT_EXIST</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">description: &quot;Resource does not exist&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">details: &quot;Nodepool not found. Check your request fields.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">req_id: &quot;sdk-python-11.8.2-1062d71d21574bce99bd4472a9fdc6ef&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Nodepool not found. Do you want to create a new nodepool alfrick/local-runner-compute-cluster/local-runner-nodepool? (y/n): y</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:52.285792 Nodepool with ID &#x27;local-runner-nodepool&#x27; is created:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">code: SUCCESS</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">description: &quot;Ok&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">req_id: &quot;sdk-python-11.8.2-66d76251237c4be38764837e639c6800&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:52.292983 Current app_id: local-runner-app |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[WARNING] 09:40:52.574021 Failed to get app with ID &#x27;local-runner-app&#x27;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">code: CONN_DOES_NOT_EXIST</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">description: &quot;Resource does not exist&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">details: &quot;app identified by path /users/alfrick/apps/local-runner-app not found&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">req_id: &quot;sdk-python-11.8.2-29b94532bf624596abbbaea66be198e2&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">App not found. Do you want to create a new app alfrick/local-runner-app? (y/n): y</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:56.302447 App with ID &#x27;local-runner-app&#x27; is created:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">code: SUCCESS</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">description: &quot;Ok&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">req_id: &quot;sdk-python-11.8.2-b5066f7c64274944ba405ba01da11c1c&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:40:56.306934 Current model_id: local-runner-model |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[WARNING] 09:40:58.007139 Failed to get model with ID &#x27;local-runner-model&#x27;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">code: MODEL_DOES_NOT_EXIST</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">description: &quot;Model does not exist&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">details: &quot;Model \&#x27;local-runner-model\&#x27; does not exist.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">req_id: &quot;sdk-python-11.8.2-8b2717eb04624aca8bf119e03b94b5b4&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Model not found. Do you want to create a new model alfrick/local-runner-app/models/local-runner-model? (y/n): y</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:14.336510 Model with ID &#x27;local-runner-model&#x27; is created:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">code: SUCCESS</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">description: &quot;Ok&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">req_id: &quot;sdk-python-11.8.2-f36c2684e1bc4d8f99e777d42e5c53f8&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[WARNING] 09:41:17.182009 No model versions found. Creating a new version for local runner. |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:17.510454 Model Version with ID &#x27;fa82276f4cfa44c08745b028471bbfa5&#x27; is created:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">code: SUCCESS</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">description: &quot;Ok&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">req_id: &quot;sdk-python-11.8.2-0121fe726015400c86e4bd3959729787&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:17.517728 Current model version fa82276f4cfa44c08745b028471bbfa5 |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:17.517802 Creating the local runner tying this &#x27;alfrick/local-runner-app/models/local-runner-model&#x27; model (version: fa82276f4cfa44c08745b028471bbfa5) to the &#x27;alfrick/local-runner-compute-cluster/local-runner-nodepool&#x27; nodepool. |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:18.591818 Runner with ID &#x27;649b39c737d84dd8a5e3d5af0b19c207&#x27; is created:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">code: SUCCESS</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">description: &quot;Ok&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">req_id: &quot;sdk-python-11.8.2-ced2523458a941519a709e6af082832a&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:18.598056 Current runner_id: 649b39c737d84dd8a5e3d5af0b19c207 |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[WARNING] 09:41:19.150091 Failed to get deployment with ID local-runner-deployment:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">code: DEPLOYMENT_INVALID_REQUEST</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">description: &quot;Invalid deployment request&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">details: &quot;Some of the deployment ids provided (local-runner-deployment) do not exist&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">req_id: &quot;sdk-python-11.8.2-9af7aa96a9a843e68f8f3ef898bf61c1&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Deployment not found. Do you want to create a new deployment alfrick/local-runner-compute-cluster/local-runner-nodepool/local-runner-deployment? (y/n): y</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:25.833184 Deployment with ID &#x27;local-runner-deployment&#x27; is created:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">code: SUCCESS</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">description: &quot;Ok&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">req_id: &quot;sdk-python-11.8.2-38e4b0bd886e4979bc9b7324361e2c56&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:25.839987 Current deployment_id: local-runner-deployment |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:25.841181 Current model section of config.yaml: {&#x27;app_id&#x27;: &#x27;local-runner-app&#x27;, &#x27;id&#x27;: &#x27;local-env-model&#x27;, &#x27;model_type_id&#x27;: &#x27;text-to-text&#x27;, &#x27;user_id&#x27;: &#x27;alfrick&#x27;} |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Do you want to backup config.yaml to config.yaml.bk then update the config.yaml with the new model information? (y/n): y</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:29.312446 Checking 2 dependencies... |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:29.313228 ✅ All 2 dependencies are installed! |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:29.313325 ✅ Starting local runner... |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:29.313404 No secrets path configured, running without secrets |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:30.647566 Detected OpenAI chat completions for Clarifai model streaming - validating stream_options... |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:34.359410 Detected OpenAI chat completions for Clarifai model streaming - validating stream_options... |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:34.359915 Running: lms get https://huggingface.co/LiquidAI/LFM2-1.2B --verbose |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:34.625973 [lms logs] D Found local API server at ws://127.0.0.1:41343 |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:34.633082 [lms logs] I Searching for models with the term https://huggingface.co/LiquidAI/LFM2-1.2B |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:34.633891 [lms logs] D Searching for models with options { |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:34.633919 [lms logs]   searchTerm: &#x27;https://huggingface.co/LiquidAI/LFM2-1.2B&#x27;, |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:34.633937 [lms logs]   compatibilityTypes: undefined, |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:34.633950 [lms logs]   limit: undefined |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:34.633963 [lms logs] } |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.602478 [lms logs] D Found 10 result(s) |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.602769 [lms logs] D Prompting user to choose a model |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.602822 [lms logs] I No exact match found. Please choose a model from the list below. |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.602867 [lms logs]  |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.603408 [lms logs] ! Use the arrow keys to navigate, type to filter, and press enter to select. |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.603520 [lms logs]  |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.619671 [lms logs] ? Select a model to download Type to filter... |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.619819 [lms logs] ❯  LiquidAI/LFM2-1.2B-GGUF |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.619874 [lms logs]    LiquidAI/LFM2-1.2B-Tool-GGUF |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.619902 [lms logs]    LiquidAI/LFM2-1.2B-Extract-GGUF |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.619946 [lms logs]    LiquidAI/LFM2-1.2B-RAG-GGUF |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.619969 [lms logs]    DevQuasar/LiquidAI.LFM2-1.2B-GGUF |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.619992 [lms logs]    bartowski/LiquidAI_LFM2-1.2B-Extract-GGUF |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.620018 [lms logs]    bartowski/LiquidAI_LFM2-1.2B-RAG-GGUF |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.620044 [lms logs]    bartowski/LiquidAI_LFM2-1.2B-Tool-GGUF |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 09:41:40.620066 [lms logs]    DevQuasar/LiquidAI.LFM2-1.2B-RAG-GGUF |  thread=8309383360 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-5-test-your-runner">Step 5: Test Your Runner<a href="#step-5-test-your-runner" class="hash-link" aria-label="Direct link to Step 5: Test Your Runner" title="Direct link to Step 5: Test Your Runner" translate="no">​</a></h2>
<p>After the Local Runner starts, you can use it to perform <a href="https://docs.clarifai.com/compute/inference/clarifai/api" target="_blank" rel="noopener noreferrer" class="">inference</a> with your LM Studio–based model.</p>
<p>You can run a snippet in a separate terminal, within the same directory, to confirm that your model is running and responding as expected.</p>
<p>Here’s an example snippet:</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Python (OpenAI)</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> openai </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> OpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Initialize the OpenAI client, pointing to Clarifai&#x27;s API</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">client </span><span class="token operator">=</span><span class="token plain"> OpenAI</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">     </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    base_url</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;https://api.clarifai.com/v2/ext/openai/v1&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Clarifai&#x27;s OpenAI-compatible API endpoint</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    api_key</span><span class="token operator">=</span><span class="token plain">os</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">environ</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;CLARIFAI_PAT&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Ensure CLARIFAI_PAT is set as an environment variable</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Make a chat completion request to a Clarifai-hosted model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">response </span><span class="token operator">=</span><span class="token plain"> client</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">chat</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">completions</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">create</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;https://clarifai.com/&lt;user-id&gt;/local-runner-app/models/local-runner-model&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;role&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;system&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;content&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;You are a helpful assistant.&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;role&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;user&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;content&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;What is the future of AI?&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Print the model&#x27;s response</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">response</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">choices</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">message</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">content</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div></div></div></div></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/compute/toolkits/hf"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Hugging Face</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/compute/toolkits/vllm"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">vLLM</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#step-1-perform-prerequisites" class="table-of-contents__link toc-highlight">Step 1: Perform Prerequisites</a><ul><li><a href="#sign-up-or-log-in" class="table-of-contents__link toc-highlight">Sign Up or Log In</a></li><li><a href="#install-the-clarifai-cli" class="table-of-contents__link toc-highlight">Install the Clarifai CLI</a></li><li><a href="#install-the-openai-package" class="table-of-contents__link toc-highlight">Install the OpenAI Package</a></li><li><a href="#install-lm-studio" class="table-of-contents__link toc-highlight">Install LM Studio</a></li></ul></li><li><a href="#step-2-initialize-a-model" class="table-of-contents__link toc-highlight">Step 2: Initialize a Model</a><ul><li><a href="#modelpy" class="table-of-contents__link toc-highlight"><code>model.py</code></a></li><li><a href="#configyaml" class="table-of-contents__link toc-highlight"><code>config.yaml</code></a></li><li><a href="#requirementstxt" class="table-of-contents__link toc-highlight"><code>requirements.txt</code></a></li></ul></li><li><a href="#step-3-log-in-to-clarifai" class="table-of-contents__link toc-highlight">Step 3: Log In to Clarifai</a></li><li><a href="#step-4-start-the-local-runner" class="table-of-contents__link toc-highlight">Step 4: Start the Local Runner</a></li><li><a href="#step-5-test-your-runner" class="table-of-contents__link toc-highlight">Step 5: Test Your Runner</a></li></ul></div></div></div><div class="custom_doc_item_footer_LMqZ"><div class="banner-primary"><p>Build your next AI app, test and tune popular LLMs models, and much more.</p><a href="https://clarifai.com/explore" target="_blank">Get started for free</a></div><footer class="custom-footer-wrapper_fHnE"><div class="logo-wrapper_GEfd"><img src="/img/logos/clarifai-color-light-logo.svg" class="dark-theme-logo_tdev"><img src="/img/logos/clarifai-color-dark-logo.svg" class="light-theme-logo_cRqu"></div><div class="copyright_aTku">© 2025 Clarifai, Inc. All rights reserved</div><div class="footerSocialIconsWrapper_tJhP"><div class="socialBrands__tjK"><a href="https://github.com/Clarifai" target="_blank" rel="noopener noreferrer" aria-label="Github"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#000" fill-rule="evenodd" d="M9.7 1.5C4.896 1.5 1 5.401 1 10.216a8.715 8.715 0 0 0 5.95 8.269c.436.08.594-.189.594-.42 0-.207-.007-.756-.011-1.482-2.421.526-2.932-1.169-2.932-1.169-.395-1.007-.966-1.275-.966-1.275-.79-.54.06-.53.06-.53.873.062 1.333.899 1.333.899.776 1.33 2.036.946 2.532.724.08-.563.304-.947.553-1.165C6.18 13.847 4.15 13.1 4.15 9.76c0-.951.339-1.73.895-2.34-.09-.22-.388-1.106.085-2.305 0 0 .731-.235 2.393.893a8.3 8.3 0 0 1 2.178-.293c.74.003 1.483.1 2.178.293 1.662-1.128 2.39-.894 2.39-.894.476 1.2.176 2.087.088 2.307a3.37 3.37 0 0 1 .894 2.339c0 3.348-2.035 4.085-3.973 4.3.313.27.59.8.59 1.614 0 1.165-.01 2.105-.01 2.39 0 .234.156.505.598.42a8.72 8.72 0 0 0 5.946-8.268C18.402 5.4 14.505 1.5 9.7 1.5" clip-rule="evenodd"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://twitter.com/clarifai" target="_blank" rel="noopener noreferrer" aria-label="Twitter"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#000" d="M14.6 3h2.454l-5.36 6.142L18 17.5h-4.937l-3.867-5.07-4.425 5.07H2.316l5.733-6.57L2 3h5.063l3.495 4.633zm-.86 13.028h1.36L6.323 4.395H4.865z"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" aria-label="Discord"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#7289DA" d="M13.63 15.997c.514.65 1.13 1.387 1.13 1.387 3.784-.12 5.24-2.603 5.24-2.603 0-5.514-2.466-9.983-2.466-9.983C15.07 2.948 12.723 3 12.723 3l-.24.274c2.91.89 4.264 2.175 4.264 2.175a14 14 0 0 0-5.155-1.644 14.5 14.5 0 0 0-3.458.034c-.103 0-.189.017-.292.034-.599.052-2.054.274-3.887 1.08-.633.29-1.01.496-1.01.496S4.366 4.096 7.45 3.206L7.277 3S4.932 2.95 2.466 4.798c0 0-2.466 4.47-2.466 9.983 0 0 1.438 2.483 5.223 2.603 0 0 .633-.77 1.147-1.421-2.175-.651-2.997-2.021-2.997-2.021s.172.12.48.291c.017.017.034.034.068.051.052.035.103.052.154.086.428.24.857.428 1.25.582.702.274 1.541.548 2.517.736 1.285.24 2.792.326 4.435.018a11.3 11.3 0 0 0 2.483-.737 9.8 9.8 0 0 0 1.97-1.01s-.857 1.404-3.1 2.038"></path><path fill="#fff" d="M6.884 9.147c-.976 0-1.746.857-1.746 1.901s.787 1.9 1.746 1.9c.976 0 1.747-.855 1.747-1.9.017-1.044-.77-1.9-1.747-1.9m6.25 0c-.976 0-1.746.857-1.746 1.901s.787 1.9 1.746 1.9c.976 0 1.747-.855 1.747-1.9s-.77-1.9-1.747-1.9"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://www.youtube.com/@theworldsai" target="_blank" rel="noopener noreferrer" aria-label="Youtube"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="20" preserveAspectRatio="xMidYMid" viewBox="0 0 256 180"><path fill="red" d="M250.346 28.075A32.18 32.18 0 0 0 227.69 5.418C207.824 0 127.87 0 127.87 0S47.912.164 28.046 5.582A32.18 32.18 0 0 0 5.39 28.24c-6.009 35.298-8.34 89.084.165 122.97a32.18 32.18 0 0 0 22.656 22.657c19.866 5.418 99.822 5.418 99.822 5.418s79.955 0 99.82-5.418a32.18 32.18 0 0 0 22.657-22.657c6.338-35.348 8.291-89.1-.164-123.134Z"></path><path fill="#FFF" d="m102.421 128.06 66.328-38.418-66.328-38.418z"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://www.linkedin.com/company/clarifai" target="_blank" rel="noopener noreferrer" aria-label="Linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><g clip-path="url(#a)"><path fill="#0A66C2" d="M16.819 2H3.18A1.18 1.18 0 0 0 2 3.181V16.82A1.18 1.18 0 0 0 3.181 18H16.82A1.18 1.18 0 0 0 18 16.819V3.18A1.18 1.18 0 0 0 16.819 2M6.769 15.63H4.363V7.989H6.77zm-1.205-8.7a1.381 1.381 0 1 1 1.39-1.38 1.36 1.36 0 0 1-1.39 1.38m10.072 8.707H13.23v-4.175c0-1.23-.523-1.61-1.199-1.61-.713 0-1.413.537-1.413 1.641v4.144H8.213V7.994h2.314v1.06h.03c.233-.47 1.046-1.274 2.287-1.274 1.343 0 2.793.797 2.793 3.13z"></path></g><defs><clipPath id="a"><path fill="#fff" d="M2 2h16v16H2z"></path></clipPath></defs></svg></a></div></div></footer></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://clarifai.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Clarifai Website<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.clarifai.com/explore/contact-us" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contact Us<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/@theworldsai" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/company/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/Clarifai/docs" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Clarifai, Inc.</div></div></div></footer></div>
</body>
</html>