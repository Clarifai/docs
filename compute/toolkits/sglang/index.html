<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-compute/toolkits/sglang" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">SGLang | Clarifai Docs</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://docs.clarifai.com/compute/toolkits/sglang"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="SGLang | Clarifai Docs"><meta data-rh="true" name="description" content="Run models using the SGLang runtime format and make them available via a public API"><meta data-rh="true" property="og:description" content="Run models using the SGLang runtime format and make them available via a public API"><link data-rh="true" rel="icon" href="/img/favicon.svg"><link data-rh="true" rel="canonical" href="https://docs.clarifai.com/compute/toolkits/sglang"><link data-rh="true" rel="alternate" href="https://docs.clarifai.com/compute/toolkits/sglang" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.clarifai.com/compute/toolkits/sglang" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://E9LMD97ZH2-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Toolkits","item":"https://docs.clarifai.com/compute/toolkits/"},{"@type":"ListItem","position":2,"name":"SGLang","item":"https://docs.clarifai.com/compute/toolkits/sglang"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3R20NHSS5H"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-3R20NHSS5H",{anonymize_ip:!0})</script>
<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-5W9P7GR",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>




<link rel="search" type="application/opensearchdescription+xml" title="Clarifai Docs" href="/opensearch.xml">




<script src="/scripts/sidebar.js" async></script>
<script src="/scripts/intercomConfig.js" async></script>
<script src="https://cdn.amplitude.com/libs/analytics-browser-2.12.0-min.js.gz" defer="defer"></script>
<script src="https://cdn.amplitude.com/libs/plugin-session-replay-browser-1.4.0-min.js.gz" defer="defer"></script>
<script src="/scripts/amplitude.js" defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.cd86c358.css">
<script src="/assets/js/runtime~main.721ed671.js" defer="defer"></script>
<script src="/assets/js/main.bca0ce79.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5W9P7GR" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementWrapper_Ma07"><div class="announcementBar_s0pr" role="banner"><div class="announcementBarPlaceholder_qxfj"></div><div class="announcementBarClose_iXyO"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="none" viewBox="0 0 32 32"><rect width="32" height="32" fill="#F3F4F6" rx="16"></rect><path stroke="#1F2A37" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21.714 10.286 10.285 21.714m0-11.428 11.429 11.428"></path></svg></div><div class="content_knG7 announcementBarContent_dpRF"><span>Clarifai Reasoning Engine:</span>Benchmarked by Artificial Analysis on GPT-OSS-120B → 544 tokens/sec, 3.6s TTFA, $0.16/M — Faster, Cheaper, Adaptive. <a target="_blank" rel="noopener noreferrer" href="https://www.clarifai.com/press-release-clarifai-launches-reasoning-engine-optimized-for-agentic-ai-inference">Learn More.</a></div></div></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo-dark.svg" alt="Clarifai Docs" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo-light.svg" alt="Clarifai Docs" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><div class="navbar__item dropdown dropdown--hoverable" style="width:unset"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">API References</a><ul class="dropdown__menu" style="display:flex;flex-direction:column;height:auto;max-height:300px;max-width:unset;flex-wrap:wrap;overflow-y:unset;width:300px;column-gap:32px"><li><a class="dropdown__link" href="/resources/api-references/python">Python SDK Reference</a></li><li><a class="dropdown__link" href="/resources/api-references/node/">Node.js SDK Reference</a></li><li><a href="https://documenter.getpostman.com/view/30622694/2s9YkuZdro" target="_blank" rel="noopener noreferrer" class="dropdown__link">Postman API Reference<svg width="12" height="12" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li><a href="https://api.clarifai.com/api-doc/?url=https://api.clarifai.com/v2/swagger.json" target="_blank" rel="noopener noreferrer" class="dropdown__link">Swagger API Reference<svg width="12" height="12" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Meta+k)" aria-keyshortcuts="Meta+k"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 24 24" aria-hidden="true"><circle cx="11" cy="11" r="8" stroke="currentColor" fill="none" stroke-width="1.4"></circle><path d="m21 21-4.3-4.3" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div><a href="https://github.com/Clarifai/docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="Github repository"></a><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-discord-link" aria-label="Discord"></a><a href="https://x.com/clarifai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-x-link" aria-label="X"></a><a href="https://www.linkedin.com/company/clarifai/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-linkedin-link" aria-label="LinkedIn"></a><a href="https://clarifai.com/login?__hstc=56460205.941fd3bdff0d161c2f70ccba4c9dcb6b.1707280236564.1715406292479.1715409915530.11&amp;__hssc=56460205.1.1715409915530&amp;__hsfp=1566939966" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link login-link" aria-label="Login">Login<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><a href="https://clarifai.com/signup?__hstc=56460205.941fd3bdff0d161c2f70ccba4c9dcb6b.1707280236564.1715406292479.1715409915530.11&amp;__hssc=56460205.1.1715409915530&amp;__hsfp=1566939966" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link signup-button" aria-label="Start for free">Start for free<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_ntye" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/"><span title="Welcome" class="linkLabel_WmDU">Welcome</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Getting Started" class="categoryLinkLabel_W154">Getting Started</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/quickstart"><span title="Quick Start With API" class="linkLabel_WmDU">Quick Start With API</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/quickstart-playground"><span title="Quick Start With Playground" class="linkLabel_WmDU">Quick Start With Playground</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/first-deployment"><span title="Deploy Your First Model" class="linkLabel_WmDU">Deploy Your First Model</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/set-up-compute"><span title="Set Up Compute Fast" class="linkLabel_WmDU">Set Up Compute Fast</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/upload-model"><span title="Build and Upload a Model" class="linkLabel_WmDU">Build and Upload a Model</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--active"><span title="Compute" class="categoryLinkLabel_W154">Compute</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/overview"><span title="Compute Orchestration" class="linkLabel_WmDU">Compute Orchestration</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/compute/deployments/"><span title="Deployments" class="categoryLinkLabel_W154">Deployments</span></a><button aria-label="Expand sidebar category &#x27;Deployments&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/compute/inference/"><span title="Inference" class="categoryLinkLabel_W154">Inference</span></a><button aria-label="Expand sidebar category &#x27;Inference&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/compute/upload/"><span title="Build and Upload Models" class="categoryLinkLabel_W154">Build and Upload Models</span></a><button aria-label="Expand sidebar category &#x27;Build and Upload Models&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/local-runners/"><span title="Local Runners" class="linkLabel_WmDU">Local Runners</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/compute/toolkits/"><span title="Toolkits" class="categoryLinkLabel_W154">Toolkits</span></a><button aria-label="Collapse sidebar category &#x27;Toolkits&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/toolkits/ollama"><span title="Ollama" class="linkLabel_WmDU">Ollama</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/toolkits/hf"><span title="Hugging Face" class="linkLabel_WmDU">Hugging Face</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/toolkits/lmstudio"><span title="LM Studio" class="linkLabel_WmDU">LM Studio</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/toolkits/vllm"><span title="vLLM" class="linkLabel_WmDU">vLLM</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/compute/toolkits/sglang"><span title="SGLang" class="linkLabel_WmDU">SGLang</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/compute/agents/"><span title="Agents" class="categoryLinkLabel_W154">Agents</span></a><button aria-label="Expand sidebar category &#x27;Agents&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Control and Governance" class="categoryLinkLabel_W154">Control and Governance</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/control/authentication/"><span title="Authentication" class="categoryLinkLabel_W154">Authentication</span></a><button aria-label="Expand sidebar category &#x27;Authentication&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/control/control-center/"><span title="Control Center" class="categoryLinkLabel_W154">Control Center</span></a><button aria-label="Expand sidebar category &#x27;Control Center&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/control/clarifai-organizations/"><span title="Clarifai Organizations" class="categoryLinkLabel_W154">Clarifai Organizations</span></a><button aria-label="Expand sidebar category &#x27;Clarifai Organizations&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Create and Manage" class="categoryLinkLabel_W154">Create and Manage</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/applications/"><span title="Applications" class="categoryLinkLabel_W154">Applications</span></a><button aria-label="Expand sidebar category &#x27;Applications&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/inputs/"><span title="Inputs" class="categoryLinkLabel_W154">Inputs</span></a><button aria-label="Expand sidebar category &#x27;Inputs&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/search/"><span title="Vector Search" class="categoryLinkLabel_W154">Vector Search</span></a><button aria-label="Expand sidebar category &#x27;Vector Search&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/datasets/"><span title="Datasets" class="categoryLinkLabel_W154">Datasets</span></a><button aria-label="Expand sidebar category &#x27;Datasets&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/concepts/"><span title="Concepts" class="categoryLinkLabel_W154">Concepts</span></a><button aria-label="Expand sidebar category &#x27;Concepts&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/labeling/"><span title="Labeling" class="categoryLinkLabel_W154">Labeling</span></a><button aria-label="Expand sidebar category &#x27;Labeling&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/models/"><span title="Models" class="categoryLinkLabel_W154">Models</span></a><button aria-label="Expand sidebar category &#x27;Models&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/workflows/"><span title="Workflows" class="categoryLinkLabel_W154">Workflows</span></a><button aria-label="Expand sidebar category &#x27;Workflows&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/agent-system-operators/"><span title="Agent System Operators" class="categoryLinkLabel_W154">Agent System Operators</span></a><button aria-label="Expand sidebar category &#x27;Agent System Operators&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/modules/"><span title="Modules" class="categoryLinkLabel_W154">Modules</span></a><button aria-label="Expand sidebar category &#x27;Modules&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Additional Resources" class="categoryLinkLabel_W154">Additional Resources</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/api-overview/"><span title="API Overview" class="categoryLinkLabel_W154">API Overview</span></a><button aria-label="Expand sidebar category &#x27;API Overview&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/platform/"><span title="Platform Overview" class="linkLabel_WmDU">Platform Overview</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/api-references/"><span title="API References" class="categoryLinkLabel_W154">API References</span></a><button aria-label="Expand sidebar category &#x27;API References&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/glossary/"><span title="Glossary" class="categoryLinkLabel_W154">Glossary</span></a><button aria-label="Expand sidebar category &#x27;Glossary&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/data-utils/"><span title="Data Utils" class="categoryLinkLabel_W154">Data Utils</span></a><button aria-label="Expand sidebar category &#x27;Data Utils&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/sdk-examples"><span title="Python SDK Notebook Examples" class="linkLabel_WmDU">Python SDK Notebook Examples</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/complementary-topics/"><span title="Complementary Topics" class="categoryLinkLabel_W154">Complementary Topics</span></a><button aria-label="Expand sidebar category &#x27;Complementary Topics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/troubleshooting"><span title="Troubleshooting" class="linkLabel_WmDU">Troubleshooting</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/tips"><span title="Additional Tips" class="linkLabel_WmDU">Additional Tips</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/privacy-security"><span title="Data Privacy and Security" class="linkLabel_WmDU">Data Privacy and Security</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Product Updates" class="categoryLinkLabel_W154">Product Updates</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/product-updates/upcoming-api-changes/"><span title="Upcoming Platform Changes" class="categoryLinkLabel_W154">Upcoming Platform Changes</span></a><button aria-label="Expand sidebar category &#x27;Upcoming Platform Changes&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/product-updates/changelog"><span title="Changelog" class="categoryLinkLabel_W154">Changelog</span></a><button aria-label="Expand sidebar category &#x27;Changelog&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Integrations" class="categoryLinkLabel_W154">Integrations</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/embedchain/"><span title="Embedchain" class="categoryLinkLabel_W154">Embedchain</span></a><button aria-label="Expand sidebar category &#x27;Embedchain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/langchain/"><span title="LangChain" class="categoryLinkLabel_W154">LangChain</span></a><button aria-label="Expand sidebar category &#x27;LangChain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/llamaindex/"><span title="LlamaIndex" class="categoryLinkLabel_W154">LlamaIndex</span></a><button aria-label="Expand sidebar category &#x27;LlamaIndex&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/databricks/"><span title="Databricks" class="categoryLinkLabel_W154">Databricks</span></a><button aria-label="Expand sidebar category &#x27;Databricks&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/DSPy/"><span title="DSPy" class="categoryLinkLabel_W154">DSPy</span></a><button aria-label="Expand sidebar category &#x27;DSPy&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/unstructured/"><span title="Unstructured.io" class="categoryLinkLabel_W154">Unstructured.io</span></a><button aria-label="Expand sidebar category &#x27;Unstructured.io&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Additional Links" class="categoryLinkLabel_W154">Additional Links</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://api.clarifai.com/api-doc/?url=https://api.clarifai.com/v2/swagger.json" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0"><span title="Swagger API Guide" class="linkLabel_WmDU">Swagger API Guide</span><svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://stackoverflow.com/tags/clarifai/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0"><span title="Stack Overflow" class="linkLabel_WmDU">Stack Overflow</span><svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://status.clarifai.com/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0"><span title="API Status" class="linkLabel_WmDU">API Status</span><svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://www.clarifai.com/blog/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0"><span title="Clarifai Blog" class="linkLabel_WmDU">Clarifai Blog</span><svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Compute</span></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/compute/toolkits/"><span>Toolkits</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">SGLang</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>SGLang</h1></header>
<p><strong>Run models using the SGLang runtime format and make them available via a public API</strong></p>
<hr>
<p><a href="https://github.com/sgl-project/sglang" target="_blank" rel="noopener noreferrer" class="">SGLang</a> is an open-source runtime and programming framework designed for structured generation and high-performance inference of large language models (LLMs) and vision-language models.</p>
<p>It provides a flexible way to execute models with advanced capabilities like multi-step prompting, structured outputs, and multimodal reasoning — all while maximizing throughput and minimizing latency.</p>
<p>With Clarifai’s <a href="https://docs.clarifai.com/compute/local-runners/" target="_blank" rel="noopener noreferrer" class="">Local Runners</a>, you can download and run these models on your own machine using the SGLang runtime format, expose them securely via a public URL, and tap into Clarifai’s powerful platform  — all while retaining the privacy, performance, and control of local execution.</p>
<blockquote>
<p><strong>Note:</strong> The SGLang toolkit specifies a runtime format to run models sourced from external sources like Hugging Face. After initializing a model using the toolkit, you can <a href="https://docs.clarifai.com/compute/upload/#step-4-upload-the-model-to-clarifai" target="_blank" rel="noopener noreferrer" class="">upload</a> it to Clarifai to leverage the platform’s capabilities.</p>
</blockquote>
<!-- -->
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-1-perform-prerequisites">Step 1: Perform Prerequisites<a href="#step-1-perform-prerequisites" class="hash-link" aria-label="Direct link to Step 1: Perform Prerequisites" title="Direct link to Step 1: Perform Prerequisites" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="sign-up-or-log-in">Sign Up or Log In<a href="#sign-up-or-log-in" class="hash-link" aria-label="Direct link to Sign Up or Log In" title="Direct link to Sign Up or Log In" translate="no">​</a></h3>
<p>Log in to your existing Clarifai account or <a href="https://clarifai.com/signup" target="_blank" rel="noopener noreferrer" class="">sign up</a> for a new one. Once you’re logged in, gather the following credentials required for setup:</p>
<ul>
<li class=""><strong>App ID</strong> – Go to the application you want to use to run the model. In the collapsible left sidebar, select <strong><a href="https://docs.clarifai.com/create/applications/manage/#app-overview" target="_blank" rel="noopener noreferrer" class="">Overview</a></strong> and copy the app ID displayed there.</li>
<li class=""><strong>User ID</strong> – In the collapsible left sidebar, open <strong>Settings</strong>, then choose <strong>Account</strong> from the dropdown list to locate your user ID.</li>
<li class=""><strong>Personal Access Token (PAT)</strong> – From the same <strong>Settings</strong> menu, select <strong>Secrets</strong> to create or copy your <a href="https://docs.clarifai.com/control/authentication/pat" target="_blank" rel="noopener noreferrer" class="">PAT</a>. This token is used to authenticate your connection with the Clarifai platform.</li>
</ul>
<p>Then, set your PAT as an environment variable:</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Unix-Like Systems</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Windows</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(189, 147, 249);font-style:italic">CLARIFAI_PAT</span><span class="token operator">=</span><span class="token plain">YOUR_PERSONAL_ACCESS_TOKEN_HERE</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">set</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(189, 147, 249);font-style:italic">CLARIFAI_PAT</span><span class="token operator">=</span><span class="token plain">YOUR_PERSONAL_ACCESS_TOKEN_HERE</span><br></span></code></pre></div></div></div></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="install-clarifai-cli">Install Clarifai CLI<a href="#install-clarifai-cli" class="hash-link" aria-label="Direct link to Install Clarifai CLI" title="Direct link to Install Clarifai CLI" translate="no">​</a></h3>
<p>Install the latest <a href="https://docs.clarifai.com/sdk/cli" target="_blank" rel="noopener noreferrer" class="">Clarifai CLI</a> which includes built-in support for Local Runners:</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Bash</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip </span><span class="token function" style="color:rgb(80, 250, 123)">install</span><span class="token plain"> </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--upgrade</span><span class="token plain"> clarifai</span><br></span></code></pre></div></div></div></div></div>
<blockquote>
<p><strong>Note:</strong> The Local Runners require <strong><a href="https://docs.clarifai.com/resources/api-overview/python-sdk#python-requirements" target="_blank" rel="noopener noreferrer" class="">Python 3.11 or 3.12</a></strong>.</p>
</blockquote>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="install-sglang">Install SGLang<a href="#install-sglang" class="hash-link" aria-label="Direct link to Install SGLang" title="Direct link to Install SGLang" translate="no">​</a></h3>
<p>Install SGLang to enable its runtime execution environment.</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Bash</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip </span><span class="token function" style="color:rgb(80, 250, 123)">install</span><span class="token plain"> sglang</span><br></span></code></pre></div></div></div></div></div>
<blockquote>
<p><strong>Tip:</strong> GPU acceleration (CUDA) is highly recommended for optimal performance.</p>
</blockquote>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="install-openai">Install OpenAI<a href="#install-openai" class="hash-link" aria-label="Direct link to Install OpenAI" title="Direct link to Install OpenAI" translate="no">​</a></h3>
<p>Install the <code>openai</code> package, which is needed to perform inference with models that use the <a href="https://docs.clarifai.com/compute/inference/#predict-with-openai-compatible-format" target="_blank" rel="noopener noreferrer" class="">OpenAI-compatible format</a>.</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Bash</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip </span><span class="token function" style="color:rgb(80, 250, 123)">install</span><span class="token plain"> openai</span><br></span></code></pre></div></div></div></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="get-hugging-face-token">Get Hugging Face Token<a href="#get-hugging-face-token" class="hash-link" aria-label="Direct link to Get Hugging Face Token" title="Direct link to Get Hugging Face Token" translate="no">​</a></h3>
<p>If you want to initialize a Hugging Face model for use with SGLang, you’ll need a Hugging Face access token to authenticate with Hugging Face services — especially when accessing private or restricted repositories.</p>
<p>You can create one by following <a href="https://huggingface.co/docs/hub/en/security-tokens" target="_blank" rel="noopener noreferrer" class="">these instructions</a>. Once you have the token, include it either in your model’s <code>config.yaml</code> file (as described <a href="#configyaml" class="">below</a>) or set it as an environment variable.</p>
<blockquote>
<p><strong>Note:</strong> If <code>hf_token</code> is not specified in the <code>config.yaml</code> file, the CLI will automatically use the <code>HF_TOKEN</code> environment variable for authentication with Hugging Face.</p>
</blockquote>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Unix-Like Systems</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Windows</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(189, 147, 249);font-style:italic">HF_TOKEN</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;YOUR_HF_ACCESS_TOKEN_HERE&quot;</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">set</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(189, 147, 249);font-style:italic">HF_TOKEN</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;YOUR_HF_ACCESS_TOKEN_HERE&quot;</span><br></span></code></pre></div></div></div></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-2-initialize-a-model">Step 2: Initialize a Model<a href="#step-2-initialize-a-model" class="hash-link" aria-label="Direct link to Step 2: Initialize a Model" title="Direct link to Step 2: Initialize a Model" translate="no">​</a></h2>
<p>With the Clarifai CLI, you can initialize a model configured to run using the SGLang runtime format. It sets up a Clarifai-compatible project directory with the appropriate files.</p>
<p>You can customize or optimize the model by editing the generated files as needed. For example, the command below initializes a default Hugging Face model (<a href="https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct" target="_blank" rel="noopener noreferrer" class="">HuggingFaceTB/SmolLM2-135M-Instruct</a>) in your current directory.</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Bash</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai model init </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--toolkit</span><span class="token plain"> sglang</span><br></span></code></pre></div></div></div></div></div>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example Output</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai model init --toolkit sglang</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 20:14:19.494294 Parsed GitHub repository: owner=Clarifai, repo=runners-examples, branch=sglang, folder_path= |  thread=8729403584 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 20:14:20.762093 Files to be downloaded are:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">1. 1/model.py</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">2. 1/openai_server_starter.py</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">3. Dockerfile</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">4. README.md</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">5. config.yaml</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">6. requirements.txt |  thread=8729403584 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Press Enter to continue...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 20:14:24.640395 Initializing model from GitHub repository: https://github.com/Clarifai/runners-examples |  thread=8729403584 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 20:14:33.997825 Successfully cloned repository from https://github.com/Clarifai/runners-examples (branch: sglang) |  thread=8729403584 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 20:14:34.006824 Updated Hugging Face model repo_id to: None |  thread=8729403584 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 20:14:34.006878 Model initialization complete with GitHub repository |  thread=8729403584 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 20:14:34.006909 Next steps: |  thread=8729403584 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 20:14:34.006929 1. Review the model configuration |  thread=8729403584 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 20:14:34.006946 2. Install any required dependencies manually |  thread=8729403584 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 20:14:34.006966 3. Test the model locally using &#x27;clarifai model local-test&#x27; |  thread=8729403584 </span><br></span></code></pre></div></div></div></div></details>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>You can use the <code>--model-name</code> parameter to initialize any supported Hugging Face model. This sets the model’s <code>repo_id</code>, specifying which Hugging Face repository to initialize from.</p><div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Bash</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai model init </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">--toolkit</span><span class="token plain"> sglang --model-name unsloth/Llama-3.2-1B-Instruct</span><br></span></code></pre></div></div></div></div></div></div></div>
<blockquote>
<p><strong>Note:</strong> Large models require significant GPU memory. Ensure your machine has enough compute capacity to run them efficiently.</p>
</blockquote>
<p>The generated structure includes:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── 1/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   └── model.py</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">|   └── openai_server_starter.py</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> ├── Dockerfile</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">└── README.md</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── config.yaml</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">└── requirements.txt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="modelpy"><code>model.py</code><a href="#modelpy" class="hash-link" aria-label="Direct link to modelpy" title="Direct link to modelpy" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example: 1/model.py</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import sys</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sys.path.append(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Iterator, List</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.openai_class import OpenAIModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.openai_convertor import build_openai_messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from openai import OpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from openai_server_starter import OpenAI_APIServer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">##################</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class SglangModel(OpenAIModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    A custom runner that integrates with the Clarifai platform and uses Server inference</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    to process inputs, including text.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    client = True  # This will be set in load_model method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model = True  # This will be set in load_model method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Load the model here and start the  server.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        os.path.join(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Use downloaded checkpoints.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Or if you intend to download checkpoint at runtime, set hf id instead. For example:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # checkpoints = &quot;Qwen/Qwen2-7B-Instruct&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # server args were generated by `upload` module</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        server_args = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;dtype&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;kv_cache_dtype&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;tp_size&#x27;: 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;load_format&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;context_length&#x27;: None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;device&#x27;: &#x27;cuda&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;port&#x27;: 23333,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;host&#x27;: &#x27;0.0.0.0&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;mem_fraction_static&#x27;: 0.9,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;max_total_tokens&#x27;: &#x27;8192&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;max_prefill_tokens&#x27;: None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;schedule_policy&#x27;: &#x27;fcfs&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;schedule_conservativeness&#x27;: 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;checkpoints&#x27;: &#x27;runtime&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # if checkpoints == &quot;checkpoints&quot; =&gt; assign to checkpoints var aka local checkpoints path</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        stage = server_args.get(&quot;checkpoints&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if stage in [&quot;build&quot;, &quot;runtime&quot;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # checkpoints = os.path.join(os.path.dirname(__file__), &quot;checkpoints&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            config_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            builder = ModelBuilder(config_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            checkpoints = builder.download_checkpoints(stage=stage)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            server_args.update({&quot;checkpoints&quot;: checkpoints})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if server_args.get(&quot;additional_list_args&quot;) == [&#x27;&#x27;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            server_args.pop(&quot;additional_list_args&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Start server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # This line were generated by `upload` module</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.server = OpenAI_APIServer.from_sglang_backend(**server_args)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Create client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.client = OpenAI(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            api_key=&quot;notset&quot;, base_url=SglangModel.make_api_url(self.server.host, self.server.port)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model = self._get_model()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;OpenAI {self.model} model loaded successfully!&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def _get_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return self.client.models.list().data[0].id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            raise ConnectionError(&quot;Failed to retrieve model ID from API&quot;) from e</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @staticmethod</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def make_api_url(host: str, port: int, version: str = &quot;v1&quot;) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;http://{host}:{port}/{version}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def predict(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_tokens: int = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        temperature: float = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=0.7,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;A decimal number that determines the degree of randomness in the response&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        top_p: float = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=0.8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;This is the method that will be called when the runner is run. It takes in an input and</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        returns an output.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        openai_messages = build_openai_messages(prompt=prompt, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        response = self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            messages=openai_messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            top_p=top_p,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if response.usage and response.usage.prompt_tokens and response.usage.completion_tokens:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self.set_output_context(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                prompt_tokens=response.usage.prompt_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                completion_tokens=response.usage.completion_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return response.choices[0].message.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def generate(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_tokens: int = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        temperature: float = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=0.7,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;A decimal number that determines the degree of randomness in the response&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        top_p: float = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=0.8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ) -&gt; Iterator[str]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Example yielding a whole batch of streamed stuff back.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        openai_messages = build_openai_messages(prompt=prompt, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for chunk in self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            messages=openai_messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            top_p=top_p,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            stream=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if chunk.choices:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                text = (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    chunk.choices[0].delta.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    if (chunk and chunk.choices[0].delta.content) is not None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    else &#x27;&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                yield text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # This method is needed to test the model with the test-locally CLI command.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def test(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Test the model here.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Testing predict...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Test predict</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                self.predict(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    prompt=&quot;Hello, how are you?&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Error in predict&quot;, e)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Testing generate...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Test generate</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for each in self.generate(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                prompt=&quot;Hello, how are you?&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                print(each, end=&quot; &quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Error in generate&quot;, e)</span><br></span></code></pre></div></div></div></div></details>
<p>This is the <a href="https://docs.clarifai.com/compute/upload/#prepare-modelpy" target="_blank" rel="noopener noreferrer" class="">main runner</a> script that defines how your model loads, runs, and handles inference.</p>
<ul>
<li class="">It subclasses <code>OpenAIModelClass</code>, meaning it exposes OpenAI-compatible endpoints for inference.</li>
<li class="">The <code>load_model()</code> method spins up a local SGLang backend server (via <code>OpenAI_APIServer.from_sglang_backend</code>) and initializes the model checkpoint.</li>
<li class="">The <code>predict()</code> and <code>generate()</code> methods define how text generation requests are processed — supporting both standard predictions and streaming outputs.</li>
<li class="">The <code>test()</code> method lets you verify locally that everything is working before deployment.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="openai_server_starterpy"><code>openai_server_starter.py</code><a href="#openai_server_starterpy" class="hash-link" aria-label="Direct link to openai_server_starterpy" title="Direct link to openai_server_starterpy" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example: 1/openai_server_starter.py</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import signal</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import subprocess</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import sys</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import threading</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import List</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import psutil</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PYTHON_EXEC = sys.executable</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def kill_process_tree(parent_pid, include_parent: bool = True, skip_pid: int = None):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Kill the process and all its child processes.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if parent_pid is None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        parent_pid = os.getpid()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        include_parent = False</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        itself = psutil.Process(parent_pid)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except psutil.NoSuchProcess:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    children = itself.children(recursive=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for child in children:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if child.pid == skip_pid:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            continue</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            child.kill()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except psutil.NoSuchProcess:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            pass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if include_parent:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            itself.kill()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Sometime processes cannot be killed with SIGKILL (e.g, PID=1 launched by kubernetes),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # so we send an additional signal to kill them.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            itself.send_signal(signal.SIGQUIT)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except psutil.NoSuchProcess:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            pass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class OpenAI_APIServer:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def __init__(self, **kwargs):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.server_started_event = threading.Event()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.process = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.backend = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.server_thread = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def __del__(self, *exc):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # This is important</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # close the server when exit the program</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.close()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def close(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if self.process:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                kill_process_tree(self.process.pid)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            except:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                self.process.terminate()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if self.server_thread:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self.server_thread.join()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def wait_for_startup(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.server_started_event.wait()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def validate_if_server_start(self, line: str):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        line_lower = line.lower()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if self.backend in [&quot;vllm&quot;, &quot;sglang&quot;, &quot;lmdeploy&quot;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if self.backend == &quot;vllm&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                return (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;application startup complete&quot; in line_lower</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    or &quot;vllm api server on&quot; in line_lower</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                return f&quot; running on http://{self.host}:&quot; in line.strip()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        elif self.backend == &quot;llamacpp&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return &quot;waiting for new tasks&quot; in line_lower</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        elif self.backend == &quot;tgi&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return &quot;Connected&quot; in line.strip()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def _start_server(self, cmds):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            env = os.environ.copy()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            env[&quot;VLLM_USAGE_SOURCE&quot;] = &quot;production-docker-image&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self.process = subprocess.Popen(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                cmds,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                stdout=subprocess.PIPE,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                stderr=subprocess.STDOUT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                text=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for line in self.process.stdout:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                logger.info(&quot;Server Log:  &quot; + line.strip())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if self.validate_if_server_start(line):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    self.server_started_event.set()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    # break</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if self.process:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                self.process.terminate()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            raise RuntimeError(f&quot;Failed to start Server server: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def start_server_thread(self, cmds: str):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Start the  server in a separate thread</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self.server_thread = threading.Thread(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                target=self._start_server, args=(cmds,), daemon=None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self.server_thread.start()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Wait for the server to start</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self.wait_for_startup()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            raise Exception(e)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @classmethod</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def from_sglang_backend(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        cls,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpoints,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        dtype: str = &quot;auto&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        kv_cache_dtype: str = &quot;auto&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tp_size: int = 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        quantization: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        load_format: str = &quot;auto&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        context_length: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        device: str = &quot;cuda&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        port=23333,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        host=&quot;0.0.0.0&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        chat_template: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        mem_fraction_static: float = 0.8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_running_requests: int = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_total_tokens: int = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_prefill_tokens: int = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        schedule_policy: str = &quot;fcfs&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        schedule_conservativeness: float = 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        cpu_offload_gb: int = 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        additional_list_args: List[str] = [],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Start SGlang OpenAI compatible server.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Args:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            checkpoints (str): model id or path.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            dtype (str, optional): Dtype used for the model {&quot;auto&quot;, &quot;half&quot;, &quot;float16&quot;, &quot;bfloat16&quot;, &quot;float&quot;, &quot;float32&quot;}. Defaults to &quot;auto&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            kv_cache_dtype (str, optional): Dtype of the kv cache, defaults to the dtype. Defaults to &quot;auto&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tp_size (int, optional): The number of GPUs the model weights get sharded over. Mainly for saving memory rather than for high throughput. Defaults to 1.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            quantization (str, optional): Quantization format {&quot;awq&quot;,&quot;fp8&quot;,&quot;gptq&quot;,&quot;marlin&quot;,&quot;gptq_marlin&quot;,&quot;awq_marlin&quot;,&quot;bitsandbytes&quot;,&quot;gguf&quot;,&quot;modelopt&quot;,&quot;w8a8_int8&quot;}. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            load_format (str, optional): The format of the model weights to load:\n* `auto`: will try to load the weights in the safetensors format and fall back to the pytorch bin format if safetensors format is not available.\n* `pt`: will load the weights in the pytorch bin format. \n* `safetensors`: will load the weights in the safetensors format. \n* `npcache`: will load the weights in pytorch format and store a numpy cache to speed up the loading. \n* `dummy`: will initialize the weights with random values, which is mainly for profiling.\n* `gguf`: will load the weights in the gguf format. \n* `bitsandbytes`: will load the weights using bitsandbytes quantization.&quot;\n* `layered`: loads weights layer by layer so that one can quantize a layer before loading another to make the peak memory envelope smaller.\n. Defaults to &quot;auto&quot;.\n</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            context_length (str, optional): The model&#x27;s maximum context length. Defaults to None (will use the value from the model&#x27;s config.json instead). Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            device (str, optional): The device type {&quot;cuda&quot;, &quot;xpu&quot;, &quot;hpu&quot;, &quot;cpu&quot;}. Defaults to &quot;cuda&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            port (int, optional): Port number. Defaults to 23333.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            host (str, optional): Host name. Defaults to &quot;0.0.0.0&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            chat_template (str, optional): The buliltin chat template name or the path of the chat template file. This is only used for OpenAI-compatible API server.. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            mem_fraction_static (float, optional): The fraction of the memory used for static allocation (model weights and KV cache memory pool). Use a smaller value if you see out-of-memory errors. Defaults to 0.8.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_running_requests (int, optional): The maximum number of running requests.. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_total_tokens (int, optional): The maximum number of tokens in the memory pool. If not specified, it will be automatically calculated based on the memory usage fraction. This option is typically used for development and debugging purposes.. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_prefill_tokens (int, optional): The maximum number of tokens in a prefill batch. The real bound will be the maximum of this value and the model&#x27;s maximum context length. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            schedule_policy (str, optional): The scheduling policy of the requests {&quot;lpm&quot;, &quot;random&quot;, &quot;fcfs&quot;, &quot;dfs-weight&quot;}. Defaults to &quot;fcfs&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            schedule_conservativeness (float, optional): How conservative the schedule policy is. A larger value means more conservative scheduling. Use a larger value if you see requests being retracted frequently. Defaults to 1.0.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cpu_offload_gb (int, optional): How many GBs of RAM to reserve for CPU offloading. Defaults to 0.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            additional_list_args (List[str], optional): additional args to run subprocess cmd e.g. [&quot;--arg-name&quot;, &quot;arg value&quot;]. See more at [github](https://github.com/sgl-project/sglang/blob/1baa9e6cf90b30aaa7dae51c01baa25229e8f7d5/python/sglang/srt/server_args.py#L298). Defaults to [].</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Returns:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            _type_: _description_</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        from clarifai.runners.utils.model_utils import execute_shell_command, wait_for_server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        cmds = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            PYTHON_EXEC,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;-m&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;sglang.launch_server&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;--model-path&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            checkpoints,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;--dtype&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            str(dtype),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;--device&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            str(device),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;--kv-cache-dtype&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            str(kv_cache_dtype),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;--tp-size&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            str(tp_size),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;--load-format&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            str(load_format),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;--mem-fraction-static&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            str(mem_fraction_static),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;--schedule-policy&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            str(schedule_policy),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;--schedule-conservativeness&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            str(schedule_conservativeness),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;--port&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            str(port),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;--host&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            host,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;--trust-remote-code&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if chat_template:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cmds += [&quot;--chat-template&quot;, chat_template]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if quantization:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;--quantization&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                quantization,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if context_length:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;--context-length&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                context_length,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if max_running_requests:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;--max-running-requests&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                max_running_requests,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if max_total_tokens:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;--max-total-tokens&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                max_total_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if max_prefill_tokens:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;--max-prefill-tokens&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                max_prefill_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if additional_list_args:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cmds += additional_list_args</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;CMDS to run `sglang` server: &quot;, &quot; &quot;.join(cmds), &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        _self = cls()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        _self.host = host</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        _self.port = port</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        _self.backend = &quot;sglang&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # _self.start_server_thread(cmds)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # new_path = os.environ[&quot;PATH&quot;] + &quot;:/sbin&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # _self.process = subprocess.Popen(cmds, text=True, stderr=subprocess.STDOUT, env={**os.environ, &quot;PATH&quot;: new_path})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        _self.process = execute_shell_command(&quot; &quot;.join(cmds))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Waiting for &quot; + f&quot;http://{_self.host}:{_self.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        wait_for_server(f&quot;http://{_self.host}:{_self.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Done&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return _self</span><br></span></code></pre></div></div></div></div></details>
<p>This utility handles starting, monitoring, and shutting down the backend SGLang server. It acts as your server controller, ensuring the backend is ready before the runner starts sending requests.</p>
<ul>
<li class="">It wraps around subprocess management for launching <code>sglang.launch_server</code>.</li>
<li class="">It ensures the server runs properly, logs startup messages, and handles safe termination.</li>
<li class="">The class <code>OpenAI_APIServer</code> can also be extended to support other backends like <code>vLLM</code>, <code>llama.cpp</code>, or <code>TGI</code>, but here it’s used for SGLang.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="dockerfile"><code>Dockerfile</code><a href="#dockerfile" class="hash-link" aria-label="Direct link to dockerfile" title="Direct link to dockerfile" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example: Dockerfile</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># syntax=docker/dockerfile:1.13-labs</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">FROM --platform=$TARGETPLATFORM lmsysorg/sglang:v0.5.3-cu129 as final</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">COPY --link requirements.txt /home/nonroot/requirements.txt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Update clarifai package so we always have latest protocol to the API. Everything should land in /venv</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN [&quot;pip&quot;, &quot;install&quot;, &quot;--no-cache-dir&quot;, &quot;-r&quot;, &quot;/home/nonroot/requirements.txt&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN [&quot;pip&quot;, &quot;show&quot;, &quot;--no-cache-dir&quot;, &quot;clarifai&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Set the NUMBA cache dir to /tmp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Set the TORCHINDUCTOR cache dir to /tmp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># The CLARIFAI* will be set by the templaing system.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ENV NUMBA_CACHE_DIR=/tmp/numba_cache \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    TORCHINDUCTOR_CACHE_DIR=/tmp/torchinductor_cache \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    HOME=/tmp \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    DEBIAN_FRONTEND=noninteractive</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#####</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Copy the files needed to download</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#####</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># This creates the directory that HF downloader will populate and with nonroot:nonroot permissions up.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">COPY --chown=nonroot:nonroot downloader/unused.yaml /home/nonroot/main/1/checkpoints/.cache/unused.yaml</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#####</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Download checkpoints if config.yaml has checkpoints.when = &quot;build&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">COPY --link=true config.yaml /home/nonroot/main/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN [&quot;python&quot;, &quot;-m&quot;, &quot;clarifai.cli&quot;, &quot;model&quot;, &quot;download-checkpoints&quot;, &quot;/home/nonroot/main&quot;, &quot;--out_path&quot;, &quot;/home/nonroot/main/1/checkpoints&quot;, &quot;--stage&quot;, &quot;build&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#####</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Copy in the actual files like config.yaml, requirements.txt, and most importantly 1/model.py</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># for the actual model.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># If checkpoints aren&#x27;t downloaded since a checkpoints: block is not provided, then they will</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># be in the build context and copied here as well.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">COPY --link=true 1 /home/nonroot/main/1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># At this point we only need these for validation in the SDK.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">COPY --link=true requirements.txt config.yaml /home/nonroot/main/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Add the model directory to the python path.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ENV PYTHONPATH=${PYTHONPATH}:/home/nonroot/main \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    CLARIFAI_PAT=${CLARIFAI_PAT} \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    CLARIFAI_USER_ID=${CLARIFAI_USER_ID} \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    CLARIFAI_RUNNER_ID=${CLARIFAI_RUNNER_ID} \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    CLARIFAI_NODEPOOL_ID=${CLARIFAI_NODEPOOL_ID} \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    CLARIFAI_COMPUTE_CLUSTER_ID=${CLARIFAI_COMPUTE_CLUSTER_ID} \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    CLARIFAI_API_BASE=${CLARIFAI_API_BASE:-https://api.clarifai.com}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">USER root</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN echo &quot;nonroot:x:65532:65532:nonroot user:/home/nonroot:/sbin/nologin&quot; &gt;&gt; /etc/passwd</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">USER nonroot</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Finally run the clarifai entrypoint to start the runner loop and local runner server.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Note(zeiler): we may want to make this a clarifai CLI call.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ENTRYPOINT [&quot;python&quot;, &quot;-m&quot;, &quot;clarifai.runners.server&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">CMD [&quot;--model_path&quot;, &quot;/home/nonroot/main&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#############################</span><br></span></code></pre></div></div></div></div></details>
<p>The Dockerfile defines the container environment used to run your model runner on Clarifai’s infrastructure.</p>
<ul>
<li class="">It builds on the official SGLang base image (<code>lmsysorg/sglang:v0.5.3-cu129</code>), which includes CUDA and SGLang dependencies.</li>
<li class="">It installs any Python packages listed in <code>requirements.txt</code>.</li>
<li class="">It copies your model files (<code>model.py</code>, <code>config.yaml</code>, etc.) into the container.</li>
<li class="">Optionally, it downloads checkpoints during build time if <code>checkpoints.when = &quot;build&quot;</code>.</li>
<li class="">It starts the Clarifai runner loop using <code>python -m clarifai.runners.server</code>.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="configyaml"><code>config.yaml</code><a href="#configyaml" class="hash-link" aria-label="Direct link to configyaml" title="Direct link to configyaml" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example: config.yaml</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: SmolLM2-135M-Instruct</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: YOUR_USER_ID</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: YOUR_APP_ID</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: text-to-text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.11&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &#x27;3&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 14Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  - NVIDIA-L40S</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: 42Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: HuggingFaceTB/SmolLM2-135M-Instruct</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: huggingface</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  when: runtime</span><br></span></code></pre></div></div></div></div></details>
<p>This is the configuration file for your SGLang model runner.</p>
<ul>
<li class="">It specifies model identifiers (<code>model.id</code>, <code>user_id</code>, <code>app_id</code>), which together determine where your model will run on the Clarifai platform. Your Clarifai user ID is set by default from your <a href="https://docs.clarifai.com/resources/api-overview/cli#clarifai-config" target="_blank" rel="noopener noreferrer" class="">active context</a>.</li>
<li class="">It defines compute resources (CPU, GPU type, and memory).</li>
<li class="">The <a href="https://docs.clarifai.com/compute/upload/#hugging-face-model-checkpoints" target="_blank" rel="noopener noreferrer" class=""><code>checkpoints</code></a> section tells the runner where and when to load model weights<!-- -->
<blockquote>
<p><strong>Tip:</strong> Use <code>when: runtime</code> for large models to reduce image size and improve load times.</p>
</blockquote>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="requirementstxt"><code>requirements.txt</code><a href="#requirementstxt" class="hash-link" aria-label="Direct link to requirementstxt" title="Direct link to requirementstxt" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example: requirements.txt</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">openai</span><br></span></code></pre></div></div></div></div></details>
<p>This file lists all the Python dependencies required for the runner to work. If you haven’t installed them yet, run the following command to install the dependencies:</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Bash</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip </span><span class="token function" style="color:rgb(80, 250, 123)">install</span><span class="token plain"> </span><span class="token parameter variable" style="color:rgb(189, 147, 249);font-style:italic">-r</span><span class="token plain"> requirements.txt</span><br></span></code></pre></div></div></div></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-3-log-in-to-clarifai">Step 3: Log In to Clarifai<a href="#step-3-log-in-to-clarifai" class="hash-link" aria-label="Direct link to Step 3: Log In to Clarifai" title="Direct link to Step 3: Log In to Clarifai" translate="no">​</a></h2>
<p>Log in and create a configuration <a href="https://docs.clarifai.com/compute/local-runners/#step-2-create-a-context-optional" target="_blank" rel="noopener noreferrer" class="">context</a>:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai login</span><br></span></code></pre></div></div>
<p>Enter the requested details:</p>
<ul>
<li class=""><strong>User ID</strong> – Your Clarifai user ID</li>
<li class=""><strong>PAT</strong> – Your personal access token (or type <code>ENVVAR</code> to use the environment variable)</li>
<li class=""><strong>Context name</strong> – Optional name for the config context (default: <code>&quot;default&quot;</code>)</li>
</ul>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example Output</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai login</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Enter your Clarifai user ID: user-id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&gt; To authenticate, you&#x27;ll need a Personal Access Token (PAT).</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&gt; You can create one from your account settings: https://clarifai.com/user-id/settings/security</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Enter your Personal Access Token (PAT) value (or type &quot;ENVVAR&quot; to use an environment variable): XXXXXXXXXX</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&gt; Verifying token...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 12:10:55.558733 Validating the Context Credentials... |  thread=8729403584 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 12:10:56.693295 ✅ Context is valid |  thread=8729403584 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&gt; Let&#x27;s save these credentials to a new context.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&gt; You can have multiple contexts to easily switch between accounts or projects.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Enter a name for this context [default]: </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">✅ Success! You are now logged in.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Credentials saved to the &#x27;default&#x27; context.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">💡 To switch contexts later, use `clarifai config use-context &lt;name&gt;`.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[INFO] 12:10:59.177368 Login successful for user &#x27;alfrick&#x27; in context &#x27;default&#x27; |  thread=8729403584 </span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-4-start-your-local-runner">Step 4: Start Your Local Runner<a href="#step-4-start-your-local-runner" class="hash-link" aria-label="Direct link to Step 4: Start Your Local Runner" title="Direct link to Step 4: Start Your Local Runner" translate="no">​</a></h2>
<p>Next, start your Local Runner, which connects to the SGLang runtime to execute your model locally.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai model local-runner</span><br></span></code></pre></div></div>
<p>If any configuration contexts or defaults are missing, the CLI will automatically guide you through setting them up.</p>
<p>This process ensures that all required components — such as compute clusters, nodepools, and deployments — are correctly configured in your context, enabling seamless local execution of your SGLang model. For more details, see <a href="https://docs.clarifai.com/compute/local-runners/#step-2-create-a-context-optional" target="_blank" rel="noopener noreferrer" class="">Local Runners documentation</a>.</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>Example Output</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-5-test-your-runner">Step 5: Test Your Runner<a href="#step-5-test-your-runner" class="hash-link" aria-label="Direct link to Step 5: Test Your Runner" title="Direct link to Step 5: Test Your Runner" translate="no">​</a></h2>
<p>After the Local Runner starts, you can use it to perform <a href="https://docs.clarifai.com/compute/inference/open-ai" target="_blank" rel="noopener noreferrer" class="">inference</a> with your SGLang-based model.</p>
<p>You can run a test snippet in a separate terminal, within the same directory, to verify that your model is running and responding correctly.</p>
<p>Here’s an example snippet:</p>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">Python SDK</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> openai </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> OpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Initialize the OpenAI client, pointing to Clarifai&#x27;s API</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">client </span><span class="token operator">=</span><span class="token plain"> OpenAI</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">     </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    base_url</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;https://api.clarifai.com/v2/ext/openai/v1&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Clarifai&#x27;s OpenAI-compatible API endpoint</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    api_key</span><span class="token operator">=</span><span class="token plain">os</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">environ</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;CLARIFAI_PAT&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Ensure CLARIFAI_PAT is set as an environment variable</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Make a chat completion request to a Clarifai-hosted model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">response </span><span class="token operator">=</span><span class="token plain"> client</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">chat</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">completions</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">create</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;https://clarifai.com/&lt;user-id&gt;/local-runner-app/models/local-runner-model&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;role&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;system&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;content&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;You are a helpful assistant.&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;role&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;user&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;content&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;What is the future of AI?&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Print the model&#x27;s response</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">response</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">choices</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">message</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">content</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div></div></div></div></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/compute/toolkits/vllm"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">vLLM</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/compute/agents/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Agents</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#step-1-perform-prerequisites" class="table-of-contents__link toc-highlight">Step 1: Perform Prerequisites</a><ul><li><a href="#sign-up-or-log-in" class="table-of-contents__link toc-highlight">Sign Up or Log In</a></li><li><a href="#install-clarifai-cli" class="table-of-contents__link toc-highlight">Install Clarifai CLI</a></li><li><a href="#install-sglang" class="table-of-contents__link toc-highlight">Install SGLang</a></li><li><a href="#install-openai" class="table-of-contents__link toc-highlight">Install OpenAI</a></li><li><a href="#get-hugging-face-token" class="table-of-contents__link toc-highlight">Get Hugging Face Token</a></li></ul></li><li><a href="#step-2-initialize-a-model" class="table-of-contents__link toc-highlight">Step 2: Initialize a Model</a><ul><li><a href="#modelpy" class="table-of-contents__link toc-highlight"><code>model.py</code></a></li><li><a href="#openai_server_starterpy" class="table-of-contents__link toc-highlight"><code>openai_server_starter.py</code></a></li><li><a href="#dockerfile" class="table-of-contents__link toc-highlight"><code>Dockerfile</code></a></li><li><a href="#configyaml" class="table-of-contents__link toc-highlight"><code>config.yaml</code></a></li><li><a href="#requirementstxt" class="table-of-contents__link toc-highlight"><code>requirements.txt</code></a></li></ul></li><li><a href="#step-3-log-in-to-clarifai" class="table-of-contents__link toc-highlight">Step 3: Log In to Clarifai</a></li><li><a href="#step-4-start-your-local-runner" class="table-of-contents__link toc-highlight">Step 4: Start Your Local Runner</a></li><li><a href="#step-5-test-your-runner" class="table-of-contents__link toc-highlight">Step 5: Test Your Runner</a></li></ul></div></div></div><div class="custom_doc_item_footer_LMqZ"><div class="banner-primary"><p>Build your next AI app, test and tune popular LLMs models, and much more.</p><a href="https://clarifai.com/explore" target="_blank">Get started for free</a></div><footer class="custom-footer-wrapper_fHnE"><div class="logo-wrapper_GEfd"><img src="/img/logos/clarifai-color-light-logo.svg" class="dark-theme-logo_tdev"><img src="/img/logos/clarifai-color-dark-logo.svg" class="light-theme-logo_cRqu"></div><div class="copyright_aTku">© 2025 Clarifai, Inc. All rights reserved</div><div class="footerSocialIconsWrapper_tJhP"><div class="socialBrands__tjK"><a href="https://github.com/Clarifai" target="_blank" rel="noopener noreferrer" aria-label="Github"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#000" fill-rule="evenodd" d="M9.7 1.5C4.896 1.5 1 5.401 1 10.216a8.715 8.715 0 0 0 5.95 8.269c.436.08.594-.189.594-.42 0-.207-.007-.756-.011-1.482-2.421.526-2.932-1.169-2.932-1.169-.395-1.007-.966-1.275-.966-1.275-.79-.54.06-.53.06-.53.873.062 1.333.899 1.333.899.776 1.33 2.036.946 2.532.724.08-.563.304-.947.553-1.165C6.18 13.847 4.15 13.1 4.15 9.76c0-.951.339-1.73.895-2.34-.09-.22-.388-1.106.085-2.305 0 0 .731-.235 2.393.893a8.3 8.3 0 0 1 2.178-.293c.74.003 1.483.1 2.178.293 1.662-1.128 2.39-.894 2.39-.894.476 1.2.176 2.087.088 2.307a3.37 3.37 0 0 1 .894 2.339c0 3.348-2.035 4.085-3.973 4.3.313.27.59.8.59 1.614 0 1.165-.01 2.105-.01 2.39 0 .234.156.505.598.42a8.72 8.72 0 0 0 5.946-8.268C18.402 5.4 14.505 1.5 9.7 1.5" clip-rule="evenodd"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://twitter.com/clarifai" target="_blank" rel="noopener noreferrer" aria-label="Twitter"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#000" d="M14.6 3h2.454l-5.36 6.142L18 17.5h-4.937l-3.867-5.07-4.425 5.07H2.316l5.733-6.57L2 3h5.063l3.495 4.633zm-.86 13.028h1.36L6.323 4.395H4.865z"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" aria-label="Discord"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#7289DA" d="M13.63 15.997c.514.65 1.13 1.387 1.13 1.387 3.784-.12 5.24-2.603 5.24-2.603 0-5.514-2.466-9.983-2.466-9.983C15.07 2.948 12.723 3 12.723 3l-.24.274c2.91.89 4.264 2.175 4.264 2.175a14 14 0 0 0-5.155-1.644 14.5 14.5 0 0 0-3.458.034c-.103 0-.189.017-.292.034-.599.052-2.054.274-3.887 1.08-.633.29-1.01.496-1.01.496S4.366 4.096 7.45 3.206L7.277 3S4.932 2.95 2.466 4.798c0 0-2.466 4.47-2.466 9.983 0 0 1.438 2.483 5.223 2.603 0 0 .633-.77 1.147-1.421-2.175-.651-2.997-2.021-2.997-2.021s.172.12.48.291c.017.017.034.034.068.051.052.035.103.052.154.086.428.24.857.428 1.25.582.702.274 1.541.548 2.517.736 1.285.24 2.792.326 4.435.018a11.3 11.3 0 0 0 2.483-.737 9.8 9.8 0 0 0 1.97-1.01s-.857 1.404-3.1 2.038"></path><path fill="#fff" d="M6.884 9.147c-.976 0-1.746.857-1.746 1.901s.787 1.9 1.746 1.9c.976 0 1.747-.855 1.747-1.9.017-1.044-.77-1.9-1.747-1.9m6.25 0c-.976 0-1.746.857-1.746 1.901s.787 1.9 1.746 1.9c.976 0 1.747-.855 1.747-1.9s-.77-1.9-1.747-1.9"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://www.youtube.com/@theworldsai" target="_blank" rel="noopener noreferrer" aria-label="Youtube"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="20" preserveAspectRatio="xMidYMid" viewBox="0 0 256 180"><path fill="red" d="M250.346 28.075A32.18 32.18 0 0 0 227.69 5.418C207.824 0 127.87 0 127.87 0S47.912.164 28.046 5.582A32.18 32.18 0 0 0 5.39 28.24c-6.009 35.298-8.34 89.084.165 122.97a32.18 32.18 0 0 0 22.656 22.657c19.866 5.418 99.822 5.418 99.822 5.418s79.955 0 99.82-5.418a32.18 32.18 0 0 0 22.657-22.657c6.338-35.348 8.291-89.1-.164-123.134Z"></path><path fill="#FFF" d="m102.421 128.06 66.328-38.418-66.328-38.418z"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://www.linkedin.com/company/clarifai" target="_blank" rel="noopener noreferrer" aria-label="Linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><g clip-path="url(#a)"><path fill="#0A66C2" d="M16.819 2H3.18A1.18 1.18 0 0 0 2 3.181V16.82A1.18 1.18 0 0 0 3.181 18H16.82A1.18 1.18 0 0 0 18 16.819V3.18A1.18 1.18 0 0 0 16.819 2M6.769 15.63H4.363V7.989H6.77zm-1.205-8.7a1.381 1.381 0 1 1 1.39-1.38 1.36 1.36 0 0 1-1.39 1.38m10.072 8.707H13.23v-4.175c0-1.23-.523-1.61-1.199-1.61-.713 0-1.413.537-1.413 1.641v4.144H8.213V7.994h2.314v1.06h.03c.233-.47 1.046-1.274 2.287-1.274 1.343 0 2.793.797 2.793 3.13z"></path></g><defs><clipPath id="a"><path fill="#fff" d="M2 2h16v16H2z"></path></clipPath></defs></svg></a></div></div></footer></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://clarifai.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Clarifai Website<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.clarifai.com/explore/contact-us" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contact Us<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/@theworldsai" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/company/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/Clarifai/docs" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Clarifai, Inc.</div></div></div></footer></div>
</body>
</html>