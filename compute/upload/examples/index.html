<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-compute/upload/examples" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Model Upload Examples | Clarifai Docs</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://docs.clarifai.com/compute/upload/examples"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Model Upload Examples | Clarifai Docs"><meta data-rh="true" name="description" content="Learn how to upload and customize your own models on the Clarifai platform"><meta data-rh="true" property="og:description" content="Learn how to upload and customize your own models on the Clarifai platform"><link data-rh="true" rel="icon" href="/img/favicon.svg"><link data-rh="true" rel="canonical" href="https://docs.clarifai.com/compute/upload/examples"><link data-rh="true" rel="alternate" href="https://docs.clarifai.com/compute/upload/examples" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.clarifai.com/compute/upload/examples" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://E9LMD97ZH2-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Build and Upload Models","item":"https://docs.clarifai.com/compute/upload/"},{"@type":"ListItem","position":2,"name":"Model Upload Examples","item":"https://docs.clarifai.com/compute/upload/examples"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3R20NHSS5H"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-3R20NHSS5H",{anonymize_ip:!0})</script>
<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-5W9P7GR",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>




<link rel="search" type="application/opensearchdescription+xml" title="Clarifai Docs" href="/opensearch.xml">




<script src="/scripts/sidebar.js" async></script>
<script src="/scripts/intercomConfig.js" async></script>
<script src="https://cdn.amplitude.com/libs/analytics-browser-2.12.0-min.js.gz" defer="defer"></script>
<script src="https://cdn.amplitude.com/libs/plugin-session-replay-browser-1.4.0-min.js.gz" defer="defer"></script>
<script src="/scripts/amplitude.js" defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.cd86c358.css">
<script src="/assets/js/runtime~main.9c0df257.js" defer="defer"></script>
<script src="/assets/js/main.bcccae44.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5W9P7GR" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementWrapper_Ma07"><div class="announcementBar_s0pr" role="banner"><div class="announcementBarPlaceholder_qxfj"></div><div class="announcementBarClose_iXyO"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="none" viewBox="0 0 32 32"><rect width="32" height="32" fill="#F3F4F6" rx="16"></rect><path stroke="#1F2A37" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21.714 10.286 10.285 21.714m0-11.428 11.429 11.428"></path></svg></div><div class="content_knG7 announcementBarContent_dpRF"><span>Clarifai Reasoning Engine:</span>Benchmarked by Artificial Analysis on GPT-OSS-120B → 544 tokens/sec, 3.6s TTFA, $0.16/M — Faster, Cheaper, Adaptive. <a target="_blank" rel="noopener noreferrer" href="https://www.clarifai.com/press-release-clarifai-launches-reasoning-engine-optimized-for-agentic-ai-inference">Learn More.</a></div></div></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo-dark.svg" alt="Clarifai Docs" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo-light.svg" alt="Clarifai Docs" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><div class="navbar__item dropdown dropdown--hoverable" style="width:unset"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">API References</a><ul class="dropdown__menu" style="display:flex;flex-direction:column;height:auto;max-height:300px;max-width:unset;flex-wrap:wrap;overflow-y:unset;width:300px;column-gap:32px"><li><a class="dropdown__link" href="/resources/api-references/python">Python SDK Reference</a></li><li><a class="dropdown__link" href="/resources/api-references/node/">Node.js SDK Reference</a></li><li><a href="https://documenter.getpostman.com/view/30622694/2s9YkuZdro" target="_blank" rel="noopener noreferrer" class="dropdown__link">Postman API Reference<svg width="12" height="12" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li><a href="https://api.clarifai.com/api-doc/?url=https://api.clarifai.com/v2/swagger.json" target="_blank" rel="noopener noreferrer" class="dropdown__link">Swagger API Reference<svg width="12" height="12" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Meta+k)" aria-keyshortcuts="Meta+k"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 24 24" aria-hidden="true"><circle cx="11" cy="11" r="8" stroke="currentColor" fill="none" stroke-width="1.4"></circle><path d="m21 21-4.3-4.3" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div><a href="https://github.com/Clarifai/docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="Github repository"></a><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-discord-link" aria-label="Discord"></a><a href="https://x.com/clarifai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-x-link" aria-label="X"></a><a href="https://www.linkedin.com/company/clarifai/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-linkedin-link" aria-label="LinkedIn"></a><a href="https://clarifai.com/login?__hstc=56460205.941fd3bdff0d161c2f70ccba4c9dcb6b.1707280236564.1715406292479.1715409915530.11&amp;__hssc=56460205.1.1715409915530&amp;__hsfp=1566939966" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link login-link" aria-label="Login">Login<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><a href="https://clarifai.com/signup?__hstc=56460205.941fd3bdff0d161c2f70ccba4c9dcb6b.1707280236564.1715406292479.1715409915530.11&amp;__hssc=56460205.1.1715409915530&amp;__hsfp=1566939966" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link signup-button" aria-label="Start for free">Start for free<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_ntye" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/"><span title="Welcome" class="linkLabel_WmDU">Welcome</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Getting Started" class="categoryLinkLabel_W154">Getting Started</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/quickstart"><span title="Quick Start With API" class="linkLabel_WmDU">Quick Start With API</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/quickstart-playground"><span title="Quick Start With Playground" class="linkLabel_WmDU">Quick Start With Playground</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/first-deployment"><span title="Deploy Your First Model" class="linkLabel_WmDU">Deploy Your First Model</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/set-up-compute"><span title="Set Up Compute Fast" class="linkLabel_WmDU">Set Up Compute Fast</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/upload-model"><span title="Build and Upload a Model" class="linkLabel_WmDU">Build and Upload a Model</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--active"><span title="Compute" class="categoryLinkLabel_W154">Compute</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/overview"><span title="Compute Orchestration" class="linkLabel_WmDU">Compute Orchestration</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/compute/deployments/"><span title="Deployments" class="categoryLinkLabel_W154">Deployments</span></a><button aria-label="Expand sidebar category &#x27;Deployments&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/compute/inference/"><span title="Inference" class="categoryLinkLabel_W154">Inference</span></a><button aria-label="Expand sidebar category &#x27;Inference&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/compute/upload/"><span title="Build and Upload Models" class="categoryLinkLabel_W154">Build and Upload Models</span></a><button aria-label="Collapse sidebar category &#x27;Build and Upload Models&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/upload/test-locally"><span title="Test Models Locally" class="linkLabel_WmDU">Test Models Locally</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/upload/data-types"><span title="Input and Output Data Types" class="linkLabel_WmDU">Input and Output Data Types</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/compute/upload/examples"><span title="Model Upload Examples" class="linkLabel_WmDU">Model Upload Examples</span></a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/local-runners/"><span title="Local Runners" class="linkLabel_WmDU">Local Runners</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/compute/toolkits/"><span title="Toolkits" class="categoryLinkLabel_W154">Toolkits</span></a><button aria-label="Expand sidebar category &#x27;Toolkits&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/compute/agents/"><span title="Agents" class="categoryLinkLabel_W154">Agents</span></a><button aria-label="Expand sidebar category &#x27;Agents&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Control and Governance" class="categoryLinkLabel_W154">Control and Governance</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/control/authentication/"><span title="Authentication" class="categoryLinkLabel_W154">Authentication</span></a><button aria-label="Expand sidebar category &#x27;Authentication&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/control/control-center/"><span title="Control Center" class="categoryLinkLabel_W154">Control Center</span></a><button aria-label="Expand sidebar category &#x27;Control Center&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/control/clarifai-organizations/"><span title="Clarifai Organizations" class="categoryLinkLabel_W154">Clarifai Organizations</span></a><button aria-label="Expand sidebar category &#x27;Clarifai Organizations&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Create and Manage" class="categoryLinkLabel_W154">Create and Manage</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/applications/"><span title="Applications" class="categoryLinkLabel_W154">Applications</span></a><button aria-label="Expand sidebar category &#x27;Applications&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/inputs/"><span title="Inputs" class="categoryLinkLabel_W154">Inputs</span></a><button aria-label="Expand sidebar category &#x27;Inputs&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/search/"><span title="Vector Search" class="categoryLinkLabel_W154">Vector Search</span></a><button aria-label="Expand sidebar category &#x27;Vector Search&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/datasets/"><span title="Datasets" class="categoryLinkLabel_W154">Datasets</span></a><button aria-label="Expand sidebar category &#x27;Datasets&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/concepts/"><span title="Concepts" class="categoryLinkLabel_W154">Concepts</span></a><button aria-label="Expand sidebar category &#x27;Concepts&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/labeling/"><span title="Labeling" class="categoryLinkLabel_W154">Labeling</span></a><button aria-label="Expand sidebar category &#x27;Labeling&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/models/"><span title="Models" class="categoryLinkLabel_W154">Models</span></a><button aria-label="Expand sidebar category &#x27;Models&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/workflows/"><span title="Workflows" class="categoryLinkLabel_W154">Workflows</span></a><button aria-label="Expand sidebar category &#x27;Workflows&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/agent-system-operators/"><span title="Agent System Operators" class="categoryLinkLabel_W154">Agent System Operators</span></a><button aria-label="Expand sidebar category &#x27;Agent System Operators&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/create/modules/"><span title="Modules" class="categoryLinkLabel_W154">Modules</span></a><button aria-label="Expand sidebar category &#x27;Modules&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Additional Resources" class="categoryLinkLabel_W154">Additional Resources</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/api-overview/"><span title="API Overview" class="categoryLinkLabel_W154">API Overview</span></a><button aria-label="Expand sidebar category &#x27;API Overview&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/platform/"><span title="Platform Overview" class="linkLabel_WmDU">Platform Overview</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/api-references/"><span title="API References" class="categoryLinkLabel_W154">API References</span></a><button aria-label="Expand sidebar category &#x27;API References&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/glossary/"><span title="Glossary" class="categoryLinkLabel_W154">Glossary</span></a><button aria-label="Expand sidebar category &#x27;Glossary&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/data-utils/"><span title="Data Utils" class="categoryLinkLabel_W154">Data Utils</span></a><button aria-label="Expand sidebar category &#x27;Data Utils&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/sdk-examples"><span title="Python SDK Notebook Examples" class="linkLabel_WmDU">Python SDK Notebook Examples</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/resources/complementary-topics/"><span title="Complementary Topics" class="categoryLinkLabel_W154">Complementary Topics</span></a><button aria-label="Expand sidebar category &#x27;Complementary Topics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/troubleshooting"><span title="Troubleshooting" class="linkLabel_WmDU">Troubleshooting</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/tips"><span title="Additional Tips" class="linkLabel_WmDU">Additional Tips</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/privacy-security"><span title="Data Privacy and Security" class="linkLabel_WmDU">Data Privacy and Security</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Product Updates" class="categoryLinkLabel_W154">Product Updates</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/product-updates/upcoming-api-changes/"><span title="Upcoming Platform Changes" class="categoryLinkLabel_W154">Upcoming Platform Changes</span></a><button aria-label="Expand sidebar category &#x27;Upcoming Platform Changes&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/product-updates/changelog"><span title="Changelog" class="categoryLinkLabel_W154">Changelog</span></a><button aria-label="Expand sidebar category &#x27;Changelog&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Integrations" class="categoryLinkLabel_W154">Integrations</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/embedchain/"><span title="Embedchain" class="categoryLinkLabel_W154">Embedchain</span></a><button aria-label="Expand sidebar category &#x27;Embedchain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/langchain/"><span title="LangChain" class="categoryLinkLabel_W154">LangChain</span></a><button aria-label="Expand sidebar category &#x27;LangChain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/llamaindex/"><span title="LlamaIndex" class="categoryLinkLabel_W154">LlamaIndex</span></a><button aria-label="Expand sidebar category &#x27;LlamaIndex&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/databricks/"><span title="Databricks" class="categoryLinkLabel_W154">Databricks</span></a><button aria-label="Expand sidebar category &#x27;Databricks&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/DSPy/"><span title="DSPy" class="categoryLinkLabel_W154">DSPy</span></a><button aria-label="Expand sidebar category &#x27;DSPy&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/integrations/unstructured/"><span title="Unstructured.io" class="categoryLinkLabel_W154">Unstructured.io</span></a><button aria-label="Expand sidebar category &#x27;Unstructured.io&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link"><span title="Additional Links" class="categoryLinkLabel_W154">Additional Links</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://api.clarifai.com/api-doc/?url=https://api.clarifai.com/v2/swagger.json" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0"><span title="Swagger API Guide" class="linkLabel_WmDU">Swagger API Guide</span><svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://stackoverflow.com/tags/clarifai/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0"><span title="Stack Overflow" class="linkLabel_WmDU">Stack Overflow</span><svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://status.clarifai.com/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0"><span title="API Status" class="linkLabel_WmDU">API Status</span><svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://www.clarifai.com/blog/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0"><span title="Clarifai Blog" class="linkLabel_WmDU">Clarifai Blog</span><svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Compute</span></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/compute/upload/"><span>Build and Upload Models</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Model Upload Examples</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Model Upload Examples</h1></header>
<p><strong>Learn how to upload and customize your own models on the Clarifai platform</strong></p>
<hr>
<p>This section provides examples that guide you through uploading custom models to Clarifai. You’ll learn how to adapt pre-built examples, configure model settings, and prepare your project for deployment on the platform.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>All the examples here are available in the Clarifai Runners Examples <a href="https://github.com/Clarifai/runners-examples" target="_blank" rel="noopener noreferrer" class="">GitHub repository</a>. You can use the Clarifai CLI to <a href="https://docs.clarifai.com/resources/api-overview/cli#initialize-with-github-template" target="_blank" rel="noopener noreferrer" class="">download a model template</a>. For example:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai model init --github-url https://github.com/Clarifai/runners-examples/tree/main/local-runners/ollama-model-upload</span><br></span></code></pre></div></div></div></div>
<p>To use these examples, create a project directory and organize your files as shown below. This structure is required for successfully uploading models to the Clarifai platform:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">your_model_directory/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── 1/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">│   └── model.py</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">├── requirements.txt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">└── config.yaml</span><br></span></code></pre></div></div>
<ul>
<li class=""><strong><code>your_model_directory/</code></strong> – Root directory containing all files related to your custom model.<!-- -->
<ul>
<li class=""><strong><code>1/</code></strong> – A subdirectory (named <code>1</code>) that contains the main model file.</li>
</ul>
</li>
<li class=""><strong><code>model.py</code></strong> – Defines your model logic, including loading the model and handling inference.</li>
<li class=""><strong><code>requirements.txt</code></strong> – Lists all Python dependencies required to run your model.</li>
<li class=""><strong><code>config.yaml</code></strong> – Includes metadata and configuration details for building the model, such as compute resources and environment settings.</li>
</ul>
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="hello-world">Hello World<a href="#hello-world" class="hash-link" aria-label="Direct link to Hello World" title="Direct link to Hello World" translate="no">​</a></h2>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_class import ModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Iterator</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import random</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class MyModel(ModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;&quot;&quot;This is a model that does some string manipulation.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Nothing to load for this model.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @ModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def predict(self, prompt: str, number_of_letters: int = Param(default=3, description=&quot;number of letters to add&quot;)) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Function to append some string information&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return new_str(prompt, number_of_letters)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @ModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def generate(self, prompt: str = &quot;&quot;, number_of_letters: int = Param(default=3, description=&quot;number of letters to add&quot;)) -&gt; Iterator[str]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Example yielding a whole batch of streamed stuff back.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for i in range(10):  # fake something iterating generating 10 times.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      yield new_str(str(i) + &quot;-&quot; + prompt, number_of_letters)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @ModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def s(self, input_iterator: Iterator[str], number_of_letters: int = Param(default=3, description=&quot;number of letters to add&quot;)) -&gt; Iterator[str]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Example yielding getting an iterator and yielding back results.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for i, inp in enumerate(input_iterator):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      yield new_str(inp, number_of_letters)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def new_str(input_str: str, number_of_letters: int = 3) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Append a dash and random letters to the input string.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    random_letters = &#x27;&#x27;.join(random.choices(string.ascii_letters, k=number_of_letters))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return f&quot;{input_str}-{random_letters}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def test_predict() -&gt; None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Test the predict method of MyModel by printing its output.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model = MyModel()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model.load_model()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;Testing predict method:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    output = model.predict(&quot;TestPredict&quot;, number_of_letters=5)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(output, end=&quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def test_generate() -&gt; None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Test the generate method of MyModel by printing its outputs.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model = MyModel()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model.load_model()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;Testing generate method:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for output in model.generate(&quot;Test&quot;, number_of_letters=5):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(output, end=&quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    test_predict()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    test_generate()</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: &quot;my-model-id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: &quot;my-user-id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: &quot;my-app-id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: &quot;text-to-text&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &quot;3.12&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: 50m</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 250Mi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 0</span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="nsfw-image-classifier">NSFW Image Classifier<a href="#nsfw-image-classifier" class="hash-link" aria-label="Direct link to NSFW Image Classifier" title="Direct link to NSFW Image Classifier" translate="no">​</a></h2>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import List, Iterator</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Third-party imports</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import cv2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from PIL import Image as PILImage</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from transformers import AutoModelForImageClassification, ViTImageProcessor</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Clarifai imports</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.visual_classifier_class import VisualClassifierClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_types import Concept, Image, Video</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class ImageClassifierModel(VisualClassifierClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;A custom runner that classifies images and outputs concepts.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Load the model and processor.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        builder = ModelBuilder(model_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpoints = builder.download_checkpoints(stage=&quot;runtime&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.device = &#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;Running on device: {self.device}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model = AutoModelForImageClassification.from_pretrained(checkpoints,).to(self.device)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model_labels = self.model.config.id2label</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.processor = ViTImageProcessor.from_pretrained(checkpoints)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Done loading!&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @VisualClassifierClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def predict(self, image: Image) -&gt; List[Concept]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Predict concepts for a list of images.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pil_image = VisualClassifierClass.preprocess_image(image.bytes)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        inputs = self.processor(images=pil_image, return_tensors=&quot;pt&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        inputs = {name: tensor.to(self.device) for name, tensor in inputs.items()}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        with torch.no_grad():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logits = self.model(**inputs).logits</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        outputs = VisualClassifierClass.process_concepts(logits, self.model_labels)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return outputs[0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @VisualClassifierClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def generate(self, video: Video) -&gt; Iterator[List[Concept]]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Generate concepts for frames extracted from a video.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        video_bytes = video.bytes</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        frame_generator = VisualClassifierClass.video_to_frames(video_bytes)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for frame in frame_generator:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            image = VisualClassifierClass.preprocess_image(frame.image.bytes)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            inputs = self.processor(images=image, return_tensors=&quot;pt&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            inputs = {name: tensor.to(self.device) for name, tensor in inputs.items()}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            with torch.no_grad():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                logits = self.model(**inputs).logits</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                outputs = VisualClassifierClass.process_concepts(logits, self.model_labels)  # Yield concepts for each frame</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                yield outputs[0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @VisualClassifierClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def stream_image(self, image_stream: Iterator[Image]) -&gt; Iterator[List[Concept]]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Stream process image inputs.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for image in image_stream:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = self.predict(image)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            yield result</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @VisualClassifierClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def stream_video(self, video_stream: Iterator[Video]) -&gt; Iterator[List[Concept]]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Stream process video inputs.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for video in video_stream:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for frame_result in self.generate(video):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                yield frame_result</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def test(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Test the model functionality.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        import requests  # Import moved here as it&#x27;s only used for testing</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Test configuration</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        TEST_URLS = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;images&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;https://samples.clarifai.com/metro-north.jpg&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;https://samples.clarifai.com/dog.tiff&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;video&quot;: &quot;https://samples.clarifai.com/beer.mp4&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        def get_test_data(url):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return Image(bytes=requests.get(url).content)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        def get_test_video():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return Video(bytes=requests.get(TEST_URLS[&quot;video&quot;]).content)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        def run_test(name, test_fn):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logger.info(f&quot;\nTesting {name}...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                test_fn()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                logger.info(f&quot;{name} test completed successfully&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                logger.error(f&quot;Error in {name} test: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Test predict</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        def test_predict():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = self.predict(get_test_data(TEST_URLS[&quot;images&quot;][0]))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logger.info(f&quot;Predict result: {result}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Test generate</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        def test_generate():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for classifications in self.generate(get_test_video()):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                logger.info(f&quot;First frame classifications: {classifications}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                break</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Test stream</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        def test_stream():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Split into two separate test functions for clarity</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            def test_stream_image():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                images = [get_test_data(url) for url in TEST_URLS[&quot;images&quot;]]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                for result in self.stream_image(iter(images)):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    logger.info(f&quot;Image stream result: {result}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            def test_stream_video():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                for result in self.stream_video(iter([get_test_video()])):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    logger.info(f&quot;Video stream result: {result}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    break  # Just test first frame</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logger.info(&quot;\nTesting image streaming...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            test_stream_image()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logger.info(&quot;\nTesting video streaming...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            test_stream_video()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Run all tests</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for test_name, test_fn in [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            (&quot;predict&quot;, test_predict),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            (&quot;generate&quot;, test_generate),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            (&quot;stream&quot;, test_stream)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            run_test(test_name, test_fn)</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch==2.6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers&gt;=4.51.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pillow==10.4.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">requests==2.32.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">timm==1.0.12</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">opencv-python-headless==4.10.0.84</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai&gt;=11.5.0,&lt;12.0.0</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># This is the sample config file for the image-classification model.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: &quot;nsfw_image_detection&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: &quot;user_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: &quot;app_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: &quot;visual-detector&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &quot;3.11&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &quot;2&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: &quot;2Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type: [&quot;NVIDIA-*&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: &quot;3Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: &quot;huggingface&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: &quot;Falconsai/nsfw_image_detection&quot;</span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="detr-resnet-image-detector">DETR ResNet Image Detector<a href="#detr-resnet-image-detector" class="hash-link" aria-label="Direct link to DETR ResNet Image Detector" title="Direct link to DETR ResNet Image Detector" translate="no">​</a></h2>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Standard library imports</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import List, Dict, Any, Iterator</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Third-party imports</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import cv2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from PIL import Image as PILImage</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from transformers import DetrForObjectDetection, DetrImageProcessor</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Clarifai imports</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.visual_detector_class import VisualDetectorClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_types import Image, Video, Region, Frame</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def detect_objects(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    images: List[PILImage],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model: DetrForObjectDetection,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    processor: DetrImageProcessor,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    device: str</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; Dict[str, Any]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Process images through the DETR model to detect objects.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Args:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        images: List of preprocessed images</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model: DETR model instance</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        processor: Image processor for DETR</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        device: Computation device (CPU/GPU)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Returns:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Detection results from the model</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model_inputs = processor(images=images, return_tensors=&quot;pt&quot;).to(device)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model_inputs = {name: tensor.to(device) for name, tensor in model_inputs.items()}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model_output = model(**model_inputs)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    results = processor.post_process_object_detection(model_output)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return results</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class MyRunner(VisualDetectorClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;A custom runner for DETR object detection model that processes images and videos&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Load the model here.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        builder = ModelBuilder(model_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpoint_path = builder.download_checkpoints(stage=&quot;runtime&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.device = &#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;Running on device: {self.device}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model = DetrForObjectDetection.from_pretrained(checkpoint_path).to(self.device)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.processor = DetrImageProcessor.from_pretrained(checkpoint_path)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model.eval()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.threshold = 0.9</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model_labels = self.model.config.id2label</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Done loading!&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @VisualDetectorClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def predict(self, image: Image) -&gt; List[Region]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Process a single image and return detected objects.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        image_bytes = image.bytes</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        image = VisualDetectorClass.preprocess_image(image_bytes)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        with torch.no_grad():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            results = detect_objects([image], self.model, self.processor, self.device)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            outputs = VisualDetectorClass.process_detections(results, self.threshold, self.model_labels)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return outputs[0]  # Return detections for single image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @VisualDetectorClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def generate(self, video: Video) -&gt; Iterator[Frame]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Process video frames and yield detected objects for each frame.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        frame_generator = VisualDetectorClass.video_to_frames(video.bytes)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for frame in frame_generator:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            with torch.no_grad():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                image = VisualDetectorClass.preprocess_image(frame.image.bytes)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                results = detect_objects([image], self.model, self.processor, self.device)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                outputs = VisualDetectorClass.process_detections(results, self.threshold, self.model_labels)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                frame.regions = outputs[0]  # Assign detections to the frame</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                yield frame  # Yield the frame with detections</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @VisualDetectorClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def stream_image(self, image_stream: Iterator[Image]) -&gt; Iterator[List[Region]]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Stream process image inputs.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for image in image_stream:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = self.predict(image)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            yield result</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @VisualDetectorClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def stream_video(self, video_stream: Iterator[Video]) -&gt; Iterator[Frame]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Stream process video inputs.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for video in video_stream:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for frame_result in self.generate(video):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                yield frame_result</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def test(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Test the model functionality.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        import requests  # Import moved here as it&#x27;s only used for testing</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Test configuration</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        TEST_URLS = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;images&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;https://samples.clarifai.com/metro-north.jpg&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;https://samples.clarifai.com/dog.tiff&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;video&quot;: &quot;https://samples.clarifai.com/beer.mp4&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        def get_test_data(url):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return Image(bytes=requests.get(url).content)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        def get_test_video():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return Video(bytes=requests.get(TEST_URLS[&quot;video&quot;]).content)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        def run_test(name, test_fn):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logger.info(f&quot;\nTesting {name}...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                test_fn()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                logger.info(f&quot;{name} test completed successfully&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                logger.error(f&quot;Error in {name} test: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Test predict</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        def test_predict():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = self.predict(get_test_data(TEST_URLS[&quot;images&quot;][0]))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logger.info(f&quot;Predict result: {result}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Test generate</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        def test_generate():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for detections in self.generate(get_test_video()):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                logger.info(f&quot;First frame detections: {detections}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                break</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Test stream</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        def test_stream():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Split into two separate test functions for clarity</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            def test_stream_image():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                images = [get_test_data(url) for url in TEST_URLS[&quot;images&quot;]]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                for result in self.stream_image(iter(images)):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    logger.info(f&quot;Image stream result: {result}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            def test_stream_video():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                for result in self.stream_video(iter([get_test_video()])):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    logger.info(f&quot;Video stream result: {result}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    break  # Just test first frame</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logger.info(&quot;\nTesting image streaming...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            test_stream_image()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logger.info(&quot;\nTesting video streaming...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            test_stream_video()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Run all tests</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for test_name, test_fn in [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            (&quot;predict&quot;, test_predict),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            (&quot;generate&quot;, test_generate),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            (&quot;stream&quot;, test_stream)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            run_test(test_name, test_fn)</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch==2.6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers&gt;=4.51.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pillow==10.4.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">requests==2.32.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">timm==1.0.12</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">opencv-python-headless==4.10.0.84</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai&gt;=11.4.10,&lt;12.0.0</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># This is the sample config file for the image-detection model.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: &quot;detr-resnet-50&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: &quot;user_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: &quot;app_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: &quot;visual-detector&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &quot;3.11&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &quot;4&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: &quot;2Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type: [&quot;NVIDIA-*&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: &quot;5Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: &quot;huggingface&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: &quot;facebook/detr-resnet-50&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  hf_token: &quot;hf_token&quot;</span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="image-segmenter">Image Segmenter<a href="#image-segmenter" class="hash-link" aria-label="Direct link to Image Segmenter" title="Direct link to Image Segmenter" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="mask2former-ade">Mask2Former ADE<a href="#mask2former-ade" class="hash-link" aria-label="Direct link to Mask2Former ADE" title="Direct link to Mask2Former ADE" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Iterator, List, Tuple</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.visual_detector_class import VisualDetectorClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils import data_types as dt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import yaml</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from PIL import Image as PILImage</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ROOT = os.path.dirname(__file__)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class MyRunner(VisualDetectorClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def _load_concepts(self, config_path, name, model_path):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    with open(config_path, &quot;r&quot;) as f:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      data = yaml.safe_load(f)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Map Clarifai concept name to id and reverse</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.conceptid2name = {each[&quot;id&quot;] : each[&quot;name&quot;] for each in data.get(&quot;concepts&quot;, [])}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.conceptname2id = {each[&quot;name&quot;] : each[&quot;id&quot;] for each in data.get(&quot;concepts&quot;, [])}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Load the model here.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    checkpoint_path = &quot;facebook/mask2former-swin-tiny-ade-semantic&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.device = &#x27;cuda&#x27; #if torch.cuda.is_available() else &#x27;cpu&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logger.info(f&quot;Running on device: {self.device}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.model = Mask2FormerForUniversalSegmentation.from_pretrained(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpoint_path, trust_remote_code=True).to(self.device)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.processor = AutoImageProcessor.from_pretrained(checkpoint_path, trust_remote_code=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.model.eval()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Load clarifai concept</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    config_path = os.path.join(ROOT, &quot;../config.yaml&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self._load_concepts(config_path, &quot;mask2former-ade&quot;, checkpoint_path)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logger.info(&quot;Done loading!&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @VisualDetectorClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def model_predict(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    images: List[PILImage.Image]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  ) -&gt; List[List[dt.Region]]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    inputs = self.processor(images=images, return_tensors=&quot;pt&quot;).to(self.device)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    with torch.no_grad():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      outputs = self.model(**inputs)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    target_sizes = [image.size[::-1] for image in images]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    results = self.processor.post_process_semantic_segmentation(outputs, target_sizes=target_sizes)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    outputs = []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for i, all_masks_tensor in enumerate(results):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      masks = []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      for clss_id in all_masks_tensor.unique().tolist():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        label = self.model.config.id2label[clss_id]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        mask = torch.zeros_like(all_masks_tensor)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        mask[all_masks_tensor == clss_id] = 255</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        mask = mask.cpu().numpy() if self.device == &quot;cuda&quot; else mask.numpy()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        mask = PILImage.fromarray(mask.astype(&quot;uint8&quot;))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        region = dt.Region(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          mask=mask,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          concepts=[dt.Concept(id=self.conceptname2id[label], name=label)]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        masks.append(region)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      outputs.append(masks)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return outputs</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @VisualDetectorClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def predict(self, image: dt.Image) -&gt; List[dt.Region]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return self.model_predict([image.to_pil()])[0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @VisualDetectorClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def stream(self, images: Iterator[dt.Image]) -&gt; Iterator[dt.Region]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for each in images:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      yield self.predict(image=each)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @VisualDetectorClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def generate(self, video: dt.Video) -&gt; Iterator[dt.Region]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for frame in self.video_to_frames(video.bytes):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      yield self.predict(image=frame.image)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def test(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    import requests</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    image = dt.Image(bytes=requests.get(&quot;https://samples.clarifai.com/metro-north.jpg&quot;).content)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    video = dt.Video(bytes=requests.get(&quot;https://samples.clarifai.com/beer.mp4&quot;).content)   </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logger.info(&quot;# -------- Test predict/detect -------------&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logger.info(f&quot;{self.predict(image=image)}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logger.info(&quot;# -------- Test generate -------------&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    n=5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for i, each in enumerate(self.generate(video=video)):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      print(each)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if i &gt; n:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        break</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logger.info(&quot;# -------- Test stream -------------&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def iteration():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      for each in [image]*10:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        yield each</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for i, each in enumerate(self.stream(images=iteration())):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      print(each)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if i &gt; n:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        break</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch==2.6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">tokenizers&gt;=0.19.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers&gt;=4.44.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pillow&gt;=10.4.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">requests&gt;=2.32.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">timm</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">opencv-python-headless==4.10.0.84</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">numpy</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">aiohttp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scipy&gt;=1.10.1</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: facebook_mask2former-swin-tiny-ade-semantic</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: a</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: b</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: visual-segmenter</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.12&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &#x27;2&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 8Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  - NVIDIA-*</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: 21Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">concepts:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: wall</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: building</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: sky</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: floor</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-4</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: tree</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: ceiling</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-6</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: road</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-7</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: &#x27;bed &#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: windowpane</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-9</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: grass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-10</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: cabinet</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-11</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: sidewalk</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-12</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: person</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-13</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: earth</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-14</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: door</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-15</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-16</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: mountain</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-17</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: plant</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-18</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: curtain</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-19</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: chair</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-20</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: car</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-21</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: water</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-22</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: painting</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-23</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: sofa</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-24</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: shelf</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-25</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: house</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-26</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: sea</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-27</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: mirror</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-28</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: rug</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-29</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: field</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-30</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: armchair</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-31</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: seat</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-32</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: fence</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-33</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: desk</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-34</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: rock</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-35</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: wardrobe</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-36</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: lamp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-37</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: bathtub</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-38</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: railing</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-39</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: cushion</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-40</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: base</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-41</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: box</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-42</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: column</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-43</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: signboard</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-44</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: chest of drawers</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-45</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: counter</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-46</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: sand</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-47</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: sink</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-48</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: skyscraper</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-49</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: fireplace</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-50</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: refrigerator</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-51</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: grandstand</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-52</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: path</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-53</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: stairs</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-54</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: runway</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-55</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: case</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-56</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: pool table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-57</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: pillow</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-58</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: screen door</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-59</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: stairway</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-60</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: river</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-61</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: bridge</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-62</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: bookcase</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-63</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: blind</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-64</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: coffee table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-65</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: toilet</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-66</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: flower</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-67</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: book</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-68</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: hill</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-69</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: bench</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-70</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: countertop</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-71</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: stove</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-72</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: palm</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-73</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: kitchen island</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-74</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: computer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-75</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: swivel chair</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-76</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: boat</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-77</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: bar</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-78</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: arcade machine</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-79</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: hovel</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-80</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: bus</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-81</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: towel</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-82</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: light</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-83</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: truck</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-84</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: tower</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-85</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: chandelier</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-86</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: awning</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-87</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: streetlight</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-88</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: booth</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-89</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: television receiver</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-90</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: airplane</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-91</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: dirt track</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-92</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: apparel</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-93</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: pole</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-94</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: land</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-95</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: bannister</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-96</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: escalator</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-97</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: ottoman</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-98</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: bottle</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-99</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: buffet</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-100</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: poster</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-101</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: stage</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-102</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: van</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-103</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: ship</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-104</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: fountain</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-105</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: conveyer belt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-106</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: canopy</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-107</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: washer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-108</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: plaything</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-109</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: swimming pool</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-110</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: stool</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-111</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: barrel</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-112</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: basket</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-113</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: waterfall</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-114</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: tent</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-115</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: bag</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-116</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: minibike</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-117</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: cradle</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-118</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: oven</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-119</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: ball</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-120</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: food</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-121</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: step</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-122</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: tank</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-123</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: trade name</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-124</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: microwave</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-125</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: pot</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-126</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: animal</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-127</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: bicycle</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-128</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: lake</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-129</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: dishwasher</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-130</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: screen</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-131</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: blanket</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-132</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: sculpture</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-133</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: hood</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-134</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: sconce</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-135</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: vase</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-136</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: traffic light</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-137</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: tray</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-138</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: ashcan</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-139</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: fan</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-140</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: pier</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-141</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: crt screen</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-142</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: plate</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-143</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: monitor</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-144</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: bulletin board</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-145</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: shower</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-146</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: radiator</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-147</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: glass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-148</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: clock</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- id: id-mask2former-ade-149</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: flag</span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="image-text-to-image">Image-Text-to-Image<a href="#image-text-to-image" class="hash-link" aria-label="Direct link to Image-Text-to-Image" title="Direct link to Image-Text-to-Image" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="stable-diffusion-2-depth">Stable Diffusion 2 Depth<a href="#stable-diffusion-2-depth" class="hash-link" aria-label="Direct link to Stable Diffusion 2 Depth" title="Direct link to Stable Diffusion 2 Depth" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import List</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.openai_class import OpenAIModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_types import Image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from diffusers import StableDiffusionDepth2ImgPipeline</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from diffusers.utils import load_image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class StableDiffusion(OpenAIModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    A Model that integrates with the Clarifai platform and uses the FluxFillPipeline for image inpainting.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    client = True  # This will be set in load_model method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model = True  # This will be set in load_model method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Load the model here.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        builder = ModelBuilder(model_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        hf_token = builder.config[&quot;checkpoints&quot;][&quot;hf_token&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.client = StableDiffusionDepth2ImgPipeline.from_pretrained(&quot;stabilityai/stable-diffusion-2-depth&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                                                       torch_dtype=torch.float16,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                                                       use_safetensors=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                                                       token=hf_token)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.client.to(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;stable-diffusion model loaded successfully.&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def predict(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                image: Image = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                negative_prompt: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                mask: Image = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                strength: float = 0.8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                ) -&gt; Image:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Predict method that uses the FluxFillPipeline to inpaint images based on the provided prompt.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if image:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if image.url:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                image = load_image(image.url)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            elif image.bytes:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                image=image.to_pil()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        response = self.client(prompt=prompt,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                            image=image,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                            negative_prompt=negative_prompt,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                            strength=strength).images[0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return Image.from_pil(pil_image = response)</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">tokenizers==0.21.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers&gt;=4.48</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">diffusers==0.32.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">accelerate==1.2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">optimum==1.23.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">xformers</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">einops==0.8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">requests==2.32.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">numpy&gt;2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch==2.5.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai-protocol</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: &quot;stable-diffusion-2-depth&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: &quot;user_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: &quot;app_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: &quot;multimodal-to-text&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.11&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &#x27;3&#x27; </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 15Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type: [&quot;NVIDIA-*&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: 6Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: huggingface</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: &quot;stabilityai/stable-diffusion-2-depth&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  hf_token: &quot;hf_token&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  when: runtime</span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="llm">LLM<a href="#llm" class="hash-link" aria-label="Direct link to LLM" title="Direct link to LLM" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="smollm2-17b-instruct-sglang">SmolLM2 1.7B Instruct (SGLang)<a href="#smollm2-17b-instruct-sglang" class="hash-link" aria-label="Direct link to SmolLM2 1.7B Instruct (SGLang)" title="Direct link to SmolLM2 1.7B Instruct (SGLang)" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import sys</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sys.path.append(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Iterator, List</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.openai_class import OpenAIModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.openai_convertor import build_openai_messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from openai import OpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from openai_server_starter import OpenAI_APIServer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">##################</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class SglangModel(OpenAIModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    A custom runner that integrates with the Clarifai platform and uses Server inference</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    to process inputs, including text.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    client = True  # This will be set in load_model method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model = True  # This will be set in load_model method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Load the model here and start the  server.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        os.path.join(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Use downloaded checkpoints.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Or if you intend to download checkpoint at runtime, set hf id instead. For example:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # checkpoints = &quot;Qwen/Qwen2-7B-Instruct&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # server args were generated by `upload` module</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        server_args = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;dtype&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;kv_cache_dtype&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;tp_size&#x27;: 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;load_format&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;context_length&#x27;: None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;device&#x27;: &#x27;cuda&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;port&#x27;: 23333,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;host&#x27;: &#x27;0.0.0.0&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;mem_fraction_static&#x27;: 0.9,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;max_total_tokens&#x27;: &#x27;8192&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;max_prefill_tokens&#x27;: None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;schedule_policy&#x27;: &#x27;fcfs&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;schedule_conservativeness&#x27;: 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &#x27;checkpoints&#x27;: &#x27;runtime&#x27;}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # if checkpoints == &quot;checkpoints&quot; =&gt; assign to checkpoints var aka local checkpoints path</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        stage = server_args.get(&quot;checkpoints&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if stage in [&quot;build&quot;, &quot;runtime&quot;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            #checkpoints = os.path.join(os.path.dirname(__file__), &quot;checkpoints&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            config_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            builder = ModelBuilder(config_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            checkpoints = builder.download_checkpoints(stage=stage)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            server_args.update({&quot;checkpoints&quot;: checkpoints})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if server_args.get(&quot;additional_list_args&quot;) == [&#x27;&#x27;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            server_args.pop(&quot;additional_list_args&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Start server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # This line were generated by `upload` module</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.server = OpenAI_APIServer.from_sglang_backend(**server_args)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Create client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.client = OpenAI(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                api_key=&quot;notset&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                base_url=SglangModel.make_api_url(self.server.host, self.server.port))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model = self._get_model()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;OpenAI {self.model} model loaded successfully!&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def _get_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return self.client.models.list().data[0].id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            raise ConnectionError(&quot;Failed to retrieve model ID from API&quot;) from e</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @staticmethod</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def make_api_url(host: str, port: int, version: str = &quot;v1&quot;) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;http://{host}:{port}/{version}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def predict(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                top_p: float = Param(default=0.8, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;, )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                ) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;This is the method that will be called when the runner is run. It takes in an input and</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        returns an output.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        openai_messages = build_openai_messages(prompt=prompt, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        response = self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            messages=openai_messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            top_p=top_p)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if response.usage and response.usage.prompt_tokens and response.usage.completion_tokens:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self.set_output_context(prompt_tokens=response.usage.prompt_tokens, completion_tokens=response.usage.completion_tokens)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return response.choices[0].message.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def generate(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                top_p: float = Param(default=0.8, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;, )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                ) -&gt; Iterator[str]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Example yielding a whole batch of streamed stuff back.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        openai_messages = build_openai_messages(prompt=prompt, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for chunk in self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            messages=openai_messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            top_p=top_p,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            stream=True):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if chunk.choices:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                text = (chunk.choices[0].delta.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        if (chunk and chunk.choices[0].delta.content) is not None else &#x27;&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                yield text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # This method is needed to test the model with the test-locally CLI command.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def test(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Test the model here.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Testing predict...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Test predict</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(self.predict(prompt=&quot;Hello, how are you?&quot;,))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Error in predict&quot;, e)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Testing generate...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Test generate</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for each in self.generate(prompt=&quot;Hello, how are you?&quot;,):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                print(each, end=&quot; &quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Error in generate&quot;, e)</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/openai_server_starter.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import signal</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import subprocess</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import sys</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import threading</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import List</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import psutil</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PYTHON_EXEC = sys.executable</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def kill_process_tree(parent_pid, include_parent: bool = True, skip_pid: int = None):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;&quot;&quot;Kill the process and all its child processes.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  if parent_pid is None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    parent_pid = os.getpid()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    include_parent = False</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    itself = psutil.Process(parent_pid)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  except psutil.NoSuchProcess:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  children = itself.children(recursive=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  for child in children:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if child.pid == skip_pid:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      continue</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      child.kill()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except psutil.NoSuchProcess:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      pass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  if include_parent:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      itself.kill()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Sometime processes cannot be killed with SIGKILL (e.g, PID=1 launched by kubernetes),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # so we send an additional signal to kill them.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      itself.send_signal(signal.SIGQUIT)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except psutil.NoSuchProcess:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      pass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class OpenAI_APIServer:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def __init__(self, **kwargs):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.server_started_event = threading.Event()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.process = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.backend = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.server_thread = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def __del__(self, *exc):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # This is important</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # close the server when exit the program</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.close()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def close(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if self.process:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        kill_process_tree(self.process.pid)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      except:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.process.terminate()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if self.server_thread:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      self.server_thread.join()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def wait_for_startup(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.server_started_event.wait()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def validate_if_server_start(self, line: str):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    line_lower = line.lower()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if self.backend in [&quot;vllm&quot;, &quot;sglang&quot;, &quot;lmdeploy&quot;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if self.backend == &quot;vllm&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return &quot;application startup complete&quot; in line_lower or &quot;vllm api server on&quot; in line_lower</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot; running on http://{self.host}:&quot; in line.strip()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    elif self.backend == &quot;llamacpp&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      return &quot;waiting for new tasks&quot; in line_lower</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    elif self.backend == &quot;tgi&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      return &quot;Connected&quot; in line.strip()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def _start_server(self, cmds):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      env = os.environ.copy()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      env[&quot;VLLM_USAGE_SOURCE&quot;] = &quot;production-docker-image&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      self.process = subprocess.Popen(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          cmds,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          stdout=subprocess.PIPE,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          stderr=subprocess.STDOUT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          text=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      for line in self.process.stdout:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Server Log:  &quot; + line.strip())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if self.validate_if_server_start(line):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          self.server_started_event.set()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          # break</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if self.process:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.process.terminate()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      raise RuntimeError(f&quot;Failed to start Server server: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def start_server_thread(self, cmds: str):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Start the  server in a separate thread</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      self.server_thread = threading.Thread(target=self._start_server, args=(cmds,), daemon=None)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      self.server_thread.start()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Wait for the server to start</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      self.wait_for_startup()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      raise Exception(e)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @classmethod</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def from_sglang_backend(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cls,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      checkpoints,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      dtype: str = &quot;auto&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      kv_cache_dtype: str = &quot;auto&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      tp_size: int = 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      quantization: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      load_format: str = &quot;auto&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      context_length: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      device: str = &quot;cuda&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      port=23333,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      host=&quot;0.0.0.0&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      chat_template: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      mem_fraction_static: float = 0.8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      max_running_requests: int = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      max_total_tokens: int = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      max_prefill_tokens: int = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      schedule_policy: str = &quot;fcfs&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      schedule_conservativeness: float = 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cpu_offload_gb: int = 0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      additional_list_args: List[str] = [],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  ):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Start SGlang OpenAI compatible server.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Args:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpoints (str): model id or path.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        dtype (str, optional): Dtype used for the model {&quot;auto&quot;, &quot;half&quot;, &quot;float16&quot;, &quot;bfloat16&quot;, &quot;float&quot;, &quot;float32&quot;}. Defaults to &quot;auto&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        kv_cache_dtype (str, optional): Dtype of the kv cache, defaults to the dtype. Defaults to &quot;auto&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tp_size (int, optional): The number of GPUs the model weights get sharded over. Mainly for saving memory rather than for high throughput. Defaults to 1.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        quantization (str, optional): Quantization format {&quot;awq&quot;,&quot;fp8&quot;,&quot;gptq&quot;,&quot;marlin&quot;,&quot;gptq_marlin&quot;,&quot;awq_marlin&quot;,&quot;bitsandbytes&quot;,&quot;gguf&quot;,&quot;modelopt&quot;,&quot;w8a8_int8&quot;}. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        load_format (str, optional): The format of the model weights to load:\n* `auto`: will try to load the weights in the safetensors format and fall back to the pytorch bin format if safetensors format is not available.\n* `pt`: will load the weights in the pytorch bin format. \n* `safetensors`: will load the weights in the safetensors format. \n* `npcache`: will load the weights in pytorch format and store a numpy cache to speed up the loading. \n* `dummy`: will initialize the weights with random values, which is mainly for profiling.\n* `gguf`: will load the weights in the gguf format. \n* `bitsandbytes`: will load the weights using bitsandbytes quantization.&quot;\n* `layered`: loads weights layer by layer so that one can quantize a layer before loading another to make the peak memory envelope smaller.\n. Defaults to &quot;auto&quot;.\n</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        context_length (str, optional): The model&#x27;s maximum context length. Defaults to None (will use the value from the model&#x27;s config.json instead). Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        device (str, optional): The device type {&quot;cuda&quot;, &quot;xpu&quot;, &quot;hpu&quot;, &quot;cpu&quot;}. Defaults to &quot;cuda&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        port (int, optional): Port number. Defaults to 23333.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        host (str, optional): Host name. Defaults to &quot;0.0.0.0&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        chat_template (str, optional): The buliltin chat template name or the path of the chat template file. This is only used for OpenAI-compatible API server.. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        mem_fraction_static (float, optional): The fraction of the memory used for static allocation (model weights and KV cache memory pool). Use a smaller value if you see out-of-memory errors. Defaults to 0.8.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_running_requests (int, optional): The maximum number of running requests.. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_total_tokens (int, optional): The maximum number of tokens in the memory pool. If not specified, it will be automatically calculated based on the memory usage fraction. This option is typically used for development and debugging purposes.. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_prefill_tokens (int, optional): The maximum number of tokens in a prefill batch. The real bound will be the maximum of this value and the model&#x27;s maximum context length. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        schedule_policy (str, optional): The scheduling policy of the requests {&quot;lpm&quot;, &quot;random&quot;, &quot;fcfs&quot;, &quot;dfs-weight&quot;}. Defaults to &quot;fcfs&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        schedule_conservativeness (float, optional): How conservative the schedule policy is. A larger value means more conservative scheduling. Use a larger value if you see requests being retracted frequently. Defaults to 1.0.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        cpu_offload_gb (int, optional): How many GBs of RAM to reserve for CPU offloading. Defaults to 0.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        additional_list_args (List[str], optional): additional args to run subprocess cmd e.g. [&quot;--arg-name&quot;, &quot;arg value&quot;]. See more at [github](https://github.com/sgl-project/sglang/blob/1baa9e6cf90b30aaa7dae51c01baa25229e8f7d5/python/sglang/srt/server_args.py#L298). Defaults to [].</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Returns:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        _type_: _description_</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    from sglang.utils import execute_shell_command, wait_for_server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cmds = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        PYTHON_EXEC, &#x27;-m&#x27;, &#x27;sglang.launch_server&#x27;, &#x27;--model-path&#x27;, checkpoints, &#x27;--dtype&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(dtype), &#x27;--device&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(device), &#x27;--kv-cache-dtype&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(kv_cache_dtype), &#x27;--tp-size&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(tp_size), &#x27;--load-format&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(load_format), &#x27;--mem-fraction-static&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(mem_fraction_static), &#x27;--schedule-policy&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(schedule_policy), &#x27;--schedule-conservativeness&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(schedule_conservativeness), &#x27;--port&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(port), &#x27;--host&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        host, &quot;--trust-remote-code&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if chat_template:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cmds += [&quot;--chat-template&quot;, chat_template]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if quantization:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &#x27;--quantization&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          quantization,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if context_length:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &#x27;--context-length&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          context_length,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if max_running_requests:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &#x27;--max-running-requests&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          max_running_requests,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if max_total_tokens:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &#x27;--max-total-tokens&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          max_total_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if max_prefill_tokens:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &#x27;--max-prefill-tokens&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          max_prefill_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if additional_list_args:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cmds += additional_list_args</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;CMDS to run `sglang` server: &quot;, &quot; &quot;.join(cmds), &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    _self = cls()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    _self.host = host</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    _self.port = port</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    _self.backend = &quot;sglang&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # _self.start_server_thread(cmds)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # new_path = os.environ[&quot;PATH&quot;] + &quot;:/sbin&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # _self.process = subprocess.Popen(cmds, text=True, stderr=subprocess.STDOUT, env={**os.environ, &quot;PATH&quot;: new_path})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    _self.process = execute_shell_command(&quot; &quot;.join(cmds))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logger.info(&quot;Waiting for &quot; + f&quot;http://{_self.host}:{_self.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    wait_for_server(f&quot;http://{_self.host}:{_self.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logger.info(&quot;Done&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return _self</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch==2.6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">tokenizers==0.21.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">accelerate==1.2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">optimum==1.23.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">xformers</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">einops==0.8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">packaging</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ninja</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">qwen-vl-utils==0.0.8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">timm==1.0.12</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">openai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai&gt;=11.5.0,&lt;12.0.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">psutil</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--extra-index-url https://flashinfer.ai/whl/cu124/torch2.4/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">flashinfer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sglang[all]==0.4.6</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers==4.51.1</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Config file for the Sglang runner</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: &quot;SmolLM2-1_7B-Instruct&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: &quot;USER_ID&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: &quot;APP_ID&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: &quot;text-to-text&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &quot;3.11&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &quot;1&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: &quot;6Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type: [&quot;NVIDIA-*&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: &quot;44Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: &quot;huggingface&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: &quot;HuggingFaceTB/SmolLM2-1.7B-Instruct&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  hf_token: &quot;hf_token&quot;</span><br></span></code></pre></div></div></div></div></details>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="llama-32-1b-instruct-hugging-face">LLaMA 3.2 1B Instruct (Hugging Face)<a href="#llama-32-1b-instruct-hugging-face" class="hash-link" aria-label="Direct link to LLaMA 3.2 1B Instruct (Hugging Face)" title="Direct link to LLaMA 3.2 1B Instruct (Hugging Face)" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import List, Iterator</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from threading import Thread</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_class import ModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.openai_convertor import openai_response</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from transformers import (AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class MyModel(ModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;&quot;&quot;A custom runner for llama-3.2-1b-instruct llm that integrates with the Clarifai platform&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Load the model here.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.device = &#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logger.info(f&quot;Running on device: {self.device}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Load checkpoints</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    builder = ModelBuilder(model_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.checkpoints = builder.download_checkpoints(stage=&quot;runtime&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Load model and tokenizer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.tokenizer = AutoTokenizer.from_pretrained(self.checkpoints,)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.tokenizer.pad_token = self.tokenizer.eos_token  # Set pad token to eos token</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.model = AutoModelForCausalLM.from_pretrained(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.checkpoints,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        low_cpu_mem_usage=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        device_map=self.device,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        torch_dtype=torch.bfloat16,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.streamer = TextIteratorStreamer(tokenizer=self.tokenizer, skip_prompt=True, skip_special_tokens=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.chat_template = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logger.info(&quot;Done loading!&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @ModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def predict(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              prompt: str =&quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              top_p: float = Param(default=0.8, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;, )) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Predict the response for the given prompt and chat history using the model.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Construct chat-style messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages = chat_history if chat_history else []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if prompt:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        messages.append({</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;role&quot;: &quot;user&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        })</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    inputs = self.tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=&quot;pt&quot;).to(self.model.device)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    generation_kwargs = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;input_ids&quot;: inputs,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;do_sample&quot;: True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;max_new_tokens&quot;: max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;temperature&quot;: temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;top_p&quot;: top_p,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;eos_token_id&quot;: self.tokenizer.eos_token_id,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    output = self.model.generate(**generation_kwargs)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    generated_tokens = output[0][inputs.shape[-1]:]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return self.tokenizer.decode(generated_tokens, skip_special_tokens=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @ModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def generate(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              prompt: str=&quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              top_p: float = Param(default=0.8, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;, )) -&gt; Iterator[str]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;&quot;&quot;Stream generated text tokens from a prompt + optional chat history.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Construct chat-style messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      messages = chat_history if chat_history else []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if prompt:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          messages.append({</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              &quot;role&quot;: &quot;user&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          })</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      response = self.chat(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          max_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          top_p=top_p</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      for each in response:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          if &#x27;choices&#x27; in each and &#x27;delta&#x27; in each[&#x27;choices&#x27;][0] and &#x27;content&#x27; in each[&#x27;choices&#x27;][0][&#x27;delta&#x27;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  yield each[&#x27;choices&#x27;][0][&#x27;delta&#x27;][&#x27;content&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @ModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def chat(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          messages: List[dict],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          top_p: float = Param(default=0.8, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;, )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          ) -&gt; Iterator[dict]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Stream back JSON dicts for assistant messages.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      Example return format:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;response here&quot;}]}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Tokenize using chat template</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      inputs = self.tokenizer.apply_chat_template(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tokenize=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          add_generation_prompt=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          return_tensors=&quot;pt&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ).to(self.model.device)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      generation_kwargs = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &quot;input_ids&quot;: inputs,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &quot;do_sample&quot;: True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &quot;max_new_tokens&quot;: max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &quot;temperature&quot;: temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &quot;top_p&quot;: top_p,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &quot;eos_token_id&quot;: self.tokenizer.eos_token_id,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &quot;streamer&quot;: self.streamer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      thread = Thread(target=self.model.generate, kwargs=generation_kwargs)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      thread.start()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Accumulate response text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      for chunk in openai_response(self.streamer):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          yield chunk</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      thread.join()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def test(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Test the model here.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      print(&quot;Testing predict...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Test predict</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      print(self.predict(prompt=&quot;What is the capital of India?&quot;,))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      print(&quot;Error in predict&quot;, e)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      print(&quot;Testing generate...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Test generate</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      for each in self.generate(prompt=&quot;What is the capital of India?&quot;,):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(each, end=&quot;&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      print()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      print(&quot;Error in generate&quot;, e)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      print(&quot;Testing chat...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      messages = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are an helpful assistant.&quot;},</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is the capital of India?&quot;},</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      for each in self.chat(messages=messages,):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(each, end=&quot;&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      print()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      print(&quot;Error in generate&quot;, e)</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch==2.5.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">tokenizers&gt;=0.21.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers&gt;=4.47.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">accelerate&gt;=1.2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scipy==1.10.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">optimum&gt;=1.23.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">protobuf==5.27.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">einops&gt;=0.8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">requests==2.32.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai&gt;=11.4.1</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: &quot;Llama-3_2-1B-Instruct&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: &quot;user_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: &quot;app_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: &quot;text-to-text&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &quot;3.11&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &quot;1&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: &quot;13Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type: [&quot;NVIDIA-*&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: &quot;44Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: &quot;huggingface&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: &quot;unsloth/Llama-3.2-1B-Instruct&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  hf_token: &quot;hf_token&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  when: &quot;runtime&quot;</span><br></span></code></pre></div></div></div></div></details>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="llama-32-3b-instruct-lmdeploy">LLaMA 3.2 3B Instruct (LMDeploy)<a href="#llama-32-3b-instruct-lmdeploy" class="hash-link" aria-label="Direct link to LLaMA 3.2 3B Instruct (LMDeploy)" title="Direct link to LLaMA 3.2 3B Instruct (LMDeploy)" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import sys</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Iterator, List</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.openai_class import OpenAIModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.openai_convertor import build_openai_messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from openai import OpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PYTHON_EXEC = sys.executable</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def lmdeploy_openai_server(checkpoints, **kwargs):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Start lmdeploy OpenAI compatible server.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    from clarifai.runners.utils.model_utils import execute_shell_command, wait_for_server, terminate_process</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Start building the command</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cmds = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        PYTHON_EXEC, &#x27;-m&#x27;, &#x27;lmdeploy&#x27;, &#x27;serve&#x27;, &#x27;api_server&#x27;, checkpoints,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Add all parameters from kwargs to the command</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for key, value in kwargs.items():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if value is None:  # Skip None values</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            continue</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        param_name = key.replace(&#x27;_&#x27;, &#x27;-&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if isinstance(value, bool):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if value:  # Only add the flag if True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                cmds.append(f&#x27;--{param_name}&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cmds.extend([f&#x27;--{param_name}&#x27;, str(value)])</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Create server instance</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    server = type(&#x27;Server&#x27;, (), {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;host&#x27;: kwargs.get(&#x27;server_name&#x27;, &#x27;0.0.0.0&#x27;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;port&#x27;: kwargs.get(&#x27;server_port&#x27;, 23333),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;backend&#x27;: &quot;lmdeploy&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;process&#x27;: None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    })()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        server.process = execute_shell_command(&quot; &quot;.join(cmds))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Waiting for &quot; + f&quot;http://{server.host}:{server.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        wait_for_server(f&quot;http://{server.host}:{server.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Server started successfully at &quot; + f&quot;http://{server.host}:{server.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.error(f&quot;Failed to start lmdeploy server: {str(e)}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if server.process:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            terminate_process(server.process)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        raise RuntimeError(f&quot;Failed to start lmdeploy server: {str(e)}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class LMDeployModel(OpenAIModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    A custom runner that integrates with the Clarifai platform and uses lmdeploy framework for inference</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    client = True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model = True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Load the model here and start the  server.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # server args were generated by `upload` module</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        server_args = {&#x27;backend&#x27;: &#x27;turbomind&#x27;, &#x27;cache_max_entry_count&#x27;: 0.95, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                      &#x27;tp&#x27;: 1, &#x27;max_prefill_token_num&#x27;: 8192, &#x27;dtype&#x27;: &#x27;auto&#x27;, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                      &#x27;model_format&#x27;: None, &#x27;quant_policy&#x27;: 0, &#x27;chat_template&#x27;: &#x27;llama3_2&#x27;, &#x27;max_batch_size&#x27;: 16, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                      &#x27;device&#x27;: &#x27;cuda&#x27;, &#x27;server_name&#x27;: &#x27;0.0.0.0&#x27;, &#x27;server_port&#x27;: 23333, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                      &#x27;tool_call_parser&#x27;: &#x27;llama3&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                      }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        builder = ModelBuilder(model_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model_config = builder.config</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        stage = model_config[&quot;checkpoints&quot;][&#x27;when&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpoints = builder.config[&quot;checkpoints&quot;][&#x27;repo_id&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if stage in [&quot;build&quot;, &quot;runtime&quot;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          checkpoints = builder.download_checkpoints(stage=stage)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Start server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.server = lmdeploy_openai_server(checkpoints, **server_args)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Create client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.client = OpenAI(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                api_key=&quot;notset&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                base_url= f&quot;http://{self.server.host}:{self.server.port}/v1&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model = self.client.models.list().data[0].id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def predict(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                tools: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                tool_choice: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                top_p: float = Param(default=0.95, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;), </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                ) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      This method is used to predict the response for the given prompt and chat history using the model and tools.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if tools is not None and tool_choice is None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tool_choice = &quot;auto&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      messages = build_openai_messages(prompt=prompt, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      response = self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tools=tools,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tool_choice=tool_choice,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          top_p=top_p)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if response.choices[0] and response.choices[0].message.tool_calls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # If the response contains tool calls, return as a string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_calls = response.choices[0].message.tool_calls</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_calls_json = json.dumps([tc.to_dict() for tc in tool_calls], indent=2)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return tool_calls_json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Otherwise, return the content of the first choice</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return response.choices[0].message.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def generate(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                tools: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                tool_choice: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                top_p: float = Param(default=0.95, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;)) -&gt; Iterator[str]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      This method is used to stream generated text tokens from a prompt + optional chat history and tools.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      messages = build_openai_messages(prompt=prompt, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      response = self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tools=tools,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tool_choice=tool_choice,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          top_p=top_p,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          stream=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      for chunk in response:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if chunk.choices:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          if chunk.choices[0].delta.tool_calls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # If the response contains tool calls, return the first one as a string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tool_calls = chunk.choices[0].delta.tool_calls</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tool_calls_json = [tc.to_dict() for tc in tool_calls]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Convert to JSON string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            json_string = json.dumps(tool_calls_json, indent=2)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Yield the JSON string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            yield json_string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Otherwise, return the content of the first choice</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            text = (chunk.choices[0].delta.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    if (chunk and chunk.choices[0].delta.content) is not None else &#x27;&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            yield text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # This method is needed to test the model with the test-locally CLI command.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def test(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Test the model here.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Testing predict...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Test predict</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(self.predict(prompt=&quot;Hello, how are you?&quot;,))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Error in predict&quot;, e)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Testing generate...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Test generate</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for each in self.generate(prompt=&quot;Hello, how are you?&quot;,):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                print(each, end=&quot; &quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Error in generate&quot;, e)</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">tokenizers&gt;=0.21.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">accelerate&gt;=1.2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">optimum&gt;=1.23.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">einops&gt;=0.8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">packaging</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ninja</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">timm</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">openai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai-protocol</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">psutil</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch==2.6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">lmdeploy==0.8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers&gt;=4.51.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">partial-json-parser</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: Llama-3_2-3B-Instruct</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: text-to-text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.11&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &#x27;1&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 6Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  - NVIDIA-*</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: 20Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">num_threads: 64</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: huggingface</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: meta-llama/Llama-3.2-3B-Instruct</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  hf_token: </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  when: runtime</span><br></span></code></pre></div></div></div></div></details>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="gemma-3-1b-instruct-vllm">Gemma 3 1B Instruct (vLLM)<a href="#gemma-3-1b-instruct-vllm" class="hash-link" aria-label="Direct link to Gemma 3 1B Instruct (vLLM)" title="Direct link to Gemma 3 1B Instruct (vLLM)" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import sys</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import List, Iterator</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.openai_class import OpenAIModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from openai import OpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.openai_convertor import build_openai_messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PYTHON_EXEC = sys.executable</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def vllm_openai_server(checkpoints, **kwargs):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Start vLLM OpenAI compatible server.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    from clarifai.runners.utils.model_utils import execute_shell_command, wait_for_server, terminate_process</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Start building the command</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cmds = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        PYTHON_EXEC, &#x27;-m&#x27;, &#x27;vllm.entrypoints.openai.api_server&#x27;, &#x27;--model&#x27;, checkpoints,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Add all parameters from kwargs to the command</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for key, value in kwargs.items():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if value is None:  # Skip None values</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            continue</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        param_name = key.replace(&#x27;_&#x27;, &#x27;-&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if isinstance(value, bool):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if value:  # Only add the flag if True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                cmds.append(f&#x27;--{param_name}&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cmds.extend([f&#x27;--{param_name}&#x27;, str(value)])</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Create server instance</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    server = type(&#x27;Server&#x27;, (), {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;host&#x27;: kwargs.get(&#x27;host&#x27;, &#x27;0.0.0.0&#x27;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;port&#x27;: kwargs.get(&#x27;port&#x27;, 23333),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;backend&#x27;: &quot;vllm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;process&#x27;: None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    })()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        server.process = execute_shell_command(&quot; &quot;.join(cmds))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Waiting for &quot; + f&quot;http://{server.host}:{server.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        wait_for_server(f&quot;http://{server.host}:{server.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Server started successfully at &quot; + f&quot;http://{server.host}:{server.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.error(f&quot;Failed to start vllm server: {str(e)}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if server.process:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            terminate_process(server.process)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        raise RuntimeError(f&quot;Failed to start vllm server: {str(e)}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class VLLMLlamaModel(OpenAIModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  A Model that integrates with the Clarifai platform and uses vLLM framework for inference to run the Llama 3.1 8B model with tool calling capabilities.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  client = True  # This will be set in load_model method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model = True  # This will be set in load_model method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Load the model here and start the  server.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    os.path.join(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # This is the path to the chat template file and you can get this chat template from vLLM repo(https://github.com/vllm-project/vllm/blob/main/examples/tool_chat_template_llama3.1_json.jinja)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    server_args = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;max_model_len&#x27;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        #&#x27;gpu_memory_utilization&#x27;: 0.8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;dtype&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;task&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;kv_cache_dtype&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;tensor_parallel_size&#x27;: 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;quantization&#x27;: None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;cpu_offload_gb&#x27;: 5.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;chat_template&#x27;: None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;port&#x27;: 23333,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;host&#x27;: &#x27;localhost&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    builder = ModelBuilder(model_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model_config = builder.config</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    stage = model_config[&quot;checkpoints&quot;][&#x27;when&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    checkpoints = builder.config[&quot;checkpoints&quot;][&#x27;repo_id&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if stage in [&quot;build&quot;, &quot;runtime&quot;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      checkpoints = builder.download_checkpoints(stage=stage)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Start server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.server = vllm_openai_server(checkpoints, **server_args)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # CLIent initialization</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.client = OpenAI(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            api_key=&quot;notset&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            base_url=f&#x27;http://{self.server.host}:{self.server.port}/v1&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.model = self.client.models.list().data[0].id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def predict(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              tools: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              tool_choice: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              top_p: float = Param(default=0.95, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;), </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              ) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    This method is used to predict the response for the given prompt and chat history using the model and tools.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if tools is not None and tool_choice is None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_choice = &quot;auto&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages = build_openai_messages(prompt=prompt, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    response = self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools=tools,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_choice=tool_choice,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        top_p=top_p)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if response.choices[0] and response.choices[0].message.tool_calls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      import json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # If the response contains tool calls, return as a string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      tool_calls = response.choices[0].message.tool_calls</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      tool_calls_json = json.dumps([tc.to_dict() for tc in tool_calls], indent=2)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      return tool_calls_json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Otherwise, return the content of the first choice</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      return response.choices[0].message.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def generate(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               tools: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               tool_choice: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               top_p: float = Param(default=0.95, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;)) -&gt; Iterator[str]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    This method is used to stream generated text tokens from a prompt + optional chat history and tools.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages = build_openai_messages(prompt=prompt, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    response = self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools=tools,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_choice=tool_choice,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        top_p=top_p,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        stream=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for chunk in response:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if chunk.choices:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if chunk.choices[0].delta.tool_calls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          # If the response contains tool calls, return the first one as a string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          import json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tool_calls = chunk.choices[0].delta.tool_calls</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tool_calls_json = [tc.to_dict() for tc in tool_calls]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          # Convert to JSON string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          json_string = json.dumps(tool_calls_json, indent=2)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          # Yield the JSON string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          yield json_string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          # Otherwise, return the content of the first choice</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          text = (chunk.choices[0].delta.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  if (chunk and chunk.choices[0].delta.content) is not None else &#x27;&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          yield text</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">tokenizers==0.21.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">accelerate==1.2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">optimum==1.23.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># xformers</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">einops==0.8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">packaging</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ninja</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">qwen-vl-utils==0.0.8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">timm</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">openai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">psutil</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch==2.6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vllm==0.8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers==4.50.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">backoff==2.2.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">peft&gt;=0.13.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">soundfile&gt;=0.13.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scipy==1.15.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">librosa</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">decord</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.12&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  hf_token: &quot;&lt;your_hf_token&gt;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: google/gemma-3-1b-it</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: huggingface</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  when: runtime</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: 5Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  - NVIDIA-*</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &#x27;1&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 5Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: APP_ID</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: MODEL_ID</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: text-to-text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: USER_ID</span><br></span></code></pre></div></div></div></div></details>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="llama-31-8b-tool-calling-vllm">LLaMA 3.1 8B Tool Calling (vLLM)<a href="#llama-31-8b-tool-calling-vllm" class="hash-link" aria-label="Direct link to LLaMA 3.1 8B Tool Calling (vLLM)" title="Direct link to LLaMA 3.1 8B Tool Calling (vLLM)" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import sys</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import List, Iterator</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.openai_class import OpenAIModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from openai import OpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.openai_convertor import build_openai_messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PYTHON_EXEC = sys.executable</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def vllm_openai_server(checkpoints, **kwargs):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Start vLLM OpenAI compatible server.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    from clarifai.runners.utils.model_utils import execute_shell_command, wait_for_server, terminate_process</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Start building the command</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cmds = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        PYTHON_EXEC, &#x27;-m&#x27;, &#x27;vllm.entrypoints.openai.api_server&#x27;, &#x27;--model&#x27;, checkpoints,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Add all parameters from kwargs to the command</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for key, value in kwargs.items():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if value is None:  # Skip None values</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            continue</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        param_name = key.replace(&#x27;_&#x27;, &#x27;-&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if isinstance(value, bool):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if value:  # Only add the flag if True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                cmds.append(f&#x27;--{param_name}&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cmds.extend([f&#x27;--{param_name}&#x27;, str(value)])</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Create server instance</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    server = type(&#x27;Server&#x27;, (), {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;host&#x27;: kwargs.get(&#x27;host&#x27;, &#x27;0.0.0.0&#x27;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;port&#x27;: kwargs.get(&#x27;port&#x27;, 23333),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;backend&#x27;: &quot;vllm&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;process&#x27;: None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    })()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        server.process = execute_shell_command(&quot; &quot;.join(cmds))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Waiting for &quot; + f&quot;http://{server.host}:{server.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        wait_for_server(f&quot;http://{server.host}:{server.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Server started successfully at &quot; + f&quot;http://{server.host}:{server.port}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.error(f&quot;Failed to start vllm server: {str(e)}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if server.process:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            terminate_process(server.process)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        raise RuntimeError(f&quot;Failed to start vllm server: {str(e)}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class VLLMLlamaModel(OpenAIModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  A Model that integrates with the Clarifai platform and uses vLLM framework for inference to run the Llama 3.1 8B model with tool calling capabilities.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  client = True  # This will be set in load_model method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model = True  # This will be set in load_model method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Load the model here and start the  server.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    os.path.join(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # This is the path to the chat template file and you can get this chat template from vLLM repo(https://github.com/vllm-project/vllm/blob/main/examples/tool_chat_template_llama3.1_json.jinja)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    chat_template = &#x27;examples/tool_chat_template_llama3.1_json.jinja&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    server_args = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;max_model_len&#x27;: 2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;gpu_memory_utilization&#x27;: 0.8,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;dtype&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;task&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;kv_cache_dtype&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;tensor_parallel_size&#x27;: 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;quantization&#x27;: None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;chat_template&#x27;: chat_template,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;cpu_offload_gb&#x27;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;port&#x27;: 23333,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;host&#x27;: &#x27;localhost&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;enable_auto_tool_choice&quot;: True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &#x27;tool_call_parser&#x27;: &quot;llama3_json&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    builder = ModelBuilder(model_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model_config = builder.config</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    stage = model_config[&quot;checkpoints&quot;][&#x27;when&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    checkpoints = builder.config[&quot;checkpoints&quot;][&#x27;repo_id&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if stage in [&quot;build&quot;, &quot;runtime&quot;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      checkpoints = builder.download_checkpoints(stage=stage)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Start server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.server = vllm_openai_server(checkpoints, **server_args)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # CLIent initialization</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.client = OpenAI(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            api_key=&quot;notset&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            base_url=f&#x27;http://{self.server.host}:{self.server.port}/v1&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.model = self.client.models.list().data[0].id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def predict(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              tools: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              tool_choice: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              top_p: float = Param(default=0.95, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;), </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              ) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    This method is used to predict the response for the given prompt and chat history using the model and tools.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if tools is not None and tool_choice is None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_choice = &quot;auto&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages = build_openai_messages(prompt=prompt, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    response = self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools=tools,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_choice=tool_choice,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        top_p=top_p)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if response.choices[0] and response.choices[0].message.tool_calls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      import json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # If the response contains tool calls, return as a string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      tool_calls = response.choices[0].message.tool_calls</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      tool_calls_json = json.dumps([tc.to_dict() for tc in tool_calls], indent=2)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      return tool_calls_json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Otherwise, return the content of the first choice</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      return response.choices[0].message.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def generate(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               tools: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               tool_choice: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               top_p: float = Param(default=0.95, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;)) -&gt; Iterator[str]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    This method is used to stream generated text tokens from a prompt + optional chat history and tools.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages = build_openai_messages(prompt=prompt, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    response = self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools=tools,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_choice=tool_choice,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        top_p=top_p,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        stream=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for chunk in response:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if chunk.choices:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if chunk.choices[0].delta.tool_calls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          # If the response contains tool calls, return the first one as a string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          import json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tool_calls = chunk.choices[0].delta.tool_calls</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          tool_calls_json = [tc.to_dict() for tc in tool_calls]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          # Convert to JSON string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          json_string = json.dumps(tool_calls_json, indent=2)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          # Yield the JSON string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          yield json_string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          # Otherwise, return the content of the first choice</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          text = (chunk.choices[0].delta.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                  if (chunk and chunk.choices[0].delta.content) is not None else &#x27;&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          yield text</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">tokenizers==0.21.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">accelerate==1.2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">optimum==1.23.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># xformers</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">einops==0.8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">packaging</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ninja</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">qwen-vl-utils==0.0.8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">timm</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">openai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">psutil</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch==2.6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vllm==0.8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers==4.50.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">backoff==2.2.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">peft&gt;=0.13.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">soundfile&gt;=0.13.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scipy==1.15.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">librosa</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">decord</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: &quot;llama-3_1-8B-instruct-tool-calling&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: &quot;user_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: &quot;app_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: &quot;text-to-text&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.12&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &#x27;1&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 12Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type: [&quot;NVIDIA-*&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: 44Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: huggingface</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: meta-llama/Llama-3.1-8B-Instruct</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  hf_token: &quot;hf_token&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  when: runtime</span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="local-runners">Local Runners<a href="#local-runners" class="hash-link" aria-label="Direct link to Local Runners" title="Direct link to Local Runners" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="ollama">Ollama<a href="#ollama" class="hash-link" aria-label="Direct link to Ollama" title="Direct link to Ollama" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Iterator, List</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.openai_class import OpenAIModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_types import Image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.openai_convertor import build_openai_messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from openai import OpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Set default host</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">if not os.environ.get(&#x27;OLLAMA_HOST&#x27;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    os.environ[&quot;OLLAMA_HOST&quot;] = &#x27;127.0.0.1:23333&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">OLLAMA_HOST = os.environ.get(&#x27;OLLAMA_HOST&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">if not os.environ.get(&#x27;OLLAMA_CONTEXT_LENGTH&#x27;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Set default context length if not set</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    os.environ[&quot;OLLAMA_CONTEXT_LENGTH&quot;] = &#x27;8192&#x27;  # Default context length for Llama 3.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">OLLAMA_CONTEXT_LENGTH = os.environ.get(&#x27;OLLAMA_CONTEXT_LENGTH&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def run_ollama_server(model_name: str = &#x27;llama3.2&#x27;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    start the Ollama server.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    from clarifai.runners.utils.model_utils import execute_shell_command, terminate_process</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;Starting Ollama server in the host: {OLLAMA_HOST}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        start_process = execute_shell_command(&quot;ollama serve&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if start_process:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            pull_model = execute_shell_command(f&quot;ollama pull {model_name}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logger.info(f&quot;Model {model_name} pulled successfully.&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logger.info(f&quot;Ollama server started successfully on {OLLAMA_HOST}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.error(f&quot;Error starting Ollama server: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if &#x27;start_process&#x27; in locals():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            terminate_process(start_process)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        raise RuntimeError(f&quot;Failed to start Ollama server: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Check if Image has content before building messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def has_image_content(image: Image) -&gt; bool:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Check if Image object has either bytes or URL.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return bool(getattr(image, &#x27;url&#x27;, None) or getattr(image, &#x27;bytes&#x27;, None))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class OllamaModelClass(OpenAIModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    client = True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model = True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Load the Ollama model.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # set the model name here or via OLLAMA_MODEL_NAME</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model = os.environ.get(&quot;OLLAMA_MODEL_NAME&quot;, &#x27;llama3.2&#x27;)  #&#x27;devstral:latest&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # start ollama server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        run_ollama_server(model_name=self.model)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.client = OpenAI(api_key=&quot;notset&quot;, base_url=f&quot;http://{OLLAMA_HOST}/v1&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;Ollama model loaded successfully: {self.model}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def predict(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        image: Image = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        images: List[Image] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_choice: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_tokens: int = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        temperature: float = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=0.7,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;A decimal number that determines the degree of randomness in the response&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        top_p: float = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=0.95,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        This method is used to predict the response for the given prompt and chat history using the model and tools.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if tools is not None and tool_choice is None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tool_choice = &quot;auto&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        img_content = image if has_image_content(image) else None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        messages = build_openai_messages(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            prompt=prompt, image=img_content, images=images, messages=chat_history</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        response = self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tools=tools,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tool_choice=tool_choice,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            top_p=top_p,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if response.usage is not None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self.set_output_context(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                prompt_tokens=response.usage.prompt_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                completion_tokens=response.usage.completion_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if len(response.choices) == 0:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                # still need to send the usage back.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                return &quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if response.choices[0] and response.choices[0].message.tool_calls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # If the response contains tool calls, return as a string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tool_calls = response.choices[0].message.tool_calls</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tool_calls_json = json.dumps([tc.to_dict() for tc in tool_calls], indent=2)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return tool_calls_json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Otherwise, return the content of the first choice</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return response.choices[0].message.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def generate(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        image: Image = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        images: List[Image] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_choice: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_tokens: int = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=2048,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        temperature: float = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=0.7,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;A decimal number that determines the degree of randomness in the response&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        top_p: float = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=0.95,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ) -&gt; Iterator[str]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        This method is used to stream generated text tokens from a prompt + optional chat history and tools.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if tools is not None and tool_choice is None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tool_choice = &quot;auto&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        img_content = image if has_image_content(image) else None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        messages = build_openai_messages(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            prompt=prompt, image=img_content, images=images, messages=chat_history</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for chunk in self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tools=tools,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tool_choice=tool_choice,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            top_p=top_p,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            stream=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            stream_options={&quot;include_usage&quot;: True},</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if chunk.usage is not None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if chunk.usage.prompt_tokens or chunk.usage.completion_tokens:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    self.set_output_context(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        prompt_tokens=chunk.usage.prompt_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        completion_tokens=chunk.usage.completion_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if len(chunk.choices) == 0:  # still need to send the usage back.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    yield &quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if chunk.choices:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if chunk.choices[0].delta.tool_calls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    # If the response contains tool calls, return the first one as a string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    import json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    tool_calls = chunk.choices[0].delta.tool_calls</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    tool_calls_json = [tc.to_dict() for tc in tool_calls]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    # Convert to JSON string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    json_string = json.dumps(tool_calls_json, indent=2)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    # Yield the JSON string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    yield json_string</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    # Otherwise, return the content of the first choice</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    text = (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        chunk.choices[0].delta.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        if (chunk and chunk.choices[0].delta.content) is not None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        else &#x27;&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    yield text</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">ollama</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">openai</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: local-dev-runner-app</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: local-dev-model</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: text-to-text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: clarifai-user-id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.12&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &#x27;3&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 14Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 0</span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="mcp">MCP<a href="#mcp" class="hash-link" aria-label="Direct link to MCP" title="Direct link to MCP" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="browser-tools">Browser Tools<a href="#browser-tools" class="hash-link" aria-label="Direct link to Browser Tools" title="Direct link to Browser Tools" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Annotated</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from urllib.parse import urljoin, urlparse</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import FastMCP  # use fastmcp v2 not the built in mcp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from pydantic import Field</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">server = FastMCP(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;browser-tools-mcp-server&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    instructions=&quot;Web browsing, scraping, and search tools for gathering information from the internet&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    stateless_http=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def make_http_request(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url: str, method: str = &quot;GET&quot;, headers: dict = None, timeout: int = 30</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; tuple[bool, dict]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Make an HTTP request with proper error handling.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    import requests</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    from requests.adapters import HTTPAdapter</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    from urllib3.util.retry import Retry</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Setup session with retries</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        session = requests.Session()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        retry_strategy = Retry(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            total=3,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            backoff_factor=1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            status_forcelist=[429, 500, 502, 503, 504],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        adapter = HTTPAdapter(max_retries=retry_strategy)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        session.mount(&quot;http://&quot;, adapter)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        session.mount(&quot;https://&quot;, adapter)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Default headers</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        default_headers = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if headers:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default_headers.update(headers)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        response = session.request(method, url, headers=default_headers, timeout=timeout)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return True, {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;status_code&quot;: response.status_code,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;headers&quot;: dict(response.headers),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;text&quot;: response.text,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;url&quot;: response.url,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return False, {&quot;error&quot;: str(e)}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;fetch_webpage&quot;, description=&quot;Fetch and return the content of a webpage&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def fetch_webpage(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url: Annotated[str, Field(description=&quot;URL of the webpage to fetch&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    include_headers: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        bool, Field(description=&quot;Include HTTP headers in response&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = False,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    max_length: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        int, Field(description=&quot;Maximum content length to return&quot;, ge=100, le=50000)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = 10000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Fetch the content of a webpage and return the text.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    success, response = make_http_request(url)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not success:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Error fetching webpage: {response.get(&#x27;error&#x27;, &#x27;Unknown error&#x27;)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    content = response.get(&#x27;text&#x27;, &#x27;&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Truncate if too long</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if len(content) &gt; max_length:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        content = (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            content[:max_length]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            + f&quot;\n\n... (content truncated, showing first {max_length} characters)&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result = f&quot;URL: {response.get(&#x27;url&#x27;, url)}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result += f&quot;Status Code: {response.get(&#x27;status_code&#x27;)}\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if include_headers:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        headers = response.get(&#x27;headers&#x27;, {})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result += &quot;Headers:\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for key, value in headers.items():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result += f&quot;  {key}: {value}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result += &quot;\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result += &quot;Content:\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result += content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return result</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;extract_text&quot;, description=&quot;Extract clean text from HTML content&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def extract_text(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url: Annotated[str, Field(description=&quot;URL of the webpage&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    remove_scripts: Annotated[bool, Field(description=&quot;Remove script and style tags&quot;)] = True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    max_length: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        int, Field(description=&quot;Maximum text length to return&quot;, ge=100, le=50000)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = 5000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Extract clean text from a webpage by removing HTML tags.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    success, response = make_http_request(url)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not success:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Error fetching webpage: {response.get(&#x27;error&#x27;, &#x27;Unknown error&#x27;)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        from bs4 import BeautifulSoup</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        soup = BeautifulSoup(response.get(&#x27;text&#x27;, &#x27;&#x27;), &#x27;html.parser&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Remove script and style elements if requested</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if remove_scripts:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for script in soup([&quot;script&quot;, &quot;style&quot;]):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                script.decompose()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Extract text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        text = soup.get_text()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Clean up whitespace</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        lines = (line.strip() for line in text.splitlines())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        chunks = (phrase.strip() for line in lines for phrase in line.split(&quot;  &quot;))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        text = &#x27; &#x27;.join(chunk for chunk in chunks if chunk)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Truncate if too long</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if len(text) &gt; max_length:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            text = (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                text[:max_length]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                + f&quot;\n\n... (text truncated, showing first {max_length} characters)&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;URL: {response.get(&#x27;url&#x27;, url)}\nExtracted Text:\n\n{text}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except ImportError:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return &quot;Error: BeautifulSoup4 not available for HTML parsing&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Error extracting text: {str(e)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;search_google&quot;, description=&quot;Search Google and return results&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def search_google(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    query: Annotated[str, Field(description=&quot;Search query&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    num_results: Annotated[int, Field(description=&quot;Number of results to return&quot;, ge=1, le=20)] = 5,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    safe_search: Annotated[bool, Field(description=&quot;Enable safe search&quot;)] = True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Search Google and return search results. Note: This is a mock implementation.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # This is a simplified mock implementation</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # In production, you&#x27;d use Google Custom Search API or similar service</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Mock search results based on common queries</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    mock_results = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;python&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;title&quot;: &quot;Welcome to Python.org&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;url&quot;: &quot;https://www.python.org/&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;snippet&quot;: &quot;The official home of the Python Programming Language&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;title&quot;: &quot;Python Tutorial&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;url&quot;: &quot;https://docs.python.org/3/tutorial/&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;snippet&quot;: &quot;Python is an easy to learn, powerful programming language&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;title&quot;: &quot;Learn Python&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;url&quot;: &quot;https://www.learnpython.org/&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;snippet&quot;: &quot;Learn Python programming with interactive tutorials&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;machine learning&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;title&quot;: &quot;Machine Learning | Coursera&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;url&quot;: &quot;https://www.coursera.org/learn/machine-learning&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;snippet&quot;: &quot;Learn Machine Learning online with courses from top universities&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;title&quot;: &quot;Machine Learning - Wikipedia&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;url&quot;: &quot;https://en.wikipedia.org/wiki/Machine_learning&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;snippet&quot;: &quot;Machine learning is a method of data analysis that automates analytical model building&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;title&quot;: &quot;Introduction to Machine Learning&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;url&quot;: &quot;https://scikit-learn.org/&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;snippet&quot;: &quot;Simple and efficient tools for predictive data analysis&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Find relevant results</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    results = []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    query_lower = query.lower()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for key, search_results in mock_results.items():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if any(word in query_lower for word in key.split()):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            results.extend(search_results)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not results:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Generic results for unknown queries</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        results = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;title&quot;: f&quot;Search results for: {query}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;url&quot;: &quot;https://www.google.com/search?q=&quot; + query.replace(&quot; &quot;, &quot;+&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;snippet&quot;: f&quot;Various results related to {query}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;title&quot;: f&quot;Wikipedia: {query}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;url&quot;: f&quot;https://en.wikipedia.org/wiki/{query.replace(&#x27; &#x27;, &#x27;_&#x27;)}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;snippet&quot;: f&quot;Wikipedia article about {query}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Limit results</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    results = results[:num_results]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Format output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    output = f&quot;Google Search Results for &#x27;{query}&#x27;:\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for i, result in enumerate(results, 1):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        output += f&quot;{i}. {result[&#x27;title&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        output += f&quot;   URL: {result[&#x27;url&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        output += f&quot;   {result[&#x27;snippet&#x27;]}\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;extract_links&quot;, description=&quot;Extract all links from a webpage&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def extract_links(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url: Annotated[str, Field(description=&quot;URL of the webpage&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    filter_domain: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        bool, Field(description=&quot;Only return links from the same domain&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = False,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    max_links: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        int, Field(description=&quot;Maximum number of links to return&quot;, ge=1, le=100)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = 20,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Extract all links from a webpage.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    success, response = make_http_request(url)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not success:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Error fetching webpage: {response.get(&#x27;error&#x27;, &#x27;Unknown error&#x27;)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        from bs4 import BeautifulSoup</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        soup = BeautifulSoup(response.get(&#x27;text&#x27;, &#x27;&#x27;), &#x27;html.parser&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Find all links</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        links = []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        base_domain = urlparse(url).netloc</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for link in soup.find_all(&#x27;a&#x27;, href=True):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            href = link[&#x27;href&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            text = link.get_text(strip=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Convert relative URLs to absolute</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if href.startswith(&#x27;/&#x27;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                href = urljoin(url, href)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            elif not href.startswith((&#x27;http://&#x27;, &#x27;https://&#x27;)):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                href = urljoin(url, href)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Filter by domain if requested</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if filter_domain:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                link_domain = urlparse(href).netloc</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if link_domain != base_domain:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    continue</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            links.append({&quot;url&quot;: href, &quot;text&quot;: text or &quot;No text&quot;})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Remove duplicates and limit</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        unique_links = []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        seen_urls = set()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for link in links:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if link[&quot;url&quot;] not in seen_urls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                unique_links.append(link)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                seen_urls.add(link[&quot;url&quot;])</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if len(unique_links) &gt;= max_links:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    break</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Format output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        output = f&quot;Links extracted from {url} ({len(unique_links)} unique links):\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for i, link in enumerate(unique_links, 1):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;{i}. {link[&#x27;text&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;   URL: {link[&#x27;url&#x27;]}\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except ImportError:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return &quot;Error: BeautifulSoup4 not available for HTML parsing&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Error extracting links: {str(e)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;take_screenshot&quot;, description=&quot;Take a screenshot of a webpage&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def take_screenshot(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url: Annotated[str, Field(description=&quot;URL of the webpage&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    width: Annotated[int, Field(description=&quot;Screenshot width&quot;, ge=100, le=3840)] = 1280,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    height: Annotated[int, Field(description=&quot;Screenshot height&quot;, ge=100, le=2160)] = 720,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    full_page: Annotated[bool, Field(description=&quot;Capture full page&quot;)] = False,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Take a screenshot of a webpage using headless browser (mock implementation).&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # This is a mock implementation</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # In production, you&#x27;d use Selenium, Playwright, or similar</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Mock screenshot functionality</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        screenshot_path = f&quot;/tmp/screenshot_{url.replace(&#x27;://&#x27;, &#x27;_&#x27;).replace(&#x27;/&#x27;, &#x27;_&#x27;)}.png&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Simulate screenshot creation</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;Screenshot would be saved to: {screenshot_path}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;URL: {url}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;Dimensions: {width}x{height}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;Full page: {full_page}\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;Note: This is a mock implementation. In production, this would use:\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;- Selenium WebDriver\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;- Playwright\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;- Puppeteer\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;- Or similar headless browser automation tools&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Error taking screenshot: {str(e)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;check_website_status&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    description=&quot;Check if a website is accessible and get status information&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def check_website_status(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url: Annotated[str, Field(description=&quot;URL to check&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    check_ssl: Annotated[bool, Field(description=&quot;Check SSL certificate validity&quot;)] = True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Check website accessibility and status.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    success, response = make_http_request(url, timeout=10)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not success:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Website is not accessible: {response.get(&#x27;error&#x27;, &#x27;Unknown error&#x27;)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    status_code = response.get(&#x27;status_code&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    headers = response.get(&#x27;headers&#x27;, {})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result = f&quot;Website Status for {url}:\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result += f&quot;Status Code: {status_code}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result += f&quot;Status: {&#x27;✓ Accessible&#x27; if 200 &lt;= status_code &lt; 400 else &#x27;✗ Error&#x27;}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result += f&quot;Server: {headers.get(&#x27;server&#x27;, &#x27;Unknown&#x27;)}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result += f&quot;Content-Type: {headers.get(&#x27;content-type&#x27;, &#x27;Unknown&#x27;)}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result += f&quot;Content-Length: {headers.get(&#x27;content-length&#x27;, &#x27;Unknown&#x27;)}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result += f&quot;Last-Modified: {headers.get(&#x27;last-modified&#x27;, &#x27;Unknown&#x27;)}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if check_ssl and url.startswith(&#x27;https://&#x27;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result += &quot;\nSSL Status: ✓ HTTPS enabled&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return result</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;search_webpage_content&quot;, description=&quot;Search for specific content within a webpage&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def search_webpage_content(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url: Annotated[str, Field(description=&quot;URL of the webpage&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    search_term: Annotated[str, Field(description=&quot;Term to search for&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    case_sensitive: Annotated[bool, Field(description=&quot;Case sensitive search&quot;)] = False,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    max_matches: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        int, Field(description=&quot;Maximum number of matches to return&quot;, ge=1, le=50)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = 10,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Search for specific content within a webpage.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    success, response = make_http_request(url)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not success:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Error fetching webpage: {response.get(&#x27;error&#x27;, &#x27;Unknown error&#x27;)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        from bs4 import BeautifulSoup</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        soup = BeautifulSoup(response.get(&#x27;text&#x27;, &#x27;&#x27;), &#x27;html.parser&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        text = soup.get_text()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Perform search</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not case_sensitive:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            text = text.lower()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            search_term = search_term.lower()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        matches = []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        lines = text.split(&#x27;\n&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for line_num, line in enumerate(lines, 1):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if search_term in line:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                # Get context around the match</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                context_start = max(0, line.find(search_term) - 50)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                context_end = min(len(line), line.find(search_term) + len(search_term) + 50)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                context = line[context_start:context_end]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                matches.append(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    {&quot;line&quot;: line_num, &quot;context&quot;: context.strip(), &quot;full_line&quot;: line.strip()}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if len(matches) &gt;= max_matches:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    break</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not matches:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;No matches found for &#x27;{search_term}&#x27; in {url}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result = f&quot;Found {len(matches)} matches for &#x27;{search_term}&#x27; in {url}:\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for i, match in enumerate(matches, 1):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result += f&quot;{i}. Line {match[&#x27;line&#x27;]}: ...{match[&#x27;context&#x27;]}...\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return result</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except ImportError:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return &quot;Error: BeautifulSoup4 not available for HTML parsing&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Error searching content: {str(e)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Static resource</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.resource(&quot;config://browser_settings&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def get_browser_settings():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;default_timeout&quot;: 30,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;max_content_length&quot;: 10000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;supported_formats&quot;: [&quot;html&quot;, &quot;text&quot;, &quot;json&quot;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;user_agent&quot;: &quot;MCP-Browser-Tools/1.0&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;screenshot_formats&quot;: [&quot;png&quot;, &quot;jpg&quot;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Dynamic resource template</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.resource(&quot;site://{domain}/info&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def get_site_info(domain: str):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;domain&quot;: domain,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;note&quot;: &quot;Use check_website_status tool to get actual site information&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.prompt()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def web_research_prompt(research_type: str) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Generate prompts for web research tasks.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    prompts = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;content&quot;: &quot;To research web content:\n1. Use search_google to find relevant pages\n2. Use fetch_webpage to get page content\n3. Use extract_text for clean text extraction\n4. Use search_webpage_content to find specific information&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;links&quot;: &quot;To analyze website links:\n1. Use extract_links to get all links\n2. Filter by domain if needed\n3. Check link status with check_website_status&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;monitoring&quot;: &quot;To monitor websites:\n1. Use check_website_status for availability\n2. Use fetch_webpage to check content changes\n3. Use take_screenshot for visual monitoring&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return prompts.get(research_type, f&quot;Web research guidance for: {research_type}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.mcp_class import MCPModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class MyModelClass(MCPModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def get_server(self) -&gt; FastMCP:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return server</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>client.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import asyncio</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.urls.helper import ClarifaiUrlHelper</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import Client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp.client.transports import StreamableHttpTransport</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PAT = os.environ[&#x27;CLARIFAI_PAT&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">url = ClarifaiUrlHelper().mcp_api_url()  # get url from the current clarifai config</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">print(url)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transport = StreamableHttpTransport(url=url, headers={&quot;Authorization&quot;: &quot;Bearer &quot; + PAT})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def main():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;=== Browser Tools MCP Server Examples ===\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    async with Client(transport) as client:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # List available tools first</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;Available tools:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools = await client.list_tools()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for tool in tools:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;- {tool.name}: {tool.description}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 1: Fetch webpage content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;1. Fetching webpage content:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;fetch_webpage&quot;, {&quot;url&quot;: &quot;https://httpbin.org/get&quot;, &quot;max_length&quot;: 2000}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 2: Extract clean text from webpage</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;2. Extracting clean text:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;extract_text&quot;, {&quot;url&quot;: &quot;https://httpbin.org/html&quot;, &quot;max_length&quot;: 1000}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 3: Search Google (mock results)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;3. Searching Google (mock implementation):&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;search_google&quot;, {&quot;query&quot;: &quot;python programming&quot;, &quot;num_results&quot;: 3}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 4: Check website status</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;4. Checking website status:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;check_website_status&quot;, {&quot;url&quot;: &quot;https://httpbin.org&quot;, &quot;check_ssl&quot;: True}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 5: Extract links from webpage</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;5. Extracting links from webpage:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;extract_links&quot;, {&quot;url&quot;: &quot;https://httpbin.org&quot;, &quot;max_links&quot;: 5}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    asyncio.run(main())</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">anyio==4.9.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">mcp==1.9.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">fastmcp==2.3.4</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">requests&gt;=2.31.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">beautifulsoup4==4.12.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">lxml==4.9.3</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.11&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: 1000m</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 1Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: mcp-examples-app</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: browser-tools-mcp-server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: text-to-text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: mcp-examples-user</span><br></span></code></pre></div></div></div></div></details>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="code-execution">Code Execution<a href="#code-execution" class="hash-link" aria-label="Direct link to Code Execution" title="Direct link to Code Execution" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import io</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import tarfile</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Annotated, Any, Dict</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import docker</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.mcp_class import MCPModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import FastMCP</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from pydantic import Field</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">server = FastMCP(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;python-execution-server&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    instructions=&quot;Execute Python code securely in Docker containers&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    stateless_http=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">_docker_client = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def get_docker_client():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Get or create Docker client.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    global _docker_client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if _docker_client is None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            _docker_client = docker.from_env()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            _docker_client.ping()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Try alternative connection methods for different Docker setups</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                # TODO: replace base_url with your local machine&#x27;s docker socket </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                _docker_client = docker.DockerClient(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    base_url=&#x27;unix:///Users/YOUR_USER_NAME/.rd/docker.sock&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                _docker_client.ping()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            except:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    _docker_client = docker.DockerClient(base_url=&#x27;unix://var/run/docker.sock&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    _docker_client.ping()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                except:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    raise Exception(f&quot;Cannot connect to Docker daemon. Original error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return _docker_client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def execute_python_code_fresh_container(code: str) -&gt; Dict[str, Any]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Execute Python code in a fresh Docker container (OpenAI approach).</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Each execution gets a completely clean environment.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        client = get_docker_client()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Pull Python image if not present</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            client.images.get(&quot;python:3.11&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except docker.errors.ImageNotFound:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            client.images.pull(&quot;python:3.11&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Create a temporary tar archive containing the script (like OpenAI)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        script_name = &quot;script.py&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tarstream = io.BytesIO()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        with tarfile.open(fileobj=tarstream, mode=&quot;w&quot;) as tar:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            script_bytes = code.encode(&quot;utf-8&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tarinfo = tarfile.TarInfo(name=script_name)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tarinfo.size = len(script_bytes)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tar.addfile(tarinfo, io.BytesIO(script_bytes))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tarstream.seek(0)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Start fresh container</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        container = client.containers.create(&quot;python:3.11&quot;, command=&quot;sleep infinity&quot;, detach=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            container.start()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Put the script into the container</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            container.put_archive(path=&quot;/tmp&quot;, data=tarstream.read())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Execute the script</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            exec_result = container.exec_run(f&quot;python /tmp/{script_name}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;stdout&quot;: exec_result.output.decode(&quot;utf-8&quot;, errors=&#x27;replace&#x27;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;stderr&quot;: &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;status&quot;: exec_result.exit_code,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        finally:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Always clean up container</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            container.remove(force=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except docker.errors.ContainerError as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return {&quot;stdout&quot;: &quot;&quot;, &quot;stderr&quot;: str(e), &quot;status&quot;: 1}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return {&quot;stdout&quot;: &quot;&quot;, &quot;stderr&quot;: f&quot;Execution error: {str(e)}&quot;, &quot;status&quot;: 1}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def execute_with_packages(code: str, packages: list = None) -&gt; Dict[str, Any]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Execute Python code with pre-installed packages.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    This is the key enhancement over #1 - allows package installation.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if packages:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Prepend package installation to the code</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        install_code = &quot;\n&quot;.join(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;import subprocess; subprocess.run([&#x27;pip&#x27;, &#x27;install&#x27;, &#x27;{pkg}&#x27;], check=True)&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                for pkg in packages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        full_code = f&quot;{install_code}\n\n{code}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        full_code = code</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return execute_python_code_fresh_container(full_code)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;execute_with_packages&quot;, description=&quot;Execute Python code with packages pre-installed&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def execute_with_packages_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    code: Annotated[str, Field(description=&quot;Python code to execute&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    packages: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        list[str], Field(description=&quot;List of packages to install before execution&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Execute Python code with specified packages installed on top of the base Python image.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    This enables users to work with the full Python ecosystem.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Example: execute_with_packages(&quot;import requests; print(requests.get(&#x27;https://httpbin.org/json&#x27;).json())&quot;, [&quot;requests&quot;])</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not code.strip():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return &quot;Error: No code provided&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result = execute_with_packages(code, packages or [])</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if result[&quot;status&quot;] == 0:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        output = &quot;--- Execution Successful ---\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if packages:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;Packages installed: {&#x27;, &#x27;.join(packages)}\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if result[&quot;stdout&quot;].strip():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += result[&quot;stdout&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += &quot;(No output - use print() to see results)&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        output = f&quot;--- Execution Error (status: {result[&#x27;status&#x27;]}) ---\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if result[&quot;stderr&quot;].strip():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += result[&quot;stderr&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if result[&quot;stdout&quot;].strip():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += &quot;\n--- Output ---\n&quot; + result[&quot;stdout&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class MyModel(MCPModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def get_server(self) -&gt; FastMCP:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Return the FastMCP server instance.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return server</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>client.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import asyncio</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.urls.helper import ClarifaiUrlHelper</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import Client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp.client.transports import StreamableHttpTransport</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PAT = os.environ[&#x27;CLARIFAI_PAT&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">url = ClarifaiUrlHelper().mcp_api_url()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transport = StreamableHttpTransport(url=url, headers={&quot;Authorization&quot;: &quot;Bearer &quot; + PAT})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def main():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    async with Client(transport) as client:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # List available tools</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;=== Available Tools ===&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools = await client.list_tools()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for tool in tools:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;- {tool.name}: {tool.description}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Test 1: execute_with_packages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;=== Test 1: execute_with_packages ===&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        code_with_pkg = &#x27;import requests; print(f&quot;Requests version: {requests.__version__}&quot;); print(&quot;Package imported successfully!&quot;)&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;execute_with_packages&quot;, {&quot;code&quot;: code_with_pkg, &quot;packages&quot;: [&quot;requests&quot;]}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(result.content[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    asyncio.run(main())</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Clarifai SDK - required</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">fastmcp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pydantic</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.11&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 500Mi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: code-execution-app</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: code-execution-model</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: text-to-text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: your_user_id</span><br></span></code></pre></div></div></div></div></details>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="code-execution-without-docker-version">Code Execution Without Docker Version<a href="#code-execution-without-docker-version" class="hash-link" aria-label="Direct link to Code Execution Without Docker Version" title="Direct link to Code Execution Without Docker Version" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import subprocess</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import tempfile</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Annotated, Any, Dict</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.mcp_class import MCPModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import FastMCP</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from pydantic import Field</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">server = FastMCP(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;python-execution-server&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    instructions=&quot;Execute Python code using local Python environment&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    stateless_http=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def execute_python_code_fresh_container(code: str) -&gt; Dict[str, Any]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Execute Python code using local Python environment.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Each execution gets a clean temporary file.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Create a temporary file for the code</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        with tempfile.NamedTemporaryFile(mode=&#x27;w&#x27;, suffix=&#x27;.py&#x27;, delete=False) as temp_file:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            temp_file.write(code)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            temp_path = temp_file.name</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Execute the script using subprocess</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = subprocess.run(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                [&quot;python&quot;, temp_path],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                capture_output=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                text=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                check=False</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;stdout&quot;: result.stdout,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;stderr&quot;: result.stderr,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;status&quot;: result.returncode,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        finally:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Clean up temp file</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                os.unlink(temp_path)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            except Exception:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                pass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return {&quot;stdout&quot;: &quot;&quot;, &quot;stderr&quot;: f&quot;Execution error: {str(e)}&quot;, &quot;status&quot;: 1}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def execute_with_packages(code: str, packages: list = None) -&gt; Dict[str, Any]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Execute Python code with pre-installed packages.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    This is the key enhancement over #1 - allows package installation.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if packages:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Prepend package installation to the code</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        install_code = &quot;\n&quot;.join(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;import subprocess; subprocess.run([&#x27;pip&#x27;, &#x27;install&#x27;, &#x27;{pkg}&#x27;], check=True)&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                for pkg in packages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        full_code = f&quot;{install_code}\n\n{code}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        full_code = code</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return execute_python_code_fresh_container(full_code)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;execute_with_packages&quot;, description=&quot;Execute Python code with packages pre-installed&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def execute_with_packages_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    code: Annotated[str, Field(description=&quot;Python code to execute&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    packages: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        list[str], Field(description=&quot;List of packages to install before execution&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Execute Python code with specified packages installed on top of the base Python image.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    This enables users to work with the full Python ecosystem.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Example: execute_with_packages(&quot;import requests; print(requests.get(&#x27;https://httpbin.org/json&#x27;).json())&quot;, [&quot;requests&quot;])</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not code.strip():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return &quot;Error: No code provided&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    result = execute_with_packages(code, packages or [])</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if result[&quot;status&quot;] == 0:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        output = &quot;--- Execution Successful ---\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if packages:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;Packages installed: {&#x27;, &#x27;.join(packages)}\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if result[&quot;stdout&quot;].strip():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += result[&quot;stdout&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += &quot;(No output - use print() to see results)&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        output = f&quot;--- Execution Error (status: {result[&#x27;status&#x27;]}) ---\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if result[&quot;stderr&quot;].strip():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += result[&quot;stderr&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if result[&quot;stdout&quot;].strip():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += &quot;\n--- Output ---\n&quot; + result[&quot;stdout&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class MyModel(MCPModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def get_server(self) -&gt; FastMCP:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Return the FastMCP server instance.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return server</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>client.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import asyncio</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.urls.helper import ClarifaiUrlHelper</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import Client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp.client.transports import StreamableHttpTransport</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PAT = os.environ[&#x27;CLARIFAI_PAT&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">url = ClarifaiUrlHelper().mcp_api_url()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transport = StreamableHttpTransport(url=url, headers={&quot;Authorization&quot;: &quot;Bearer &quot; + PAT})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def main():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    async with Client(transport) as client:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # List available tools</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;=== Available Tools ===&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools = await client.list_tools()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for tool in tools:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;- {tool.name}: {tool.description}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Test 1: execute_with_packages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;=== Test 1: execute_with_packages ===&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        code_with_pkg = &#x27;import requests; print(f&quot;Requests version: {requests.__version__}&quot;); print(&quot;Package imported successfully!&quot;)&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;execute_with_packages&quot;, {&quot;code&quot;: code_with_pkg, &quot;packages&quot;: [&quot;requests&quot;]}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(result.content[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    asyncio.run(main())</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Clarifai SDK - required</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai==11.7.5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">fastmcp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pydantic</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.11&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 500Mi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: code-execution-app-no-docker</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: code-execution-model-no-docker</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: text-to-text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: your_user_id</span><br></span></code></pre></div></div></div></div></details>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="google-drive">Google Drive<a href="#google-drive" class="hash-link" aria-label="Direct link to Google Drive" title="Direct link to Google Drive" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Annotated</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import FastMCP  # use fastmcp v2 not the built in mcp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from pydantic import Field</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">server = FastMCP(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;google-drive-mcp-server&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    instructions=&quot;Google Drive operations for file storage, sharing, and collaboration&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    stateless_http=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def get_drive_service():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Create and return a Google Drive service object.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        from google.auth.transport.requests import Request</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        from google.oauth2.credentials import Credentials</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        from google_auth_oauthlib.flow import InstalledAppFlow</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        from googleapiclient.discovery import build</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Define the scope</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        SCOPES = [&#x27;https://www.googleapis.com/auth/drive&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        creds = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Check for existing token</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if os.path.exists(&#x27;token.json&#x27;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            creds = Credentials.from_authorized_user_file(&#x27;token.json&#x27;, SCOPES)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # If there are no valid credentials, use mock data</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not creds or not creds.valid:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            logger.warning(&quot;Google Drive credentials not available, using mock data&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        service = build(&#x27;drive&#x27;, &#x27;v3&#x27;, credentials=creds)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return service</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except ImportError:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.error(&quot;Google API client libraries not available&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.error(f&quot;Failed to create Drive service: {str(e)}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def handle_drive_operation(operation_func):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Decorator to handle Drive operations with proper error handling.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def wrapper(*args, **kwargs):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            service = get_drive_service()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if not service:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                # Return mock data if service not available</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                return operation_func(None, *args, **kwargs)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return operation_func(service, *args, **kwargs)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;Google Drive operation failed: {str(e)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return wrapper</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;drive_list_files&quot;, description=&quot;List files in Google Drive&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def drive_list_files(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    folder_id: Annotated[str, Field(description=&quot;Folder ID to list files from (optional)&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    file_type: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Field(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;Filter by file type (document, spreadsheet, presentation, folder, etc.)&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    max_results: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        int, Field(description=&quot;Maximum number of files to return&quot;, ge=1, le=100)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = 20,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    order_by: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str, Field(description=&quot;Order by: name, modifiedTime, createdTime&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = &quot;modifiedTime desc&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;List files in Google Drive.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @handle_drive_operation</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def _list_files(service, folder_id, file_type, max_results, order_by):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not service:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Mock response</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            mock_files = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;id&quot;: &quot;1abc123&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;name&quot;: &quot;Project Document.docx&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;mimeType&quot;: &quot;application/vnd.google-apps.document&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;modifiedTime&quot;: &quot;2024-01-15T10:30:00Z&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;size&quot;: &quot;2048576&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;owners&quot;: [{&quot;displayName&quot;: &quot;John Doe&quot;}],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;id&quot;: &quot;2def456&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;name&quot;: &quot;Budget Spreadsheet.xlsx&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;mimeType&quot;: &quot;application/vnd.google-apps.spreadsheet&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;modifiedTime&quot;: &quot;2024-01-14T14:22:00Z&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;size&quot;: &quot;1048576&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;owners&quot;: [{&quot;displayName&quot;: &quot;Jane Smith&quot;}],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;id&quot;: &quot;3ghi789&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;name&quot;: &quot;Presentation.pptx&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;mimeType&quot;: &quot;application/vnd.google-apps.presentation&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;modifiedTime&quot;: &quot;2024-01-13T09:15:00Z&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;size&quot;: &quot;5242880&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;owners&quot;: [{&quot;displayName&quot;: &quot;Bob Johnson&quot;}],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output = f&quot;Google Drive Files (showing {len(mock_files)} files):\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for file in mock_files:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                file_size_mb = int(file.get(&#x27;size&#x27;, 0)) / (1024 * 1024)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                output += f&quot;• {file[&#x27;name&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                output += f&quot;  ID: {file[&#x27;id&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                output += f&quot;  Type: {file[&#x27;mimeType&#x27;].split(&#x27;.&#x27;)[-1] if &#x27;.&#x27; in file[&#x27;mimeType&#x27;] else &#x27;Google App&#x27;}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                output += f&quot;  Size: {file_size_mb:.2f} MB\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                output += f&quot;  Modified: {file[&#x27;modifiedTime&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                output += f&quot;  Owner: {file[&#x27;owners&#x27;][0][&#x27;displayName&#x27;]}\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Real implementation would use service.files().list()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        query_parts = []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if folder_id:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            query_parts.append(f&quot;&#x27;{folder_id}&#x27; in parents&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if file_type:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            mime_type_map = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;document&quot;: &quot;application/vnd.google-apps.document&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;spreadsheet&quot;: &quot;application/vnd.google-apps.spreadsheet&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;presentation&quot;: &quot;application/vnd.google-apps.presentation&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;folder&quot;: &quot;application/vnd.google-apps.folder&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;pdf&quot;: &quot;application/pdf&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if file_type in mime_type_map:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                query_parts.append(f&quot;mimeType=&#x27;{mime_type_map[file_type]}&#x27;&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        query = &quot; and &quot;.join(query_parts) if query_parts else None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        results = (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            service.files()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            .list(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                q=query,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                pageSize=max_results,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                orderBy=order_by,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                fields=&quot;files(id,name,mimeType,size,modifiedTime,owners)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            .execute()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        files = results.get(&#x27;files&#x27;, [])</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not files:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return &quot;No files found in Google Drive&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        output = f&quot;Google Drive Files ({len(files)} files):\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for file in files:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            file_size = int(file.get(&#x27;size&#x27;, 0))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            file_size_mb = file_size / (1024 * 1024) if file_size &gt; 0 else 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;• {file[&#x27;name&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;  ID: {file[&#x27;id&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;  Type: {file[&#x27;mimeType&#x27;].split(&#x27;.&#x27;)[-1] if &#x27;.&#x27; in file[&#x27;mimeType&#x27;] else &#x27;Google App&#x27;}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;  Size: {file_size_mb:.2f} MB\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;  Modified: {file[&#x27;modifiedTime&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if file.get(&#x27;owners&#x27;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                output += f&quot;  Owner: {file[&#x27;owners&#x27;][0][&#x27;displayName&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += &quot;\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return _list_files(folder_id, file_type, max_results, order_by)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;drive_upload_file&quot;, description=&quot;Upload a file to Google Drive&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def drive_upload_file(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    file_path: Annotated[str, Field(description=&quot;Local file path to upload&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    file_name: Annotated[str, Field(description=&quot;Name for the file in Drive (optional)&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    folder_id: Annotated[str, Field(description=&quot;Folder ID to upload to (optional)&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    description: Annotated[str, Field(description=&quot;File description&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Upload a file to Google Drive.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @handle_drive_operation</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def _upload_file(service, file_path, file_name, folder_id, description):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not os.path.exists(file_path):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;Error: File &#x27;{file_path}&#x27; does not exist&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not service:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Mock response</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            file_name = file_name or os.path.basename(file_path)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            file_size = os.path.getsize(file_path)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            file_size_mb = file_size / (1024 * 1024)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Mock upload successful!\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;File: {file_name}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Size: {file_size_mb:.2f} MB\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Drive ID: mock-file-id-{hash(file_path) % 10000}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Note: This is a mock response. Install Google API libraries for actual uploads.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        from googleapiclient.http import MediaFileUpload</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        file_name = file_name or os.path.basename(file_path)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        file_metadata = {&#x27;name&#x27;: file_name, &#x27;description&#x27;: description}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if folder_id:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            file_metadata[&#x27;parents&#x27;] = [folder_id]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        media = MediaFileUpload(file_path, resumable=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        file = (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            service.files()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            .create(body=file_metadata, media_body=media, fields=&#x27;id,name,size,webViewLink&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            .execute()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        file_size = int(file.get(&#x27;size&#x27;, 0))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        file_size_mb = file_size / (1024 * 1024) if file_size &gt; 0 else 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;Successfully uploaded &#x27;{file_name}&#x27; to Google Drive\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;File ID: {file[&#x27;id&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;Size: {file_size_mb:.2f} MB\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;View Link: {file.get(&#x27;webViewLink&#x27;, &#x27;N/A&#x27;)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return _upload_file(file_path, file_name, folder_id, description)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;drive_download_file&quot;, description=&quot;Download a file from Google Drive&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def drive_download_file(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    file_id: Annotated[str, Field(description=&quot;Google Drive file ID&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    local_path: Annotated[str, Field(description=&quot;Local path to save the file&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    export_format: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str, Field(description=&quot;Export format for Google Docs (pdf, docx, etc.)&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Download a file from Google Drive.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @handle_drive_operation</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def _download_file(service, file_id, local_path, export_format):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not service:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Mock response</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            local_path = local_path or f&quot;downloaded_file_{file_id}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Mock download successful!\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;File ID: {file_id}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Saved to: {local_path}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Note: This is a mock response. Install Google API libraries for actual downloads.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Get file metadata</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        file_metadata = service.files().get(fileId=file_id).execute()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        file_name = file_metadata[&#x27;name&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not local_path:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            local_path = file_name</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Check if it&#x27;s a Google Workspace file that needs to be exported</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        google_mime_types = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;application/vnd.google-apps.document&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;application/vnd.google-apps.spreadsheet&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;application/vnd.google-apps.presentation&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if file_metadata[&#x27;mimeType&#x27;] in google_mime_types:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if not export_format:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                export_format = &#x27;pdf&#x27;  # Default export format</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            export_mime_types = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &#x27;pdf&#x27;: &#x27;application/pdf&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &#x27;docx&#x27;: &#x27;application/vnd.openxmlformats-officedocument.wordprocessingml.document&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &#x27;xlsx&#x27;: &#x27;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &#x27;pptx&#x27;: &#x27;application/vnd.openxmlformats-officedocument.presentationml.presentation&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            request = service.files().export_media(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                fileId=file_id,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                mimeType=export_mime_types.get(export_format, export_mime_types[&#x27;pdf&#x27;]),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            request = service.files().get_media(fileId=file_id)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Download the file</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        import io</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        fh = io.BytesIO()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        downloader = MediaIoBaseDownload(fh, request)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        done = False</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        while done is False:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            status, done = downloader.next_chunk()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Save to local file</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        with open(local_path, &#x27;wb&#x27;) as f:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f.write(fh.getvalue())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        file_size = os.path.getsize(local_path)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        file_size_mb = file_size / (1024 * 1024)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;Successfully downloaded &#x27;{file_name}&#x27; from Google Drive\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;Saved to: {local_path}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;Size: {file_size_mb:.2f} MB&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return _download_file(file_id, local_path, export_format)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;drive_share_file&quot;, description=&quot;Share a file or folder in Google Drive&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def drive_share_file(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    file_id: Annotated[str, Field(description=&quot;Google Drive file or folder ID&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    email: Annotated[str, Field(description=&quot;Email address to share with (optional)&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    role: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str, Field(description=&quot;Permission role: reader, writer, commenter&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = &quot;reader&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    anyone_can_view: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        bool, Field(description=&quot;Make file viewable by anyone with the link&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = False,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Share a file or folder in Google Drive.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @handle_drive_operation</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def _share_file(service, file_id, email, role, anyone_can_view):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not service:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Mock response</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            share_url = f&quot;https://drive.google.com/file/d/{file_id}/view&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Mock sharing successful!\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;File ID: {file_id}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Share URL: {share_url}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Permissions: {role}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Note: This is a mock response. Install Google API libraries for actual sharing.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        permissions_created = []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Share with specific email if provided</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if email:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            permission = {&#x27;type&#x27;: &#x27;user&#x27;, &#x27;role&#x27;: role, &#x27;emailAddress&#x27;: email}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                service.permissions()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                .create(fileId=file_id, body=permission, sendNotificationEmail=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                .execute()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            permissions_created.append(f&quot;Shared with {email} as {role}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Make viewable by anyone with link if requested</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if anyone_can_view:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            permission = {&#x27;type&#x27;: &#x27;anyone&#x27;, &#x27;role&#x27;: &#x27;reader&#x27;}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            service.permissions().create(fileId=file_id, body=permission).execute()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            permissions_created.append(&quot;Made viewable by anyone with the link&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Get the file&#x27;s web view link</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        file_metadata = service.files().get(fileId=file_id, fields=&#x27;name,webViewLink&#x27;).execute()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result = f&quot;Successfully shared &#x27;{file_metadata[&#x27;name&#x27;]}&#x27;\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result += f&quot;File ID: {file_id}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result += f&quot;Share URL: {file_metadata.get(&#x27;webViewLink&#x27;, &#x27;N/A&#x27;)}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if permissions_created:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result += &quot;\nPermissions:\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for perm in permissions_created:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                result += f&quot;  • {perm}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return result</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return _share_file(file_id, email, role, anyone_can_view)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;drive_create_folder&quot;, description=&quot;Create a new folder in Google Drive&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def drive_create_folder(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    folder_name: Annotated[str, Field(description=&quot;Name for the new folder&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    parent_folder_id: Annotated[str, Field(description=&quot;Parent folder ID (optional)&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    description: Annotated[str, Field(description=&quot;Folder description&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Create a new folder in Google Drive.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @handle_drive_operation</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def _create_folder(service, folder_name, parent_folder_id, description):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not service:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Mock response</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Mock folder creation successful!\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Folder name: {folder_name}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Folder ID: mock-folder-id-{hash(folder_name) % 10000}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Note: This is a mock response. Install Google API libraries for actual folder creation.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        folder_metadata = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;name&#x27;: folder_name,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;mimeType&#x27;: &#x27;application/vnd.google-apps.folder&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;description&#x27;: description,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if parent_folder_id:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            folder_metadata[&#x27;parents&#x27;] = [parent_folder_id]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        folder = (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            service.files().create(body=folder_metadata, fields=&#x27;id,name,webViewLink&#x27;).execute()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;Successfully created folder &#x27;{folder_name}&#x27;\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;Folder ID: {folder[&#x27;id&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f&quot;View Link: {folder.get(&#x27;webViewLink&#x27;, &#x27;N/A&#x27;)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return _create_folder(folder_name, parent_folder_id, description)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;drive_delete_file&quot;, description=&quot;Delete a file or folder from Google Drive&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def drive_delete_file(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    file_id: Annotated[str, Field(description=&quot;Google Drive file or folder ID to delete&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    permanent: Annotated[bool, Field(description=&quot;Permanently delete (bypass trash)&quot;)] = False,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Delete a file or folder from Google Drive.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @handle_drive_operation</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def _delete_file(service, file_id, permanent):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not service:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Mock response</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Mock deletion successful!\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;File ID: {file_id}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Permanent: {permanent}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;Note: This is a mock response. Install Google API libraries for actual deletion.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Get file metadata before deletion</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            file_metadata = service.files().get(fileId=file_id, fields=&#x27;name&#x27;).execute()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            file_name = file_metadata[&#x27;name&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;Error: File with ID &#x27;{file_id}&#x27; not found&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if permanent:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            service.files().delete(fileId=file_id).execute()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;Permanently deleted &#x27;{file_name}&#x27; (ID: {file_id})&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Move to trash</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            service.files().update(fileId=file_id, body={&#x27;trashed&#x27;: True}).execute()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;Moved &#x27;{file_name}&#x27; to trash (ID: {file_id})&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return _delete_file(file_id, permanent)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;drive_search_files&quot;, description=&quot;Search for files in Google Drive&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def drive_search_files(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    query: Annotated[str, Field(description=&quot;Search query&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    file_type: Annotated[str, Field(description=&quot;File type filter&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    max_results: Annotated[int, Field(description=&quot;Maximum number of results&quot;, ge=1, le=100)] = 10,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Search for files in Google Drive.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @handle_drive_operation</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def _search_files(service, query, file_type, max_results):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not service:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Mock response</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            mock_results = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;id&quot;: &quot;search1&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;name&quot;: f&quot;Document about {query}.docx&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;mimeType&quot;: &quot;application/vnd.google-apps.document&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;id&quot;: &quot;search2&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;name&quot;: f&quot;{query} Spreadsheet.xlsx&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;mimeType&quot;: &quot;application/vnd.google-apps.spreadsheet&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output = f&quot;Search results for &#x27;{query}&#x27; (mock data):\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for i, file in enumerate(mock_results, 1):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                output += f&quot;{i}. {file[&#x27;name&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                output += f&quot;   ID: {file[&#x27;id&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                output += f&quot;   Type: {file[&#x27;mimeType&#x27;].split(&#x27;.&#x27;)[-1]}\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        search_query = f&quot;name contains &#x27;{query}&#x27;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if file_type:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            mime_type_map = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;document&quot;: &quot;application/vnd.google-apps.document&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;spreadsheet&quot;: &quot;application/vnd.google-apps.spreadsheet&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;presentation&quot;: &quot;application/vnd.google-apps.presentation&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if file_type in mime_type_map:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                search_query += f&quot; and mimeType=&#x27;{mime_type_map[file_type]}&#x27;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        results = (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            service.files()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            .list(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                q=search_query, pageSize=max_results, fields=&quot;files(id,name,mimeType,modifiedTime)&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            .execute()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        files = results.get(&#x27;files&#x27;, [])</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not files:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;No files found matching &#x27;{query}&#x27;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        output = f&quot;Search results for &#x27;{query}&#x27; ({len(files)} files):\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for i, file in enumerate(files, 1):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;{i}. {file[&#x27;name&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;   ID: {file[&#x27;id&#x27;]}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;   Type: {file[&#x27;mimeType&#x27;].split(&#x27;.&#x27;)[-1] if &#x27;.&#x27; in file[&#x27;mimeType&#x27;] else &#x27;Google App&#x27;}\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output += f&quot;   Modified: {file[&#x27;modifiedTime&#x27;]}\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return _search_files(query, file_type, max_results)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Static resource</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.resource(&quot;config://drive_settings&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def get_drive_settings():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;api_version&quot;: &quot;v3&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;scopes&quot;: [&quot;https://www.googleapis.com/auth/drive&quot;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;supported_formats&quot;: [&quot;pdf&quot;, &quot;docx&quot;, &quot;xlsx&quot;, &quot;pptx&quot;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;max_upload_size&quot;: &quot;5TB&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;permission_roles&quot;: [&quot;reader&quot;, &quot;writer&quot;, &quot;commenter&quot;, &quot;owner&quot;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Dynamic resource template</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.resource(&quot;drive://file/{file_id}/info&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def get_file_info(file_id: str):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;file_id&quot;: file_id,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;note&quot;: &quot;Use drive_list_files or other tools to get actual file information&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.prompt()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def drive_workflow_prompt(workflow_type: str) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Generate prompts for Google Drive workflows.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    prompts = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;collaboration&quot;: &quot;For collaboration workflow:\n1. Use drive_upload_file to share documents\n2. Use drive_share_file to set permissions\n3. Use drive_create_folder for organization\n4. Grant appropriate roles (reader, writer, commenter)&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;backup&quot;: &quot;For backup workflow:\n1. Use drive_create_folder for organized storage\n2. Use drive_upload_file to backup important files\n3. Consider using drive_share_file for team access\n4. Regular sync using automated tools&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;document_management&quot;: &quot;For document management:\n1. Create folder structure with drive_create_folder\n2. Upload files with drive_upload_file\n3. Use drive_search_files to find documents\n4. Share selectively with drive_share_file&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return prompts.get(workflow_type, f&quot;Google Drive workflow guidance for: {workflow_type}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.mcp_class import MCPModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class MyModelClass(MCPModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def get_server(self) -&gt; FastMCP:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return server</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>client.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import asyncio</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import tempfile</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.urls.helper import ClarifaiUrlHelper</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import Client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp.client.transports import StreamableHttpTransport</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PAT = os.environ[&#x27;CLARIFAI_PAT&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">url = ClarifaiUrlHelper().mcp_api_url()  # get url from the current clarifai config</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transport = StreamableHttpTransport(url=url, headers={&quot;Authorization&quot;: &quot;Bearer &quot; + PAT})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def main():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;=== Google Drive MCP Server Examples ===\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    async with Client(transport) as client:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # List available tools first</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;Available tools:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools = await client.list_tools()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for tool in tools:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;- {tool.name}: {tool.description}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 1: List files in Google Drive</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;1. Listing files in Google Drive:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;drive_list_files&quot;, {&quot;max_results&quot;: 5, &quot;order_by&quot;: &quot;modifiedTime desc&quot;}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 2: Search for files</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;2. Searching for files:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;drive_search_files&quot;, {&quot;query&quot;: &quot;project&quot;, &quot;max_results&quot;: 3}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 3: Create a folder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;3. Creating a folder:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;drive_create_folder&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                {&quot;folder_name&quot;: &quot;MCP Demo Folder&quot;, &quot;description&quot;: &quot;Folder created by MCP example&quot;},</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 4: Upload a file (creates a temporary file for demo)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;4. Uploading a file:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Create a temporary file for demonstration</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        with tempfile.NamedTemporaryFile(mode=&#x27;w&#x27;, delete=False, suffix=&#x27;.txt&#x27;) as f:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            f.write(&quot;This is a test file for Google Drive upload demonstration.&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            temp_file_path = f.name</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;drive_upload_file&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;file_path&quot;: temp_file_path,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;file_name&quot;: &quot;MCP Demo File.txt&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;description&quot;: &quot;File uploaded by MCP example&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        finally:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Clean up temporary file</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            os.unlink(temp_file_path)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 5: Share a file</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;5. Sharing a file:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;drive_share_file&quot;, {&quot;file_id&quot;: &quot;mock-file-id-123&quot;, &quot;anyone_can_view&quot;: True}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 6: Download a file</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;6. Downloading a file:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;drive_download_file&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;file_id&quot;: &quot;mock-file-id-123&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;local_path&quot;: &quot;downloaded_document.pdf&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;export_format&quot;: &quot;pdf&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;\n&quot; + &quot;=&quot; * 50)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;Note: Google Drive authentication required for actual operations:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;- Set up OAuth 2.0 credentials in Google Cloud Console&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;- Download credentials.json file&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;- Run authentication flow to generate token.json&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;- This example uses mock data for demonstration&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;=&quot; * 50)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    asyncio.run(main())</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">anyio==4.9.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">mcp==1.9.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">fastmcp==2.3.4</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">google-api-python-client==2.111.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">google-auth-httplib2==0.2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">google-auth-oauthlib==1.1.0</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.11&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: 1000m</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 1Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: mcp-examples-app</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: google-drive-mcp-server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: text-to-text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: mcp-examples-user</span><br></span></code></pre></div></div></div></div></details>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="math">Math<a href="#math" class="hash-link" aria-label="Direct link to Math" title="Direct link to Math" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import FastMCP</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from pydantic import Field</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Annotated</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.mcp_class import MCPModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">server = FastMCP(&quot;my-mcp-server&quot;, instructions=&quot;&quot;, stateless_http=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;addition_tool&quot;, description=&quot;Add two numbers&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def addition_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    a: Annotated[float, Field(description=&quot;First number&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    b: Annotated[float, Field(description=&quot;Second number&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; float:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Add two numbers&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return a + b</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;subtraction_tool&quot;, description=&quot;Subtract two numbers&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def subtraction_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    a: Annotated[float, Field(description=&quot;First number&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    b: Annotated[float, Field(description=&quot;Second number&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; float:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Subtract two numbers&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return a - b</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;multiplication_tool&quot;, description=&quot;Multiply two numbers&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def multiplication_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    a: Annotated[float, Field(description=&quot;First number&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    b: Annotated[float, Field(description=&quot;Second number&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; float:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Multiply two numbers&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return a * b</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;division_tool&quot;, description=&quot;Divide two numbers&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def division_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    a: Annotated[float, Field(description=&quot;First number&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    b: Annotated[float, Field(description=&quot;Second number&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; float:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Divide two numbers&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return a / b</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class MyModel(MCPModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def get_server(self) -&gt; FastMCP:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Return the FastMCP server instance.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return server</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>client.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import asyncio</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.urls.helper import ClarifaiUrlHelper</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import Client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp.client.transports import StreamableHttpTransport</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PAT = os.environ[&#x27;CLARIFAI_PAT&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">url = ClarifaiUrlHelper().mcp_api_url()  # get url from the current clarifai config</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transport = StreamableHttpTransport(url=url, headers={&quot;Authorization&quot;: &quot;Bearer &quot; + PAT})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def main():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    async with Client(transport) as client:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools = await client.list_tools()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for tool in tools:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;- {tool.name}: {tool.description}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result = await client.call_tool(&quot;addition_tool&quot;, {&quot;a&quot;: 10.1, &quot;b&quot;: 5.2})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(f&quot;10.1 + 5.2 = {result.content[0].text}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result = await client.call_tool(&quot;subtraction_tool&quot;, {&quot;a&quot;: 10.1, &quot;b&quot;: 3.2})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(f&quot;10.1 - 3.2 = {result.content[0].text}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result = await client.call_tool(&quot;multiplication_tool&quot;, {&quot;a&quot;: 4.1, &quot;b&quot;: 7.2})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(f&quot;4.1 * 7.2 = {result.content[0].text}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        result = await client.call_tool(&quot;division_tool&quot;, {&quot;a&quot;: 20.1, &quot;b&quot;: 4.2})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(f&quot;20.1 / 4.2 = {result.content[0].text}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    asyncio.run(main())</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Clarifai SDK - required</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">fastmcp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pydantic</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.11&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 500Mi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: mcp-math-app</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: mcp-math-model</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: text-to-text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: mcp-math-user</span><br></span></code></pre></div></div></div></div></details>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="postgres">Postgres<a href="#postgres" class="hash-link" aria-label="Direct link to Postgres" title="Direct link to Postgres" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Annotated, Any</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import FastMCP  # use fastmcp v2 not the built in mcp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from pydantic import Field</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">server = FastMCP(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;postgres-mcp-server&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    instructions=&quot;PostgreSQL database operations and management&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    stateless_http=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def get_postgres_connection(host: str, port: int, user: str, password: str, database: str):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Create a PostgreSQL connection. Returns connection object or None if failed.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        import psycopg2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        connection = psycopg2.connect(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            host=host, port=port, user=user, password=password, database=database</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        connection.autocommit = True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return connection</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.error(f&quot;PostgreSQL connection failed: {str(e)}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def execute_postgres_query(connection, query: str, params: tuple = None) -&gt; tuple[bool, Any]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Execute a PostgreSQL query and return results.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        from psycopg2.extras import RealDictCursor</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        cursor = connection.cursor(cursor_factory=RealDictCursor)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        cursor.execute(query, params or ())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Handle different query types</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if query.strip().upper().startswith((&#x27;SELECT&#x27;, &#x27;WITH&#x27;, &#x27;SHOW&#x27;, &#x27;EXPLAIN&#x27;)):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            results = cursor.fetchall()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Convert to list of dicts for JSON serialization</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            results = [dict(row) for row in results]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cursor.close()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return True, results</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # For INSERT, UPDATE, DELETE, etc.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            affected_rows = cursor.rowcount</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cursor.close()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return True, {&quot;affected_rows&quot;: affected_rows, &quot;message&quot;: &quot;Query executed successfully&quot;}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return False, {&quot;error&quot;: str(e)}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;postgres_connect&quot;, description=&quot;Test PostgreSQL database connection&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def postgres_connect(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    host: Annotated[str, Field(description=&quot;PostgreSQL host&quot;)] = &quot;localhost&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    port: Annotated[int, Field(description=&quot;PostgreSQL port&quot;, ge=1, le=65535)] = 5432,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    user: Annotated[str, Field(description=&quot;PostgreSQL username&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    password: Annotated[str, Field(description=&quot;PostgreSQL password&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    database: Annotated[str, Field(description=&quot;Database name&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Test connection to PostgreSQL database.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    connection = get_postgres_connection(host, port, user, password, database)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if connection:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cursor = connection.cursor()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cursor.execute(&quot;SELECT version();&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            version = cursor.fetchone()[0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cursor.close()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            connection.close()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;Successfully connected to PostgreSQL database &#x27;{database}&#x27; on {host}:{port}\nPostgreSQL Version: {version}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            connection.close()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;Connected but failed to get version: {str(e)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Failed to connect to PostgreSQL database &#x27;{database}&#x27; on {host}:{port}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;postgres_execute_query&quot;, description=&quot;Execute a PostgreSQL query&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def postgres_execute_query(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    query: Annotated[str, Field(description=&quot;SQL query to execute&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    host: Annotated[str, Field(description=&quot;PostgreSQL host&quot;)] = &quot;localhost&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    port: Annotated[int, Field(description=&quot;PostgreSQL port&quot;, ge=1, le=65535)] = 5432,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    user: Annotated[str, Field(description=&quot;PostgreSQL username&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    password: Annotated[str, Field(description=&quot;PostgreSQL password&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    database: Annotated[str, Field(description=&quot;Database name&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    limit: Annotated[</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        int, Field(description=&quot;Limit results for SELECT queries&quot;, ge=1, le=1000)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ] = 100,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Execute a SQL query on PostgreSQL database.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    connection = get_postgres_connection(host, port, user, password, database)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not connection:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Failed to connect to PostgreSQL database &#x27;{database}&#x27; on {host}:{port}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Add LIMIT to SELECT queries if not already present</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;QQQQQQQQQQQQQQQQQQQQQQQQQQQQQQQ&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(query)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if query.strip().upper().startswith(&#x27;SELECT&#x27;) and &#x27;LIMIT&#x27; not in query.upper():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            l = limit</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            query = f&quot;{query.strip().rstrip(&#x27;;&#x27;)} LIMIT {l};&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(query)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        success, result = execute_postgres_query(connection, query)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        connection.close()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not success:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;Query failed: {result.get(&#x27;error&#x27;, &#x27;Unknown error&#x27;)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if isinstance(result, list):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Format SELECT results</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if not result:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                return &quot;Query executed successfully. No rows returned.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Create a formatted table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output = f&quot;Query results ({len(result)} rows):\n\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if result:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                # Get column names</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                columns = list(result[0].keys())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                # Calculate column widths</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                col_widths = {}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                for col in columns:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    col_widths[col] = max(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        len(col), max(len(str(row.get(col, &#x27;&#x27;))) for row in result)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                # Create header</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                header = &quot; | &quot;.join(col.ljust(col_widths[col]) for col in columns)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                separator = &quot; | &quot;.join(&quot;-&quot; * col_widths[col] for col in columns)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                output += header + &quot;\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                output += separator + &quot;\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                # Add data rows</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                for row in result:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    row_str = &quot; | &quot;.join(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        str(row.get(col, &#x27;&#x27;)).ljust(col_widths[col]) for col in columns</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    output += row_str + &quot;\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # Non-SELECT query result</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;Query executed successfully. {result.get(&#x27;message&#x27;, &#x27;&#x27;)} Affected rows: {result.get(&#x27;affected_rows&#x27;, 0)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if connection:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            connection.close()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Error executing query: {str(e)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;postgres_list_tables&quot;, description=&quot;List all tables in the database&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def postgres_list_tables(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    host: Annotated[str, Field(description=&quot;PostgreSQL host&quot;)] = &quot;localhost&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    port: Annotated[int, Field(description=&quot;PostgreSQL port&quot;, ge=1, le=65535)] = 5432,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    user: Annotated[str, Field(description=&quot;PostgreSQL username&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    password: Annotated[str, Field(description=&quot;PostgreSQL password&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    database: Annotated[str, Field(description=&quot;Database name&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    schema: Annotated[str, Field(description=&quot;Schema name&quot;)] = &quot;public&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;List all tables in the PostgreSQL database.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    query = f&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    SELECT table_name, table_type</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    FROM information_schema.tables</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    WHERE table_schema = &#x27;{schema}&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ORDER BY table_name;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return postgres_execute_query(query, host, port, user, password, database)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;postgres_describe_table&quot;, description=&quot;Describe the structure of a table&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def postgres_describe_table(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    table_name: Annotated[str, Field(description=&quot;Table name to describe&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    host: Annotated[str, Field(description=&quot;PostgreSQL host&quot;)] = &quot;localhost&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    port: Annotated[int, Field(description=&quot;PostgreSQL port&quot;, ge=1, le=65535)] = 5432,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    user: Annotated[str, Field(description=&quot;PostgreSQL username&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    password: Annotated[str, Field(description=&quot;PostgreSQL password&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    database: Annotated[str, Field(description=&quot;Database name&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    schema: Annotated[str, Field(description=&quot;Schema name&quot;)] = &quot;public&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Describe the structure of a PostgreSQL table.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    query = f&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    SELECT</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        column_name,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        data_type,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        character_maximum_length,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        is_nullable,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        column_default</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    FROM information_schema.columns</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    WHERE table_schema = &#x27;{schema}&#x27; AND table_name = &#x27;{table_name}&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ORDER BY ordinal_position;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return postgres_execute_query(query, host, port, user, password, database)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;postgres_list_databases&quot;, description=&quot;List all databases&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def postgres_list_databases(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    host: Annotated[str, Field(description=&quot;PostgreSQL host&quot;)] = &quot;localhost&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    port: Annotated[int, Field(description=&quot;PostgreSQL port&quot;, ge=1, le=65535)] = 5432,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    user: Annotated[str, Field(description=&quot;PostgreSQL username&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    password: Annotated[str, Field(description=&quot;PostgreSQL password&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;List all databases on the PostgreSQL server.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Use postgres database as default for this query</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    query = &quot;SELECT datname as database_name FROM pg_database WHERE datistemplate = false ORDER BY datname;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return postgres_execute_query(query, host, port, user, password, &quot;postgres&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;postgres_table_stats&quot;, description=&quot;Get statistics for a table&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def postgres_table_stats(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    table_name: Annotated[str, Field(description=&quot;Table name&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    host: Annotated[str, Field(description=&quot;PostgreSQL host&quot;)] = &quot;localhost&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    port: Annotated[int, Field(description=&quot;PostgreSQL port&quot;, ge=1, le=65535)] = 5432,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    user: Annotated[str, Field(description=&quot;PostgreSQL username&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    password: Annotated[str, Field(description=&quot;PostgreSQL password&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    database: Annotated[str, Field(description=&quot;Database name&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    schema: Annotated[str, Field(description=&quot;Schema name&quot;)] = &quot;public&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Get statistics for a PostgreSQL table.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    query = f&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    SELECT</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        schemaname,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tablename,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        attname as column_name,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        n_distinct,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        correlation</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    FROM pg_stats</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    WHERE schemaname = &#x27;{schema}&#x27; AND tablename = &#x27;{table_name}&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ORDER BY attname;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return postgres_execute_query(query, host, port, user, password, database)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;postgres_table_size&quot;, description=&quot;Get size information for tables&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def postgres_table_size(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    host: Annotated[str, Field(description=&quot;PostgreSQL host&quot;)] = &quot;localhost&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    port: Annotated[int, Field(description=&quot;PostgreSQL port&quot;, ge=1, le=65535)] = 5432,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    user: Annotated[str, Field(description=&quot;PostgreSQL username&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    password: Annotated[str, Field(description=&quot;PostgreSQL password&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    database: Annotated[str, Field(description=&quot;Database name&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    schema: Annotated[str, Field(description=&quot;Schema name&quot;)] = &quot;public&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Get size information for all tables in the schema.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    query = f&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    SELECT</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pg_size_pretty(pg_total_relation_size(schemaname||&#x27;.&#x27;||tablename)) AS size,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pg_size_pretty(pg_relation_size(schemaname||&#x27;.&#x27;||tablename)) AS table_size,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pg_size_pretty(pg_total_relation_size(schemaname||&#x27;.&#x27;||tablename) - pg_relation_size(schemaname||&#x27;.&#x27;||tablename)) AS index_size</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    FROM pg_tables</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    WHERE schemaname = &#x27;{schema}&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ORDER BY pg_total_relation_size(schemaname||&#x27;.&#x27;||tablename) DESC;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return postgres_execute_query(query, host, port, user, password, database)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;postgres_active_connections&quot;, description=&quot;Show active database connections&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def postgres_active_connections(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    host: Annotated[str, Field(description=&quot;PostgreSQL host&quot;)] = &quot;localhost&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    port: Annotated[int, Field(description=&quot;PostgreSQL port&quot;, ge=1, le=65535)] = 5432,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    user: Annotated[str, Field(description=&quot;PostgreSQL username&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    password: Annotated[str, Field(description=&quot;PostgreSQL password&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    database: Annotated[str, Field(description=&quot;Database name&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Show active connections to the PostgreSQL database.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    query = &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    SELECT</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pid,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        usename,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        datname,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        client_addr,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        application_name,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        state,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        query_start,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        state_change</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    FROM pg_stat_activity</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    WHERE state = &#x27;active&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ORDER BY query_start DESC;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return postgres_execute_query(query, host, port, user, password, database)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;postgres_create_backup&quot;, description=&quot;Create a backup using pg_dump&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def postgres_create_backup(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    backup_type: Annotated[str, Field(description=&quot;Backup type: &#x27;database&#x27; or &#x27;table&#x27;&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    target_name: Annotated[str, Field(description=&quot;Database name or table name&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    host: Annotated[str, Field(description=&quot;PostgreSQL host&quot;)] = &quot;localhost&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    port: Annotated[int, Field(description=&quot;PostgreSQL port&quot;, ge=1, le=65535)] = 5432,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    user: Annotated[str, Field(description=&quot;PostgreSQL username&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    password: Annotated[str, Field(description=&quot;PostgreSQL password&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    database: Annotated[str, Field(description=&quot;Database name (for table backup)&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Create a backup using pg_dump.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    import subprocess</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        env = os.environ.copy()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        env[&#x27;PGPASSWORD&#x27;] = password</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if backup_type == &quot;database&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cmd = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;pg_dump&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;--host={host}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;--port={port}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;--username={user}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;--format=custom&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;--no-password&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                target_name,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            backup_file = f&quot;{target_name}_backup.dump&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        elif backup_type == &quot;table&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            cmd = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;pg_dump&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;--host={host}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;--port={port}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;--username={user}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;--format=custom&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;--no-password&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                f&quot;--table={target_name}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                database,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            backup_file = f&quot;{database}_{target_name}_backup.dump&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return &quot;Error: backup_type must be &#x27;database&#x27; or &#x27;table&#x27;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Execute pg_dump</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        with open(backup_file, &#x27;wb&#x27;) as f:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = subprocess.run(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                cmd, stdout=f, stderr=subprocess.PIPE, env=env, timeout=300, check=False</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if result.returncode == 0:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;Backup created successfully: {backup_file}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return f&quot;Backup failed: {result.stderr.decode()}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Backup failed: {str(e)}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.tool(&quot;postgres_analyze_table&quot;, description=&quot;Analyze a table to update statistics&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def postgres_analyze_table(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    table_name: Annotated[str, Field(description=&quot;Table name to analyze&quot;)],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    host: Annotated[str, Field(description=&quot;PostgreSQL host&quot;)] = &quot;localhost&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    port: Annotated[int, Field(description=&quot;PostgreSQL port&quot;, ge=1, le=65535)] = 5432,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    user: Annotated[str, Field(description=&quot;PostgreSQL username&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    password: Annotated[str, Field(description=&quot;PostgreSQL password&quot;)] = &quot;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    database: Annotated[str, Field(description=&quot;Database name&quot;)] = &quot;postgres&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Analyze a PostgreSQL table to update statistics.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return postgres_execute_query(f&quot;ANALYZE {table_name};&quot;, host, port, user, password, database)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Static resource</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.resource(&quot;config://postgres_settings&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def get_postgres_settings():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;default_port&quot;: 5432,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;default_host&quot;: &quot;localhost&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;default_schema&quot;: &quot;public&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;max_query_limit&quot;: 1000,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;supported_operations&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;SELECT&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;INSERT&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;UPDATE&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;DELETE&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;CREATE&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;DROP&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;ALTER&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;backup_formats&quot;: [&quot;custom&quot;, &quot;plain&quot;, &quot;tar&quot;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Dynamic resource template</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.resource(&quot;database://{database_name}/schema_info&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def get_database_schema_info(database_name: str):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;database&quot;: database_name,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;note&quot;: &quot;Use postgres_list_tables and postgres_describe_table tools to get actual schema information&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@server.prompt()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def postgres_query_prompt(query_type: str) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Generate prompts for PostgreSQL query construction.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    prompts = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;select&quot;: &quot;To write a SELECT query:\nSELECT column1, column2 FROM schema.table_name WHERE condition ORDER BY column LIMIT n;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;insert&quot;: &quot;To write an INSERT query:\nINSERT INTO schema.table_name (column1, column2) VALUES (value1, value2);&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;update&quot;: &quot;To write an UPDATE query:\nUPDATE schema.table_name SET column1 = value1 WHERE condition;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;delete&quot;: &quot;To write a DELETE query:\nDELETE FROM schema.table_name WHERE condition;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;create&quot;: &quot;To create a table:\nCREATE TABLE schema.table_name (column1 datatype constraints, column2 datatype constraints);&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;index&quot;: &quot;To create an index:\nCREATE INDEX index_name ON schema.table_name (column1, column2);&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;jsonb&quot;: &quot;For JSONB operations:\nSELECT data-&gt;&gt;&#x27;key&#x27; FROM table WHERE data @&gt; &#x27;{\&quot;key\&quot;: \&quot;value\&quot;}&#x27;;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return prompts.get(query_type, f&quot;PostgreSQL query guidance for: {query_type}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.mcp_class import MCPModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class MyModelClass(MCPModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def get_server(self) -&gt; FastMCP:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return server</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>client.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import asyncio</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.urls.helper import ClarifaiUrlHelper</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import Client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp.client.transports import StreamableHttpTransport</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PAT = os.environ[&#x27;CLARIFAI_PAT&#x27;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">url = ClarifaiUrlHelper().mcp_api_url()  # get url from the current clarifai config</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transport = StreamableHttpTransport(url=url, headers={&quot;Authorization&quot;: &quot;Bearer &quot; + PAT})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def main():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;=== PostgreSQL MCP Server Examples ===\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Note: These examples assume you have PostgreSQL credentials</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Set environment variables: POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_HOST, POSTGRES_DATABASE</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    postgres_config = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;host&quot;: os.environ.get(&quot;POSTGRES_HOST&quot;, &quot;localhost&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;port&quot;: os.environ.get(&quot;POSTGRES_PORT&quot;, &quot;5432&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;user&quot;: os.environ.get(&quot;POSTGRES_USER&quot;, &quot;postgres&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;password&quot;: os.environ.get(&quot;POSTGRES_PASSWORD&quot;, &quot;&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;database&quot;: os.environ.get(&quot;POSTGRES_DATABASE&quot;, &quot;postgres&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    async with Client(transport) as client:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # List available tools first</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;Available tools:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools = await client.list_tools()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for tool in tools:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;- {tool.name}: {tool.description}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 1: Test PostgreSQL connection</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;1. Testing PostgreSQL connection:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(&quot;postgres_connect&quot;, postgres_config)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 2: List databases</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;2. Listing databases:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;postgres_list_databases&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;host&quot;: postgres_config[&quot;host&quot;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;port&quot;: postgres_config[&quot;port&quot;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;user&quot;: postgres_config[&quot;user&quot;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;password&quot;: postgres_config[&quot;password&quot;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 3: List tables in database</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;3. Listing tables:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(&quot;postgres_list_tables&quot;, postgres_config)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 4: Execute a sample query</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;4. Executing a sample query (SELECT version):&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;postgres_execute_query&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    **postgres_config,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    &quot;query&quot;: &quot;SELECT version() as postgres_version, current_timestamp as current_time;&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Example 5: Get table sizes</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;5. Getting table sizes:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            result = await client.call_tool(&quot;postgres_table_size&quot;, postgres_config)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(result[0].text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;\n&quot; + &quot;=&quot; * 50 + &quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;\n&quot; + &quot;=&quot; * 50)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;Note: Set these environment variables for actual PostgreSQL connections:&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;- POSTGRES_HOST (default: localhost)&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;- POSTGRES_USER (default: postgres)&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;- POSTGRES_PASSWORD&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;- POSTGRES_DATABASE (default: postgres)&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;=&quot; * 50)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    asyncio.run(main())</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">anyio==4.9.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">mcp==1.9.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">fastmcp==2.3.4</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">psycopg2-binary==2.9.9</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.11&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: 1000m</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 1Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: mcp-examples-app</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: postgres-mcp-server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: text-to-text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: mcp-examples-user</span><br></span></code></pre></div></div></div></div></details>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="web-search">Web Search<a href="#web-search" class="hash-link" aria-label="Direct link to Web Search" title="Direct link to Web Search" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">from __future__ import annotations</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os, re</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from dataclasses import dataclass, field</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Dict, List, Optional, Union</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from urllib.parse import urlparse, parse_qs, unquote</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import httpx  # type: ignore</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from bs4 import BeautifulSoup  # type: ignore</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from mcp.server.fastmcp import FastMCP, Context  # type: ignore</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">USER_AGENT = (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) &quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0 Safari/537.36&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Optional SDK for DuckDuckGo (pip install duckduckgo_search)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   from ddgs import DDGS  # type: ignore</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">except ImportError:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    DDGS = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># ---------------- Data Models ----------------</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@dataclass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class SearchResult:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    id: int</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    title: str</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url: str</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    snippet: str</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@dataclass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class PageCache:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url: str</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    text_lines: List[str]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@dataclass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class SessionState:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    last_query: Optional[str] = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    results: List[SearchResult] = field(default_factory=list)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    opened_pages: Dict[str, PageCache] = field(default_factory=dict)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    last_open_url: Optional[str] = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def ddg_sdk_search(query: str, topn: int, region: str, safesearch: str) -&gt; List[SearchResult]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Use duckduckgo_search AsyncDDGS instead of manual HTML scraping.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Falls back to manual method if SDK not available.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if DDGS is None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        raise RuntimeError(&quot;duckduckgo_search not installed&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # The library expects: region like &#x27;wt-wt&#x27;, safesearch one of: &#x27;moderate&#x27;,&#x27;off&#x27;,&#x27;strict&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    safe = safesearch.lower()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if safe not in {&quot;moderate&quot;, &quot;off&quot;, &quot;strict&quot;}:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        safe = &quot;moderate&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    results: List[SearchResult] = []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        results_gen = DDGS().text(query, region=region, safesearch=safe, max_results=topn)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for r in results_gen:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            # r keys commonly: title, href, body</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            title = (r.get(&quot;title&quot;) or &quot;&quot;).strip()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            url = (r.get(&quot;href&quot;) or &quot;&quot;).strip()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            snippet = (r.get(&quot;body&quot;) or &quot;&quot;).strip()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if title and url.startswith(&quot;http&quot;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                results.append(SearchResult(id=len(results) + 1, title=title, url=url, snippet=snippet))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if len(results) &gt;= topn:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                break</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(f&quot;[ddg_sdk_search] Exception: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        raise</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return results</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def _clean_duckduckgo_href(raw: str) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(f&quot;[_clean_duckduckgo_href] raw={raw}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not raw:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return &quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if raw.startswith(&quot;//&quot;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        raw = &quot;https:&quot; + raw</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    p = urlparse(raw)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if p.netloc.endswith(&quot;duckduckgo.com&quot;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if p.path.startswith(&quot;/l/&quot;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            qs = parse_qs(p.query)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if qs.get(&quot;uddg&quot;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                target = unquote(qs[&quot;uddg&quot;][0])</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if &quot;duckduckgo.com&quot; in urlparse(target).netloc:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    return &quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                return target</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if p.path.endswith(&quot;.js&quot;) or p.path.startswith(&quot;/y.js&quot;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return &quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not p.scheme:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return &quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return raw</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def parse_duckduckgo(html: str, topn: int) -&gt; List[SearchResult]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(f&quot;[parse_duckduckgo] Parsing HTML, topn={topn}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    soup = BeautifulSoup(html, &quot;html.parser&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    results: List[SearchResult] = []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for block in soup.select(&quot;div.result&quot;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        a = block.select_one(&quot;a.result__a&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not a:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            continue</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        title = a.get_text(&quot; &quot;, strip=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        url = _clean_duckduckgo_href(a.get(&quot;href&quot;) or &quot;&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not url or &quot;duckduckgo.com&quot; in urlparse(url).netloc:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            continue</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        snip_el = block.select_one(&quot;.result__snippet, .snippet&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        snippet = snip_el.get_text(&quot; &quot;, strip=True) if snip_el else &quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not title or not url.startswith(&quot;http&quot;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            continue</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        results.append(SearchResult(id=len(results) + 1, title=title, url=url, snippet=snippet))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if len(results) &gt;= topn:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            break</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(f&quot;[parse_duckduckgo] Found {len(results)} results&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return results</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def format_search_results(results: List[SearchResult]) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(f&quot;[format_search_results] Formatting {len(results)} results&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not results:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return &quot;No results.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return &quot;\n\n&quot;.join(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        f&quot;[{r.id}] {r.title}\nURL: {r.url}\nSnippet: {r.snippet or &#x27;(no snippet)&#x27;}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for r in results</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def fetch_page(url: str, timeout: int = 20) -&gt; PageCache:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(f&quot;[fetch_page] Fetching URL: {url} with timeout={timeout}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    headers = {&quot;User-Agent&quot;: USER_AGENT, &quot;Accept-Language&quot;: &quot;en-US,en;q=0.9&quot;}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        async with httpx.AsyncClient(timeout=timeout, follow_redirects=True) as client:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            r = await client.get(url, headers=headers)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;[fetch_page] HTTP status: {r.status_code}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            r.raise_for_status()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            html = r.text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(f&quot;[fetch_page] Exception: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        raise</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    soup = BeautifulSoup(html, &quot;html.parser&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for tag in soup([&quot;script&quot;, &quot;style&quot;, &quot;noscript&quot;]):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tag.decompose()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    text = soup.get_text(&quot;\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    lines = [ln.rstrip() for ln in text.splitlines() if ln.strip()]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(f&quot;[fetch_page] Extracted {len(lines)} lines&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return PageCache(url=url, text_lines=lines)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># ---------------- FastMCP Server (in-process) ----------------</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">mcp = FastMCP(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    name=&quot;duckduckgo-browser&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    instructions=r&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Tool for browsing.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">The `cursor` appears in brackets before each browsing display: `[{cursor}]`.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Cite information from the tool using the following format:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">`【{cursor}†L{line_start}(-L{line_end})?】`, for example: `【6†L9-L11】` or `【8†L3】`. </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Do not quote more than 10 words directly from the tool output.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sources=web</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;&quot;&quot;.strip(),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    port=8001,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@mcp.tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    name=&quot;search&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    title=&quot;Search for information&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    description=</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;Searches for information related to `query` and displays `topn` results.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def search(query: str, topn: int = 10,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                 region: str = &quot;wt-wt&quot;, safesearch: str = &quot;moderate&quot;) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(f&quot;[search] Query: {query}, topn={topn}, region={region}, safesearch={safesearch}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;[search] Using DuckDuckGo SDK&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        results = await ddg_sdk_search(query, topn, region, safesearch)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">           </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:  # noqa: BLE001</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(f&quot;[search] Exception: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Search error: {e}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return format_search_results(results)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@mcp.tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    name=&quot;open&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    title=&quot;Open a link or page&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    description=&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Opens the link `id` from the page indicated by `cursor` starting at line number `loc`, showing `num_lines` lines.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Valid link ids are displayed with the formatting: `【{id}†.*】`.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">If `cursor` is not provided, the most recent page is implied.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">If `id` is a string, it is treated as a fully qualified URL associated with `source`.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">If `loc` is not provided, the viewport will be positioned at the beginning of the document or centered on the most relevant passage, if available.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Use this function without `id` to scroll to a new location of an opened page.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;&quot;&quot;.strip(),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def open(id: Union[int, str] = -1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">               loc: int = 0, num_lines: int = 60) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(f&quot;[open] id={id}, loc={loc}, num_lines={num_lines}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if isinstance(id, int) and id != -1:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;[open] Invalid id (int but not -1)&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return &quot;Result id not found. Run search.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if not isinstance(id, str) or not id.startswith(&quot;http&quot;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;[open] Invalid id (not a valid URL)&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return &quot;Provide result id or full http(s) URL.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        url = id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        page = await fetch_page(url)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:  # noqa: BLE001</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(f&quot;[open] Exception: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Open failed: {e}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    total = len(page.text_lines)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if loc &lt; 0: loc = 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if num_lines &lt;= 0: num_lines = 60</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    end = min(total, loc + num_lines)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    body = &quot;\n&quot;.join(f&quot;L{loc+i+1}: {line}&quot; for i, line in enumerate(page.text_lines[loc:end]))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(f&quot;[open] Returning lines {loc+1}-{end} of {total}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return f&quot;URL: {url}\nLines {loc+1}-{end} of {total}\n&quot; + &quot;-&quot;*60 + &quot;\n&quot; + body</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@mcp.tool(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    name=&quot;find&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    title=&quot;Find pattern in page&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    description=</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;Finds exact matches of `pattern` in the current page, or the page given by `cursor`.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def find(pattern: str, url: Optional[str] = None, max_matches: int = 50) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(f&quot;[find] pattern={pattern}, url={url}, max_matches={max_matches}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not url:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;[find] No URL provided&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return &quot;No page open.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        page = await fetch_page(url)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(f&quot;[find] Exception: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;Fetch failed: {e}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    rx = re.compile(re.escape(pattern), re.IGNORECASE)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hits: List[str] = []</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    for i, line in enumerate(page.text_lines, start=1):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if rx.search(line):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            hits.append(f&quot;L{i}: {rx.sub(lambda m: &#x27;**&#x27;+m.group(0)+&#x27;**&#x27;, line)}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if len(hits) &gt;= max_matches:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                break</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(f&quot;[find] Found {len(hits)} matches&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return &quot;\n&quot;.join(hits) if hits else f&quot;No matches for &#x27;{pattern}&#x27;.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@mcp.resource(&quot;config://browser_search_settings&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def get_browser_search_settings() -&gt; Dict[str, str]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;available_tools&quot;: [&quot;search&quot;, &quot;open&quot;, &quot;find&quot;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@mcp.prompt()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def web_browsing_prompt(task_type: str) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Generate a usage prompt for web browsing and extraction tasks, tailored to the available tools in this file.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    prompts = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;content_research&quot;: (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;To research web content:\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;1. Use the &#x27;search&#x27; tool to find relevant pages.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;2. Use &#x27;open&#x27; to read the content of a result or URL.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;3. Use &#x27;find&#x27; to locate specific information within an opened page.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;data_extraction&quot;: (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;To extract structured data:\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;1. Use &#x27;search&#x27; to find pages with the data you need.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;2. Use &#x27;open&#x27; to load the page content.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;3. Use &#x27;find&#x27; to extract or locate specific patterns or fields.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;website_analysis&quot;: (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;To analyze a website:\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;1. Use &#x27;search&#x27; to discover relevant pages.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;2. Use &#x27;open&#x27; to inspect the content of those pages.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;3. Use &#x27;find&#x27; to search for keywords, features, or patterns.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;competitive_research&quot;: (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;To research competitors:\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;1. Use &#x27;search&#x27; to find competitor websites or pages.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;2. Use &#x27;open&#x27; to review their content.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;3. Use &#x27;find&#x27; to compare features, pricing, or other details.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;market_research&quot;: (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;To conduct market research:\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;1. Use &#x27;search&#x27; for industry trends and news.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;2. Use &#x27;open&#x27; to read relevant articles or reports.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;3. Use &#x27;find&#x27; to extract market insights or statistics.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;content_monitoring&quot;: (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;To monitor web content:\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;1. Use &#x27;search&#x27; to discover new or updated content.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;2. Use &#x27;open&#x27; to review the latest pages.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;3. Use &#x27;find&#x27; to detect changes or specific updates.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Default fallback if task_type is not recognized</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return prompts.get(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        task_type,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;Web browsing guidance:\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;• Use &#x27;search&#x27; to find information.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;• Use &#x27;open&#x27; to read a page.\n&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;• Use &#x27;find&#x27; to locate details within a page.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.mcp_class import MCPModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class MyBrowserSearchToolClass(MCPModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def get_server(self) -&gt; FastMCP:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return mcp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Main function to run the MCP server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    import asyncio</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    import sys</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Simple approach - just run the server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        asyncio.run(mcp.run())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except KeyboardInterrupt:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;Server stopped by user&quot;, file=sys.stderr)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sys.exit(0)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(f&quot;Server error: {e}&quot;, file=sys.stderr)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sys.exit(1)</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>client.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import asyncio</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from openai import AsyncOpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp import Client</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from fastmcp.client.transports import StreamableHttpTransport</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.urls.helper import ClarifaiUrlHelper</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">API_KEY = os.getenv(&quot;CLARIFAI_PAT&quot;, &quot;None&quot;)  # Set env var; avoid hardcoding secrets.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transport = StreamableHttpTransport(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url=ClarifaiUrlHelper().mcp_api_url(),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    headers={&quot;Authorization&quot;: f&quot;Bearer {API_KEY}&quot;},</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">openai_client = AsyncOpenAI(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    api_key=API_KEY,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    base_url=&quot;https://api.clarifai.com/v2/ext/openai/v1&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">MODEL_ID = &quot;https://clarifai.com/openai/chat-completion/models/gpt-oss-120b&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def format_tools_to_openai_function(tools):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;type&quot;: &quot;function&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;function&quot;: {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;name&quot;: tool.name,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;description&quot;: f&quot;[{tool.name}] {tool.description}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;parameters&quot;: tool.inputSchema,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for tool in tools</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def first_model_call(messages, tools):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return await openai_client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model=MODEL_ID,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        temperature=0.4,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools=tools,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_choice=&quot;auto&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        stream=False,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def final_model_call(messages):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Force answer without further tool use</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return await openai_client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model=MODEL_ID,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        messages=messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        temperature=0.4,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tool_choice=&quot;none&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        stream=False,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def run_two_step_answer(user_prompt: str):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # 1. Base messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;role&quot;: &quot;system&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &quot;content&quot;: (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;You can call tools only in the FIRST response if needed to gather info. &quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;After tool results are provided, you MUST produce the final answer without more tool calls.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_prompt},</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Load tool definitions</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    async with Client(transport) as client:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tools_raw = await client.list_tools()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    tools = format_tools_to_openai_function(tools_raw)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # 2. First model pass (may request tool calls)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    first_resp = await first_model_call(messages, tools)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    first_msg = first_resp.choices[0].message</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages.append({</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;role&quot;: &quot;assistant&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;content&quot;: first_msg.content,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;tool_calls&quot;: getattr(first_msg, &quot;tool_calls&quot;, None)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    })</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # If no tool calls, just answer now</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if not first_msg.tool_calls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        print(&quot;Assistant (no tools needed):&quot;, first_msg.content)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return first_msg.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # 3. Execute ALL requested tool calls once</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    async with Client(transport) as client:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for tool_call in first_msg.tool_calls:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            tool_name = tool_call.function.name</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            raw_args = tool_call.function.arguments or &quot;{}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                args = json.loads(raw_args)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            except json.JSONDecodeError:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                args = {}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;\n== Executing tool: {tool_name} | args: {raw_args}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                result = await client.call_tool(tool_name, arguments=args)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                # Collect text parts</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                if hasattr(result, &quot;content&quot;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    parts = [getattr(seg, &quot;text&quot;, &quot;&quot;) for seg in result.content if getattr(seg, &quot;text&quot;, &quot;&quot;)]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    result_text = &quot;\n&quot;.join(parts) if parts else str(result)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    result_text = str(result)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                result_text = f&quot;Tool {tool_name} failed: {e}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                print(result_text)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if len(result_text) &gt; 4000:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                result_text = result_text[:3500] + &quot;\n...[truncated]...&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            messages.append({</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;role&quot;: &quot;tool&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;tool_call_id&quot;: tool_call.id,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;content&quot;: result_text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            })</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # 4. Final model call (NO more tools)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages.append({</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;role&quot;: &quot;system&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;content&quot;: &quot;Use the tool outputs above to craft the final answer. Do not call tools again.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    })</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    final_resp = await final_model_call(messages)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    final_msg = final_resp.choices[0].message.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;\nFinal Answer:\n&quot;, final_msg)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return final_msg</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">async def main():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    await run_two_step_answer(&quot;Who won the 2025 Ballon d&#x27;Or?&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    asyncio.run(main())</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai==11.7.5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">anyio==4.9.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">mcp==1.9.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">fastmcp==2.3.4</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">requests&gt;=2.31.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">beautifulsoup4==4.12.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">lxml&gt;=4.9.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ddgs</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &#x27;3.11&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: 1000m</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: 1Gi</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: test-mcp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: browser-search-mcp-model</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: text-to-text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: clarifai-user-id</span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="multimodal-models">Multimodal Models<a href="#multimodal-models" class="hash-link" aria-label="Direct link to Multimodal Models" title="Direct link to Multimodal Models" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="qwen25-vl-3b-instruct">Qwen2.5 VL 3B Instruct<a href="#qwen25-vl-3b-instruct" class="hash-link" aria-label="Direct link to Qwen2.5 VL 3B Instruct" title="Direct link to Qwen2.5 VL 3B Instruct" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import sys</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sys.path.append(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import Iterator, List</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.openai_class import OpenAIModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_types import Image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.openai_convertor import build_openai_messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from openai import OpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from openai_server_starter import OpenAI_APIServer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class VLLMModel(OpenAIModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    A custom runner that integrates with the Clarifai platform and uses Server inference</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    to process inputs, including text and images.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    client = True  # This will be set in load_model method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model = True  # This will be set in load_model method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Load the model here and start the server.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        os.path.join(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        server_args = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;max_model_len&#x27;: &#x27;8192&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;gpu_memory_utilization&#x27;: 0.95,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;dtype&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;task&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;kv_cache_dtype&#x27;: &#x27;auto&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;tensor_parallel_size&#x27;: 1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;chat_template&#x27;: None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;cpu_offload_gb&#x27;: 0.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;quantization&#x27;: None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;port&#x27;: 23333,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;host&#x27;: &#x27;localhost&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;checkpoints&#x27;: &#x27;runtime&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        stage = server_args.get(&quot;checkpoints&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if stage in [&quot;build&quot;, &quot;runtime&quot;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            config_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            builder = ModelBuilder(config_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            checkpoints = builder.download_checkpoints(stage=stage)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            server_args.update({&quot;checkpoints&quot;: checkpoints})</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if server_args.get(&quot;additional_list_args&quot;) == [&#x27;&#x27;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            server_args.pop(&quot;additional_list_args&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Start server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # This line were generated by `upload` module</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.server = OpenAI_APIServer.from_vllm_backend(**server_args)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.client = OpenAI(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                api_key=&quot;notset&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                base_url=VLLMModel.make_api_url(self.server.host, self.server.port))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model = self._get_model()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;OpenAI {self.model} model loaded successfully!&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def _get_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return self.client.models.list().data[0].id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            raise ConnectionError(&quot;Failed to retrieve model ID from API&quot;) from e</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @staticmethod</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def make_api_url(host: str, port: int, version: str = &quot;v1&quot;) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot;http://{host}:{port}/{version}&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def predict(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                image: Image = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                images: List[Image] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                top_p: float = Param(default=0.95, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;, )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                ) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;This is the method that will be called when the runner is run. It takes in an input and</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        returns an output.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        openai_messages = build_openai_messages(prompt=prompt, image=image, images=images, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        response = self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            messages=openai_messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            top_p=top_p)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if response.usage and response.usage.prompt_tokens and response.usage.completion_tokens:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self.set_output_context(prompt_tokens=response.usage.prompt_tokens, completion_tokens=response.usage.completion_tokens)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return response.choices[0].message.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def generate(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                image: Image = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                images: List[Image] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                chat_history: List[dict] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                max_tokens: int = Param(default=512, description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                temperature: float = Param(default=0.7, description=&quot;A decimal number that determines the degree of randomness in the response&quot;, ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                top_p: float = Param(default=0.95, description=&quot;An alternative to sampling with temperature, where the model considers the results of the tokens with top_p probability mass.&quot;, )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                ) -&gt; Iterator[str]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Example yielding a whole batch of streamed stuff back.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        openai_messages = build_openai_messages(prompt=prompt, image=image, images=images, messages=chat_history)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        for chunk in self.client.chat.completions.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            model=self.model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            messages=openai_messages,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            max_completion_tokens=max_tokens,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            temperature=temperature,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            top_p=top_p,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            stream=True):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            if chunk.choices:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                text = (chunk.choices[0].delta.content</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        if (chunk and chunk.choices[0].delta.content) is not None else &#x27;&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                yield text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def test(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Testing predict...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(self.predict(prompt=&quot;Explain why cat can&#x27;t fly&quot;))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(self.predict(prompt=&quot;Describe this image&quot;, image=Image.from_url(&quot;https://samples.clarifai.com/metro-north.jpg&quot;)))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error in predict {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(&quot;Testing generate...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for each in self.generate(prompt=&quot;Explain why cat can&#x27;t fly&quot;):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                print(each, end=&quot; &quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for each in self.generate(prompt=&quot;Describe this image&quot;, image=Image.from_url(&quot;https://samples.clarifai.com/metro-north.jpg&quot;)):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                print(each, end=&quot; &quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            print(f&quot;Error in generate {e}&quot;)</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/openai_server_starter.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import signal</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import subprocess</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import sys</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import threading</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import List</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import psutil</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">PYTHON_EXEC = sys.executable</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def kill_process_tree(parent_pid, include_parent: bool = True, skip_pid: int = None):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;&quot;&quot;Kill the process and all its child processes.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  if parent_pid is None:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    parent_pid = os.getpid()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    include_parent = False</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    itself = psutil.Process(parent_pid)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  except psutil.NoSuchProcess:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  children = itself.children(recursive=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  for child in children:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if child.pid == skip_pid:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      continue</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      child.kill()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except psutil.NoSuchProcess:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      pass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  if include_parent:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      itself.kill()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Sometime processes cannot be killed with SIGKILL (e.g, PID=1 launched by kubernetes),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # so we send an additional signal to kill them.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      itself.send_signal(signal.SIGQUIT)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except psutil.NoSuchProcess:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      pass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class OpenAI_APIServer:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def __init__(self, **kwargs):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.server_started_event = threading.Event()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.process = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.backend = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.server_thread = None</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def __del__(self, *exc):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # This is important</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # close the server when exit the program</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.close()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def close(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if self.process:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        kill_process_tree(self.process.pid)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      except:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.process.terminate()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if self.server_thread:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      self.server_thread.join()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def wait_for_startup(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.server_started_event.wait()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def validate_if_server_start(self, line: str):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    line_lower = line.lower()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if self.backend in [&quot;vllm&quot;, &quot;sglang&quot;, &quot;lmdeploy&quot;]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if self.backend == &quot;vllm&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return &quot;application startup complete&quot; in line_lower or &quot;vllm api server on&quot; in line_lower</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      else:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return f&quot; running on http://{self.host}:&quot; in line.strip()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    elif self.backend == &quot;llamacpp&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      return &quot;waiting for new tasks&quot; in line_lower</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    elif self.backend == &quot;tgi&quot;:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      return &quot;Connected&quot; in line.strip()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def _start_server(self, cmds):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      env = os.environ.copy()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      env[&quot;VLLM_USAGE_SOURCE&quot;] = &quot;production-docker-image&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      self.process = subprocess.Popen(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          cmds,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          stdout=subprocess.PIPE,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          stderr=subprocess.STDOUT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          text=True,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      for line in self.process.stdout:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Server Log:  &quot; + line.strip())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if self.validate_if_server_start(line):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          self.server_started_event.set()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          # break</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      if self.process:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.process.terminate()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      raise RuntimeError(f&quot;Failed to start Server server: {e}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def start_server_thread(self, cmds: str):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Start the  server in a separate thread</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      self.server_thread = threading.Thread(target=self._start_server, args=(cmds,), daemon=None)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      self.server_thread.start()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # Wait for the server to start</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      self.wait_for_startup()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      raise Exception(e)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @classmethod</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def from_vllm_backend(cls,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        checkpoints,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        limit_mm_per_prompt: str = &#x27;&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        max_model_len: float = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        gpu_memory_utilization: float = 0.9,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        dtype=&quot;auto&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        task=&quot;auto&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        kv_cache_dtype: str = &quot;auto&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        tensor_parallel_size=1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        chat_template: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        cpu_offload_gb: float = 0.,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        quantization: str = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        port=23333,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        host=&quot;localhost&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        additional_list_args: List[str] = []):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Run VLLM OpenAI compatible server</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Args:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      checkpoints (str): model id or path</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      limit_mm_per_prompt (str, optional): For each multimodal plugin, limit how many input instances to allow for each prompt. Expects a comma-separated list of items, e.g.: image=16,video=2 allows a maximum of 16 images and 2 videos per prompt. Defaults to 1 for each modality.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      max_model_len (float, optional):Model context length. If unspecified, will be automatically derived from the model config. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      gpu_memory_utilization (float, optional): The fraction of GPU memory to be used for the model executor, which can range from 0 to 1. For example, a value of 0.5 would imply 50% GPU memory utilization. If unspecified, will use the default value of 0.9. This is a per-instance limit, and only applies to the current vLLM instance.It does not matter if you have another vLLM instance running on the same GPU. For example, if you have two vLLM instances running on the same GPU, you can set the GPU memory utilization to 0.5 for each instance. Defaults to 0.9.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      dtype (str, optional): dtype. Defaults to &quot;float16&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      task (str, optional): The task to use the model for. Each vLLM instance only supports one task, even if the same model can be used for multiple tasks. When the model only supports one task, &quot;auto&quot; can be used to select it; otherwise, you must specify explicitly which task to use. Choices {auto, generate, embedding, embed, classify, score, reward, transcription}. Defaults to &quot;auto&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      kv_cache_dtype (str, optional): Data type for kv cache storage. If “auto”, will use model data type. CUDA 11.8+ supports fp8 (=fp8_e4m3) and fp8_e5m2. ROCm (AMD GPU) supports fp8 (=fp8_e4m3). Defaults to &quot;auto&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      tensor_parallel_size (int, optional): n gpus. Defaults to 1.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      chat_template (str, optional): The file path to the chat template, or the template in single-line form for the specified model. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cpu_offload_gb (float, optional): The space in GiB to offload to CPU, per GPU. Default is 0, which means no offloading. Intuitively, this argument can be seen as a virtual way to increase the GPU memory size. For example, if you have one 24 GB GPU and set this to 10, virtually you can think of it as a 34 GB GPU. Then you can load a 13B model with BF16 weight, which requires at least 26GB GPU memory. Note that this requires fast CPU-GPU interconnect, as part of the model is loaded from CPU memory to GPU memory on the fly in each model forward pass. Defaults to 0.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      quantization (str, optional): quantization format {aqlm,awq,deepspeedfp,tpu_int8,fp8,fbgemm_fp8,modelopt,marlin,gguf,gptq_marlin_24,gptq_marlin,awq_marlin,gptq,compressed-tensors,bitsandbytes,qqq,hqq,experts_int8,neuron_quant,ipex,quark,moe_wna16,None}. Defaults to None.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      port (int, optional): port. Defaults to 23333.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      host (str, optional): host name. Defaults to &quot;localhost&quot;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      additional_list_args (List[str], optional): additional args to run subprocess cmd e.g. [&quot;--arg-name&quot;, &quot;arg value&quot;]. See more at [this document](https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html#vllm-serve). Defaults to [].</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cmds = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        PYTHON_EXEC, &#x27;-m&#x27;, &#x27;vllm.entrypoints.openai.api_server&#x27;, &#x27;--model&#x27;, checkpoints, &#x27;--dtype&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(dtype), &#x27;--task&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(task), &#x27;--kv-cache-dtype&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(kv_cache_dtype), &#x27;--tensor-parallel-size&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(tensor_parallel_size), &#x27;--gpu-memory-utilization&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(gpu_memory_utilization), &#x27;--cpu-offload-gb&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(cpu_offload_gb), &#x27;--port&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(port), &#x27;--host&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        str(host), &quot;--trust-remote-code&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if quantization:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &#x27;--quantization&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          str(quantization),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if chat_template:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &#x27;--chat-template&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          str(chat_template),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if max_model_len:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &#x27;--max-model-len&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          str(max_model_len),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if limit_mm_per_prompt:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cmds += [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          &#x27;--limit-mm-per-prompt&#x27;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          str(limit_mm_per_prompt),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if additional_list_args != []:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      cmds += additional_list_args</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(&quot;CMDS to run vllm server: &quot;, cmds)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    _self = cls()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    _self.host = host</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    _self.port = port</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    _self.backend = &quot;vllm&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    _self.start_server_thread(cmds)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    import time</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    time.sleep(5)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return _self</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch==2.6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">tokenizers==0.21.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">accelerate==1.2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">optimum==1.23.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">xformers</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">einops==0.8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">packaging</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ninja</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">qwen-vl-utils==0.0.8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">timm==1.0.12</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">openai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai&gt;=11.5.0,&lt;12.0.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">psutil</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vllm==0.8.5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers==4.51.1</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Config file for the vLLM runner</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: &quot;Qwen2_5-VL-3B-Instruct&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: &quot;user_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: &quot;app_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: &quot;multimodal-to-text&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &quot;3.11&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &quot;3&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: &quot;14Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type: [&quot;NVIDIA-*&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: &quot;44Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: &quot;huggingface&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: &quot;Qwen/Qwen2.5-VL-3B-Instruct&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  hf_token: &quot;hf_token&quot;</span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="ocr">OCR<a href="#ocr" class="hash-link" aria-label="Direct link to OCR" title="Direct link to OCR" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="nanonets-ocr-small">NanoNets OCR Small<a href="#nanonets-ocr-small" class="hash-link" aria-label="Direct link to NanoNets OCR Small" title="Direct link to NanoNets OCR Small" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from io import BytesIO</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Third-party imports</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from PIL import Image as PILImage</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from transformers import AutoTokenizer, AutoProcessor, AutoModelForImageTextToText</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Clarifai imports</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_class import ModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_types import Image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">DEFAULT_PROMPT = &quot;&quot;&quot;Extract the text from the above document as if you were reading it naturally. Return the tables in html format. Return the equations in LaTeX representation. If there is an image in the document and image caption is not present, add a small description of the image inside the &lt;img&gt;&lt;/img&gt; tag; otherwise, add the image caption inside &lt;img&gt;&lt;/img&gt;. Watermarks should be wrapped in brackets. Ex: &lt;watermark&gt;OFFICIAL COPY&lt;/watermark&gt;. Page numbers should be wrapped in brackets. Ex: &lt;page_number&gt;14&lt;/page_number&gt; or &lt;page_number&gt;9/22&lt;/page_number&gt;. Prefer using ☐ and ☑ for check boxes.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def preprocess_image(image_bytes: bytes) -&gt; PILImage:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Convert image bytes to PIL Image.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return PILImage.open(BytesIO(image_bytes)).convert(&quot;RGB&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class MyRunner(ModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;A custom runner that loads the OCR model and runs it on the input image.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Load the model here.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        builder = ModelBuilder(model_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpoint_path = builder.download_checkpoints(stage=&quot;runtime&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;Running on device: {self.device}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model = AutoModelForImageTextToText.from_pretrained(checkpoint_path).to(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self.device</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.model.eval()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.processor = AutoProcessor.from_pretrained(checkpoint_path)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(&quot;Done loading!&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @ModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def predict(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        image: Image,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        prompt: str = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=DEFAULT_PROMPT, description=&quot;The prompt to use for the OCR model.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_new_tokens: int = Param(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            default=512,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            description=&quot;The maximum number of tokens to generate. Shorter token lengths will provide faster performance.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ) -&gt; str:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;This is the method that will be called when the runner is run. It takes in an input and returns an output.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        messages = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;role&quot;: &quot;user&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                &quot;content&quot;: [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        &quot;type&quot;: &quot;image_url&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        &quot;image_url&quot;: f&quot;data:image/png;base64,{image.bytes}&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                    {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt},</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                ],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        image = preprocess_image(image.bytes)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        text = self.processor.apply_chat_template(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            messages, tokenize=False, add_generation_prompt=True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        inputs = self.processor(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            text=[text], images=[image], padding=True, return_tensors=&quot;pt&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        inputs = inputs.to(self.model.device)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        output_ids = self.model.generate(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            **inputs, max_new_tokens=max_new_tokens, do_sample=False</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        generated_ids = [</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            output_ids[len(input_ids) :]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            for input_ids, output_ids in zip(inputs.input_ids, output_ids)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        output_text = self.processor.batch_decode(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return output_text[0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def test(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Test the model with a sample image.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        import requests  # Import moved here as it&#x27;s only used for testing</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Load a sample image from the IAM database</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        url = &quot;https://dl.a9t9.com/ocr/solarcell.jpg&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        image = Image(bytes=requests.get(url).content)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # image = Image.from_url(url)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        generated_text = self.predict(image)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Log the detected text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;Detected text:\n{generated_text}&quot;)</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai&gt;=11.5.2,&lt;12.0.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pillow==10.4.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch==2.6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">torchvision==0.21.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers&gt;=4.51.1</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: &quot;nanonets-ocr-s&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: &quot;user_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: &quot;app_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: &quot;multimodal-to-text&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &quot;3.11&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &quot;2&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: &quot;18Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type: [&quot;NVIDIA-*&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: &quot;18Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: &quot;huggingface&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: &quot;nanonets/Nanonets-OCR-s&quot;</span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="text-embedder">Text Embedder<a href="#text-embedder" class="hash-link" aria-label="Direct link to Text Embedder" title="Direct link to Text Embedder" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="jina-embeddings-v3">Jina Embeddings v3<a href="#jina-embeddings-v3" class="hash-link" aria-label="Direct link to Jina Embeddings v3" title="Direct link to Jina Embeddings v3" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import List, Iterator</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.openai_class import OpenAIModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import onnxruntime</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from transformers import AutoTokenizer, PretrainedConfig</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.utils.logging import logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#Helper function Mean pool function</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def mean_pooling(model_output: np.ndarray, attention_mask: np.ndarray):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            token_embeddings = model_output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            input_mask_expanded = np.expand_dims(attention_mask, axis=-1)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            input_mask_expanded = np.broadcast_to(input_mask_expanded, token_embeddings.shape)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            sum_embeddings = np.sum(token_embeddings * input_mask_expanded, axis=1)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            sum_mask = np.clip(np.sum(input_mask_expanded, axis=1), a_min=1e-9, a_max=None)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return sum_embeddings / sum_mask</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class Jinaai_embedding_v2(OpenAIModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    A custom runner that integrates with the Clarifai platform and uses Jinaai embedding v2 model to process inputs, including text and images.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    client = True</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model = &quot;jinaai-embedding-v3&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;Load the model here and start the server.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Load checkpoints</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        builder = ModelBuilder(model_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;\nDownloading Jinaai {self.model} model checkpoints...\n&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.checkpoints =  builder.download_checkpoints(stage=&#x27;runtime&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;Checkpoints downloaded to {self.checkpoints}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        #logger.info(&quot;Loading Jinaai embedding v3 model...&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.tokenizer = AutoTokenizer.from_pretrained(self.checkpoints)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.config = PretrainedConfig.from_pretrained(self.checkpoints)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        #logger.info(f&quot;Tokenizer and config loaded from &#x27;jinaai/jinaai-embeddings-v3&#x27;&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self.session = onnxruntime.InferenceSession(self.checkpoints + &#x27;/onnx/model.onnx&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # log that system is ready</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        logger.info(f&quot;Jinaai {self.model} model loaded successfully!&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def tokenize_and_embed(self, input: str):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Tokenize the input text and return the embedding vector.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Args:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            input (str): The input text to be tokenized and embedded.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Returns:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            np.ndarray: The embedding vector for the input text.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Tokenize input</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        input_text = self.tokenizer(input, return_tensors=&#x27;np&#x27;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">           # Prepare inputs for ONNX model</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        task_type = &#x27;text-matching&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        task_id = np.array(self.config.lora_adaptations.index(task_type), dtype=np.int64)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        inputs = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;input_ids&#x27;: input_text[&#x27;input_ids&#x27;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;attention_mask&#x27;: input_text[&#x27;attention_mask&#x27;],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            &#x27;task_id&#x27;: task_id</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Run model</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        outputs = self.session.run(None, inputs)[0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return outputs, input_text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    @OpenAIModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    def predict(self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                input: str,) -&gt; List[float]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Predict method to process the input text and return the embedding vector.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Args:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            input (str): The input text to be processed.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Returns:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            List[float]: The embedding vector for the input text.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">       &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Tokenize and embed the input text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        outputs, input_text = self.tokenize_and_embed(input)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Apply mean pooling and normalization to the model outputs</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        embeddings = mean_pooling(outputs, input_text[&quot;attention_mask&quot;])</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        embeddings = embeddings / np.linalg.norm(embeddings, ord=2, axis=1, keepdims=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return embeddings[0].tolist()</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers #4.52.4</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai #11.4.10</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">onnxruntime</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">numpy</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">model:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: &quot;jinaai-embeddings-v3&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: &quot;user_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: &quot;app_id&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: &quot;text-embedder&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &quot;3.11&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &quot;1&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: &quot;5Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: &quot;huggingface&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: &quot;jinaai/jina-embeddings-v3&quot;</span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="text-to-image">Text-to-Image<a href="#text-to-image" class="hash-link" aria-label="Direct link to Text-to-Image" title="Direct link to Text-to-Image" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="flux-schnell">FLUX Schnell<a href="#flux-schnell" class="hash-link" aria-label="Direct link to FLUX Schnell" title="Direct link to FLUX Schnell" translate="no">​</a></h3>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>1/model.py</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from typing import List</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_class import ModelClass</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_utils import Param</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.utils.data_types import Image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from clarifai.runners.models.model_builder import ModelBuilder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from diffusers import FluxPipeline</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class TextToImageModel(ModelClass):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  A custom runner for the FLUX model that integrates with the Clarifai platform.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def load_model(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;Load the model here.&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # &quot;black-forest-labs/FLUX.1-schnell&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.device = &quot;cuda&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model_path = os.path.dirname(os.path.dirname(__file__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    builder = ModelBuilder(model_path, download_validation_only=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    checkpoints = builder.download_checkpoints(stage=&quot;runtime&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # load model and scheduler</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.pipeline = FluxPipeline.from_pretrained(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      checkpoints,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      torch_dtype=torch.bfloat16</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self.pipeline = self.pipeline.to(self.device)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @ModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def predict(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    prompt: str,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    num_inference_steps: int = Param(default=28, description=&quot;The number of denoising steps. More denoising steps usually lead to a higher quality image at the expense of slower inference.&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    guidance_scale: float = Param(default=3.5, description=&quot;The `guidance_scale` controls how strongly the model follows the conditioning input during generation.&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    negative_prompt: str = Param(default=&quot;&quot;, description=&quot;The prompt to guide what to not include in image generation. Ignored when not using guidance (guidance_scale &lt; 1)&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    true_cfg_scale: float = Param(default=1.0, description=&quot;When &gt; 1.0 and a provided negative_prompt, enables true classifier-free guidance&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    height: int = Param(default=1024, description=&quot;The height in pixels of the generated image. This is set to 1024 by default for the best results.&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    width: int = Param(default=1024, description=&quot;The width in pixels of the generated image. This is set to 1024 by default for the best results.&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    max_sequence_length: int = Param(default=256, description=&quot;Maximum sequence length to use with the prompt&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    seed: int = Param(default=None, description=&quot;Seed value to make generation deterministic.&quot;),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # No need</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sigmas: List[float] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  ) -&gt; Image:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    image = self.pipeline(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        prompt=prompt,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        negative_prompt=negative_prompt,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        guidance_scale=guidance_scale,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        num_inference_steps=num_inference_steps,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_sequence_length=max_sequence_length,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        width=width,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        height=height,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        true_cfg_scale=true_cfg_scale,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        generator=torch.Generator(&quot;cpu&quot;).manual_seed(seed) if seed else None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sigmas=sigmas,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ).images[0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # this is important, delete all model cache to avoid OOM</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    torch.cuda.empty_cache()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return Image.from_pil(image)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  @ModelClass.method</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    prompt: List[str],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    prompt_2: List[str] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    negative_prompt: List[str] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    negative_prompt_2: List[str] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    true_cfg_scale: float = 1.0,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    height: int = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    width: int = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    max_sequence_length: int = 256,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    num_inference_steps: int = 28,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    guidance_scale: float = 3.5,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    seed: int = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sigmas: List[float] = None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  ) -&gt; List[Image]:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Generate an image from the given prompt using the FLUX model.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Args:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      * prompt (`List[str]`): The prompt or prompts to guide the image generation.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      * prompt_2 (`List[str]`, *optional*): The prompt to be sent to `tokenizer_2` and `text_encoder_2`. If not defined, `prompt` is will be used instead.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      * negative_prompt (`List[str]`, *optional*): The prompt to guide what to not include in image generation. Ignored when not using guidance (guidance_scale &lt; 1).</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      * negative_prompt_2 (`List[str]`, *optional*): The negative_prompt to be sent to `tokenizer_2` and `text_encoder_2`. If not defined, `negative_prompt` is will be used instead.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      * height (`int`, *optional*, defaults to model.unet.config.sample_size * model.vae_scale_factor): The height in pixels of the generated image. This is set to 1024 by default for the best results.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      * width (`int`, *optional*, defaults to model.unet.config.sample_size * model.vae_scale_factor): The width in pixels of the generated image. This is set to 1024 by default for the best results.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      * num_inference_steps (`int`, *optional*, defaults to 28): The number of denoising steps. More denoising steps usually lead to a higher quality image at the expense of slower inference.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      * guidance_scale (`float`, *optional*, defaults to 3.5):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          `guidance_scale` is defined as `w` of equation 2. of [Imagen</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale &gt;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          usually at the expense of lower image quality.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      * seed (`int`, *optional*, defaults to None):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">          Seed value passed to `torch.Generator(&quot;cpu&quot;).manual_seed(seed)` (see more [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)) to make generation deterministic.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      * sigmas (`List[float]`, *optional*): Custom sigmas to use for the denoising process with schedulers which support a `sigmas` argument in their `set_timesteps` method. If not defined, the default behavior when `num_inference_steps` is passed will be used.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      * max_sequence_length (`int` defaults to `256`): Maximum sequence length to use with the prompt.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    (see more at this [doc](https://huggingface.co/docs/diffusers/v0.32.2/en/api/pipelines/flux#diffusers.FluxPipeline.__call__))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    assert isinstance(prompt, list), ValueError(&quot;prompt must be a list of string&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    assert len(prompt) &lt;= 4, ValueError(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        f&quot;The provided prompt length ({len(prompt)}) exceeds the maximum limit (4). Please reduce the number of prompts in `prompt`.&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    images = self.pipeline(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        prompt=prompt,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        prompt_2=prompt_2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        negative_prompt=negative_prompt,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        negative_prompt_2=negative_prompt_2,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        guidance_scale=guidance_scale,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        num_inference_steps=num_inference_steps,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_sequence_length=max_sequence_length,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        width=width,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        height=height,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        true_cfg_scale=true_cfg_scale,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        generator=torch.Generator(&quot;cpu&quot;).manual_seed(seed) if seed else None,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sigmas=sigmas,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ).images</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # this is important, delete all model cache to avoid OOM</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    torch.cuda.empty_cache()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return [Image.from_pil(image) for image in images]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  def test(self):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot; </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Test cases only executed when running `clarifai model test-locally`</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    image = self.predict(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    prompt=&quot;A Ghibli animated orange cat, panicked about a deadline, sits in front of a Banana-brand laptop.&quot;, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    negative_prompt=&quot;Ugly, cute&quot;, guidance_scale=7)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(image)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    images = self.create(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        prompt=[&quot;A Ghibli animated orange cat, panicked about a deadline, sits in front of a Banana-brand laptop.&quot;]*3, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        negative_prompt=[&quot;Ugly, cute&quot;]*2, guidance_scale=7)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(images)</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>requirements.txt</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">tokenizers==0.21.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformers&gt;=4.48</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">diffusers==0.32.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">accelerate==1.2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">optimum==1.23.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">xformers</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">einops==0.8.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">requests==2.32.3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sentencepiece==0.2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">numpy&gt;2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ninja</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">aiohttp</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">packaging</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch==2.5.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">clarifai-protocol</span><br></span></code></pre></div></div></div></div></details>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><code>config.yaml</code></summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">model: </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  id: &quot;flux_1-schnell&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  user_id: </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  app_id: </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_type_id: &quot;text-to-image&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  python_version: &quot;3.11&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inference_compute_info:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_limit: &quot;3&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  cpu_memory: &quot;18Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  num_accelerators: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_type: [&quot;NVIDIA-L40S&quot;, &quot;NVIDIA-A100&quot;, &quot;NVIDIA-H100&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  accelerator_memory: &quot;44Gi&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">checkpoints:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  type: huggingface</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  repo_id: black-forest-labs/FLUX.1-schnell</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  hf_token: </span><br></span></code></pre></div></div></div></div></details></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/compute/upload/data-types"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Input and Output Data Types</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/compute/local-runners/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Local Runners</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#hello-world" class="table-of-contents__link toc-highlight">Hello World</a></li><li><a href="#nsfw-image-classifier" class="table-of-contents__link toc-highlight">NSFW Image Classifier</a></li><li><a href="#detr-resnet-image-detector" class="table-of-contents__link toc-highlight">DETR ResNet Image Detector</a></li><li><a href="#image-segmenter" class="table-of-contents__link toc-highlight">Image Segmenter</a><ul><li><a href="#mask2former-ade" class="table-of-contents__link toc-highlight">Mask2Former ADE</a></li></ul></li><li><a href="#image-text-to-image" class="table-of-contents__link toc-highlight">Image-Text-to-Image</a><ul><li><a href="#stable-diffusion-2-depth" class="table-of-contents__link toc-highlight">Stable Diffusion 2 Depth</a></li></ul></li><li><a href="#llm" class="table-of-contents__link toc-highlight">LLM</a><ul><li><a href="#smollm2-17b-instruct-sglang" class="table-of-contents__link toc-highlight">SmolLM2 1.7B Instruct (SGLang)</a></li><li><a href="#llama-32-1b-instruct-hugging-face" class="table-of-contents__link toc-highlight">LLaMA 3.2 1B Instruct (Hugging Face)</a></li><li><a href="#llama-32-3b-instruct-lmdeploy" class="table-of-contents__link toc-highlight">LLaMA 3.2 3B Instruct (LMDeploy)</a></li><li><a href="#gemma-3-1b-instruct-vllm" class="table-of-contents__link toc-highlight">Gemma 3 1B Instruct (vLLM)</a></li><li><a href="#llama-31-8b-tool-calling-vllm" class="table-of-contents__link toc-highlight">LLaMA 3.1 8B Tool Calling (vLLM)</a></li></ul></li><li><a href="#local-runners" class="table-of-contents__link toc-highlight">Local Runners</a><ul><li><a href="#ollama" class="table-of-contents__link toc-highlight">Ollama</a></li></ul></li><li><a href="#mcp" class="table-of-contents__link toc-highlight">MCP</a><ul><li><a href="#browser-tools" class="table-of-contents__link toc-highlight">Browser Tools</a></li><li><a href="#code-execution" class="table-of-contents__link toc-highlight">Code Execution</a></li><li><a href="#code-execution-without-docker-version" class="table-of-contents__link toc-highlight">Code Execution Without Docker Version</a></li><li><a href="#google-drive" class="table-of-contents__link toc-highlight">Google Drive</a></li><li><a href="#math" class="table-of-contents__link toc-highlight">Math</a></li><li><a href="#postgres" class="table-of-contents__link toc-highlight">Postgres</a></li><li><a href="#web-search" class="table-of-contents__link toc-highlight">Web Search</a></li></ul></li><li><a href="#multimodal-models" class="table-of-contents__link toc-highlight">Multimodal Models</a><ul><li><a href="#qwen25-vl-3b-instruct" class="table-of-contents__link toc-highlight">Qwen2.5 VL 3B Instruct</a></li></ul></li><li><a href="#ocr" class="table-of-contents__link toc-highlight">OCR</a><ul><li><a href="#nanonets-ocr-small" class="table-of-contents__link toc-highlight">NanoNets OCR Small</a></li></ul></li><li><a href="#text-embedder" class="table-of-contents__link toc-highlight">Text Embedder</a><ul><li><a href="#jina-embeddings-v3" class="table-of-contents__link toc-highlight">Jina Embeddings v3</a></li></ul></li><li><a href="#text-to-image" class="table-of-contents__link toc-highlight">Text-to-Image</a><ul><li><a href="#flux-schnell" class="table-of-contents__link toc-highlight">FLUX Schnell</a></li></ul></li></ul></div></div></div><div class="custom_doc_item_footer_LMqZ"><div class="banner-primary"><p>Build your next AI app, test and tune popular LLMs models, and much more.</p><a href="https://clarifai.com/explore" target="_blank">Get started for free</a></div><footer class="custom-footer-wrapper_fHnE"><div class="logo-wrapper_GEfd"><img src="/img/logos/clarifai-color-light-logo.svg" class="dark-theme-logo_tdev"><img src="/img/logos/clarifai-color-dark-logo.svg" class="light-theme-logo_cRqu"></div><div class="copyright_aTku">© 2025 Clarifai, Inc. All rights reserved</div><div class="footerSocialIconsWrapper_tJhP"><div class="socialBrands__tjK"><a href="https://github.com/Clarifai" target="_blank" rel="noopener noreferrer" aria-label="Github"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#000" fill-rule="evenodd" d="M9.7 1.5C4.896 1.5 1 5.401 1 10.216a8.715 8.715 0 0 0 5.95 8.269c.436.08.594-.189.594-.42 0-.207-.007-.756-.011-1.482-2.421.526-2.932-1.169-2.932-1.169-.395-1.007-.966-1.275-.966-1.275-.79-.54.06-.53.06-.53.873.062 1.333.899 1.333.899.776 1.33 2.036.946 2.532.724.08-.563.304-.947.553-1.165C6.18 13.847 4.15 13.1 4.15 9.76c0-.951.339-1.73.895-2.34-.09-.22-.388-1.106.085-2.305 0 0 .731-.235 2.393.893a8.3 8.3 0 0 1 2.178-.293c.74.003 1.483.1 2.178.293 1.662-1.128 2.39-.894 2.39-.894.476 1.2.176 2.087.088 2.307a3.37 3.37 0 0 1 .894 2.339c0 3.348-2.035 4.085-3.973 4.3.313.27.59.8.59 1.614 0 1.165-.01 2.105-.01 2.39 0 .234.156.505.598.42a8.72 8.72 0 0 0 5.946-8.268C18.402 5.4 14.505 1.5 9.7 1.5" clip-rule="evenodd"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://twitter.com/clarifai" target="_blank" rel="noopener noreferrer" aria-label="Twitter"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#000" d="M14.6 3h2.454l-5.36 6.142L18 17.5h-4.937l-3.867-5.07-4.425 5.07H2.316l5.733-6.57L2 3h5.063l3.495 4.633zm-.86 13.028h1.36L6.323 4.395H4.865z"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" aria-label="Discord"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#7289DA" d="M13.63 15.997c.514.65 1.13 1.387 1.13 1.387 3.784-.12 5.24-2.603 5.24-2.603 0-5.514-2.466-9.983-2.466-9.983C15.07 2.948 12.723 3 12.723 3l-.24.274c2.91.89 4.264 2.175 4.264 2.175a14 14 0 0 0-5.155-1.644 14.5 14.5 0 0 0-3.458.034c-.103 0-.189.017-.292.034-.599.052-2.054.274-3.887 1.08-.633.29-1.01.496-1.01.496S4.366 4.096 7.45 3.206L7.277 3S4.932 2.95 2.466 4.798c0 0-2.466 4.47-2.466 9.983 0 0 1.438 2.483 5.223 2.603 0 0 .633-.77 1.147-1.421-2.175-.651-2.997-2.021-2.997-2.021s.172.12.48.291c.017.017.034.034.068.051.052.035.103.052.154.086.428.24.857.428 1.25.582.702.274 1.541.548 2.517.736 1.285.24 2.792.326 4.435.018a11.3 11.3 0 0 0 2.483-.737 9.8 9.8 0 0 0 1.97-1.01s-.857 1.404-3.1 2.038"></path><path fill="#fff" d="M6.884 9.147c-.976 0-1.746.857-1.746 1.901s.787 1.9 1.746 1.9c.976 0 1.747-.855 1.747-1.9.017-1.044-.77-1.9-1.747-1.9m6.25 0c-.976 0-1.746.857-1.746 1.901s.787 1.9 1.746 1.9c.976 0 1.747-.855 1.747-1.9s-.77-1.9-1.747-1.9"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://www.youtube.com/@theworldsai" target="_blank" rel="noopener noreferrer" aria-label="Youtube"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="20" preserveAspectRatio="xMidYMid" viewBox="0 0 256 180"><path fill="red" d="M250.346 28.075A32.18 32.18 0 0 0 227.69 5.418C207.824 0 127.87 0 127.87 0S47.912.164 28.046 5.582A32.18 32.18 0 0 0 5.39 28.24c-6.009 35.298-8.34 89.084.165 122.97a32.18 32.18 0 0 0 22.656 22.657c19.866 5.418 99.822 5.418 99.822 5.418s79.955 0 99.82-5.418a32.18 32.18 0 0 0 22.657-22.657c6.338-35.348 8.291-89.1-.164-123.134Z"></path><path fill="#FFF" d="m102.421 128.06 66.328-38.418-66.328-38.418z"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://www.linkedin.com/company/clarifai" target="_blank" rel="noopener noreferrer" aria-label="Linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><g clip-path="url(#a)"><path fill="#0A66C2" d="M16.819 2H3.18A1.18 1.18 0 0 0 2 3.181V16.82A1.18 1.18 0 0 0 3.181 18H16.82A1.18 1.18 0 0 0 18 16.819V3.18A1.18 1.18 0 0 0 16.819 2M6.769 15.63H4.363V7.989H6.77zm-1.205-8.7a1.381 1.381 0 1 1 1.39-1.38 1.36 1.36 0 0 1-1.39 1.38m10.072 8.707H13.23v-4.175c0-1.23-.523-1.61-1.199-1.61-.713 0-1.413.537-1.413 1.641v4.144H8.213V7.994h2.314v1.06h.03c.233-.47 1.046-1.274 2.287-1.274 1.343 0 2.793.797 2.793 3.13z"></path></g><defs><clipPath id="a"><path fill="#fff" d="M2 2h16v16H2z"></path></clipPath></defs></svg></a></div></div></footer></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://clarifai.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Clarifai Website<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.clarifai.com/explore/contact-us" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contact Us<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/@theworldsai" target="_blank" rel="noopener noreferrer" class="footer__link-item">YouTube<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/company/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/Clarifai/docs" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Clarifai, Inc.</div></div></div></footer></div>
</body>
</html>