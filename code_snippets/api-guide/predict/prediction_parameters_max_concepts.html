<!--index.html file-->
<script>
    ////////////////////////////////////////////////////////////////////////////////////
    // In this section, we set the user authentication, app and model IDs, url of the image
    // we want as an input, and prediction language. Change these strings to run your own example.
    ////////////////////////////////////////////////////////////////////////////////////

    const USER_ID = 'YOUR_USER_ID_HERE';
    // Your PAT (Personal Access Token) can be found in the portal under Authentification
    const PAT = 'YOUR_PAT_HERE';
    const APP_ID = 'YOUR_APP_ID_HERE';
    // Change these to whatever you want to process
    const MODEL_ID = 'general-image-recognition'
    const IMAGE_URL = 'https://samples.clarifai.com/metro-north.jpg'
    const MAX_CONCEPTS = 3

    ///////////////////////////////////////////////////////////////////////////////////
    // YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE
    ///////////////////////////////////////////////////////////////////////////////////

    const raw = JSON.stringify({
        "user_app_id": {
            "user_id": USER_ID,
            "app_id": APP_ID
        },
        "inputs": [
            {
                "data": {
                    "image": {
                        "url": IMAGE_URL
                    }
                }
            }
        ],
        "model": {
            "output_info": {
                "output_config": {
                    "max_concepts": MAX_CONCEPTS
                }
            }
        }
    });

    const requestOptions = {
        method: 'POST',
        headers: {
            'Accept': 'application/json',
            'Authorization': 'Key ' + PAT
        },
        body: raw
    };

    fetch("https://api.clarifai.com/v2/models/" + MODEL_ID + "/outputs", requestOptions)
        .then(response => response.text())
        .then(result => console.log(result))
        .catch(error => console.log('error', error));
</script>