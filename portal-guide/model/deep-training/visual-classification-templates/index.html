<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-portal-guide/model/deep-training/visual-classification-templates">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.0">
<title data-rh="true">Visual Classification Templates | Clarifai Guide</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://docs.clarifai.com/portal-guide/model/deep-training/visual-classification-templates"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Visual Classification Templates | Clarifai Guide"><meta data-rh="true" name="description" content="Learn about our visual classification templates"><meta data-rh="true" property="og:description" content="Learn about our visual classification templates"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docs.clarifai.com/portal-guide/model/deep-training/visual-classification-templates"><link data-rh="true" rel="alternate" href="https://docs.clarifai.com/portal-guide/model/deep-training/visual-classification-templates" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.clarifai.com/portal-guide/model/deep-training/visual-classification-templates" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://E9LMD97ZH2-dsn.algolia.net" crossorigin="anonymous"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EN8LWMPFVR"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-EN8LWMPFVR",{anonymize_ip:!0})</script>


<link rel="search" type="application/opensearchdescription+xml" title="Clarifai Guide" href="/opensearch.xml">
<!-- Google Tag Manager -->
    <script>!function(e,t,a,n,g){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var m=t.getElementsByTagName(a)[0],r=t.createElement(a);r.async=!0,r.src="https://www.googletagmanager.com/gtm.js?id=GTM-5W9P7GR",m.parentNode.insertBefore(r,m)}(window,document,"script","dataLayer")</script>
    <!-- End Google Tag Manager --><link rel="stylesheet" href="/assets/css/styles.f196ca18.css">
<link rel="preload" href="/assets/js/runtime~main.1b291614.js" as="script">
<link rel="preload" href="/assets/js/main.5d8d05ee.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Clarifai" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="Clarifai" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Clarifai Guide</b></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/Clarifai/docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://join.slack.com/t/clarifaicommunity/shared_invite/zt-1jehqesme-l60djcd3c_4a1eCV~uPUjQ" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Community Slack<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://api.clarifai.com/api-doc/?url=https://api.clarifai.com/v2/swagger.json" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Swagger API Guide<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/">Welcome</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Clarifai Basics</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/clarifai-basics/start-here-5-mins-or-less">Start Here (5 mins or less!)</a><button aria-label="Toggle the collapsible sidebar category &#x27;Start Here (5 mins or less!)&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/clarifai-basics/glossary">Key Terminology to Know</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/clarifai-basics/applications/">Applications</a><button aria-label="Toggle the collapsible sidebar category &#x27;Applications&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/clarifai-basics/authentication/">Authentication</a><button aria-label="Toggle the collapsible sidebar category &#x27;Authentication&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/clarifai-basics/community">Get Started With Community Portal</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Tutorials</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/tutorials/node-js-tutorial">Add AI to a Node.js Web App</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/tutorials/how-to-evaluate-an-image-classification-model">How to Evaluate An Image Classification Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/tutorials/image-classification-detection-segmentation">Image classification vs detection vs segmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/tutorials/organizations-and-teams">Organization and Teams</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Python SDK Guide</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/python-sdk/sdk-overview">Installation Guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/python-sdk/tutorial">Tutorial</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/python-sdk/api-reference">API Reference</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Integrations</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/integrations/langchain/">LangChain</a><button aria-label="Toggle the collapsible sidebar category &#x27;LangChain&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/integrations/llamaindex/">LlamaIndex</a><button aria-label="Toggle the collapsible sidebar category &#x27;LlamaIndex&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/integrations/databricks/">Databricks</a><button aria-label="Toggle the collapsible sidebar category &#x27;Databricks&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">API Guide</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/api-guide/api-overview/">Clarifai API Basics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Clarifai API Basics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/api-guide/data/">Your Data</a><button aria-label="Toggle the collapsible sidebar category &#x27;Your Data&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/api-guide/predict/">Making Predictions</a><button aria-label="Toggle the collapsible sidebar category &#x27;Making Predictions&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/api-guide/concepts/">Creating and Managing Concepts</a><button aria-label="Toggle the collapsible sidebar category &#x27;Creating and Managing Concepts&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/api-guide/annotate/">Labeling Your Data</a><button aria-label="Toggle the collapsible sidebar category &#x27;Labeling Your Data&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/api-guide/model/">Creating and Training Models</a><button aria-label="Toggle the collapsible sidebar category &#x27;Creating and Training Models&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/api-guide/evaluate/">Evaluating Models</a><button aria-label="Toggle the collapsible sidebar category &#x27;Evaluating Models&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/api-guide/workflows/">Creating Workflows</a><button aria-label="Toggle the collapsible sidebar category &#x27;Creating Workflows&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/api-guide/search/">Search, Sort, Filter, and Save</a><button aria-label="Toggle the collapsible sidebar category &#x27;Search, Sort, Filter, and Save&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/api-guide/advanced-topics/">Advanced Topics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Advanced Topics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--active">Portal Guide</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/portal-overview">Clarifai Portal Basics</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/portal-guide/data/">Your Data</a><button aria-label="Toggle the collapsible sidebar category &#x27;Your Data&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/ppredict">Making Predictions</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/portal-guide/concepts/">Creating and Managing Concepts</a><button aria-label="Toggle the collapsible sidebar category &#x27;Creating and Managing Concepts&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/portal-guide/annotate/">Labeling Your Data</a><button aria-label="Toggle the collapsible sidebar category &#x27;Labeling Your Data&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/portal-guide/datasets/">Datasets</a><button aria-label="Toggle the collapsible sidebar category &#x27;Datasets&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/portal-guide/model/">Creating and Training Models</a><button aria-label="Toggle the collapsible sidebar category &#x27;Creating and Training Models&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/model/clarifai-models">Clarifai Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/model/pcustom-model-walkthrough">Custom Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/model/training-basics">Training Basics</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/model/training-faqs">Model Training FAQs</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/portal-guide/model/model-types/">Model Types</a><button aria-label="Toggle the collapsible sidebar category &#x27;Model Types&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/portal-guide/model/deep-training/">Deep Fine-Tuning Templates</a><button aria-label="Toggle the collapsible sidebar category &#x27;Deep Fine-Tuning Templates&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/portal-guide/model/deep-training/visual-classification-templates">Visual Classification Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/model/deep-training/visual-detection-templates">Visual Detection Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/model/deep-training/visual-embedding-templates">Visual Embedding Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/model/deep-training/visual-segmenter-templates">Visual Segmenter Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/model/deep-training/text-templates">Text Fine-Tuning Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/model/deep-training/custom-templates">Create Your Own Template</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/portal-guide/model/agent-system-operators/">Agent System Operators</a><button aria-label="Toggle the collapsible sidebar category &#x27;Agent System Operators&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/model/hf-model-importer">Import Models from Hugging Face</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/model/local-model-upload">Local Model Upload</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/model-versions/">Creating and Managing Model Versions</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/portal-guide/evaluate/">Evaluating Models</a><button aria-label="Toggle the collapsible sidebar category &#x27;Evaluating Models&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/portal-guide/workflows/">Creating Workflows</a><button aria-label="Toggle the collapsible sidebar category &#x27;Creating Workflows&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/portal-guide/modules/">Modules</a><button aria-label="Toggle the collapsible sidebar category &#x27;Modules&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/portal-guide/psearch/">Smart Search: Search, Sort, Filter, &amp; Save</a><button aria-label="Toggle the collapsible sidebar category &#x27;Smart Search: Search, Sort, Filter, &amp; Save&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/portal-guide/clarifai-organizations/">Clarifai Organizations</a><button aria-label="Toggle the collapsible sidebar category &#x27;Clarifai Organizations&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/portal-guide/usage-dashboard">Usage Dashboard</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/portal-guide/advanced-topics">Advanced Topics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Advanced Topics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Data Labeling Services</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/data-labeling-services/labeling-services">Scribe LabelForce</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Product Updates</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/product-updates/upcoming-api-changes/">Upcoming Platform Changes</a><button aria-label="Toggle the collapsible sidebar category &#x27;Upcoming Platform Changes&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/product-updates/changelog">Changelog</a><button aria-label="Toggle the collapsible sidebar category &#x27;Changelog&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Additional Resources</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://status.clarifai.com/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">API Status<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://www.clarifai.com/blog/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">Clarifai Blog<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://help.clarifai.com/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">Clarifai Help<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://clarifai.com/explore" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">Clarifai Community<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Portal Guide</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/portal-guide/model/"><span itemprop="name">Creating and Training Models</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/portal-guide/model/deep-training/"><span itemprop="name">Deep Fine-Tuning Templates</span></a><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Visual Classification Templates</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Visual Classification Templates</h1><p><strong>Learn about our visual classification templates</strong></p><hr><p>Clarifai visual classification templates let you train a model to classify objects in your image inputs. Each template comes with its own hyperparameters, which you can tune to influence “how” your model learns. With hyperparameters, you can customize and fine-tune a template to suit your specific tasks and achieve better performance.</p><div class="theme-admonition theme-admonition-tip alert alert--success admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_S0QG"><p>You can customize most hyperparameters by specifying the following values:</p><ul><li><code>minimum</code>—the minimum value a given parameter can take.</li><li><code>maximum</code>—the maximum value a given parameter can take.</li><li><code>step</code>—determines how much you can increment or decrement the minimum or maximum value in a single click/change.</li></ul></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="mmclassification_resnet_50_rsb_a1">MMClassification_ResNet_50_RSB_A1<a href="#mmclassification_resnet_50_rsb_a1" class="hash-link" aria-label="Direct link to MMClassification_ResNet_50_RSB_A1" title="Direct link to MMClassification_ResNet_50_RSB_A1">​</a></h2><p>This template is a customized variant of the ResNet-50 architecture for multimodal classification tasks. Let’s break down the components in the naming of the deep learning model architecture:</p><ul><li><p><strong>MMClassification:</strong> This refers to the <a href="https://github.com/open-mmlab/mmpretrain/tree/main" target="_blank" rel="noopener noreferrer">MMClassification toolkit</a> that is designed for image classification tasks. </p></li><li><p><strong>ResNet_50:</strong> This refers to a specific variant of the Residual Network (ResNet) architecture. ResNet is a popular deep neural network architecture known for its skip connections that help alleviate the vanishing gradient problem. The number &quot;50&quot; typically denotes the depth or number of layers in the ResNet model.</p></li><li><p><strong>RSB_A1:</strong> This refers to a particular modification, adaptation, or variant of the ResNet architecture.</p></li></ul><p>The <strong>MMClassification_ResNet_50_RSB_A1</strong> template supports the following hyperparameters:</p><ul><li><strong>Image size</strong>—This is the image size for training and inference. ResNet uses square images. Images are scaled for efficient processing, and a lower number will take up less memory and run faster. A higher number will have more pixel information to train on and will increase accuracy.</li><li><strong>Batch size</strong>—The number of images used during training. Increased batch size allows for a better approximation of gradient over those samples. Batches allow for stochastic gradient descent, by choosing a random set of X images for each training update. You may want to increase the batch size if the model is large and takes a long time to train. You may also want to increase the batch size if your total number of model concepts is larger than the batch size (you may want to increase it to around 2x the category count). The minimum value it supports for customization is <code>1</code>, while the maximum is <code>256</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Num epochs</strong>—This is the total number of epochs to train for. An epoch is defined as one-pass over the entire dataset. If you increase it, the model will take longer to train, but it could make the model more robust. The minimum value it supports for customization is <code>1</code>, while the maximum is <code>600</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Per item_lrate</strong>—This is the initial learning rate per item; it&#x27;s the rate that the model weights are changed per item. The <strong>lrate</strong> (learning rate) is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function. The overall learning rate (per step) is calculated by <code>lrate = batch_size * per_item_lrate</code>. The minimum value it supports for customization is <code>0.0</code>.</li><li><strong>Weight decay</strong>—This is the weight decay value. It is used to prevent overfitting by penalizing large weights in the model. The minimum value it supports for customization is <code>0.0</code>, while the maximum is <code>1</code>. </li><li><strong>Per item_min_lrate</strong>—This is the minimum learning (per item) at the end of training using the cosine schedule. The minimum value it supports for customization is <code>0.0</code>. </li><li><strong>Warmup iters</strong>—This is the number of steps in the warmup phase, during which the learning rate gradually increases before reaching its specified value.  The minimum value it supports for customization is <code>0.0</code>. </li><li><strong>Warmup ratio</strong>—The warmup phase learning rate multiplier, which scales the learning rate during the warmup phase.</li><li><strong>Pretrained weights</strong>—This specifies whether to init the model with pre-trained weights. You can choose either <code>None</code> or <code>ImageNet-1k</code> (default) for this parameter. </li><li><strong>Flip probability</strong>—This is the probability that an image will be randomly flipped during training. Flipping images horizontally or vertically can augment the dataset and improve model generalization. The minimum value it supports for customization is <code>0.0</code>, while the maximum is <code>1</code>. </li><li><strong>Flip direction</strong>—This is the direction to randomly flip during training. You can choose either <code>horizontal</code> (default) or <code>vertical</code> for this parameter. </li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="clarifai_inceptionbatchnorm">Clarifai_InceptionBatchNorm<a href="#clarifai_inceptionbatchnorm" class="hash-link" aria-label="Direct link to Clarifai_InceptionBatchNorm" title="Direct link to Clarifai_InceptionBatchNorm">​</a></h2><p>This is an image classifier template based on the Inception architecture, which has been pre-trained on a combination of the ImageNet-21K dataset and additional image classification data.</p><p>The Inception architecture, initially introduced by Google, is known for its effectiveness in image classification tasks. It utilizes various convolutional layers and pooling operations to extract hierarchical features from images, enabling accurate classification.</p><p>By leveraging transfer learning, the pretrained Inception model can be used as a starting point for training an image classifier on a specific dataset or task.</p><p>In this case, the model has been pre-trained on the ImageNet-21K dataset, which consists of millions of labeled images from a wide range of categories. This dataset serves as a general-purpose pretraining source, providing the model with a foundation of knowledge about various visual concepts and features.</p><p>Additionally, the model has been further trained or fine-tuned on additional image classification data. This suggests that specific image datasets related to the intended classification task or domain have been utilized to enhance the model&#x27;s performance and adapt it to the specific context.</p><p>The template is implemented using the Batch Normalization technique. The Batch Normalization method is a normalization technique that helps accelerate training and improve model performance by reducing internal covariate shift.</p><p>By incorporating Batch Normalization into the Inception architecture, the <strong>Clarifai_InceptionBatchNorm</strong> classifier achieves better generalization and stability during training. It allows for efficient and accurate classification of images, leveraging the rich pretraining on the ImageNet-21K dataset and the additional image classification data.</p><p>The <strong>Clarifai_InceptionBatchNorm</strong> template supports the following hyperparameters:</p><ul><li><strong>Logreg</strong>—This specifies whether to use sigmoid units (logreg=1) or softmax (logreg=0); you can choose either &quot;Logistic Regression&quot; or &quot;Softmax&quot; as the activation function of the output layer. The default setting, 1, corresponds to Logistic Regression and will allow for multiple True concepts (i.e., P &gt; 0.5) to be predicted for a given input. Conversely, specify a value of 0 to implement Softmax if your concepts should be treated as &quot;mutually exclusive&quot; (i.e., only one concept could be correctly assigned to a given input). This will result in each prediction output representing a discrete probability distribution (i.e., all predicted values sum to 1). The minimum value it supports for customization is <code>0</code>, while the maximum is <code>1</code>—with an incremental or decremental step of <code>1</code>.  </li><li><strong>Image size</strong>—This is the input image size, specifically the minimum side dimension. Images are scaled for efficient processing, and a lower number will take up less memory and run faster. A higher number will have more pixel information to train on and will increase accuracy. The minimum value it supports for customization is <code>32</code>, while the maximum is <code>1024</code>—with an incremental or decremental step of <code>16</code>. </li><li><strong>Batch size</strong>—The number of images used during training. Increased batch size allows for a better approximation of gradient over those samples. Batches allow for stochastic gradient descent, by choosing a random set of X images for each training update. You may want to increase the batch size if the model is large and takes a long time to train. You may also want to increase the batch size if your total number of model concepts is larger than the batch size (you may want to increase it to around 2x the category count). The minimum value it supports for customization is <code>1</code>, while the maximum is <code>128</code>—with an incremental or decremental step of <code>1</code>.  </li><li><strong>Init epochs</strong>—This is the number of epochs to run at the initial learning rate before the first step/change in the learning rate. An epoch is defined as one-pass over the entire dataset. If you increase it, the model will take longer to train, but it could make the model more robust. The minimum value it supports for customization is <code>1</code>, while the maximum is <code>200</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Step epochs</strong>—This is the number of epochs between learning rate decreases. The learning rate will be adjusted after each &quot;Step epochs&quot; number of epochs. The minimum value it supports for customization is <code>1</code>, while the maximum is <code>200</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Num epochs</strong>—This is the total number of epochs to train the model. It determines how many passes the model makes over the entire dataset during training. The minimum value it supports for customization is <code>1</code>, while the maximum is <code>200</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Per item_lrate</strong>—This is the initial learning rate per item; it&#x27;s the rate that the model weights are changed per item. The overall learning rate (per step) is calculated by <code>lrate = batch_size * per_item_lrate</code>. The minimum value it supports for customization is <code>0.0</code>. </li><li><strong>Num items_per_epoch</strong>—This is the number of input images per &quot;epoch.&quot; The default value is the number of images in the dataset.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="clarifai_inceptionv2">Clarifai_InceptionV2<a href="#clarifai_inceptionv2" class="hash-link" aria-label="Direct link to Clarifai_InceptionV2" title="Direct link to Clarifai_InceptionV2">​</a></h2><p>This template is an implementation of the InceptionV2 architecture without any modifications, starting with randomly initialized weights. This means that the model does not utilize any pretraining on large-scale datasets like ImageNet or any other specific initialization method.</p><p>Instead, it begins with random parameter values for all the layers in the InceptionV2 network. This allows for training the model from scratch or adapting it to a specific task or dataset by optimizing the weights based on the provided training data.</p><p>The InceptionV2 architecture is a variant of the Inception architecture, which was introduced by researchers at Google as a deep convolutional neural network (CNN) for image classification tasks. InceptionV2 is an improvement upon the original Inception architecture, also known as InceptionV1.</p><p>The main goal of the InceptionV2 architecture, like its predecessor, is to efficiently capture multi-scale information from images by utilizing various convolutional layers with different receptive field sizes. This allows the network to handle objects of different scales and capture both fine-grained and high-level features simultaneously.</p><p>The <strong>Clarifai_InceptionV2</strong> template supports the following hyperparameters:</p><ul><li><strong>Logreg</strong>—This specifies whether to use sigmoid units (logreg=1) or softmax (logreg=0); you can choose either &quot;Logistic Regression&quot; or &quot;Softmax&quot; as the activation function of the output layer. The default setting, 1, corresponds to Logistic Regression and will allow for multiple True concepts (i.e., P &gt; 0.5) to be predicted for a given input. Conversely, specify a value of 0 to implement Softmax if your concepts should be treated as &quot;mutually exclusive&quot; (i.e., only one concept could be correctly assigned to a given input). This will result in each prediction output representing a discrete probability distribution (i.e., all predicted values sum to 1). The minimum value it supports for customization is <code>0</code>, while the maximum is <code>1</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Image size</strong>—This is the input image size, specifically the minimum side dimension. Images are scaled for efficient processing, and a lower number will take up less memory and run faster. A higher number will have more pixel information to train on and will increase accuracy. The minimum value it supports for customization is <code>32</code>, while the maximum is <code>1024</code>—with an incremental or decremental step of <code>16</code>. </li><li><strong>Batch size</strong>—The number of images used during training. Increased batch size allows for a better approximation of gradient over those samples. Batches allow for stochastic gradient descent, by choosing a random set of X images for each training update. You may want to increase the batch size if the model is large and takes a long time to train. You may also want to increase the batch size if your total number of model concepts is larger than the batch size (you may want to increase it to around 2x the category count). The minimum value it supports for customization is <code>1</code>, while the maximum is <code>128</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Init epochs</strong>—This is the number of epochs to run at the initial learning rate before the first step/change in the learning rate. An epoch is defined as one-pass over the entire dataset. If you increase it, the model will take longer to train, but it could make the model more robust. The minimum value it supports for customization is <code>1</code>, while the maximum is <code>200</code>—with an incremental or decremental step of <code>1</code>.  </li><li><strong>Step epochs</strong>—This is the number of epochs between learning rate decreases. The learning rate will be adjusted after each &quot;Step epochs&quot; number of epochs. The minimum value it supports for customization is <code>1</code>, while the maximum is <code>200</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Num epochs</strong>—This is the total number of epochs to train the model. It determines how many passes the model makes over the entire dataset during training. The minimum value it supports for customization is <code>1</code>, while the maximum is <code>200</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Per item_lrate</strong>—This is the initial learning rate per item; it&#x27;s the rate that the model weights are changed per item. The overall learning rate (per step) is calculated by <code>lrate = batch_size * per_item_lrate</code>. The minimum value it supports for customization is <code>0.0</code>. </li><li><strong>Num items_per_epoch</strong>—This is the number of input images per &quot;epoch.&quot; The default value is the number of images in the dataset.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="clarifai_resnext">Clarifai_ResNext<a href="#clarifai_resnext" class="hash-link" aria-label="Direct link to Clarifai_ResNext" title="Direct link to Clarifai_ResNext">​</a></h2><p>This template combines the power of the ResNeXt architecture, pre-trained on ImageNet-21K, with fine-tuning on domain-specific image classification data, and tailored modifications to meet Clarifai&#x27;s unique requirements.</p><p><a href="https://github.com/open-mmlab/mmpretrain/tree/main/configs/resnext" target="_blank" rel="noopener noreferrer">ResNeXt</a>, short for &quot;Residual Next,&quot; is a deep convolutional neural network (CNN) architecture that extends the ResNet (Residual Network) architecture. It was introduced by researchers at Facebook AI Research (FAIR) as an advancement in the field of computer vision.</p><p>ResNeXt introduces the concept of &quot;cardinality&quot; to enhance the representational power of the network. The cardinality represents the number of parallel paths within each network block, and it captures different types of feature interactions. Unlike the original ResNet architecture, which focuses on increasing depth or width,
ResNeXt achieves higher model capacity by increasing the number of parallel branches, thus allowing for richer and more diverse feature representations.</p><p>The main idea behind ResNeXt is to provide a flexible and scalable architecture that can be easily adjusted based on available computational resources and requirements. By varying the cardinality parameter, ResNeXt can be customized to balance model complexity and performance.</p><p>ResNeXt architectures have demonstrated superior performance on various computer vision tasks, particularly image classification, by leveraging the power of deep residual connections, which enable efficient training of very deep networks. These networks have achieved state-of-the-art results on benchmark datasets, such as ImageNet.</p><p>This implementation is pre-trained on the ImageNet-21K dataset, which encompasses millions of labeled images across a diverse range of categories. By leveraging this large-scale pretraining, <strong>Clarifai_ResNext</strong> benefits from learning rich and generalizable visual representations from the vast and diverse ImageNet-21K dataset.</p><p>Additionally, <strong>Clarifai_ResNext</strong> has been further trained or fine-tuned on additional image classification data specific to the target domain or task. This additional training ensures that the model is adapted to the nuances and characteristics of the specific image classification problem, further improving its performance and accuracy within the desired context.</p><p>The <strong>Clarifai_ResNext</strong> template supports the following hyperparameters:</p><ul><li><strong>Logreg</strong>—This specifies whether to use sigmoid units (logreg=1) or softmax (logreg=0); you can choose either &quot;Logistic Regression&quot; or &quot;Softmax&quot; as the activation function of the output layer. The default setting, 1, corresponds to Logistic Regression and will allow for multiple True concepts (i.e., P &gt; 0.5) to be predicted for a given input. Conversely, specify a value of 0 to implement Softmax if your concepts should be treated as &quot;mutually exclusive&quot; (i.e., only one concept could be correctly assigned to a given input). This will result in each prediction output representing a discrete probability distribution (i.e., all predicted values sum to 1). The minimum value it supports for customization is <code>0</code>, while the maximum is <code>1</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Image size</strong>—This is the input image size, specifically the minimum side dimension. Images are scaled for efficient processing, and a lower number will take up less memory and run faster. A higher number will have more pixel information to train on and will increase accuracy. The minimum value it supports for customization is <code>32</code>, while the maximum is <code>1024</code>—with an incremental or decremental step of <code>16</code>.  </li><li><strong>Batch size</strong>—The number of images used during training. Increased batch size allows for a better approximation of gradient over those samples. Batches allow for stochastic gradient descent, by choosing a random set of X images for each training update. You may want to increase the batch size if the model is large and takes a long time to train. You may also want to increase the batch size if your total number of model concepts is larger than the batch size (you may want to increase it to around 2x the category count). The minimum value it supports for customization is <code>1</code>, while the maximum is <code>128</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Init epochs</strong>—This is the number of epochs to run at the initial learning rate before the first step/change in the learning rate. An epoch is defined as one-pass over the entire dataset. If you increase it, the model will take longer to train, but it could make the model more robust. The minimum value it supports for customization is <code>1</code>, while the maximum is <code>200</code>—with an incremental or decremental step of <code>1</code>.  </li><li><strong>Step epochs</strong>—This is the number of epochs between learning rate decreases. The learning rate will be adjusted after each &quot;Step epochs&quot; number of epochs. The minimum value it supports for customization is <code>1</code>, while the maximum is <code>200</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Num epochs</strong>—This is the total number of epochs to train the model. It determines how many passes the model makes over the entire dataset during training. The minimum value it supports for customization is <code>1</code>, while the maximum is <code>200</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Per item_lrate</strong>—This is the initial learning rate per item; it&#x27;s the rate that the model weights are changed per item. The overall learning rate (per step) is calculated by <code>lrate = batch_size * per_item_lrate</code>. The minimum value it supports for customization is <code>0.0</code>.</li><li><strong>Num items_per_epoch</strong>—This is the number of input images per &quot;epoch.&quot; The default value is the number of images in the dataset.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="clarifai_inceptiontransferembednorm">Clarifai_InceptionTransferEmbedNorm<a href="#clarifai_inceptiontransferembednorm" class="hash-link" aria-label="Direct link to Clarifai_InceptionTransferEmbedNorm" title="Direct link to Clarifai_InceptionTransferEmbedNorm">​</a></h2><p>This template is an advanced image classifier that leverages the power of the Inception architecture as its foundation. It has been pre-trained on the vast and diverse ImageNet-21K dataset, which provides a comprehensive understanding of various visual concepts. Additionally, to enhance its capabilities further, the model has been exposed to additional image classification data, enabling it to handle a broader range of tasks.</p><p>To adapt the pretrained model for transfer learning, the classification head and hyperparameters have undergone careful modifications and tuning. The classification head refers to the top layers of the network responsible for mapping the learned representations to specific classes or categories. By customizing this component, <strong>Clarifai_InceptionTransferEmbedNorm</strong> can effectively transfer its knowledge from the source domain (ImageNet-21K) to new, target domains with different sets of classes.</p><p>Furthermore, the hyperparameters of the model have been fine-tuned to optimize its performance for transfer learning tasks. Hyperparameters are adjustable settings that govern the learning process, such as learning rate, batch size, and regularization parameters. Through meticulous experimentation and validation, the hyperparameters of <strong>Clarifai_InceptionTransferEmbedNorm</strong> have been carefully chosen to strike a balance between preserving the general knowledge from the source domain and adapting to the unique characteristics of the target domain.</p><p>By combining the powerful Inception architecture, pre-trained on ImageNet-21K, with the tailored modifications and hyperparameter tuning for transfer learning, <strong>Clarifai_InceptionTransferEmbedNorm</strong> offers an effective and efficient solution for various image classification tasks, providing accurate predictions and insights.</p><p>The <strong>Clarifai_InceptionTransferEmbedNorm</strong> template supports the following hyperparameters:</p><ul><li><strong>Logreg</strong>—This specifies whether to use sigmoid units (logreg=1) or softmax (logreg=0); you can choose either &quot;Logistic Regression&quot; or &quot;Softmax&quot; as the activation function of the output layer. The default setting, 1, corresponds to Logistic Regression and will allow for multiple True concepts (i.e., P &gt; 0.5) to be predicted for a given input. Conversely, specify a value of 0 to implement Softmax if your concepts should be treated as &quot;mutually exclusive&quot; (i.e., only one concept could be correctly assigned to a given input). This will result in each prediction output representing a discrete probability distribution (i.e., all predicted values sum to 1). The minimum value it supports for customization is <code>0</code>, while the maximum is <code>1</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Image size</strong>—This is the input image size, specifically the minimum side dimension. Images are scaled for efficient processing, and a lower number will take up less memory and run faster. A higher number will have more pixel information to train on and will increase accuracy. The minimum value it supports for customization is <code>32</code>, while the maximum is <code>1024</code>—with an incremental or decremental step of <code>16</code>. </li><li><strong>Batch size</strong>—The number of images used during training. Increased batch size allows for a better approximation of gradient over those samples. Batches allow for stochastic gradient descent, by choosing a random set of X images for each training update. You may want to increase the batch size if the model is large and takes a long time to train. You may also want to increase the batch size if your total number of model concepts is larger than the batch size (you may want to increase it to around 2x the category count). The minimum value it supports for customization is <code>1</code>, while the maximum is <code>128</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>lrate</strong>—This is the learning rate per minibatch. It is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function. The minimum value it supports for customization is <code>0.0</code>.</li><li><strong>Base gradient_multiplier</strong>—This sets the learning rate of the pre-initialized base (also sometimes called &quot;backbone&quot;) model that generates embeddings. Learning rate controls how the weights of our network are adjusted with respect to the loss gradient. The lower the value, the slower the trip along the downward slope. A low learning rate can help ensure that local minima are not missed, but can take a long time to converge, especially if the model gets stuck on a plateau region.</li><li><strong>Num epochs</strong>—This is the total number of epochs to train the model. It determines how many passes the model makes over the entire dataset during training. The minimum value it supports for customization is <code>1</code>, while the maximum is <code>200</code>—with an incremental or decremental step of <code>1</code>. </li><li><strong>Num items_per_epoch</strong>—This is the number of input images per &quot;epoch.&quot; The default value is the number of images in the dataset.</li><li><strong>Average horizontal_flips</strong>—If set to true, the template will average the embeddings from the original image and a horizontal flip of the image to get the final embedding vectors to output.</li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/Clarifai/docs/blob/main/docs/portal-guide/model/deep-training/visual-classification-templates.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/portal-guide/model/deep-training/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Deep Fine-Tuning Templates</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/portal-guide/model/deep-training/visual-detection-templates"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Visual Detection Templates</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#mmclassification_resnet_50_rsb_a1" class="table-of-contents__link toc-highlight">MMClassification_ResNet_50_RSB_A1</a></li><li><a href="#clarifai_inceptionbatchnorm" class="table-of-contents__link toc-highlight">Clarifai_InceptionBatchNorm</a></li><li><a href="#clarifai_inceptionv2" class="table-of-contents__link toc-highlight">Clarifai_InceptionV2</a></li><li><a href="#clarifai_resnext" class="table-of-contents__link toc-highlight">Clarifai_ResNext</a></li><li><a href="#clarifai_inceptiontransferembednorm" class="table-of-contents__link toc-highlight">Clarifai_InceptionTransferEmbedNorm</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://clarifai.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Clarifai Website<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://join.slack.com/t/clarifaicommunity/shared_invite/zt-1jehqesme-l60djcd3c_4a1eCV~uPUjQ" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/company/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.facebook.com/Clarifai/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Facebook<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Clarifai, Inc.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.1b291614.js"></script>
<script src="/assets/js/main.5d8d05ee.js"></script>
<!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5W9P7GR" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) --></body>
</html>