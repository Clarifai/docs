<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-create/models/templates/text" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Text Fine-Tuning Templates | Clarifai Docs</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://docs.clarifai.com/create/models/templates/text"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Text Fine-Tuning Templates | Clarifai Docs"><meta data-rh="true" name="description" content="Learn about our text fine-tuning templates"><meta data-rh="true" property="og:description" content="Learn about our text fine-tuning templates"><meta data-rh="true" name="keywords" content="text templates,deep learning text templates,AI text processing,text classification templates,deep training text models,machine learning text processing,custom text models,pre-trained text templates,natural language processing templates,NLP model templates"><link data-rh="true" rel="icon" href="/img/favicon.svg"><link data-rh="true" rel="canonical" href="https://docs.clarifai.com/create/models/templates/text"><link data-rh="true" rel="alternate" href="https://docs.clarifai.com/create/models/templates/text" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.clarifai.com/create/models/templates/text" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://E9LMD97ZH2-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Models","item":"https://docs.clarifai.com/create/models/"},{"@type":"ListItem","position":2,"name":"Training Templates","item":"https://docs.clarifai.com/create/models/templates/"},{"@type":"ListItem","position":3,"name":"Text Fine-Tuning Templates","item":"https://docs.clarifai.com/create/models/templates/text"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3R20NHSS5H"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-3R20NHSS5H",{anonymize_ip:!0})</script>
<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-5W9P7GR",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>




<link rel="search" type="application/opensearchdescription+xml" title="Clarifai Docs" href="/opensearch.xml">




<script src="/scripts/sidebar.js" async></script>
<script src="/scripts/intercomConfig.js" async></script>
<script src="https://cdn.amplitude.com/libs/analytics-browser-2.12.0-min.js.gz" defer="defer"></script>
<script src="https://cdn.amplitude.com/libs/plugin-session-replay-browser-1.4.0-min.js.gz" defer="defer"></script>
<script src="/scripts/amplitude.js" defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.7876bb28.css">
<script src="/assets/js/runtime~main.199c16e5.js" defer="defer"></script>
<script src="/assets/js/main.2d0cff94.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5W9P7GR" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementWrapper_Ma07"><div class="announcementBar_s0pr" role="banner"><div class="announcementBarPlaceholder_qxfj"></div><div class="announcementBarClose_iXyO"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="none" viewBox="0 0 32 32"><rect width="32" height="32" fill="#F3F4F6" rx="16"></rect><path stroke="#1F2A37" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21.714 10.286 10.285 21.714m0-11.428 11.429 11.428"></path></svg></div><div class="content_knG7 announcementBarContent_dpRF"><span>New!</span> Local Runners let you run models locally for development, debugging, or compute tasks.  <a target="_blank" rel="noopener noreferrer" href="https://docs.clarifai.com/compute/models/upload/local-runners/">Learn more.</a></div></div></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo-dark.svg" alt="Clarifai Docs" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo-light.svg" alt="Clarifai Docs" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><div class="navbar__item dropdown dropdown--hoverable" style="width:unset"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">API References</a><ul class="dropdown__menu" style="display:flex;flex-direction:column;height:auto;max-height:300px;max-width:unset;flex-wrap:wrap;overflow-y:unset;width:300px;column-gap:32px"><li><a class="dropdown__link" href="/resources/api-references/python">Python SDK Reference</a></li><li><a class="dropdown__link" href="/resources/api-references/node/">Node.js SDK Reference</a></li><li><a href="https://documenter.getpostman.com/view/30622694/2s9YkuZdro" target="_blank" rel="noopener noreferrer" class="dropdown__link">Postman API Reference<svg width="12" height="12" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li><a href="https://api.clarifai.com/api-doc/?url=https://api.clarifai.com/v2/swagger.json" target="_blank" rel="noopener noreferrer" class="dropdown__link">Swagger API Reference<svg width="12" height="12" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div><a href="https://github.com/Clarifai/docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="Github repository"></a><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-discord-link" aria-label="Discord"></a><a href="https://x.com/clarifai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-x-link" aria-label="X"></a><a href="https://www.linkedin.com/company/clarifai/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-linkedin-link" aria-label="LinkedIn"></a><a href="https://clarifai.com/login?__hstc=56460205.941fd3bdff0d161c2f70ccba4c9dcb6b.1707280236564.1715406292479.1715409915530.11&amp;__hssc=56460205.1.1715409915530&amp;__hsfp=1566939966" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link login-link" aria-label="Login">Login<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><a href="https://clarifai.com/signup?__hstc=56460205.941fd3bdff0d161c2f70ccba4c9dcb6b.1707280236564.1715406292479.1715409915530.11&amp;__hssc=56460205.1.1715409915530&amp;__hsfp=1566939966" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link signup-button" aria-label="Start for free">Start for free<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_ntye" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/">Welcome</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Getting Started</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/quickstart">Quick Start With API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/quickstart-playground">Quick Start With Playground</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/first-deployment">Deploy Your First Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/set-up-compute">Set Up Compute Fast</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/upload-model">Build and Upload a Model</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Compute</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/overview">Compute Orchestration</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/compute/deployments/">Deployments</a><button aria-label="Expand sidebar category &#x27;Deployments&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/compute/inference/">Inference</a><button aria-label="Expand sidebar category &#x27;Inference&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/compute/upload/">Build and Upload Models</a><button aria-label="Expand sidebar category &#x27;Build and Upload Models&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/compute/local-runners/">Local Runners</a><button aria-label="Expand sidebar category &#x27;Local Runners&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/compute/agents/">Agents</a><button aria-label="Expand sidebar category &#x27;Agents&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Control and Governance</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/control/authentication/">Authentication</a><button aria-label="Expand sidebar category &#x27;Authentication&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/control/control-center/">Control Center</a><button aria-label="Expand sidebar category &#x27;Control Center&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/control/clarifai-organizations/">Clarifai Organizations</a><button aria-label="Expand sidebar category &#x27;Clarifai Organizations&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--active">Create and Manage</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/applications/">Applications</a><button aria-label="Expand sidebar category &#x27;Applications&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/inputs/">Inputs</a><button aria-label="Expand sidebar category &#x27;Inputs&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/search/">Vector Search</a><button aria-label="Expand sidebar category &#x27;Vector Search&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/datasets/">Datasets</a><button aria-label="Expand sidebar category &#x27;Datasets&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/concepts/">Concepts</a><button aria-label="Expand sidebar category &#x27;Concepts&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/labeling/">Labeling</a><button aria-label="Expand sidebar category &#x27;Labeling&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/create/models/">Models</a><button aria-label="Collapse sidebar category &#x27;Models&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/models/transfer-learning/">Transfer Learning</a><button aria-label="Expand sidebar category &#x27;Transfer Learning&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/models/deep-fine-tuning/">Deep Fine-Tuning</a><button aria-label="Expand sidebar category &#x27;Deep Fine-Tuning&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/create/models/templates/">Training Templates</a><button aria-label="Collapse sidebar category &#x27;Training Templates&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/templates/visual-classification">Visual Classification Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/templates/visual-detection">Visual Detection Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/templates/visual-embedding">Visual Embedding Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/templates/visual-segmentation">Visual Segmenter Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/create/models/templates/text">Text Fine-Tuning Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/templates/custom">Advanced Config</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/model-versions/">Model Versions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/manage">Manage Models</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/models/evaluate/">Evaluations</a><button aria-label="Expand sidebar category &#x27;Evaluations&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/export">Model Export</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/workflows/">Workflows</a><button aria-label="Expand sidebar category &#x27;Workflows&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/agent-system-operators/">Agent System Operators</a><button aria-label="Expand sidebar category &#x27;Agent System Operators&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/modules/">Modules</a><button aria-label="Expand sidebar category &#x27;Modules&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Additional Resources</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/resources/api-overview/">API Overview</a><button aria-label="Expand sidebar category &#x27;API Overview&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/platform/">Platform Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/resources/api-references/">API References</a><button aria-label="Expand sidebar category &#x27;API References&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/resources/glossary/">Glossary</a><button aria-label="Expand sidebar category &#x27;Glossary&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/resources/data-utils/">Data Utils</a><button aria-label="Expand sidebar category &#x27;Data Utils&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/sdk-examples">Python SDK Notebook Examples</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/resources/complementary-topics/">Complementary Topics</a><button aria-label="Expand sidebar category &#x27;Complementary Topics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/troubleshooting">Troubleshooting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/tips">Additional Tips</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/privacy-security">Data Privacy and Security</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Product Updates</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/product-updates/upcoming-api-changes/">Upcoming Platform Changes</a><button aria-label="Expand sidebar category &#x27;Upcoming Platform Changes&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/product-updates/changelog">Changelog</a><button aria-label="Expand sidebar category &#x27;Changelog&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Integrations</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/integrations/embedchain/">Embedchain</a><button aria-label="Expand sidebar category &#x27;Embedchain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/integrations/langchain/">LangChain</a><button aria-label="Expand sidebar category &#x27;LangChain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/integrations/llamaindex/">LlamaIndex</a><button aria-label="Expand sidebar category &#x27;LlamaIndex&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/integrations/databricks/">Databricks</a><button aria-label="Expand sidebar category &#x27;Databricks&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/integrations/DSPy/">DSPy</a><button aria-label="Expand sidebar category &#x27;DSPy&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/integrations/unstructured/">Unstructured.io</a><button aria-label="Expand sidebar category &#x27;Unstructured.io&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Additional Links</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://api.clarifai.com/api-doc/?url=https://api.clarifai.com/v2/swagger.json" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">Swagger API Guide<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://stackoverflow.com/tags/clarifai/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://status.clarifai.com/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">API Status<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://www.clarifai.com/blog/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">Clarifai Blog<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Create and Manage</span></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/create/models/"><span>Models</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/create/models/templates/"><span>Training Templates</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Text Fine-Tuning Templates</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Text Fine-Tuning Templates</h1></header>
<p><strong>Learn about our text fine-tuning templates</strong></p>
<hr>
<p>Clarifai&#x27;s text fine-tuning templates empower you to leverage pre-trained language models and refine them through additional training on specific tasks or datasets, customizing them for precise use cases.</p>
<p>Each template comes with its own hyperparameters, which you can tune to influence “how” your model learns. With hyperparameters, you can customize and adapt a template to suit your specific tasks and achieve better performance.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>train text-to-text models</div><div class="admonitionContent_BuS1"><p><a href="https://docs.clarifai.com/portal-guide/model/model-types/text-to-text#how-to-fine-tune-text-generation-models" target="_blank" rel="noopener noreferrer">Click here</a> to learn how to use these text templates to  fine-tune text-to-text models.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llama-31">Llama 3.1<a href="#llama-31" class="hash-link" aria-label="Direct link to Llama 3.1" title="Direct link to Llama 3.1">​</a></h2>
<p><a href="https://ai.meta.com/blog/meta-llama-3-1/" target="_blank" rel="noopener noreferrer">Llama 3.1</a> is a collection of pre-trained and instruction-tuned large language models (LLMs) developed by Meta AI. It’s known for its open-source nature and impressive capabilities, such as being optimized for multilingual dialogue use cases, extended                                                                                                                                                           context length of 128K, advanced tool usage, and improved reasoning capabilities.</p>
<p>It is available in three model sizes:</p>
<ul>
<li><strong>405 billion parameters:</strong> The flagship foundation model designed to push the boundaries of AI capabilities.</li>
<li><strong>70 billion parameters:</strong> A highly performant model that supports a wide range of use cases.</li>
<li><strong>8 billion parameters:</strong> A lightweight, ultra-fast model that retains many of the advanced features of its larger counterpart, which makes it highly capable.</li>
</ul>
<p>At Clarifai, we offer the <a href="https://clarifai.com/meta/Llama-3/models/llama-3_1-8b-instruct" target="_blank" rel="noopener noreferrer">8 billion parameter version</a>, which you can fine-tune for text generation and text classification tasks. We converted it into the Hugging Face Transformers format to enhance its compatibility with our platform and pipelines, ease its consumption, and optimize its deployment in various environments.</p>
<p>Further, to get the best of what’s possible with the Llama 3.1 8B model, we quantized it using the <a href="https://arxiv.org/pdf/2210.17323.pdf" target="_blank" rel="noopener noreferrer">GPTQ</a> quantization method.
In addition, we employed the LoRA (Low-Rank Adaptation) method to achieve efficient and fast fine-tuning of the pre-trained Llama 3.1 8B model.</p>
<p>These enhancements ensure that users get the best performance and adaptability from the LlaMA 3.1 8B model on the Clarifai platform.</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Quantization</div><div class="admonitionContent_BuS1"><p>Quantization is a model compression method that involves converting the weights and activations within an LLM from a high-precision data representation to a lower-precision one – without sacrificing significant accuracy.</p><p>This means transitioning from a data type capable of holding more information, such as a 32-bit floating-point number (FP32), to one with less capacity, such as an 8-bit or 4-bit integer (INT8 or INT4).</p><p>GPTQ offers a highly efficient and accurate method for quantizing LLMs, addressing the computational and storage challenges associated with their deployment, and unlocking significant performance improvements in inference speed.</p></div></div>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>LoRA</div><div class="admonitionContent_BuS1"><p>Full parameter fine-tuning traditionally involves adjusting all parameters across all layers of a pre-trained model. While it typically yields optimal performance, it is resource-intensive and time-consuming, demanding significant GPU resources and time.</p><p>On the other hand, Parameter Efficient Fine-Tuning (PEFT) offers a way to fine-tune models with minimal resources and costs. One notable PEFT method is <a href="https://arxiv.org/abs/2106.09685" target="_blank" rel="noopener noreferrer">Low-Rank Adaptation (LoRA)</a>.</p><p>LoRA is a game-changer for fine-tuning LLMs on resource-constrained devices or environments. It achieves this by exploiting inherent low-rank structures within the model&#x27;s parameters. These structures capture essential patterns and relationships in the data, allowing LoRA to focus on these during fine-tuning, rather than modifying the entire parameter space.</p><p>This leads to efficient fine-tuning for text-to-text tasks, like text classification. LoRA significantly reduces the number of trainable parameters in models, enabling faster and more resource-friendly adaptation to specific downstream tasks.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llama-2">Llama 2<a href="#llama-2" class="hash-link" aria-label="Direct link to Llama 2" title="Direct link to Llama 2">​</a></h2>
<p><a href="https://arxiv.org/abs/2307.09288" target="_blank" rel="noopener noreferrer">Llama 2</a> is a collection of pre-trained and fine-tuned large language models (LLMs) created and publicly released by Meta AI. It is available in three model sizes: 7, 13, and 70 billion parameters. Llama 2-Chat is a fine-tuned version of Llama 2, specifically optimized for dialogue-based scenarios.</p>
<p><a href="https://clarifai.com/meta/Llama-2/models/llama2-70b-chat" target="_blank" rel="noopener noreferrer">Llama 2-Chat</a> is designed to produce human-like responses to user inputs, which makes it appropriate for powering conversational and chatbot-like AI applications. The model can learn the structures and intricate patterns of natural language conversations and produce coherent and contextually relevant outputs.</p>
<p>Llama 2-Chat is an efficient, versatile AI assistant that can tackle complicated reasoning tasks across diverse domains. You can use it for a wide range of use cases, such as:</p>
<ul>
<li>Text generation</li>
<li>Text classification</li>
</ul>
<p>At Clarifai, we converted Llama 2-Chat into the Hugging Face Transformers format to enhance its compatibility with our platform and pipelines, ease its consumption, and optimize its deployment in various environments.</p>
<p>Further, to get the best of what’s possible with the Llama 2-Chat model, we quantized it using the GPTQ quantization method.</p>
<p>In addition, we employed the LoRA (Low-Rank Adaptation) method to achieve efficient and fast fine-tuning of the pre-trained Llama 2-Chat model.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="gpt-neo">GPT-Neo<a href="#gpt-neo" class="hash-link" aria-label="Direct link to GPT-Neo" title="Direct link to GPT-Neo">​</a></h2>
<p><a href="https://www.eleuther.ai/artifacts/gpt-neo" target="_blank" rel="noopener noreferrer">GPT-Neo</a>, introduced by EleutherAI, is a variant of the Generative Pre-trained Transformer (GPT) model, which is part of the broader family of transformer-based language models. The transformer-based architecture allows models to process and understand complex relationships within text data.</p>
<p>The GPT-Neo model comes in 125M, 1.3B, and 2.7B parameter variants. This allows users to choose the model size that best fits their specific use case and computational constraints.</p>
<p>GPT-Neo is notable for being an open-source, community-driven project aimed at creating large-scale, high-quality language models that are accessible to researchers and developers. It is designed to offer similar capabilities to other large language models like GPT-3, but without the need for extensive computational resources or costly infrastructure.</p>
<p>At Clarifai, we converted GPT-Neo into the Hugging Face Transformers format to improve its compatibility with our platform and pipelines, simplify its usage, and enhance its deployment across different environments.</p>
<p>Furthermore, we utilized the LoRA technique to efficiently and swiftly fine-tune the pre-trained GPT-Neo model.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mistral-7b">Mistral 7B<a href="#mistral-7b" class="hash-link" aria-label="Direct link to Mistral 7B" title="Direct link to Mistral 7B">​</a></h2>
<p><a href="https://mistral.ai/news/announcing-mistral-7b/" target="_blank" rel="noopener noreferrer">Mistral 7B</a>, introduced by Mistral AI, is an LLM that has gathered attention due to its efficiency and strong performance.</p>
<p>It is a 7.3 billion-parameter model, making it smaller than other models like GPT-3 (175 billion) but still powerful for various tasks. Despite its size, Mistral 7B has shown impressive performance on various benchmarks, even surpassing some larger models in specific areas.</p>
<p>You can use it for a wide range of use cases, such as:</p>
<ul>
<li>Text generation</li>
<li>Text classification</li>
<li>Text summarization</li>
<li>Code completion</li>
</ul>
<p>One of Mistral 7B&#x27;s strengths is its ability to achieve good results with fewer parameters compared to some other LLMs. This translates to lower resource requirements when using the model.</p>
<p>To become efficient, the model utilizes techniques like Grouped-query Attention and Sliding Window Attention. This allows it to achieve faster processing and reduce memory usage during inference.</p>
<p>It is presented as a foundational model that can easily be fine-tuned for specific tasks, making it adaptable to various scenarios. For example, the Mistral 7B Instruct model is a strong showcase of how the base Mistral 7B model can be effectively fine-tuned for impressive results.  This version of the model is fine-tuned for question-answering and conversation tasks.</p>
<p>For Clarifai users, we&#x27;ve made Mistral 7B Instruct even more accessible by converting it into the Hugging Face Transformers format. This ensures seamless compatibility with our platform and pipelines, simplifies its use, and allows for optimized deployment across diverse environments.</p>
<p>To unlock Mistral 7B Instruct&#x27;s full potential, we combined two powerful techniques: quantization with GPTQ and fine-tuning with LoRA. Quantization reduces the model size for faster inference, while LoRA enables efficient and rapid fine-tuning for specific tasks — as explained earlier.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hugging-face-advanced-config">Hugging Face Advanced Config<a href="#hugging-face-advanced-config" class="hash-link" aria-label="Direct link to Hugging Face Advanced Config" title="Direct link to Hugging Face Advanced Config">​</a></h2>
<p>The Hugging Face Advanced Config is a flexible template designed to empower users to tailor fine-tuning configurations for language models according to their precise requirements. It allows users to define a wide range of advanced parameters and settings that govern the fine-tuning process.</p>
<p>With the template, you can specify various advanced parameters and settings that control the fine-tuning process. These advanced parameters enable you to optimize model performance, adapt fine-tuning processes to specific datasets, and fine-tune models for various downstream tasks more effectively.</p>
<p>It serves as a powerful tool for customizing and refining the fine-tuning process, ultimately enhancing the performance and versatility of language models across diverse applications and use cases.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="template-hyperparameters">Template Hyperparameters<a href="#template-hyperparameters" class="hash-link" aria-label="Direct link to Template Hyperparameters" title="Direct link to Template Hyperparameters">​</a></h2>
<p>The text templates support a wide range of hyperparameters, which empower you to fine-tune language models effectively for diverse text-to-text use cases.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="model-config">Model config​<a href="#model-config" class="hash-link" aria-label="Direct link to Model config​" title="Direct link to Model config​">​</a></h3>
<p>It is a dictionary of key-value pairs that outlines the aspects of the model configuration, its initialization process, and the approach to training, including the handling of pre-trained weights and the potential for resuming training from a specific checkpoint.</p>
<p>Here is an example:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;pretrained_model_name&quot;: &quot;TheBloke/Llama-2-7b-Chat-GPTQ&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;problem_type&quot;: &quot;multi_label_classification&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;torch_dtype&quot;: &quot;torch.float32&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre></div></div>
<ul>
<li>The <code>pretrained_model_name</code> key specifies the name of the pre-trained model to be loaded from the Hugging Face Hub and used as the base.  In this case, it&#x27;s the <code>Llama-2-7b-Chat-GPTQ</code> model from the <code>TheBloke</code> repository.</li>
<li>The <code>problem_type</code> key indicates the type of problem the model is designed to solve. In this case, it&#x27;s <code>multi_label_classification</code>, suggesting the model is trained to classify input data into multiple labels or categories.</li>
<li>The <code>torch_dtype</code> key sets the numerical data type to be used within PyTorch, influencing precision and memory usage. It is set as <code>torch.float32</code>, indicating the model operates on 32-bit floating-point numbers.</li>
</ul>
<p>The keys and values of the model config are passed to the <code>transformers.AutoModelForCausalLM.from_pretrained()</code> function from the <code>transformers</code> library, which initializes the model architecture and loads pre-trained weights based on the provided configuration.</p>
<p>Also, a <code>resume_from_model</code> parameter can be specified in the <code>train_info</code> section of the <code>PostModelVersions</code> request. This parameter overrides the <code>pretrained_model_name_or_path</code>, indicating that during training, the model will resume from a specific point indicated by <code>resume_from_model</code>, disregarding the pre-trained model&#x27;s path or name.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="quantization-config">Quantization Config<a href="#quantization-config" class="hash-link" aria-label="Direct link to Quantization Config" title="Direct link to Quantization Config">​</a></h3>
<p>It is a dictionary of key-value pairs for quantizing a transformer model by specifying the number of bits used for representation and indicating whether to utilize the <code>ExLLaMA</code> optimization technique.</p>
<p>Here is an example:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;bits&quot;: 4,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;use_exllama&quot;: false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre></div></div>
<ul>
<li>The <code>bits</code> key specifies the target precision for weight quantization. In this case, the weights will be compressed to 4 bits each. This significantly reduces model size and potentially improves inference speed, but may introduce some accuracy loss.</li>
<li>The <code>use_exllama</code> key controls whether to utilize the <code>ExLLaMA</code> optimization technique. This optimization technique could potentially improve the quantization process. Setting it to <code>false</code> means that the technique is not used.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="peft-config">Peft config​<a href="#peft-config" class="hash-link" aria-label="Direct link to Peft config​" title="Direct link to Peft config​">​</a></h3>
<p>It is a dictionary of key-value pairs that define how to fine-tune a pre-trained model on a downstream task using the PEFT method.</p>
<p>Here is an example:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;inference_mode&quot;: false,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;lora_alpha&quot;: 16,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;lora_dropout&quot;: 0.1,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;peft_type&quot;: &quot;LORA&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;r&quot;: 16,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;task_type&quot;: &quot;CAUSAL_LM&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre></div></div>
<ul>
<li>The <code> inference_mode</code> key specifies whether the model is being configured for inference mode. Setting it to <code>false</code> suggests that the model is not being optimized specifically for inference, but rather for training or fine-tuning.</li>
<li>The <code>lora_alpha</code> key specifies the dimensionality of the latent vectors used for adaptation, potentially impacting training efficiency and model performance. A higher value might lead to better fine-tuning but also require more memory.</li>
<li>The <code>lora_dropout</code> key specifies the dropout rate applied during training. Dropout is a regularization technique that helps prevent overfitting by randomly dropping connections between neurons. This value sets the probability of dropping out a latent vector element during training.</li>
<li>The <code>peft_type</code> key specifies the type of PEFT technique to be used. In this case, it&#x27;s set to <code>LoRA</code>.</li>
<li>The <code>r</code> key specifies the rank of the low-rank adaptation matrices. It influences the number of parameters to be used and potentially impacts training efficiency and performance.</li>
<li>The <code>task_type</code> key specifies the type of task the model is being fine-tuned for. In this case, it&#x27;s set to <code>CAUSAL_LM</code>, implying the model is being fine-tuned for a causal language modeling task, where the model predicts the next word in a sequence given previous words.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tokenizer-config">Tokenizer config​<a href="#tokenizer-config" class="hash-link" aria-label="Direct link to Tokenizer config​" title="Direct link to Tokenizer config​">​</a></h3>
<p>It is a dictionary of key-value pairs that define the configuration of a pre-trained tokenizer. A tokenizer is a crucial component in natural language processing tasks, responsible for breaking down text input into individual tokens or subwords.</p>
<p>Configuration involves specifying parameters that govern how the tokenizer behaves, such as tokenization rules and maximum sequence length.</p>
<p>Here is an example:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;model_max_length&quot;: 512</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre></div></div>
<ul>
<li>The <code>model_max_length</code> key sets the maximum length (in tokens) that the tokenizer will consider for sequences.  In this case, it&#x27;s set to 512, meaning that input sequences longer than 512 tokens will be truncated or split to fit within this limit.</li>
</ul>
<p>The keys and values of the tokenizer config are passed to the <code>transformers.AutoTokenizer.from_pretrained()</code> function to instantiate a pre-trained tokenizer.</p>
<p>If the tokenizer config is not specified, the function will use the model name from the model config to instantiate the appropriate pre-trained tokenizer. For example, if the model config specifies the model name as <code>EleutherAI/gpt-neo-2.7B</code>, the function will instantiate the <code>GPTNeoTokenizer</code> class.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="trainer-config">Trainer config​<a href="#trainer-config" class="hash-link" aria-label="Direct link to Trainer config​" title="Direct link to Trainer config​">​</a></h3>
<p>It is a dictionary of key-value pairs that define how the training process will be executed, including settings related to optimization, training duration, and hardware utilization.</p>
<p>Here is an example:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;auto_find_batch_size&quot;: true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;fp16&quot;: true,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;learning_rate&quot;: 0.0002,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &quot;num_train_epochs&quot;: 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre></div></div>
<ul>
<li>The <code>auto_find_batch_size</code> key enables automatic batch size selection during training. The trainer will attempt to find an optimal batch size based on available GPU resources and model characteristics.</li>
<li>The <code> fp16</code> key enables mixed-precision training using 16-bit floating-point numbers (FP16). Mixed precision is a technique that can speed up training, and reduce memory usage, with compatible hardware (e.g., GPUs with Tensor Cores).  However, it might introduce slight numerical instability.</li>
<li>The <code>learning_rate</code> key specifies the learning rate used by the optimizer during training. This value controls how much the model&#x27;s weights are updated during each training step. In this case, it&#x27;s set to 0.0002, indicating a relatively low learning rate.</li>
<li>The <code>num_train_epochs</code> key specifies the number of training epochs; that is, the number of times the entire training dataset will be traversed during training. In this case, it&#x27;s set to 1, implying that the model will be trained for a single epoch.</li>
</ul>
<p>The keys and values of the trainer config are passed to the <code>transformers.TrainingArguments()</code> function to instantiate a <code>TrainingArguments</code> object. The object defines the hyperparameters and other settings that are used by the <code>Trainer</code> class to train a pre-trained model.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/create/models/templates/visual-segmentation"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Visual Segmenter Templates</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/create/models/templates/custom"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Advanced Config</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#llama-31" class="table-of-contents__link toc-highlight">Llama 3.1</a></li><li><a href="#llama-2" class="table-of-contents__link toc-highlight">Llama 2</a></li><li><a href="#gpt-neo" class="table-of-contents__link toc-highlight">GPT-Neo</a></li><li><a href="#mistral-7b" class="table-of-contents__link toc-highlight">Mistral 7B</a></li><li><a href="#hugging-face-advanced-config" class="table-of-contents__link toc-highlight">Hugging Face Advanced Config</a></li><li><a href="#template-hyperparameters" class="table-of-contents__link toc-highlight">Template Hyperparameters</a><ul><li><a href="#model-config" class="table-of-contents__link toc-highlight">Model config​</a></li><li><a href="#quantization-config" class="table-of-contents__link toc-highlight">Quantization Config</a></li><li><a href="#peft-config" class="table-of-contents__link toc-highlight">Peft config​</a></li><li><a href="#tokenizer-config" class="table-of-contents__link toc-highlight">Tokenizer config​</a></li><li><a href="#trainer-config" class="table-of-contents__link toc-highlight">Trainer config​</a></li></ul></li></ul></div></div></div><div class="custom_doc_item_footer_LMqZ"><div class="banner-primary"><p>Build your next AI app, test and tune popular LLMs models, and much more.</p><a href="https://clarifai.com/explore" target="_blank">Get started for free</a></div><footer class="custom-footer-wrapper_fHnE"><div class="logo-wrapper_GEfd"><img src="/img/logos/clarifai-color-light-logo.svg" class="dark-theme-logo_tdev"><img src="/img/logos/clarifai-color-dark-logo.svg" class="light-theme-logo_cRqu"></div><div class="copyright_aTku">© 2025 Clarifai, Inc. All rights reserved</div><div class="footerSocialIconsWrapper_tJhP"><div class="socialBrands__tjK"><a href="https://github.com/Clarifai" target="_blank" rel="noopener noreferrer" aria-label="Github"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#000" fill-rule="evenodd" d="M9.7 1.5C4.896 1.5 1 5.401 1 10.216a8.715 8.715 0 0 0 5.95 8.269c.436.08.594-.189.594-.42 0-.207-.007-.756-.011-1.482-2.421.526-2.932-1.169-2.932-1.169-.395-1.007-.966-1.275-.966-1.275-.79-.54.06-.53.06-.53.873.062 1.333.899 1.333.899.776 1.33 2.036.946 2.532.724.08-.563.304-.947.553-1.165C6.18 13.847 4.15 13.1 4.15 9.76c0-.951.339-1.73.895-2.34-.09-.22-.388-1.106.085-2.305 0 0 .731-.235 2.393.893a8.3 8.3 0 0 1 2.178-.293c.74.003 1.483.1 2.178.293 1.662-1.128 2.39-.894 2.39-.894.476 1.2.176 2.087.088 2.307a3.37 3.37 0 0 1 .894 2.339c0 3.348-2.035 4.085-3.973 4.3.313.27.59.8.59 1.614 0 1.165-.01 2.105-.01 2.39 0 .234.156.505.598.42a8.72 8.72 0 0 0 5.946-8.268C18.402 5.4 14.505 1.5 9.7 1.5" clip-rule="evenodd"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://twitter.com/clarifai" target="_blank" rel="noopener noreferrer" aria-label="Twitter"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#000" d="M14.6 3h2.454l-5.36 6.142L18 17.5h-4.937l-3.867-5.07-4.425 5.07H2.316l5.733-6.57L2 3h5.063l3.495 4.633zm-.86 13.028h1.36L6.323 4.395H4.865z"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" aria-label="Discord"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#7289DA" d="M13.63 15.997c.514.65 1.13 1.387 1.13 1.387 3.784-.12 5.24-2.603 5.24-2.603 0-5.514-2.466-9.983-2.466-9.983C15.07 2.948 12.723 3 12.723 3l-.24.274c2.91.89 4.264 2.175 4.264 2.175a14 14 0 0 0-5.155-1.644 14.5 14.5 0 0 0-3.458.034c-.103 0-.189.017-.292.034-.599.052-2.054.274-3.887 1.08-.633.29-1.01.496-1.01.496S4.366 4.096 7.45 3.206L7.277 3S4.932 2.95 2.466 4.798c0 0-2.466 4.47-2.466 9.983 0 0 1.438 2.483 5.223 2.603 0 0 .633-.77 1.147-1.421-2.175-.651-2.997-2.021-2.997-2.021s.172.12.48.291c.017.017.034.034.068.051.052.035.103.052.154.086.428.24.857.428 1.25.582.702.274 1.541.548 2.517.736 1.285.24 2.792.326 4.435.018a11.3 11.3 0 0 0 2.483-.737 9.8 9.8 0 0 0 1.97-1.01s-.857 1.404-3.1 2.038"></path><path fill="#fff" d="M6.884 9.147c-.976 0-1.746.857-1.746 1.901s.787 1.9 1.746 1.9c.976 0 1.747-.855 1.747-1.9.017-1.044-.77-1.9-1.747-1.9m6.25 0c-.976 0-1.746.857-1.746 1.901s.787 1.9 1.746 1.9c.976 0 1.747-.855 1.747-1.9s-.77-1.9-1.747-1.9"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://www.youtube.com/@theworldsai" target="_blank" rel="noopener noreferrer" aria-label="Youtube"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="20" preserveAspectRatio="xMidYMid" viewBox="0 0 256 180"><path fill="red" d="M250.346 28.075A32.18 32.18 0 0 0 227.69 5.418C207.824 0 127.87 0 127.87 0S47.912.164 28.046 5.582A32.18 32.18 0 0 0 5.39 28.24c-6.009 35.298-8.34 89.084.165 122.97a32.18 32.18 0 0 0 22.656 22.657c19.866 5.418 99.822 5.418 99.822 5.418s79.955 0 99.82-5.418a32.18 32.18 0 0 0 22.657-22.657c6.338-35.348 8.291-89.1-.164-123.134Z"></path><path fill="#FFF" d="m102.421 128.06 66.328-38.418-66.328-38.418z"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://www.linkedin.com/company/clarifai" target="_blank" rel="noopener noreferrer" aria-label="Linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><g clip-path="url(#a)"><path fill="#0A66C2" d="M16.819 2H3.18A1.18 1.18 0 0 0 2 3.181V16.82A1.18 1.18 0 0 0 3.181 18H16.82A1.18 1.18 0 0 0 18 16.819V3.18A1.18 1.18 0 0 0 16.819 2M6.769 15.63H4.363V7.989H6.77zm-1.205-8.7a1.381 1.381 0 1 1 1.39-1.38 1.36 1.36 0 0 1-1.39 1.38m10.072 8.707H13.23v-4.175c0-1.23-.523-1.61-1.199-1.61-.713 0-1.413.537-1.413 1.641v4.144H8.213V7.994h2.314v1.06h.03c.233-.47 1.046-1.274 2.287-1.274 1.343 0 2.793.797 2.793 3.13z"></path></g><defs><clipPath id="a"><path fill="#fff" d="M2 2h16v16H2z"></path></clipPath></defs></svg></a></div></div></footer></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://clarifai.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Clarifai Website<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://join.slack.com/t/clarifaicommunity/shared_invite/zt-1jehqesme-l60djcd3c_4a1eCV~uPUjQ" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://twitter.com/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/company/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.facebook.com/Clarifai/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Facebook<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Clarifai, Inc.</div></div></div></footer></div>
</body>
</html>