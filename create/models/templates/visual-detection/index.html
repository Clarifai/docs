<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-create/models/templates/visual-detection" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Visual Detection Templates | Clarifai Docs</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://docs.clarifai.com/create/models/templates/visual-detection"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Visual Detection Templates | Clarifai Docs"><meta data-rh="true" name="description" content="Learn about our visual detection templates"><meta data-rh="true" property="og:description" content="Learn about our visual detection templates"><meta data-rh="true" name="keywords" content="visual detection templates,deep learning visual detection,AI visual detection,object detection templates,deep training visual detection,machine learning visual detection,custom visual detection models,pre-trained visual detection templates,image detection AI,deep learning object detection"><link data-rh="true" rel="icon" href="/img/favicon.svg"><link data-rh="true" rel="canonical" href="https://docs.clarifai.com/create/models/templates/visual-detection"><link data-rh="true" rel="alternate" href="https://docs.clarifai.com/create/models/templates/visual-detection" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.clarifai.com/create/models/templates/visual-detection" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://E9LMD97ZH2-dsn.algolia.net" crossorigin="anonymous"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3R20NHSS5H"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-3R20NHSS5H",{anonymize_ip:!0})</script>
<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-5W9P7GR",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>




<link rel="search" type="application/opensearchdescription+xml" title="Clarifai Docs" href="/opensearch.xml">


<script src="/scripts/sidebar.js" async></script>
<script src="/scripts/intercomConfig.js" async></script><link rel="stylesheet" href="/assets/css/styles.09525a61.css">
<script src="/assets/js/runtime~main.a6313211.js" defer="defer"></script>
<script src="/assets/js/main.10dec8b7.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5W9P7GR" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>



<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):window.matchMedia("(prefers-color-scheme: light)").matches?t("light"):t("dark")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementWrapper_Ma07"><div class="announcementBar_s0pr" role="banner"><div class="announcementBarPlaceholder_qxfj"></div><div class="announcementBarClose_iXyO"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="none" viewBox="0 0 32 32"><rect width="32" height="32" fill="#F3F4F6" rx="16"></rect><path stroke="#1F2A37" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21.714 10.286 10.285 21.714m0-11.428 11.429 11.428"></path></svg></div><div class="content_knG7 announcementBarContent_dpRF"><span>New!</span> Local Runners let you run models locally for development, debugging, or compute tasks.  <a target="_blank" rel="noopener noreferrer" href="https://docs.clarifai.com/compute/models/upload/local-runners/">Learn more.</a></div></div></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo-dark.svg" alt="Clarifai Docs" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo-light.svg" alt="Clarifai Docs" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><div class="navbar__item dropdown dropdown--hoverable" style="width:unset"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">API References</a><ul class="dropdown__menu" style="display:flex;flex-direction:column;height:auto;max-height:300px;max-width:unset;flex-wrap:wrap;overflow-y:unset;width:300px;column-gap:32px"><li><a class="dropdown__link" href="/resources/api-references/python">Python SDK Reference</a></li><li><a class="dropdown__link" href="/resources/api-references/node/">Node.js SDK Reference</a></li><li><a href="https://documenter.getpostman.com/view/30622694/2s9YkuZdro" target="_blank" rel="noopener noreferrer" class="dropdown__link">Postman API Reference<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://api.clarifai.com/api-doc/?url=https://api.clarifai.com/v2/swagger.json" target="_blank" rel="noopener noreferrer" class="dropdown__link">Swagger API Reference<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div><a href="https://github.com/Clarifai/docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="Github repository"></a><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-discord-link" aria-label="Discord"></a><a href="https://x.com/clarifai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-x-link" aria-label="X"></a><a href="https://www.linkedin.com/company/clarifai/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-linkedin-link" aria-label="LinkedIn"></a><a href="https://clarifai.com/login?__hstc=56460205.941fd3bdff0d161c2f70ccba4c9dcb6b.1707280236564.1715406292479.1715409915530.11&amp;__hssc=56460205.1.1715409915530&amp;__hsfp=1566939966" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link login-link" aria-label="Login">Login<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://clarifai.com/signup?__hstc=56460205.941fd3bdff0d161c2f70ccba4c9dcb6b.1707280236564.1715406292479.1715409915530.11&amp;__hssc=56460205.1.1715409915530&amp;__hsfp=1566939966" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link signup-button" aria-label="Start for free">Start for free<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite" aria-pressed="true"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_ntye" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/">Welcome</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Getting Started</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/quickstart">Quick Start With API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/quickstart-playground">Quick Start With Playground</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/first-deployment">Deploy Your First Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/upload-model">Upload Your First Model</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Compute</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/compute/overview">Compute Orchestration</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/compute/models/">Models</a><button aria-label="Expand sidebar category &#x27;Models&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/compute/deployments/">Deployments</a><button aria-label="Expand sidebar category &#x27;Deployments&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/compute/providers/">Providers</a><button aria-label="Expand sidebar category &#x27;Providers&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/compute/agents/">Agents</a><button aria-label="Expand sidebar category &#x27;Agents&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Control and Governance</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/control/authentication/">Authentication</a><button aria-label="Expand sidebar category &#x27;Authentication&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/control/control-center/">Control Center</a><button aria-label="Expand sidebar category &#x27;Control Center&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/control/clarifai-organizations/">Clarifai Organizations</a><button aria-label="Expand sidebar category &#x27;Clarifai Organizations&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--active">Create and Manage</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/applications/">Applications</a><button aria-label="Expand sidebar category &#x27;Applications&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/inputs/">Inputs</a><button aria-label="Expand sidebar category &#x27;Inputs&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/search/">Vector Search</a><button aria-label="Expand sidebar category &#x27;Vector Search&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/datasets/">Datasets</a><button aria-label="Expand sidebar category &#x27;Datasets&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/concepts/">Concepts</a><button aria-label="Expand sidebar category &#x27;Concepts&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/labeling/">Labeling</a><button aria-label="Expand sidebar category &#x27;Labeling&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/create/models/">Models</a><button aria-label="Collapse sidebar category &#x27;Models&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/models/transfer-learning/">Transfer Learning</a><button aria-label="Expand sidebar category &#x27;Transfer Learning&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/models/deep-fine-tuning/">Deep Fine-Tuning</a><button aria-label="Expand sidebar category &#x27;Deep Fine-Tuning&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/create/models/templates/">Training Templates</a><button aria-label="Collapse sidebar category &#x27;Training Templates&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/templates/visual-classification">Visual Classification Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/create/models/templates/visual-detection">Visual Detection Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/templates/visual-embedding">Visual Embedding Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/templates/visual-segmentation">Visual Segmenter Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/templates/text">Text Fine-Tuning Templates</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/templates/custom">Advanced Config</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/model-versions/">Model Versions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/manage">Manage Models</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/models/evaluate/">Evaluations</a><button aria-label="Expand sidebar category &#x27;Evaluations&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/create/models/export">Model Export</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/workflows/">Workflows</a><button aria-label="Expand sidebar category &#x27;Workflows&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/agent-system-operators/">Agent System Operators</a><button aria-label="Expand sidebar category &#x27;Agent System Operators&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/create/modules/">Modules</a><button aria-label="Expand sidebar category &#x27;Modules&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Additional Resources</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/resources/api-overview/">API Overview</a><button aria-label="Expand sidebar category &#x27;API Overview&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/platform/">Platform Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/resources/api-references/">API References</a><button aria-label="Expand sidebar category &#x27;API References&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/resources/glossary/">Glossary</a><button aria-label="Expand sidebar category &#x27;Glossary&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/resources/data-utils/">Data Utils</a><button aria-label="Expand sidebar category &#x27;Data Utils&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/sdk-examples">Python SDK Notebook Examples</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/resources/complementary-topics/">Complementary Topics</a><button aria-label="Expand sidebar category &#x27;Complementary Topics&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/resources/privacy-security">Data Privacy and Security</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Product Updates</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/product-updates/upcoming-api-changes/">Upcoming Platform Changes</a><button aria-label="Expand sidebar category &#x27;Upcoming Platform Changes&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/product-updates/changelog">Changelog</a><button aria-label="Expand sidebar category &#x27;Changelog&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Integrations</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/integrations/embedchain/">Embedchain</a><button aria-label="Expand sidebar category &#x27;Embedchain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/integrations/langchain/">LangChain</a><button aria-label="Expand sidebar category &#x27;LangChain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/integrations/llamaindex/">LlamaIndex</a><button aria-label="Expand sidebar category &#x27;LlamaIndex&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/integrations/databricks/">Databricks</a><button aria-label="Expand sidebar category &#x27;Databricks&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/integrations/DSPy/">DSPy</a><button aria-label="Expand sidebar category &#x27;DSPy&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/integrations/unstructured/">Unstructured.io</a><button aria-label="Expand sidebar category &#x27;Unstructured.io&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link">Additional Links</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://api.clarifai.com/api-doc/?url=https://api.clarifai.com/v2/swagger.json" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">Swagger API Guide<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://stackoverflow.com/tags/clarifai/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://status.clarifai.com/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">API Status<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a href="https://www.clarifai.com/blog/" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK" tabindex="0">Clarifai Blog<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Create and Manage</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/create/models/"><span itemprop="name">Models</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/create/models/templates/"><span itemprop="name">Training Templates</span></a><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Visual Detection Templates</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Visual Detection Templates</h1></header>
<p><strong>Learn about our visual detection templates</strong></p>
<hr>
<p>Our visual detection templates are essentially configuration files and scripts that serve as starting points or blueprints for creating, training, and evaluating object detection models. They streamline the process of building models that can accurately identify objects within specific regions of your images or videos.</p>
<p>With these training templates, you can quickly and efficiently create detection models that return concepts and bounding boxes for the identified objects.</p>
<p><img decoding="async" loading="lazy" src="/assets/images/visual-detection-templates-d0b943700c0cc1d3d6c603f05566901e.png" width="1539" height="758" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mmdetection-templates">MMDetection Templates<a href="#mmdetection-templates" class="hash-link" aria-label="Direct link to MMDetection Templates" title="Direct link to MMDetection Templates">​</a></h2>
<p><a href="https://mmdetection.readthedocs.io/en/latest/overview.html" target="_blank" rel="noopener noreferrer">MMDetection</a> is a powerful open-source toolbox developed as part of the OpenMMLab project. It is based on PyTorch and provides a flexible and extensible framework for object detection and instance segmentation tasks.</p>
<p>MMDetection offers a rich set of templates and resources that simplify the process of developing and deploying advanced object detection and instance segmentation models.</p>
<p>We support a wide range of MMDetection templates to accelerate your development efforts and ensure you achieve state-of-the-art results.</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>We currently support MMDetection v3.3.0.</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mmdetection_yolox">MMDetection_YOLOX<a href="#mmdetection_yolox" class="hash-link" aria-label="Direct link to MMDetection_YOLOX" title="Direct link to MMDetection_YOLOX">​</a></h3>
<p>The <strong>MMDetection_YOLOX</strong> template is a configuration in the MMDetection framework for utilizing the advanced <a href="https://github.com/Megvii-BaseDetection/YOLOX" target="_blank" rel="noopener noreferrer">YOLOX</a> model, part of the YOLO (You Only Look Once) family of object detection models.</p>
<p>YOLOX introduces several improvements over previous YOLO versions, including:</p>
<ul>
<li><strong>Anchor-free design</strong> — Eliminates the need for predefined anchors (reference boxes for bounding box prediction). The absence of hand-crafted anchors allows the model to predict bounding boxes directly. This makes the model more flexible and efficient in handling objects of various shapes and sizes.</li>
<li><strong>Multi positives with center sampling</strong> — Enhances positive sample selection by focusing on bounding box centers, improving feature learning and detection accuracy.</li>
<li><strong>Decoupled head</strong>: Separates the tasks of object classification and bounding box regression into two branches, which is a significant departure from the single-head design in the previous YOLO models. Decoupled head leads to more accurate predictions and faster model convergence.</li>
<li><strong>SimOTA label assignment</strong> — Assigns positive or negative labels to objects based on their Intersection over Union (IoU) with ground truth boxes, ensuring more accurate and context-aware label assignments.</li>
<li><strong>Advanced data augmentations</strong> — Uses advanced techniques to improve the model&#x27;s generalization (working on new data) by exposing it to diverse object arrangements and conditions.</li>
</ul>
<p>This template leverages these advanced features to create highly efficient and accurate object detection pipelines, facilitating quick setup and customization for various applications.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mmdetection_yolof">MMDetection_YOLOF<a href="#mmdetection_yolof" class="hash-link" aria-label="Direct link to MMDetection_YOLOF" title="Direct link to MMDetection_YOLOF">​</a></h3>
<p><strong>MMDetection_YOLOF</strong> is a configuration provided by the MMDetection framework specifically designed to utilize the <a href="https://arxiv.org/abs/2103.09460" target="_blank" rel="noopener noreferrer">YOLOF</a> model, which stands for &quot;You Only Look One-level Feature.&quot; YOLOF is a simplified, efficient variant of the YOLO (You Only Look Once) series tailored for real-time object detection tasks.</p>
<p>Here are the key features of the template:</p>
<ul>
<li><strong>One-level feature extraction</strong> — YOLOF uses a single-level feature map for detection, unlike multi-scale feature maps used in more complex models. This simplified architecture reduces computational overhead, making it suitable for real-time applications where speed is crucial.</li>
<li><strong>Anchor-free design</strong> — Similar to YOLOX, YOLOF adopts an anchor-free approach, eliminating the need for predefined anchor boxes and allowing for more straightforward bounding box predictions.</li>
<li><strong>High efficiency</strong> — YOLOF is designed to ensure rapid inference and low latency.</li>
</ul>
<p>This template facilitates quick setup and customization, enabling efficient deployment of object detection models in various real-world applications requiring speed and accuracy.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mmdetection_ssd">MMDetection_SSD<a href="#mmdetection_ssd" class="hash-link" aria-label="Direct link to MMDetection_SSD" title="Direct link to MMDetection_SSD">​</a></h3>
<p>The <strong>MMDetection_SSD</strong> template is a configuration provided by the MMDetection framework for utilizing the <a href="https://arxiv.org/abs/1512.02325" target="_blank" rel="noopener noreferrer">SSD</a> (Single Shot MultiBox Detector) model. SSD is an efficient and straightforward object detection model known for its balance of speed and accuracy, making it suitable for real-time applications.</p>
<p>SSD is designed to detect objects in images using a single deep neural network. It eliminates the need for a separate proposal generation stage, making it faster and more efficient than some other object detection models.</p>
<p>Here are the key features of the template:</p>
<ul>
<li><strong>Single shot detection</strong> — Detects objects and their bounding boxes in a single forward pass of the network, as opposed to two-stage detectors like Faster R-CNN. The one-step process significantly reduces the computational complexity and increases the speed of detection.</li>
<li><strong>Multi-scale feature maps</strong> — SSD uses multiple feature maps at different scales to detect objects of various sizes. This approach allows SSD to effectively handle objects at different resolutions and aspect ratios.</li>
<li><strong>Default boxes (anchors)</strong> — Predicts offsets and confidences for predefined anchor boxes of different shapes and sizes.</li>
<li><strong>Hard negative mining</strong> — Uses hard negative mining during training to handle the class imbalance between the background and object classes. This technique helps in focusing the training on difficult examples, improving the overall accuracy of the detector.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mmdetection_fasterrcnn">MMDetection_FasterRCNN<a href="#mmdetection_fasterrcnn" class="hash-link" aria-label="Direct link to MMDetection_FasterRCNN" title="Direct link to MMDetection_FasterRCNN">​</a></h3>
<p>The <strong>MMDetection_FasterRCNN</strong> template is a configuration provided by the MMDetection framework for utilizing the <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener noreferrer">Faster R-CNN</a> model, which is a popular and highly effective object detection model. Faster R-CNN stands for Faster Region-based Convolutional Neural Network and is known for its high accuracy in detecting objects within images.</p>
<p>Here are the key features of the template:</p>
<ul>
<li><strong>Two-stage detection</strong> — Uses an RPN (Region Proposal Network) for generating region proposals (potential object bounding boxes) and a Fast R-CNN detector for performing object classification and bounding box regression on the proposed regions.</li>
<li><strong>Shared convolutional layers</strong> — The RPN and the Fast R-CNN detection network share convolutional features, improving efficiency.</li>
<li><strong>Anchor boxes</strong> — Uses predefined anchor boxes of different scales and aspect ratios at each sliding window location to handle objects of various shapes and sizes. Predicts offsets to these anchors to refine the bounding box locations.</li>
<li><strong>End-to-end training</strong> — The entire Faster R-CNN model, including the RPN and the detection network, is trained end-to-end, enhancing performance.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mmdetection_advancedconfig">MMDetection_AdvancedConfig<a href="#mmdetection_advancedconfig" class="hash-link" aria-label="Direct link to MMDetection_AdvancedConfig" title="Direct link to MMDetection_AdvancedConfig">​</a></h3>
<p><a href="https://docs.clarifai.com/portal-guide/model/deep-training/custom-templates" target="_blank" rel="noopener noreferrer">Click here</a> to learn how to use the <strong>MMDetection_AdvancedConfig</strong> template to create your own customized template for deep fine-tuning tasks.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="clarifai-templates">Clarifai Templates<a href="#clarifai-templates" class="hash-link" aria-label="Direct link to Clarifai Templates" title="Direct link to Clarifai Templates">​</a></h2>
<p>Clarifai’s templates are our own configurations designed to streamline common object detection and instance segmentation tasks. These templates provide essential settings and structures, offering a solid foundation for building custom detection and segmentation pipelines.</p>
<p>We offer the following visual detection templates.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="clarifai_inceptionv4">Clarifai_InceptionV4<a href="#clarifai_inceptionv4" class="hash-link" aria-label="Direct link to Clarifai_InceptionV4" title="Direct link to Clarifai_InceptionV4">​</a></h3>
<p>The <strong>Clarifai_InceptionV4</strong> template is a pre-configured setup provided by Clarifai, leveraging the <a href="https://arxiv.org/abs/1602.07261" target="_blank" rel="noopener noreferrer">InceptionV4</a> model for visual recognition tasks such as object detection and instance segmentation.</p>
<p>InceptionV4 is a convolutional neural network architecture that builds on the success of the earlier Inception models (also known as GoogLeNet), designed by researchers at Google. InceptionV4 combines the strengths of InceptionV3 and Residual Networks (ResNet) to achieve high accuracy and efficiency in visual recognition tasks.</p>
<p>Here are the key features of the template:</p>
<ul>
<li><strong>Hybrid architecture</strong> — Combines inception modules and residual connections for comprehensive feature extraction and efficient training.</li>
<li><strong>High accuracy</strong> — Achieves high precision in visual recognition tasks due to its deep and complex architecture.</li>
<li><strong>Efficient training</strong> — Designed to be trained efficiently on large datasets, making it suitable for tasks requiring detailed feature extraction and high precision.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="clarifai_inceptionv2">Clarifai_InceptionV2<a href="#clarifai_inceptionv2" class="hash-link" aria-label="Direct link to Clarifai_InceptionV2" title="Direct link to Clarifai_InceptionV2">​</a></h3>
<p>The <strong>Clarifai_InceptionV2</strong> template is a pre-configured setup provided by Clarifai, leveraging the <a href="https://arxiv.org/pdf/1512.00567v3" target="_blank" rel="noopener noreferrer">InceptionV2</a> model, a convolutional neural network designed for efficient and accurate visual recognition tasks such as object detection and instance segmentation.</p>
<p>InceptionV2 is an improvement over the original Inception (GoogLeNet) model, enhancing both performance and efficiency. It includes several architectural updates to optimize computational resources while maintaining high accuracy.</p>
<p>Here are the key features of the template:</p>
<ul>
<li><strong>Inception modules</strong> — Uses inception modules to perform convolutions at multiple scales for comprehensive feature extraction.</li>
<li><strong>Efficiency improvements</strong> — Utilizes factorized convolutions and reduction modules to reduce computational complexity.</li>
<li><strong>Improved training</strong> — Incorporates batch normalization to stabilize and accelerate training.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="other-templates">Other Templates<a href="#other-templates" class="hash-link" aria-label="Direct link to Other Templates" title="Direct link to Other Templates">​</a></h2>
<p>We also support the following additional templates.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="detection_msc10">Detection_MSC10<a href="#detection_msc10" class="hash-link" aria-label="Direct link to Detection_MSC10" title="Direct link to Detection_MSC10">​</a></h3>
<p>The <strong>Detection_MSC10</strong> template provides an excellent starting point for building and deploying sophisticated object detection and instance segmentation models. With its blend of accuracy, efficiency, and customizability, the template can significantly enhance the development process for various visual detection applications.</p>
<p>For example, you can customize it with the MSCOCO (Microsoft Common Objects in Context) dataset, a large-scale object detection, segmentation, and captioning dataset. You can also customize it with the InceptionV4 architecture, a state-of-the-art architecture known for handling complex image recognition and detection tasks. This allows it to achieve faster convergence and better performance on related tasks.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hyperparameters">Hyperparameters<a href="#hyperparameters" class="hash-link" aria-label="Direct link to Hyperparameters" title="Direct link to Hyperparameters">​</a></h2>
<p>Each visual detection template comes with its own hyperparameters, which you can tune to influence “how” your model learns. With hyperparameters, you can customize and fine-tune a template to suit your specific tasks and achieve better performance.</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Customize values</div><div class="admonitionContent_BuS1"><p>You can customize most hyperparameters by specifying the following values:</p><ul>
<li><code>minimum</code> — The minimum value a given parameter can take;</li>
<li><code>maximum</code> — The maximum value a given parameter can take;</li>
<li><code>step</code> — Determines how much you can increase or decrease the minimum or maximum value in a single click/change.</li>
</ul></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="image-size">Image Size<a href="#image-size" class="hash-link" aria-label="Direct link to Image Size" title="Direct link to Image Size">​</a></h3>
<p>The image size hyperparameter defines the dimensions of the input images used for training and inference. It is crucial because it affects the model&#x27;s performance, memory consumption, and computational requirements.</p>
<ul>
<li><strong>Lower values:</strong> Use less memory and enable faster processing but might reduce detection accuracy due to fewer pixels.</li>
<li><strong>Higher values:</strong> Provide more pixel information, potentially increasing detection accuracy, but require more memory and computational power.</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>Choosing the appropriate image size involves balancing the need for detailed image information with the constraints of memory and computational resources. Selecting the right size can enhance model performance and detection accuracy.</p></div></div>
<p>You can specify either a single value or multiple values:</p>
<ul>
<li><strong>Single value:</strong> When a single value is specified, images are resized so that the minimum side (either width or height) matches that value. The aspect ratio is maintained by adjusting the other dimension proportionally.</li>
<li><strong>Multiple values:</strong> When more than one value is specified, and combined with the &quot;keep_aspect_ratio=False&quot; hyperparameter (if supported by the template), images are resized to the exact width and height specified, regardless of the original aspect ratio.</li>
</ul>
<p>For example, the valid choices for the image size hyperparameter you can specify for the <strong>Clarifai_InceptionV4</strong> template are 320, 512, or 800.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="max-aspect-ratio">Max Aspect Ratio<a href="#max-aspect-ratio" class="hash-link" aria-label="Direct link to Max Aspect Ratio" title="Direct link to Max Aspect Ratio">​</a></h3>
<p>When &quot;keep_aspect_ratio&quot; is set to True, this hyperparameter controls the maximum ratio between the longer side and the shorter side of an image during resizing. You can customize this ratio to ensure that the longer side of the image is no more than a specified multiple of the shorter side. The allowed range for this parameter is from 1.0 to 5.0.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="keep-aspect-ratio">Keep Aspect Ratio<a href="#keep-aspect-ratio" class="hash-link" aria-label="Direct link to Keep Aspect Ratio" title="Direct link to Keep Aspect Ratio">​</a></h3>
<p>This boolean hyperparameter determines whether to preserve the original aspect ratio of an image during resizing.</p>
<ul>
<li><strong>True (default, recommended):</strong> The aspect ratio of the image will be maintained, ensuring the image is resized proportionally to fit within the desired dimensions without distortion.</li>
<li><strong>False:</strong> The image will be resized to exactly match the specified dimensions, disregarding the original aspect ratio. This may result in distortion as the image&#x27;s proportions are altered.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="batch-size">Batch Size<a href="#batch-size" class="hash-link" aria-label="Direct link to Batch Size" title="Direct link to Batch Size">​</a></h3>
<p>This hyperparameter specifies the number of images used in each training iteration, directly affecting how often the model parameters are updated based on the gradient of the loss function.</p>
<ul>
<li>
<p><strong>Larger batch size:</strong> Provides more data per update, resulting in more stable and accurate gradient estimates. However, it requires more memory and computational resources.</p>
</li>
<li>
<p><strong>Smaller batch size:</strong> Uses less memory and computational power, allowing for faster updates. However, it introduces more noise and variance in the gradient estimates, which can lead to less stable training.</p>
</li>
</ul>
<p>The batch size can be customized with values ranging from 1 to 32, adjusted in increments of 1. Selecting the appropriate batch size involves balancing the trade-offs to optimize training efficiency and performance.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="num-epochs">Num Epochs<a href="#num-epochs" class="hash-link" aria-label="Direct link to Num Epochs" title="Direct link to Num Epochs">​</a></h3>
<p>This hyperparameter specifies the total number of epochs for training. An epoch is defined as one complete pass over the entire dataset. One epoch corresponds to a single pass through the full training dataset.</p>
<p>Increasing the number of epochs allows the model to learn from the data for a longer period, potentially leading to a more robust and accurate model. Since more epochs will result in longer training times, it’s important to monitor the model’s performance to avoid overfitting, which can occur if the model is trained for too many epochs.</p>
<p>The number of epochs can be customized with values ranging from 1 to 200, adjustable in increments of 1.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="min-samples-per-epoch">Min Samples Per Epoch<a href="#min-samples-per-epoch" class="hash-link" aria-label="Direct link to Min Samples Per Epoch" title="Direct link to Min Samples Per Epoch">​</a></h3>
<p>This hyperparameter specifies the minimum number of samples processed in one epoch during training, which is particularly useful for very small datasets. It ensures that a sufficient number of samples are processed in each epoch to provide meaningful training updates.</p>
<p>It&#x27;s essential to manage this hyperparameter carefully to prevent overfitting and maintain stable training. For very small datasets, a common approach is to repeat the dataset multiple times within an epoch, effectively increasing the number of training iterations and improving model learning without overfitting.</p>
<p>By setting an appropriate value for this hyperparameter, you can ensure effective training even with limited data, enhancing model performance and stability.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="per-item-lrate">Per Item Lrate<a href="#per-item-lrate" class="hash-link" aria-label="Direct link to Per Item Lrate" title="Direct link to Per Item Lrate">​</a></h3>
<p>This is the initial learning rate per item; it&#x27;s the rate at which the model weights are changed per item. The lrate (learning rate) is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function.</p>
<p>The overall learning rate (per step) is calculated by <code>lrate = batch_size * per_item_lrate</code>. The minimum value it supports for customization is 0.0.</p>
<p>Properly adjusting the per item learning rate allows fine-tuning of the model’s convergence speed and stability, which is essential for effective training.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pretrained-weights">Pretrained Weights<a href="#pretrained-weights" class="hash-link" aria-label="Direct link to Pretrained Weights" title="Direct link to Pretrained Weights">​</a></h3>
<p>This hyperparameter specifies whether to initialize the model with pre-trained weights. You can choose from the following options:</p>
<ul>
<li>
<p><strong>None:</strong> The model will not be initialized with weights.</p>
</li>
<li>
<p><strong>coco (default):</strong> The model will be initialized with weights pre-trained on the COCO (Common Objects in Context) dataset, which can accelerate training and improve performance by leveraging prior knowledge from a large and diverse dataset.</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="frozen-stages">Frozen Stages<a href="#frozen-stages" class="hash-link" aria-label="Direct link to Frozen Stages" title="Direct link to Frozen Stages">​</a></h3>
<p>This hyperparameter specifies which stages of the backbone network should remain frozen (i.e., their weights do not get updated) during training. Freezing certain stages can help retain pre-trained features and reduce the risk of overfitting, especially when fine-tuning a model on a new dataset.</p>
<p>You can choose to freeze between 1 and 4 stages, adjustable in increments of 1. By selecting the appropriate number of frozen stages, you can balance retaining valuable pre-trained features and adapting the model to new data.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="random-resize-lower">Random Resize Lower<a href="#random-resize-lower" class="hash-link" aria-label="Direct link to Random Resize Lower" title="Direct link to Random Resize Lower">​</a></h3>
<p>This is the lower limit for the random resizing. It means that during training, the input images will be randomly resized to a size equal to or larger than this lower limit.</p>
<p>It uses the same one or two-element format as <code>image_size</code>. And if it&#x27;s empty, it uses <code>image_size</code>. If the original image size is smaller than the lower limit, it will not be resized, and the original size will be used.</p>
<p>By setting an appropriate lower limit, you can ensure that input images are resized within a desirable range, which helps in augmenting the training data and improving model robustness.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="random-resize-upper">Random Resize Upper<a href="#random-resize-upper" class="hash-link" aria-label="Direct link to Random Resize Upper" title="Direct link to Random Resize Upper">​</a></h3>
<p>This is the upper limit for the random resizing. It means that during training, the input images will be randomly resized to a size equal to or smaller than this upper limit.</p>
<p>It uses the same one or two-element format as <code>image_size</code>. And if it&#x27;s empty, it uses <code>image_size</code>. If the original image size is already smaller than the upper limit, it will not be resized, and the original size will be used.</p>
<p>Setting an appropriate upper limit helps ensure that input images are resized within a desired range, enhancing data augmentation and contributing to more effective model training.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="load-from">Load From<a href="#load-from" class="hash-link" aria-label="Direct link to Load From" title="Direct link to Load From">​</a></h3>
<p>This hyperparameter specifies the source path from which to load a model checkpoint as a pre-trained model.</p>
<ul>
<li><strong>Empty:</strong> Leave this field empty to train a model from scratch.</li>
<li><strong>coco:</strong> Enter &quot;coco&quot; to load the pre-trained model from the COCO (Common Objects in Context) dataset.</li>
<li><strong>URL:</strong> Enter a URL to load the pre-trained model from a specified path.</li>
</ul>
<p>Using this hyperparameter, you can easily initialize your model with pre-trained weights to accelerate training and leverage existing knowledge, or opt to start training from scratch as needed.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="use-perclass-regression">Use Perclass Regression<a href="#use-perclass-regression" class="hash-link" aria-label="Direct link to Use Perclass Regression" title="Direct link to Use Perclass Regression">​</a></h3>
<p>This boolean hyperparameter determines whether to use separate coordinate regressors for each class or a single set for all classes.</p>
<ul>
<li><strong>True:</strong> Enables per-class regression, where separate box coordinate regressors are used for each class. This means that each object class has its own dedicated set of regression parameters, allowing for more tailored and potentially accurate predictions of bounding box coordinates (e.g., x, y, width, height) specific to each class.</li>
<li><strong>False:</strong> A single set of box coordinate regressors is used for all classes, which simplifies the model and reduces computational complexity.</li>
</ul>
<p>By setting this hyperparameter, you can choose between increased specificity with per-class regressors and a more streamlined model with shared regressors.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="anchor-ratios">Anchor Ratios<a href="#anchor-ratios" class="hash-link" aria-label="Direct link to Anchor Ratios" title="Direct link to Anchor Ratios">​</a></h3>
<p>These define the width (w) to height (h) ratios of anchor boxes, which are predefined bounding boxes of various shapes and sizes used as reference templates in object detection.</p>
<p>Anchor boxes help detect objects of different scales and aspect ratios in an image. The anchor ratios determine the shapes of these boxes, enabling the object detector to effectively handle objects with diverse aspect ratios.</p>
<p>By configuring anchor ratios appropriately, you can improve the object detector&#x27;s ability to accurately detect and localize objects of varying shapes and sizes within images.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="use-focal-loss">Use Focal Loss<a href="#use-focal-loss" class="hash-link" aria-label="Direct link to Use Focal Loss" title="Direct link to Use Focal Loss">​</a></h3>
<p>This boolean parameter specifies whether to use focal loss or Online Hard Example Mining (OHEM) during training.</p>
<ul>
<li>
<p><strong>Focal Loss (True):</strong> Focal loss is a modification of the standard cross-entropy loss that addresses class imbalance by introducing a modulating factor. This factor downweights the contribution of easy examples and focuses more on hard examples, improving the training of imbalanced datasets by giving more importance to challenging samples.</p>
</li>
<li>
<p><strong>OHEM (False):</strong> Online Hard Example Mining (OHEM) is a technique that also addresses class imbalance. Instead of using all samples in a batch, OHEM selects the hardest examples (those with the highest loss) for backpropagation. This focuses the training on difficult samples, enhancing learning efficiency and effectiveness, especially when dealing with many easy background samples.</p>
</li>
</ul>
<p>By setting this hyperparameter, you can choose between focal loss and OHEM to handle class imbalance, focusing training efforts on more challenging and informative examples.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pretrain-base-data">Pretrain Base Data<a href="#pretrain-base-data" class="hash-link" aria-label="Direct link to Pretrain Base Data" title="Direct link to Pretrain Base Data">​</a></h3>
<p>This hyperparameter specifies the pre-initialization weights for the base model. For instance, &quot;mscoco&quot; refers to using weights pre-trained on the Microsoft COCO dataset.</p>
<p>This setting allows you to initialize your model with weights trained on a large and diverse dataset, leveraging learned features and accelerating training on your specific task or dataset.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="base-model">Base Model<a href="#base-model" class="hash-link" aria-label="Direct link to Base Model" title="Direct link to Base Model">​</a></h3>
<p>This refers to the foundational architecture used for the detector. Pre-trained architectures enable transfer learning, where models trained on large datasets can be fine-tuned for specific tasks with smaller datasets, saving time and resources.</p>
<p>Choosing the appropriate base model architecture is crucial as it forms the backbone of your detector, determining its overall performance, speed, and capability to handle various tasks.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="continue-from-eid">Continue From Eid<a href="#continue-from-eid" class="hash-link" aria-label="Direct link to Continue From Eid" title="Direct link to Continue From Eid">​</a></h3>
<p>If specified, this parameter initializes the model with weights from a checkpoint identified by the Eid (Experiment ID).</p>
<p>This allows you to resume training or initialize a model with specific weights stored in a checkpoint corresponding to a particular experiment ID (Eid).</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/create/models/templates/visual-classification"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Visual Classification Templates</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/create/models/templates/visual-embedding"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Visual Embedding Templates</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#mmdetection-templates" class="table-of-contents__link toc-highlight">MMDetection Templates</a><ul><li><a href="#mmdetection_yolox" class="table-of-contents__link toc-highlight">MMDetection_YOLOX</a></li><li><a href="#mmdetection_yolof" class="table-of-contents__link toc-highlight">MMDetection_YOLOF</a></li><li><a href="#mmdetection_ssd" class="table-of-contents__link toc-highlight">MMDetection_SSD</a></li><li><a href="#mmdetection_fasterrcnn" class="table-of-contents__link toc-highlight">MMDetection_FasterRCNN</a></li><li><a href="#mmdetection_advancedconfig" class="table-of-contents__link toc-highlight">MMDetection_AdvancedConfig</a></li></ul></li><li><a href="#clarifai-templates" class="table-of-contents__link toc-highlight">Clarifai Templates</a><ul><li><a href="#clarifai_inceptionv4" class="table-of-contents__link toc-highlight">Clarifai_InceptionV4</a></li><li><a href="#clarifai_inceptionv2" class="table-of-contents__link toc-highlight">Clarifai_InceptionV2</a></li></ul></li><li><a href="#other-templates" class="table-of-contents__link toc-highlight">Other Templates</a><ul><li><a href="#detection_msc10" class="table-of-contents__link toc-highlight">Detection_MSC10</a></li></ul></li><li><a href="#hyperparameters" class="table-of-contents__link toc-highlight">Hyperparameters</a><ul><li><a href="#image-size" class="table-of-contents__link toc-highlight">Image Size</a></li><li><a href="#max-aspect-ratio" class="table-of-contents__link toc-highlight">Max Aspect Ratio</a></li><li><a href="#keep-aspect-ratio" class="table-of-contents__link toc-highlight">Keep Aspect Ratio</a></li><li><a href="#batch-size" class="table-of-contents__link toc-highlight">Batch Size</a></li><li><a href="#num-epochs" class="table-of-contents__link toc-highlight">Num Epochs</a></li><li><a href="#min-samples-per-epoch" class="table-of-contents__link toc-highlight">Min Samples Per Epoch</a></li><li><a href="#per-item-lrate" class="table-of-contents__link toc-highlight">Per Item Lrate</a></li><li><a href="#pretrained-weights" class="table-of-contents__link toc-highlight">Pretrained Weights</a></li><li><a href="#frozen-stages" class="table-of-contents__link toc-highlight">Frozen Stages</a></li><li><a href="#random-resize-lower" class="table-of-contents__link toc-highlight">Random Resize Lower</a></li><li><a href="#random-resize-upper" class="table-of-contents__link toc-highlight">Random Resize Upper</a></li><li><a href="#load-from" class="table-of-contents__link toc-highlight">Load From</a></li><li><a href="#use-perclass-regression" class="table-of-contents__link toc-highlight">Use Perclass Regression</a></li><li><a href="#anchor-ratios" class="table-of-contents__link toc-highlight">Anchor Ratios</a></li><li><a href="#use-focal-loss" class="table-of-contents__link toc-highlight">Use Focal Loss</a></li><li><a href="#pretrain-base-data" class="table-of-contents__link toc-highlight">Pretrain Base Data</a></li><li><a href="#base-model" class="table-of-contents__link toc-highlight">Base Model</a></li><li><a href="#continue-from-eid" class="table-of-contents__link toc-highlight">Continue From Eid</a></li></ul></li></ul></div></div></div><div class="custom_doc_item_footer_LMqZ"><div class="banner-primary"><p>Build your next AI app, test and tune popular LLMs models, and much more.</p><a href="https://clarifai.com/explore" target="_blank">Get started for free</a></div><footer class="custom-footer-wrapper_fHnE"><div class="logo-wrapper_GEfd"><img src="/img/logos/clarifai-color-light-logo.svg" class="dark-theme-logo_tdev"><img src="/img/logos/clarifai-color-dark-logo.svg" class="light-theme-logo_cRqu"></div><div class="copyright_aTku">© 2025 Clarifai, Inc. All rights reserved</div><div class="footerSocialIconsWrapper_tJhP"><div class="socialBrands__tjK"><a href="https://github.com/Clarifai" target="_blank" rel="noopener noreferrer" aria-label="Github"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#000" fill-rule="evenodd" d="M9.7 1.5C4.896 1.5 1 5.401 1 10.216a8.715 8.715 0 0 0 5.95 8.269c.436.08.594-.189.594-.42 0-.207-.007-.756-.011-1.482-2.421.526-2.932-1.169-2.932-1.169-.395-1.007-.966-1.275-.966-1.275-.79-.54.06-.53.06-.53.873.062 1.333.899 1.333.899.776 1.33 2.036.946 2.532.724.08-.563.304-.947.553-1.165C6.18 13.847 4.15 13.1 4.15 9.76c0-.951.339-1.73.895-2.34-.09-.22-.388-1.106.085-2.305 0 0 .731-.235 2.393.893a8.3 8.3 0 0 1 2.178-.293c.74.003 1.483.1 2.178.293 1.662-1.128 2.39-.894 2.39-.894.476 1.2.176 2.087.088 2.307a3.37 3.37 0 0 1 .894 2.339c0 3.348-2.035 4.085-3.973 4.3.313.27.59.8.59 1.614 0 1.165-.01 2.105-.01 2.39 0 .234.156.505.598.42a8.72 8.72 0 0 0 5.946-8.268C18.402 5.4 14.505 1.5 9.7 1.5" clip-rule="evenodd"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://twitter.com/clarifai" target="_blank" rel="noopener noreferrer" aria-label="Twitter"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#000" d="M14.6 3h2.454l-5.36 6.142L18 17.5h-4.937l-3.867-5.07-4.425 5.07H2.316l5.733-6.57L2 3h5.063l3.495 4.633zm-.86 13.028h1.36L6.323 4.395H4.865z"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://discord.gg/WgUvPK4pVD" target="_blank" rel="noopener noreferrer" aria-label="Discord"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><path fill="#7289DA" d="M13.63 15.997c.514.65 1.13 1.387 1.13 1.387 3.784-.12 5.24-2.603 5.24-2.603 0-5.514-2.466-9.983-2.466-9.983C15.07 2.948 12.723 3 12.723 3l-.24.274c2.91.89 4.264 2.175 4.264 2.175a14 14 0 0 0-5.155-1.644 14.5 14.5 0 0 0-3.458.034c-.103 0-.189.017-.292.034-.599.052-2.054.274-3.887 1.08-.633.29-1.01.496-1.01.496S4.366 4.096 7.45 3.206L7.277 3S4.932 2.95 2.466 4.798c0 0-2.466 4.47-2.466 9.983 0 0 1.438 2.483 5.223 2.603 0 0 .633-.77 1.147-1.421-2.175-.651-2.997-2.021-2.997-2.021s.172.12.48.291c.017.017.034.034.068.051.052.035.103.052.154.086.428.24.857.428 1.25.582.702.274 1.541.548 2.517.736 1.285.24 2.792.326 4.435.018a11.3 11.3 0 0 0 2.483-.737 9.8 9.8 0 0 0 1.97-1.01s-.857 1.404-3.1 2.038"></path><path fill="#fff" d="M6.884 9.147c-.976 0-1.746.857-1.746 1.901s.787 1.9 1.746 1.9c.976 0 1.747-.855 1.747-1.9.017-1.044-.77-1.9-1.747-1.9m6.25 0c-.976 0-1.746.857-1.746 1.901s.787 1.9 1.746 1.9c.976 0 1.747-.855 1.747-1.9s-.77-1.9-1.747-1.9"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://www.youtube.com/@theworldsai" target="_blank" rel="noopener noreferrer" aria-label="Youtube"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="20" preserveAspectRatio="xMidYMid" viewBox="0 0 256 180"><path fill="red" d="M250.346 28.075A32.18 32.18 0 0 0 227.69 5.418C207.824 0 127.87 0 127.87 0S47.912.164 28.046 5.582A32.18 32.18 0 0 0 5.39 28.24c-6.009 35.298-8.34 89.084.165 122.97a32.18 32.18 0 0 0 22.656 22.657c19.866 5.418 99.822 5.418 99.822 5.418s79.955 0 99.82-5.418a32.18 32.18 0 0 0 22.657-22.657c6.338-35.348 8.291-89.1-.164-123.134Z"></path><path fill="#FFF" d="m102.421 128.06 66.328-38.418-66.328-38.418z"></path></svg></a></div><div class="socialBrands__tjK"><a href="https://www.linkedin.com/company/clarifai" target="_blank" rel="noopener noreferrer" aria-label="Linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="none" viewBox="0 0 20 20"><g clip-path="url(#a)"><path fill="#0A66C2" d="M16.819 2H3.18A1.18 1.18 0 0 0 2 3.181V16.82A1.18 1.18 0 0 0 3.181 18H16.82A1.18 1.18 0 0 0 18 16.819V3.18A1.18 1.18 0 0 0 16.819 2M6.769 15.63H4.363V7.989H6.77zm-1.205-8.7a1.381 1.381 0 1 1 1.39-1.38 1.36 1.36 0 0 1-1.39 1.38m10.072 8.707H13.23v-4.175c0-1.23-.523-1.61-1.199-1.61-.713 0-1.413.537-1.413 1.641v4.144H8.213V7.994h2.314v1.06h.03c.233-.47 1.046-1.274 2.287-1.274 1.343 0 2.793.797 2.793 3.13z"></path></g><defs><clipPath id="a"><path fill="#fff" d="M2 2h16v16H2z"></path></clipPath></defs></svg></a></div></div></footer></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://clarifai.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Clarifai Website<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://join.slack.com/t/clarifaicommunity/shared_invite/zt-1jehqesme-l60djcd3c_4a1eCV~uPUjQ" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/company/clarifai" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.facebook.com/Clarifai/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Facebook<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Clarifai, Inc.</div></div></div></footer></div>
</body>
</html>